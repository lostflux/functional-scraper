Close Search Skip to main content Site Navigation Research Overview Index GPT-4 DALL·E 3 API Overview Data privacy Pricing Docs ChatGPT Overview Enterprise Try ChatGPT Safety Company About Blog Careers Residency Charter Security Customer stories Search Navigation quick links Log in Try ChatGPT Menu Mobile Navigation Close Site Navigation Research Overview Index GPT-4 DALL·E 3 API Overview Data privacy Pricing Docs ChatGPT Overview Enterprise Try ChatGPT Safety Company About Blog Careers Residency Charter Security Customer stories Quick Links Log in Try ChatGPT Search Pioneering research on the path to AGI Quick links View research index Learn about safety Safely aligning powerful AI systems is one of the most important unsolved problems for our mission. Techniques like learning from human feedback are helping us get closer, and we are actively researching new techniques to help us fill the gaps.
Josh Achiam Researcher at OpenAI Focus areas Text Aligning language models to follow instructions We’ve trained language models that are much better at following user intentions than GPT-3.
Summarizing books with human feedback We've trained a model to summarize entire books with human feedback.
Language models are few-shot learners We trained GPT-3, an autoregressive language model with 175 billion parameters.
Image Hierarchical text-conditional image generation with CLIP latents We show that explicitly generating image representations improves image diversity with minimal loss in photorealism and caption similarity.
DALL·E: Creating images from text We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of concepts expressible in natural language.
CLIP: Connecting text and images We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language supervision.
Audio Introducing Whisper We’ve trained and are open-sourcing a neural net that approaches human level robustness and accuracy on English speech recognition.
Jukebox We’re introducing Jukebox, a neural net that generates music as raw audio in a variety of genres and artist styles.
MuseNet We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different instruments.
Past highlights Our current AI research builds upon a wealth of previous projects and advances.
View all research Image GPT Jun 17, 2020 June 17, 2020 Solving Rubik’s Cube with a robot hand Oct 15, 2019 October 15, 2019 Emergent tool use from multi-agent interaction Sep 17, 2019 September 17, 2019 Featured roles View all careers Research Program Manager, Basic Research San Francisco, California, United States — Algorithms Apply now AI Policy Counsel San Francisco, California, United States — Legal Apply now Senior Manager, Strategic Sourcing (Non-Technology) San Francisco, California, United States — Finance Apply now Model Teacher (Contract) Remote or San Francisco HQ — Research, Engineering, Product Apply now Senior AI Product Counsel San Francisco, California, United States — Legal Apply now Research Overview Index GPT-4 DALL·E 3 API Overview Data privacy Pricing Docs ChatGPT Overview Enterprise Try ChatGPT Company About Blog Careers Charter Security Customer stories Safety OpenAI © 2015 – 2023 Terms & policies Privacy policy Brand guidelines Social Twitter YouTube GitHub SoundCloud LinkedIn Back to top
