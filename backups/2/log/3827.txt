Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Vittoria Elliott Business Twitter Really Is Worse Than Ever Photograph: Jordan Lye/Getty Images Save this story Save Save this story Save A year ago, Elon Musk announced that he wanted to buy Twitter to clear it of bots and turn â€œthe de facto public town squareâ€ into a place for unfettered free speech. Social media experts worried that would mean the platform would stop moderating what users post, and warned that the consequence of Muskâ€™s stated absolutism would be that the platform would be overrun with violent and hateful content. It turns out they were right.
After he took over the platform, Musk insisted that â€œTwitterâ€™s strong commitment to content moderation remains absolutely unchanged.â€ But around the same time, Twitter fired most of its trust and safety staff, the team responsible for keeping content that violates the companyâ€™s policies off the platform.
The result, perhaps unsurprisingly, was that hate speech on Twitter surged â€œdramaticallyâ€ in the weeks following the takeover, according to a new study from the University of Southern Californiaâ€™s Information Sciences Institute, Oregon State University, UCLA, and UC Merced, which also found that there had been no decrease in the number of bots on the platform. It is yet another data point in a series of changes that have taken Twitter from being a global public square to a platform where racists, bigots, and propagandists are more empowered than ever.
â€œA few months ago it was the first place you looked for insight,â€ says Imran Ahmed, CEO of the Center for Countering Digital Hate (CCDH), a nonprofit that tracks disinformation. â€œIt was always about finding communities of mutual interest and seeing what the most interesting people around the world were saying about things and what the news was. And that is just destroyed.â€ Twitter did not respond to a request for comment about its moderation practices since Muskâ€™s takeover or what systems it has in place.
Researchers found that the increase in hateful content began almost immediately after Muskâ€™s takeover as users began to test the boundaries of what would get past Twitterâ€™s new moderation regime.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œThe day that [Musk] officially took over the platform, a lot of right-wing figures had started tweeting anti-LGBTQ rhetoric, specifically the term â€˜groomer,â€™â€ says Kayla Gogarty, research director at Media Matters for America, a media watchdog group, referring to the conspiracy theory that LGBTQ people prey on younger people by â€œgroomingâ€ them. â€œ[These accounts] were basically saying that they were testing the watersâ€ of Twitterâ€™s content moderation, she says.
Twitterâ€™s policies do not allow slurs and tropes that â€œintend to degrade or reinforce negative or harmful stereotypes about a protected category.â€ â€œThere seems to have been a clear indication that people anticipated that Musk would reduce moderation,â€ says Keith Burghardt, a computer scientist at USCâ€™s Information Sciences Institute and one of the co-authors of the paper. â€œBut itâ€™s clear that hate speech didnâ€™t decline immediately after Elon Musk bought Twitter, suggesting that whatever moderation he did was not enough.â€ Even before it reduced the size of its moderation teams, Twitter wasnâ€™t particularly quick to remove hateful content, according to Tal-Or Cohen Montemayor, founder and executive director of CyberWell, a nonprofit that tracks anti-Semitism online in both English and Arabic.
Data collected by CyberWell found that though only 2 percent of anti-Semitism content on social media platforms in 2022 was violent, 90 percent of that came from Twitter. And Cohen Montemayor notes that even the companyâ€™s standard moderation systems would likely have struggled under the strain of so much hateful content. â€œIf youâ€™re experiencing surges [of online hate speech] and you have changed nothing in the infrastructure of content moderation, that means youâ€™re leaving more hate speech on the platform,â€ she says.
Civil society organizations that used to have a direct line to Twitterâ€™s moderation and policy teams have struggled to raise their concerns, says Isedua Oribhabor, business and human rights lead at Access Now. â€œWe've seen failure in those respects of the platform to actually moderate properly and to provide the services in the way that it used to for its users,â€ she says.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker Daniel Hickey, a visiting scholar at the USCâ€™s Information Sciences Institute and coauthor of the paper, says that Twitterâ€™s lack of transparency makes it hard to assess whether there was simply more hate speech on the platform, or whether the company made substantive changes to its policies after Muskâ€™s takeover. â€œIt is quite difficult to disentangle often because Twitter is not going to be fully transparent about these types of things,â€ he says.
That lack of transparency is likely to get worse. Twitter announced in February that it would no longer allow free access to its APâ€”the tool that allows academics and researchers to download and interact with the platformâ€™s data. â€œFor researchers who want to get a more extended view of how hate speech is changing, as Elon Musk is leading the company for longer and longer, that is certainly much more difficult now,â€ says Hickey.
In the months since Musk took over Twitter, major public news outlets like National Public Radio, Canadian Broadcasting Company, and other public media outlets have left the platform after being labeled as â€œstate-sponsored,â€ a designation that was formerly only used for Russian, Chinese, and Iranian state media. Yesterday, Musk reportedly threatened to reassign NPRâ€™s Twitter handle.
Meanwhile, actual state-sponsored media appears to be thriving on Twitter. An April report from the Atlantic Councilâ€™s Digital Forensic Research Lab found that, after Twitter stopped suppressing these accounts, they gained tens of thousands of new followers.
In December, accounts that had been previously banned were allowed back on the platform, including right-wing academic Jordan Peterson and prominent misogynist Andrew Tate, who was later arrested in Romania for human trafficking. Liz Crokin, a proponent of the QAnon and Pizzagate conspiracy theories, was also reinstated under Muskâ€™s leadership. On March 16 , Crokin allegedâ€”falselyâ€”in a Tweet that talk show host Jimmy Kimmel tweet had featured a pedophile symbol in a skit on his show.
Recent changes to Twitterâ€™s verification system, Twitter Blue, where users can pay to get blue check marks and more prominence on the platform, has also contributed to the chaos. In November, a tweet from a fake account pretending to be corporate giant Eli Lilly announced that insulin was free. The tweet caused the companyâ€™s stock to dip almost 5 percent. But Ahmed says the implications for the pay-to-play verification are much starker.
â€œOur analysis showed that Twitter Blue was being weaponized, particularly being taken up by people who were spreading disinformation,â€ says CCDHâ€™s Ahmed. â€œScientists, journalists theyâ€™re finding themselves in an incredibly hostile environment in which their information is not achieving the reach that is enjoyed by bad actors spreading disinformation and hate.â€ Despite Twitterâ€™s protestations, says Ahmed, the study validates what many civil society organizations have been saying for months. â€œTwitterâ€™s strategy in response to all this massive data from different organizations showing that things were getting worse was to gaslight us and say, â€˜No, weâ€™ve got data that shows the opposite.â€™â€ You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Platforms and power reporter Topics twitter content moderation Elon Musk hate speech Matt Burgess Joel Khalili Reece Rogers Joel Khalili Will Knight Joel Khalili Morgan Meaker Eliza Gkritsi Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
