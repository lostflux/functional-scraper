Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Sidney Fussell Business This Film Examines the Biases in the Code That Runs Our Lives Shalini Kantayya says she didn't set out to make a film focusing on women.
Photograph: Omar Mullick/7th Empire Media Save this story Save Save this story Save Application Content moderation Ethics Face recognition Human-computer interaction End User Research Sector Research Source Data Images Technology Machine learning Machine vision Shalini Kantayya is the documentary filmmaker behind the recent films Catching the Sun and Coded Bias , which premiered this month online.
Coded Bias follows MIT researcher Joy Buolamwini as she investigates and combats the racial disparities of facial recognition for people of color, in both impact and accuracy. As it follows Buolamwini from MIT to her testimony on Capitol Hill, the film looks at the ubiquitous, but overlooked impact of algorithms on our daily lives, from policing to housing to education and shopping. Days after the film‚Äôs premiere, WIRED spoke with Kantayya about the documentary, sci-fi, and Big Tech's grasping control of our lives. An edited transcript follows.
WIRED: People hear phrases like machine learning , artificial intelligence , recommender systems, and it's overwhelming. How did you get interested in this field, and how did you acclimate yourself to it, given that two or three years ago, when you started, there was a lot less digestible scholarship? Shalini Kantayya: I stumbled upon the work of Joy Buolamwini through a TED talk and read Cathy O'Neil's book Weapons of Math Destruction , and just fell down a rabbit hole of the dark side of artificial intelligence.
I couldn't talk to people for two years at parties because I was so worried people would ask me about what I was working on. I think the working title at the time was Racist Robots , and it was really hard to explain. As someone who doesn't have advanced degrees in data science, I had this fear of improperly explaining ideas like algorithms or artificial intelligence or machine learning. But I think what enabled me to get over my fear was just asking a lot of questions. And I came to see that artificial intelligence is going to transform every sector of society and touch every civil right we enjoy.
I read this incredible body of research by women who help translate the subject matter. All of them are incredibly astute, some of the smartest people I've ever met. I think there are seven PhDs in the film. They have advanced degrees, but they also are women or people of color or LGBTQ or had some experience of being marginalized that allowed them to have this very unique perspective on technology. It allows them to see technology from the perspective of those for whom it could fail.
Talk about the decision to make it a female-led film. It‚Äôs very rare to see such a technical film led by women as subjects, experts, as centering the film and not being singled out.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker When I first started making the film, I actually didn't plan to make the film so predominantly led by women. But my research just kept leading me back to all these incredibly brilliant and badass women.
"My research just kept leading me back to all these incredibly brilliant and badass women." What I came to learn is that the people who are leading the data, the scientists and mathematicians and journalists and activists who are leading the fight for ethics and more humane uses of artificial intelligence, are actually women, people of color, and LGBTQ.
And so what I came to see is that there was this canon inside of tech that was not being heard. The role of women and feminism as a force for change within Silicon Valley has been long underestimated.
In the making of this film, I learned that there's always been this connection between artists and science fiction writers and technological developers. Because artificial intelligence has been developed by people who are mostly white, mostly male, mostly from elite educational backgrounds, there's been this startling lack of imagination in the technologies of the future.
And I think that the cast of this film just made me see that there are other ways that artificial intelligence can work than this kind of surveillance capitalism model that we have come to see as the only way.
What were some of the biggest roadblocks to finishing the film? What can you tell me about the process in bringing it all together? I feel like there was no road map for me. There were no other films that I know of that are about bias and artificial intelligence in this particular way.
By Tom Simonite And so for me, I was really looking at this scholarship for breadcrumbs. And then it was a task to try to find the stories of people who had been harmed by algorithmic bias but fought back. And that was a challenge, because so many times these systems are so opaque to us that sometimes we don't even know when we've been denied an opportunity because of an algorithm.
And so I am trying to meld these stories together. I think it would have been much easier to make a film about just facial recognition. Facial recognition is the easiest to understand, because it's so visceral. But I think it was important to show the pervasiveness of these algorithms that are making decisions that are shifting human destinies.
It‚Äôs interesting how the film talks about emerging technologies and different algorithms. It‚Äôs very different from films like The Great Hack or The Social Dilemma.
 Those really zoom in on specific companies like Google or Facebook , but Coded Bias doesn‚Äôt lay the blame on individual companies.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The first inspiration or spark to tell a story is always a compelling character. And I knew that I had a compelling character in Joy Buolamwini, enjoyable and witty. I'm of the belief that people don't care about issues. They care about people. And Joy has such integrity as a scientist and can challenge power in many ways.
We often talk about the fear of not knowing. Knowledge is power. So she has that power, but then she also is connecting it to the marginalized.
"These systems are so opaque to us that sometimes we don't even know when we've been denied an opportunity because of an algorithm." I think it was only when she went to Capitol Hill to testify that I knew I had the structure of a film. I just knew that there was a character up there. There was a story. There was a person who went on a journey. And so the backbone is that character-driven story.
And then for me, it was about making the science palatable. It was challenging to take subject matter that was so abstract and to try to make it visual, even cinematic. I really draw from the tropes of American science fiction. I think that everything that I knew about AI prior to starting this project came from Stanley Kubrick and Steven Spielberg.
But the film isn‚Äôt that abstract, it also is more literal in places, like with people who were dealing with racist or oppressive algorithms. You feature Tranae Moran, who campaigned against her landlord's installation of facial recognition at her complex, and Daniel Santos, a Houston teacher fired after failing an evaluation by algorithm.
Right. I make documentaries in part because you get to make a hero out of everyday people. It gets to shine a light on the fact that everyday people are heroes.
I have this incredible gratitude for the stories of Daniel and for Tranae, who didn't even know what biometric data was and not only fought back, but changed legislation. And Daniel, he lays out all his teaching awards, and you see the look on his face when he talks about being dehumanized by the system.
I think we are in a moment in history where we're all being asked to lead from a deeper place in our humanity. And when you see someone as inspiring as Daniel or Tranae, you realize how really wrong this technology can be and how unfair it is.
I think a lot of times we talk about tech as if it's like magic or God. And when you pull back the curtain, what I realized is that technology is just a reflection of ourselves. Because these technologies impact all of us, we all should have some sort of voice in how they get deployed. We should move toward technology that values the inherent value of every person.
This article has been updated to include a more recent photograph of Kantayya.
üì© Want the latest on tech, science, and more? Sign up for our newsletters ! The scammer who wanted to save his country I fostered a one-eyed goblin.
She changed my life in lockdown The history of poop is really the history of technology Going solar: My year-long quest to get off the grid ‚ÄúProning‚Äù Covid patients seems to save lives.
But how many ? üéÆ WIRED Games: Get the latest tips, reviews, and more ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Senior Writer X Topics diversity artificial intelligence face recognition machine learning Steven Levy Will Knight Steven Levy Gregory Barber Niamh Rowe Will Knight Khari Johnson Steven Levy Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
