Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Lily Hay Newman Security AI Wrote Better Phishing Emails Than Humans in a Recent Test More people clicked the links in the AI-generated messages than the human-written ones‚Äîby a significant margin.
Photograph: MirageC/Getty Images Save this story Save Save this story Save Application Deepfakes Identifying Fabrications Text generation Company Open AI Source Data Text Technology Machine learning Natural language processing Natural language processing continues to find its way into unexpected corners.
 This time, it's phishing emails.
 In a small study, researchers found that they could use the deep learning language model GPT-3, along with other AI-as-a-service platforms, to significantly lower the barrier to entry for crafting spearphishing campaigns at a massive scale.
Researchers have long debated whether it would be worth the effort for scammers to train machine learning algorithms that could then generate compelling phishing messages. Mass phishing messages are simple and formulaic, after all, and are already highly effective. Highly targeted and tailored ‚Äúspearphishing‚Äù messages are more labor intensive to compose, though. That's where NLP may come in surprisingly handy.
At the Black Hat and Defcon security conferences in Las Vegas this week, a team from Singapore's Government Technology Agency presented a recent experiment in which they sent targeted phishing emails they crafted themselves and others generated by an AI-as-a-service platform to 200 of their colleagues. Both messages contained links that were not actually malicious but simply reported back clickthrough rates to the researchers. They were surprised to find that more people clicked the links in the AI-generated messages than the human-written ones‚Äîby a significant margin.
‚ÄúResearchers have pointed out that AI requires some level of expertise. It takes millions of dollars to train a really good model,‚Äù says Eugene Lim, a Government Technology Agency cybersecurity specialist. ‚ÄúBut once you put it on AI-as-a-service it costs a couple of cents and it‚Äôs really easy to use‚Äîjust text in, text out. You don‚Äôt even have to run code, you just give it a prompt and it will give you output. So that lowers the barrier of entry to a much bigger audience and increases the potential targets for spearphishing. Suddenly every single email on a mass scale can be personalized for each recipient.‚Äù The researchers used OpenAI's GPT-3 platform in conjunction with other AI-as-a-service products focused on personality analysis to generate phishing emails tailored to their colleagues' backgrounds and traits. Machine learning focused on personality analysis aims to be predict a person's proclivities and mentality based on behavioral inputs. By running the outputs through multiple services, the researchers were able to develop a pipeline that groomed and refined the emails before sending them out. They say that the results sounded ‚Äúweirdly human‚Äù and that the platforms automatically supplied surprising specifics, like mentioning a Singaporean law when instructed to generate content for people living in Singapore.
While they were impressed by the quality of the synthetic messages and how many clicks they garnered from colleagues versus the human-composed ones, the researchers note that the experiment was just a first step. The sample size was relatively small and the target pool was fairly homogenous in terms of employment and geographic region. Plus, both the human-generated messages and those generated by the AI-as-a-service pipeline were created by office insiders rather than outside attackers trying to strike the right tone from afar.
Gear 13 Best Deals at Target‚Äôs Black Friday Sale Medea Giordano Science The First Crispr Medicine Just Got Approved Emily Mullin Buying Guides The Best Binoculars to Zoom In on Real Life Scott Gilbertson Culture Assassin‚Äôs Creed Nexus VR Makes the Case for Immersive Gaming‚ÄîFinally Matt Kamen ‚ÄúThere are lots of variables to account for,‚Äù says Tan Kee Hock, a Government Technology Agency cybersecurity specialist.
Still, the findings spurred the researchers to think more deeply about how AI-as-a-service may play a role in phishing and spearphishing campaigns moving forward. OpenAI itself, for example, has long feared the potential for misuse of its own service or other similar ones. The researchers note that it and other scrupulous AI-as-a-service providers have clear codes of conduct, attempt to audit their platforms for potentially malicious activity, or even try to verify user identities to some degree.
‚ÄúMisuse of language models is an industry-wide issue that we take very seriously as part of our commitment to the safe and responsible deployment of AI,‚Äù OpenAI told WIRED in a statement. ‚ÄúWe grant access to GPT-3 through our API, and we review every production use of GPT-3 before it goes live. We impose technical measures, such as rate limits, to reduce the likelihood and impact of malicious use by API users. Our active monitoring systems and audits are designed to surface potential evidence of misuse at the earliest possible stage, and we are continually working to improve the accuracy and effectiveness of our safety tools.‚Äù OpenAI does its own studies on anti-abuse measures and the Government Technology Agency researchers notified the company about their work.
The researchers emphasize, though, that in practice there's a tension between monitoring these services for potential abuse and conducting invasive surveillance on legitimate platform users. And what's even more complicated is that not all AI-as-a-service providers care about reducing abusive uses of their platforms. Some may ultimately even cater to scammers.
‚ÄúReally what surprised us was how easy it is to get access to these AI APIs," Lim says. ‚ÄúSome like OpenAI are very strict and stringent, but other providers offer free trials, don‚Äôt verify your email address, don‚Äôt ask for a credit card. You could just keep using new free trials and churning out content. It's a technically advanced resource that actors can get access to easily.‚Äù AI governance frameworks like those in development by the Singaporean government and European Union could aid businesses in addressing abuse, the researchers say. But they also focused a portion of their research on tools that could potentially detect synthetic or AI-generated phishing emails‚Äîa challenging topic that has also gained attention as deepfakes and AI-generated fake news proliferate. The researchers again used deep learning language models like OpenAI's GPT-3 to develop a framework that can differentiate AI generated text from that composed by humans. The idea is to build mechanisms that can flag synthetic media in emails to make it easier to catch possible AI-generated phishing messages.
Gear 13 Best Deals at Target‚Äôs Black Friday Sale Medea Giordano Science The First Crispr Medicine Just Got Approved Emily Mullin Buying Guides The Best Binoculars to Zoom In on Real Life Scott Gilbertson Culture Assassin‚Äôs Creed Nexus VR Makes the Case for Immersive Gaming‚ÄîFinally Matt Kamen The researchers note, though, that as synthetic media is used for more and more legitimate functions, like customer service communications and marketing, it will be even more difficult to develop screening tools that flag only phishing messages.
‚ÄúPhishing email detection is important, but also just generally be prepared for messages that are coming that may be extremely appealing and then also convincing,‚Äù Government Technology Agency cybersecurity specialist Glenice Tan says. ‚ÄúThere's still a role for security training. Be careful and remain skeptical. Unfortunately, those are still important things.‚Äù And as Government Technology Agency researcher Timothy Lee puts it, the impressive human mimicry of AI-generated phishing emails means that for potential victims the challenge is still the same as the stakes grow ever higher.
‚ÄúThey still only need to get it right once, it doesn‚Äôt matter if you receive thousands of phishing messages written all different ways," Lee says. "Just one that caught you off guard‚Äîand boom!‚Äù üì© The latest on tech, science, and more: Get our newsletters ! When the next animal plague hits, can this lab stop it? What rat empathy may reveal about human compassion Struggling to recruit, police turn to targeted ads These games taught me to love the freemium grind A guide to RCS , and why it makes texting so much better üëÅÔ∏è Explore AI like never before with our new database üéÆ WIRED Games: Get the latest tips, reviews, and more üì± Torn between the latest phones? Never fear‚Äîcheck out our iPhone buying guide and favorite Android phones Senior Writer X Topics machine learning phishing artificial intelligence cybersecurity Lily Hay Newman Lily Hay Newman Matt Burgess Andy Greenberg David Gilbert Lily Hay Newman Andy Greenberg Reece Rogers Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
