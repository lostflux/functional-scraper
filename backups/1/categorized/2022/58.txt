People Trust Deepfake Faces Generated by AI More Than Real Ones, Study Finds
2022
https://singularityhub.com/2022/02/21/people-trust-deepfake-faces-more-than-real-ones-study-finds

Topics AI Biotech Computing Space Energy Future Tech Robotics Science Experts Featured Experts Perspectives Books Events Videos Latest Series Interviews About Singularity About Programs Membership Experts Community Careers Subscribe Welcome! Search.
News and Insights from Singularity Group Search Subscribe to our newsletter Singularity Group Singularity Community Facebook Instagram Twitter Youtube.
st0{fill:#FFFFFF;} .st1{fill:url(#SVGID_1_);} Singularity Hub News and Insights from Singularity Group Topics Experts Events Videos Search singularity group singularity community Facebook Instagram Twitter Youtube.
st0{fill:#FFFFFF;} .st1{fill:url(#SVGID_1_);} Singularity Hub News and Insights from Singularity Group Topics Experts Events Videos Search People Trust Deepfake Faces Generated by AI More Than Real Ones, Study Finds By The proliferation of deepfake technology is raising concerns that AI could start to warp our sense of shared reality. New research suggests AI-synthesized faces don’t simply dupe us into thinking they’re real people, we actually trust them more than our fellow humans.
In 2018, Nvidia wowed the world with an AI that could churn out ultra-realistic photos of people that don’t exist. Its researchers relied on a type of algorithm known as a generative adversarial network (GAN), which pit s two neural networks against each other, one trying to spot fakes and the other trying to generate more convincing ones. Given enough time, GANS can generate remarkably good counterfeits.
Since then, capabilities have improved considerably, with some worrying implications: enabling scammers to trick people , making it possible to splice people into porn movies without their consent, and undermining trust in online media. While it’s possible to use AI itself to spot deepfakes, tech companies’ failures to effectively moderate much less complicated material suggests this won’t be a silver bullet.
That means the more pertinent question is whether humans can spot the difference, and more importantly how they relate to deepfakes. The results from a new study in PNAS are not promising—researchers found that peoples’ ability to detect fakes was no better than a random guess, and they actually rated the made-up faces as more trustworthy than the real ones.
“ Our evaluation of the photorealism of AI-synthesized faces indicates that synthesis engines have passed through the uncanny valley and are capable of creating faces that are indistinguishable—and more trustworthy—than real faces,” the authors wr o te.
To test reactions to fake faces, the researchers used an updated version of Nvidia’s GAN to generate 400 of them , with an equal gender split and 100 faces each from four ethnic groups: Black, Caucasian, East Asian, and South Asian. They matched each of these with real face s pulled from the database that was originally used to train the GAN, which had been judged to be similar by a different neural network.
They then recruited 315 participants from the Amazon Mechanical Turk crowdsourcing platform. Each person was asked to judge 128 faces from the combined dataset and decide if they were fake or not. They achieved an accuracy rate of just 48 percent, actually worse than the 50 percent you should get from a random guess.
Deepfakes often have characteristic defects and glitches that can help people single them out. So the researchers carried out a second experiment with another 219 participants where they gave them some basic training in what to look out for before getting them to judge the same number of faces. Their performance improved only slightly, to 59 percent.
In a final experiment, the team decided to see if more immediate gut reactions to faces might give people better clues. They decided to see whether trustworthiness—something we typically decide in a split second based on hard-to-pin-down features—might help people make better calls. But when they got another 223 participants to rate the trustworthiness of 128 faces, they found people actually rated the fake ones 8 percent more trustworthy, a small but statistically significant difference.
Given the nefarious uses deepfakes can be put to, that is a worrying finding. The researchers suggest that part of the reason why the fake faces are rated more highly is because they tend to look more like average faces, which previous research has found people tend to trust more. This was born out by looking at the four most untrustworthy faces, which were all real, and the three most trustworthy, which were all fake.
The researchers say their findings suggest that those developing the underlying technology behind deepfakes need to think hard about what they’re doing. An important first step is to ask themselves whether the benefits of the technology outweigh its risks. The industry should also consider building in safeguards, which could include things like getting deepfake generators to add watermarks to their output.
“ Because it is the democratization of access to this powerful technology that poses the most significant threat, we also encourage reconsideration of the often laissez-faire approach to the public and unrestricted releasing of code for anyone to incorporate into any application,” the authors wr o te.
Unfortunately though, it might be too late for that. Publicly-available models are already capable of producing highly convincing deepfakes, and it seems unlikely that we’ll be able to put the genie back in the bottle.
Image Credit: geralt / 23929 images Looking for ways to stay ahead of the pace of change? Rethink what’s possible.
Join a highly curated, exclusive cohort of 80 executives for Singularity’s flagship Executive Program (EP), a five-day, fully immersive leadership transformation program that disrupts existing ways of thinking. Discover a new mindset, toolset and network of fellow futurists committed to finding solutions to the fast pace of change in the world.
Click here to learn more and apply today! Tags Artificial Intelligence Ethics RELATED Like Humans, This Breakthrough AI Makes Concepts Out of the Words It Learns October 31, 2023 Why Google and Bing’s Embrace of Generative AI Could Upend the SEO Industry October 29, 2023 AI in the C-Suite? Why We’ll Need New Laws to Govern AI Agents in Business October 27, 2023 latest Like Humans, This Breakthrough AI Makes Concepts Out of the Words It Learns October 31, 2023 Why Google and Bing’s Embrace of Generative AI Could Upend the SEO Industry October 29, 2023 This Week’s Awesome Tech Stories From Around the Web (Through October 28) October 28, 2023 featured Carl Sagan Detected Life on Earth 30 Years Ago—Here’s Why His Experiment Still Matters Today October 26, 2023 Singularity Hub News and Insights from Singularity Group Singularity labs A 360 Singularity Hub About Creative Commons Pitch Us Contact Us Terms of Use Privacy Policy Singularity Group About Executive Program Custom Programs Podcasts Insights Blog Stay connected Facebook Instagram RSS Twitter Youtube Get the latest news from Singularity Hub! Sign Up Copyright © Singularity Group. All rights reserved.
