AI Can Write Code Like Humans‚ÄîBugs and All | WIRED
2021
https://www.wired.com/story/ai-write-code-like-humans-bugs

Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business AI Can Write Code Like Humans‚ÄîBugs and All Illustration: Elena Lacey Save this story Save Save this story Save Application Text generation Sector IT Source Data Text Technology Natural language processing Machine learning Some software developers are now letting artificial intelligence help write their code. They‚Äôre finding that AI is just as flawed as humans.
Last June, GitHub , a subsidiary of Microsoft that provides tools for hosting and collaborating on code, released a beta version of a program that uses AI to assist programmers. Start typing a command, a database query, or a request to an API, and the program, called Copilot , will guess your intent and write the rest.
Alex Naka , a data scientist at a biotech firm who signed up to test Copilot, says the program can be very helpful, and it has changed the way he works. ‚ÄúIt lets me spend less time jumping to the browser to look up API docs or examples on Stack Overflow,‚Äù he says. ‚ÄúIt does feel a little like my work has shifted from being a generator of code to being a discriminator of it.‚Äù But Naka has found that errors can creep into his code in different ways. ‚ÄúThere have been times where I've missed some kind of subtle error when I accept one of its proposals,‚Äù he says. ‚ÄúAnd it can be really hard to track this down, perhaps because it seems like it makes errors that have a different flavor than the kind I would make.‚Äù The risks of AI generating faulty code may be surprisingly high. Researchers at NYU recently analyzed code generated by Copilot and found that, for certain tasks where security is crucial, the code contains security flaws around 40 percent of the time.
The figure ‚Äúis a little bit higher than I would have expected,‚Äù says Brendan Dolan-Gavitt , a professor at NYU involved with the analysis. ‚ÄúBut the way Copilot was trained wasn‚Äôt actually to write good code‚Äîit was just to produce the kind of text that would follow a given prompt.‚Äù Despite such flaws, Copilot and similar AI-powered tools may herald a sea change in the way software developers write code. There‚Äôs growing interest in using AI to help automate more mundane work. But Copilot also highlights some of the pitfalls of today‚Äôs AI techniques.
‚ÄúIt seems like it makes errors that have a different flavor than the kind I would make.‚Äù Alex Naka, data scientist While analyzing the code made available for a Copilot plugin, Dolan-Gavitt found that it included a list of restricted phrases. These were apparently introduced to prevent the system from blurting out offensive messages or copying well-known code written by someone else.
Oege de Moor , vice president of research at GitHub and one of the developers of Copilot, says security has been a concern from the start. He says the percentage of flawed code cited by the NYU researchers is only relevant for a subset of code where security flaws are more likely.
Gear Everything Apple Announced at Today‚Äôs Hardware Event Brenda Stolyar Business Sam Bankman-Fried Built a Crypto Paradise in the Bahamas‚ÄîNow He's a Bad Memory Joel Khalili Science Everyone Was Wrong About Why Cats Purr Jorge Garay Security They Cracked the Code to a Locked USB Drive Worth $235 Million in Bitcoin. Then It Got Weird Andy Greenberg De Moor invented CodeQL , a tool used by the NYU researchers that automatically identifies bugs in code. He says GitHub recommends that developers use Copilot together with CodeQL to ensure their work is safe.
The GitHub program is built on top of an AI model developed by OpenAI , a prominent AI company doing cutting-edge work in machine learning.
 That model, called Codex, consists of a large artificial neural network trained to predict the next characters in both text and computer code. The algorithm ingested billions of lines of code stored on GitHub‚Äînot all of it perfect‚Äîin order to learn how to write code.
OpenAI has built its own AI coding tool on top of Codex that can perform some stunning coding tricks.
 It can turn a typed instruction, such as ‚ÄúCreate an array of random variables between 1 and 100 and then return the largest of them,‚Äù into working code in several programming languages.
Another version of the same OpenAI program, called GPT-3, can generate coherent text on a given subject , but it can also regurgitate offensive or biased language learned from the darker corners of the web.
Copilot and Codex have led some developers to wonder if AI might automate them out of work. In fact, as Naka‚Äôs experience shows, developers need considerable skill to use the program, as they often must vet or tweak its suggestions.
Hammond Pearce , a postdoctoral researcher at NYU involved with the analysis of Copilot code, says the program sometimes produces problematic code because it doesn‚Äôt fully understand what a piece of code is trying to do. ‚ÄúVulnerabilities are often caused by a lack of context that a developer needs to know,‚Äù he says.
Some developers worry that AI is already picking up bad habits. ‚ÄúWe have worked hard as an industry to get away from copy-pasting solutions, and now Copilot has created a supercharged version of that,‚Äù says Maxim Khailo , a software developer who has experimented with using AI to generate code but has not tried Copilot.
Khailo says it might be possible for hackers to mess with a program like Copilot. ‚ÄúIf I was a bad actor, what I would do would be to create vulnerable code projects on GitHub, artificially boost their popularity by buying GitHub stars on the black market, and hope that it will become part of the corpus for the next training round.‚Äù Gear Everything Apple Announced at Today‚Äôs Hardware Event Brenda Stolyar Business Sam Bankman-Fried Built a Crypto Paradise in the Bahamas‚ÄîNow He's a Bad Memory Joel Khalili Science Everyone Was Wrong About Why Cats Purr Jorge Garay Security They Cracked the Code to a Locked USB Drive Worth $235 Million in Bitcoin. Then It Got Weird Andy Greenberg Both GitHub and OpenAI say that, on the contrary, their AI coding tools are only likely to become less error prone. OpenAI says it vets projects and code both manually and using automated tools.
De Moor at GitHub says recent updates to Copilot should have reduced the frequency of security vulnerabilities. But he adds that his team is exploring other ways of improving the output of Copilot. One is to remove bad examples that the underlying AI model learns from. Another may be to use reinforcement learning, an AI technique that has produced some impressive results in games and other areas, to automatically spot bad output, including previously unseen examples. ‚ÄúEnormous improvements are happening,‚Äù he says. ‚ÄúIt‚Äôs almost unimaginable what it will look like in a year.‚Äù üì© The latest on tech, science, and more: Get our newsletters ! Looks that quill: The dark side of hedgehog Instagram Climate change is making it harder to flee disasters I'm a Lyft driver.
Passengers act like I'm part of the app Covid has created a virtual Renaissance for life drawing The US AI industry risks becoming winner-take-most üëÅÔ∏è Explore AI like never before with our new database üéÆ WIRED Games: Get the latest tips, reviews, and more üéß Things not sounding right? Check out our favorite wireless headphones , soundbars , and Bluetooth speakers Senior Writer X Topics artificial intelligence machine learning github programming developers OpenAI Will Knight Will Knight Lauren Goode Christopher Beam Reece Rogers Steven Levy Paresh Dave Grace Browne Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n
