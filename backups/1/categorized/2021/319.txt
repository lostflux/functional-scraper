Neural interface translates thoughts into type
2021
https://www.nature.com/articles/d41586-021-00776-8

Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.
Advertisement View all journals Search Log in Explore content About the journal Publish with us Subscribe Sign up for alerts RSS feed nature news & views article Download PDF NEWS AND VIEWS 12 May 2021 Neural interface translates thoughts into type Pavithra Rajeswaran 0 & Amy L. Orsborn 1 Pavithra Rajeswaran Pavithra Rajeswaran is in the Department of Bioengineering, University of Washington, Seattle, Washington 98195, USA.
View author publications You can also search for this author in PubMed Google Scholar Amy L. Orsborn Amy L. Orsborn is in the Department of Bioengineering, University of Washington, Seattle, Washington 98195, USA; and in the Department of Electrical and Computer Engineering, and at the Washington National Primate Research Center, University of Washington.
View author publications You can also search for this author in PubMed Google Scholar Twitter Facebook Email You have full access to this article via your institution.
Download PDF Download PDF We can think much faster than we can communicate — a fact that many of us feel aware of as we struggle with our smartphone keyboards. For people with severe paralysis, this information bottleneck is much more extreme. Willett et al.
1 report in a paper in Nature the development of a brain–computer interface (BCI) for typing that could eventually let people with paralysis communicate at the speed of their thoughts.
Read the paper: High-performance brain-to-text communication via handwriting Commercially available assistive typing devices predominantly rely on the person using the device being able to make eye movements or deliver voice commands. Eye-tracking keyboards can let people with paralysis type at around 47.5 characters per minute 2 , slower than the 115-per-minute speeds achieved by people without a comparable injury. However, these technologies do not work for people whose paralysis impairs eye movements or vocalization. And the technology has limitations. For instance, it is hard to reread an e-mail, so that you can compose your reply, while you are typing with your eyes.
By contrast, BCIs restore function by deciphering patterns of brain activity. Such interfaces have successfully restored simple movements — such as reaching for and manipulating large objects — to people with paralysis 3 – 7.
 By directly tapping into neural processing, BCIs hold the tantalizing promise of seamlessly restoring function to a wide range of people.
But, so far, BCIs for typing have been unable to compete with simpler assistive technologies such as eye-trackers. One reason is that typing is a complex task. In English, we select from 26 letters of the Latin alphabet. Building a classification algorithm to predict which letter a user wants to choose, on the basis of their neural activity, is challenging, so BCIs have solved typing tasks indirectly. For instance, non-invasive BCI spellers present several sequential visual cues to the user and analyse the neural responses to all cues to determine the desired letter 8.
 The most successful invasive BCI (iBCI; one that involves implanting an electrode into the brain) for typing allowed users to control a cursor to select keys, and achieved speeds of 40 characters per minute 6.
 But these iBCIs, like non-invasive eye-trackers, occupy the user’s visual attention and do not provide notably faster typing speeds.
Willett and colleagues developed a different approach, which directly solves the typing task in an iBCI and thereby leapfrogs far beyond past devices, in terms of both performance and functionality. The approach involves decoding letters as users imagine writing at their own pace (Fig. 1).
Figure 1 | A brain–computer interface (BCI) for typing.
Willett et al.
1 have developed a BCI that enables a person with paralysis to type, by translating the neural activity produced from imagined attempts at handwriting into text on the computer screen. As a simplified description, electrodes implanted into the brain measure the activity of many neurons as the user imagines writing each letter (lines indicate time points at which each neuron fires). A deep-learning model called a recurrent neural network (RNN) learns the neural activity patterns produced from each character, and analyses how these activity patterns relate across multiple trials, generating cluster plots. This information is used to by an algorithm to predict the letters being imagined by the participant in the current trial, and the prediction is translated into a typographic output. (Figure adapted from Fig. 2a of ref. 1.) Such an approach required a classification algorithm that predicts which of 26 letters or 5 punctuation marks a user with paralysis is trying to write — a challenging feat when the attempts cannot be observed and occur whenever the user chooses. To overcome this challenge, Willett et al.
first repurposed another type of algorithm — a machine-learning algorithm originally developed for speech recognition. This allowed them to estimate, on the basis of neural activity alone, when a user started attempting to write a character. The pattern of neural activity generated each time their study participant imagined a given character was remarkably consistent. From this information, the group produced a labelled data set that contained the neural-activity patterns corresponding to each character. They used this data set to train the classification algorithm.
To achieve accurate classification in such a high-dimensional space, Willett and colleagues’ classification algorithm used current machine-learning methods, along with a type of artificial neural network called a recurrent neural network (RNN), which is especially good at predicting sequential data. Harnessing the power of RNNs requires ample training data, but such data are limited in neural interfaces, because few users want to imagine writing for hours on end. The authors solved this problem using an approach known as data augmentation, in which neural activity patterns previously generated by the participant are used to produce artificial sentences on which to train the RNN. They also expanded their training data by introducing artificial variability into the patterns of neural activity, to mimic changes that occur naturally in the human brain. Such variability can make RNN BCIs more robust 9.
Neuroprosthetic device maintains blood pressure after spinal-cord injury Thanks to these methods, Willett and colleagues’ algorithm provided impressively accurate classification, picking the correct character 94.1% of the time. By including predictive-language models (similar to those that drive auto-correct functions on a smartphone), they further improved accuracy to 99.1%. The participant was able to type accurately at a speed of 90 characters per minute — a twofold improvement on his performance with past iBCIs.
This study’s achievements, however, stem from more than machine learning. A decoder’s performance is ultimately only as good as the data that are fed into it. The researchers found that neural data associated with attempted handwriting are particularly well-suited for typing tasks and classification. In fact, handwriting could be classified quite well even with simpler, linear algorithms, suggesting that the neural data themselves played a large part in the success of the authors’ approach.
By simulating how the classification algorithm performed when tested with different types of neural activity, Willett et al.
made a key insight — neural activity during handwriting has more temporal variability between characters than does neural activity when users attempt to draw straight lines, and this variablility actually makes classification easier. This knowledge should inform future BCIs. Perhaps counter-intuitively, it might be advantageous to decode complex behaviours rather than simple ones, particularly for classification tasks.
Brain implants that let you speak your mind Willett and co-workers’ study begins to deliver on the promise of BCI technologies. iBCIs will need to provide tremendous performance and usability benefits to justify the expense and risks associated with implanting electrodes into the brain. Importantly, typing speed is not the only factor that will determine whether the technology is adopted — the longevity and robustness of the approach also require analysis. The authors present promising evidence that their algorithms will perform well with limited training data, but further research will probably be required to enable the device to maintain performance over its lifetime as neural activity patterns change. It will also be crucial to conduct studies to test whether the approach can be generalized for other users, and for settings outside the laboratory.
Another question is how the approach will scale and translate to other languages. Willett and colleagues’ simulations highlight that several characters of the Latin alphabet are written similarly (r, v and u, for instance), and so are harder to classify than are others. One of us (P.R.) speaks Tamil, which has 247, often very closely related, characters, and so might be much harder to classify. And the question of translation is particularly pertinent for languages that are not yet well represented in machine-learning predictive-language models.
Although much work remains to be done, Willett and co-workers’ study is a milestone that broadens the horizon of iBCI applications. Because it uses machine-learning methods that are rapidly improving, plugging in the latest models offers a promising path for future improvements. The team is also making its data set publicly available, which will accelerate advances. The authors’ approach has brought neural interfaces that allow rapid communication much closer to a practical reality.
Nature 593 , 197-198 (2021) doi: https://doi.org/10.1038/d41586-021-00776-8 References Willett, F. R., Avansino, D. T., Hochberg, L. R., Henderson, J. M. & Shenoy, K. V.
Nature 593 , 249–254 (2021).
Article Google Scholar Mott, M. E., Williams, S., Wobbrock, J. O. & Morris, M. R. in Proc. 2017 CHI Conf. Human Factors in Computing Systems 2558–2570 (ACM, 2017).
Google Scholar Hochberg, L. R.
et al.
Nature 442 , 164–171 (2006).
Article PubMed Google Scholar Hochberg, L. R.
et al.
Nature 485 , 372–375 (2012).
Article PubMed Google Scholar Collinger, J. L.
et al.
Lancet 381 , 557–564 (2013).
Article PubMed Google Scholar Pandarinath, C.
et al.
eLife 6 , e18554 (2017).
Article PubMed Google Scholar Ajiboye, A. B.
et al.
Lancet 389 , 1821–1830 (2017).
Article PubMed Google Scholar Rezeika, A.
et al.
Brain Sci.
8 , 57 (2018).
Article Google Scholar Sussillo, D., Stavisky, S. D., Kao, J. C., Ryu, S. I. & Shenoy, K. V.
Nature Commun.
7 , 13749 (2016).
Article PubMed Google Scholar Download references Reprints and Permissions Related Articles Read the paper: High-performance brain-to-text communication via handwriting Neuroprosthetic device maintains blood pressure after spinal-cord injury Brain implants that let you speak your mind See all News & Views Subjects Neuroscience Brain Medical research Latest on: CHIT1-positive microglia drive motor neuron aging in the primate spinal cord Article 31 OCT 23 An ON-type direction-selective ganglion cell in primate retina Article 25 OCT 23 A single photoreceptor splits perception and entrainment by cotransmission Article 25 OCT 23 Dopamine determines how reward overrides risk News & Views 25 OCT 23 ‘Mind-blowing’ IBM chip speeds up AI News 19 OCT 23 Deep asleep? You can still follow simple commands, study finds News 18 OCT 23 Is CRISPR safe? Genome editing gets its first FDA scrutiny News Explainer 28 OCT 23 An AI revolution is brewing in medicine. What will it look like? News Feature 24 OCT 23 Long COVID research risks losing momentum – we need a moonshot Comment 18 OCT 23 Jobs [DGIST] The second half of 2023 Tenure-Track Faculty Public Invitation South Korea (KR) DGIST Principle Investigator and Joint Recruitment Position-Postdoc The Center for Evolutionary & Organismal Biology invites applications from evolutionary scientists for All ranks.
Hangzhou, Zhejiang, China Center for Evolutionary & Organismal Biology, Zhejiang University Tenure-track Faculty Positions in Particle Physics and Cosmology Faculty Positions in Particle Physics and Cosmology Hong Kong (HK) Department of Physics, The Hong Kong University of Science & Technology (HKUST) Assistant/Associate Professor Center for Virology and Vaccine Research (CVVR) at Beth Israel Deaconess Medical Center (BIDMC) is seeking Assistant or Associate Professor.
Boston, Massachusetts (US) Beth Israel Deaconess Medical Center (BIDMC) Scientific and Technical Advisory Panel to the Global Environment Facility Scientific and Technical Advisory Panel to the Global Environment Facility: Panel Member for Land Degradation Washington D.C. (US) Scientific and Technical Advisory Panel (STAP) of the Global Environment Facility (GEF) You have full access to this article via your institution.
Download PDF Download PDF Related Articles Read the paper: High-performance brain-to-text communication via handwriting Neuroprosthetic device maintains blood pressure after spinal-cord injury Brain implants that let you speak your mind See all News & Views Subjects Neuroscience Brain Medical research Sign up to Nature Briefing An essential round-up of science news, opinion and analysis, delivered to your inbox every weekday.
Close Sign up for the Nature Briefing newsletter — what matters in science, free to your inbox daily.
Close Get the most important science stories of the day, free in your inbox.
Explore content Research articles News Opinion Research Analysis Careers Books & Culture Podcasts Videos Current issue Browse issues Collections Subjects Follow us on Facebook Follow us on Twitter Subscribe Sign up for alerts RSS feed About the journal Journal Staff About the Editors Journal Information Our publishing models Editorial Values Statement Journal Metrics Awards Contact Editorial policies History of Nature Send a news tip Publish with us For Authors For Referees Language editing services Submit manuscript Search Quick links Explore articles by subject Find a job Guide to authors Editorial policies Nature ( Nature ) ISSN 1476-4687 (online) ISSN 0028-0836 (print) nature.com sitemap About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Nano Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Live Expert Trainer-led workshops Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Career development Nature Careers Nature Conferences Nature events Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2023 Springer Nature Limited
