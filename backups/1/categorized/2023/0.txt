MIT Technology Review
2023
https://www.technologyreview.com

Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts Policy 2 days Three things to know about the White House’s executive order on AI Experts say its emphasis on content labeling, watermarking, and transparency represents important steps forward.
Artificial intelligence 2 days Joy Buolamwini: “We’re giving AI companies a free pass” Biotechnology and health 5 days Some deaf children in China can hear after gene treatment Climate change and energy 6 days How heat batteries promise a cleaner future in industrial manufacturing Artificial intelligence 6 days Exclusive: Ilya Sutskever, OpenAI’s chief scientist, on his hopes and fears for the future of AI Biotechnology and health 7 days Three people were gene-edited in an effort to cure their HIV. The result is unknown.
Space 1 week Inside NASA’s bid to make spacecraft as small as possible The latest from The Technocrat : Our weekly tech policy email Why Meta is getting sued over its beauty filters Dozens of states sued Meta on October 24, claiming that the company knowingly harms young users.
The case is a pretty big deal and will almost certainly have a sweeping impact on the national debate about child safety online—a topic regular readers know I’ve covered quite a bit.
 Potentially, it could lead to policy and platform changes. The case is also poised to stress-test existing privacy law that protects minors’ data.
Some of its core allegations are that Meta misleads young users about safety features and the pervasiveness of harmful content on platforms, and that it harvests their data and violates federal laws on children’s privacy and consumer protection. The case grew out of an investigation triggered largely by Frances Haugen’s whistleblowing in 2021, which revealed damning evidence that Meta knew Instagram has detrimental effects on the mental health of young girls.
Interestingly, Haugen’s testimony revealed some of the best concrete evidence we seem to have about how kids have been specifically harmed by social media. In fact, the evidence (or lack of it) for the impact of social media on kids could become a flash point in the debate over online safety, and it’s possible that this court case will bring critical new findings to light. But we will have to wait and see; the filing was heavily redacted.
(If you want to know more, there’s been a lot of good writing about the case in recent days.
 I’d recommend reading Casey Newton’s newsletter to understand the evidence we do have and why this case matters.) This leads me to what I want to focus on today: allegations of harm created by visual filters on Instagram. As you probably know, one key aspect of the platform is filters that can easily be added to photos. The features range from basic editing tools to sophisticated real-time virtual-reality computer vision. I’ve written about the impact of beauty filters in the past , and once I even asked an AI how beautiful I am.
 As I found then, their impact on kids hasn’t been well established through causal research, but we do have lots of anecdotal and correlative data, such as a survey of 200 teens in which 61% of respondents said beauty filters made them feel worse about themselves.
The case against Meta specifically calls out visual tools “known to promote body dysmorphia” as one of the “psychologically manipulative platform features designed to maximize young users’ time spent on its social media platforms.” It also says that “Meta was aware that young users’ developing brains are particularly vulnerable to certain forms of manipulation, and it chose to exploit those vulnerabilities through targeted features,” like filters.
To better understand what’s going on here and what to expect from the case, I called up someone I consider a real expert: Jessica DeFino, a reporter and cultural critic who focuses on how beauty culture , online and otherwise , affects individuals.
 (She also writes a searing and worthwhile Substack newsletter called The Unpublishable.
) Here’s some of our conversation, which has been edited for length and clarity.
The case asserts that there is evidence, a lot of which appears to be redacted, that shows Meta and Meta's products exploit young users and that the company is aware of the effect of their products on the mental health of young people, specifically teenage girls. What do you know about the evidence? From the standpoint of psychological health, there are definitely studies and surveys that show that teen girls specifically, but also women across the age spectrum, are experiencing higher instances of appearance-related anxiety, depression, body dysmorphia, facial dysmorphia, obsessive beauty behaviors, disordered eating, self-harm, and even suicide. And there's a lot that can be traced back in one way or another to this increasingly visual virtual world that we exist in.
On the more material side of things, there is a lot happening in the beauty industry that has been specifically inspired by Instagram. I think a really great example of this is the phenomenon of Instagram face , which is basically a term that’s been coined to describe the way that Instagram filters have inspired real-world procedures and surgeries.
I have interviewed a lot of cosmetic surgeons and cosmetic injectors over the years who tell me that patients use the filters and photo-editing tools that are really popular on Instagram, but maybe not owned by Meta or Instagram, to alter their own images and bring that in to a plastic surgeon or an injector consult and say, This is what I wanna look like.
I tell this story all the time because it was just so shocking to me and such a strong example of what’s happening in the medical world in response to Instagram filters: I was interviewing this cosmetic injector, a doctor and dermatologist named Anna Guanche, at an event hosted by Allergan, the makers of Botox Cosmetic, with a small group of journalists.
She said, “One of the biggest things I tell my patients is, ‘You want to look more like your filtered photos—what can we do to make you look more like them, so people don’t see you in real life and go, what?’” So that is a medical opinion that’s being given by an actual doctor to clients. And of course, all of these behaviors and the surgeries that are being performed in response to Instagram filters come with a huge host of potential side effects and risks, including deaths.
One thing that was specifically named in the case is that Meta promotes platform features such as visual filters known to promote eating disorders and body dysmorphia in youth. Do we know that this is true? We do know that this is true, I would say, and it’s true because these platforms are engineered by people, and that these biases exist in people is very well documented.
 There are very well-documented cases of these biases popping up in some of the filter technology.
For instance, filters that are literally called “beauty filters” will automatically give somebody a smaller nose, slightly lighten and brighten their skin, and widen their eyes. These are all beauty preferences that are passed down from systems of patriarchy, white supremacy, colonialism, and capitalism that end up in our lives, in our systems, in our corporations, and in our engineers and the filters that they create.
These issues are often talked about in the context of women and teen girls being insecure about their bodies rather than framed as untested, mass-deployed, sophisticated consumer-facing augmented-reality tech. Have you seen that dynamic play out? Issues [that affect] teen girls have culturally, historically, been swept under the rug and dismissed. Things like beauty are seen as frivolous interests. And if they’re dismissed, we end up not getting enough studies, enough data about the harms of beauty culture, when in reality there are these huge and harmful cultural implications.
It recently came out that period products have never been scientifically tested using blood , and periods have been around since the beginning of time. If periods, which have affected teen girls and women for literal millennia, are understudied, it does not surprise me that this relatively new phenomenon of beauty filters and beauty standards affecting the mental health of teen girls does not have a robust set of data yet.
What groups profit off the disconnect between the beauty ideal and real life? It’s a very capitalist ideal. The further away the standard is from the human body, the more products and procedures and surgeries need to be bought in order to meet that ideal. And so corporations benefit and the tech industry benefits.
One concrete example is how Instagram face has financially benefited Instagram. The Instagram-face phenomenon sort of came about in an earlier iteration of Instagram when it was primarily a social media platform. A couple of years later, Instagram transitioned into a social shopping platform. They put a huge emphasis on shopping; there was a shopping tab. At that point, not only was it distorting users’ perception of beauty, but it’s also selling them everything they need to distort their bodies to match and taking a cut of all of those sales.
What in particular are you going to be watching as this lawsuit develops? I would absolutely love to see more hard data on beauty standards and beauty culture and how social photo-editing technologies are contributing to that and their psychological impact.
But I’m more interested right now in the human behavior aspect of it. As evidence does come out in this lawsuit and we begin to see, Oh, these technologies that we’ve become obsessed with to an unhealthy degree are actually detrimental to our lives and our well-being in a lot of ways , I’m interested to see if people will, one, want to opt out of them and, two, be able to opt out of them. I’m interested to see if this lawsuit being more publicized will inspire more people to consider non-social-media lives.
As far as other potential regulations, there was one study done in the UK [that looked at] whether disclaimers on Photoshopped images had a positive effect on people who were viewing these advertisements.
[Ed. note: Similar labels have been suggested as a regulatory response to social media harms.] And what it found is that in a lot of cases, the disclaimer that an image had been Photoshopped actually made people feel worse, because knowing that an image has been doctored and that it’s not physically possible doesn’t actually lessen the pressure society places on young women to look as perfect as possible. So I am very skeptical of any potential regulation that would require disclosure of filters or Photoshop or any sort of photo-editing things.
What else I’m reading California suspended Cruise robotaxis from operating in the state. State regulators cited safety concerns with the driverless-car technology after a slew of incidents over the past few weeks, including an accident that trapped a pedestrian (who was hit by another car) underneath the robotaxi, and the company’s alleged attempts to withhold crash footage.
There are still a lot of AI meetings happening among lawmakers, including the US Congress’s second AI Insight Forum on October 24 and the UK’s AI Safety Summit commencing on November 1. I’m excited to see whether these meetings lead to tangible results. I’ll also be watching for a forthcoming executive order on AI from President Biden.
Apropos of nothing: I was engrossed by this story by Chiara Dello Joio in the Atlantic about humans who have cloned their pets and how their relationship with the cloned animal differs from their relationship with the original.
What I learned this week A new tool called Nightshade can “poison” training data for image-generating AI models and help artists fight back against copyright violations, my colleague Melissa Heikkilä reported. “A new tool lets artists add invisible changes to the pixels in their art before they upload it online so that if it’s scraped into an AI training set, it can cause the resulting model to break in chaotic and unpredictable ways,” she writes. Melissa’s story comes from an exclusive preview of research out of the University of Chicago that has been submitted for peer review.
Sign up to get The Technocrat weekly in your inbox.
Highlights Artificial intelligence 1 week This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
Culture How to fix the internet If we want online discourse to improve, we need to move beyond the big platforms.
Climate change and energy Underground thermal energy networks are becoming crucial to the US’s energy future Their advantages extend beyond reducing carbon emissions.
Artificial intelligence This robotic exoskeleton can help runners sprint faster It encourages wearers to take more steps, covering distances more quickly than they could without it.
Artificial intelligence Now you can chat with ChatGPT using your voice The new feature is part of a round of updates for OpenAI’s app, including the ability to answer questions about images.
Computing What’s next for the world’s fastest supercomputers Scientists have begun running experiments on Frontier, the world’s first official exascale machine, while facilities worldwide build other machines to join the ranks.
Explore Climate change and energy 4 weeks 15 Climate Tech Companies to Watch Climate change and energy Introducing MIT Technology Review’s 2023 list of 15 Climate Tech Companies to Watch Technology plays a crucial role in addressing one of society's most daunting threats.
Climate change and energy 2023 Climate Tech Companies to Watch: Form Energy and its iron batteries Cheaper batteries made from widely-available materials could help the grid transition more quickly towards renewables.
Climate change and energy 2023 Climate Tech Companies to Watch: Sublime Systems and its clean cement The firm is using electrochemistry to reinvent one of the world’s dirtiest materials.
Climate change and energy 2023 Climate Tech Companies to Watch: BYD and its affordable EVs The electric vehicle maker could help decarbonize transportation with an innovative battery that’s safe and efficient.
Climate change and energy 2023 Climate Tech Companies to Watch: Climeworks and its carbon-sucking fans Companies are paying Climeworks to turn carbon pollution into rocks.
A selection from our popular explainer series Previous slide Next slide Policy Three things to know about the White House’s executive order on AI Experts say its emphasis on content labeling, watermarking, and transparency represents important steps forward.
Biotechnology and health Everything you need to know about artificial wombs Artificial wombs are nearing human trials. But the goal is to save the littlest preemies, not replace the uterus.
Climate change and energy Here’s what we know about hurricanes and climate change More rainfall and intensifying storms are hallmarks of rising temperatures, but questions remain about some links between extreme storms and climate change.
Business China just fought back in the semiconductor exports war. Here’s what you need to know.
The country aims to restrict the supply of gallium and germanium, two materials used in computer chips and other products. But experts say it won’t have the desired impact.
Climate change and energy Here’s what we know about lab-grown meat and climate change Cultivated meat is coming to the US. Whether it’ll clean up emissions from food is complicated.
Artificial intelligence Our quick guide to the 6 ways we can regulate AI Let us walk you through all the most (and least) promising efforts to govern AI around the world.
Biotechnology and health How do fungi communicate? Each fungus may “speak” with many other species— and it turns out they have a lot to say.
Climate change and energy Everything you need to know about the wild world of heat pumps Heat pumps could help address climate change and save you money. Here’s how they work.
Culture How to log off Sick of spending all your time staring at your devices? Here’s how to strike a healthier balance.
Climate change and energy How did China come to dominate the world of electric cars? From generous government subsidies to support for lithium batteries, here are the keys to understanding how China managed to build a world-leading industry in electric vehicles.
Magazine November/December 2023 The Hard Problems issue Climate change and energy Think that your plastic is being recycled? Think again.
Plastic is cheap to make and shockingly profitable. It’s everywhere. And we’re all paying the price.
Artificial intelligence Minds of machines: The great AI consciousness conundrum Philosophers, cognitive scientists, and engineers are grappling with what it would take for AI to become conscious.
Policy Government technology is famously bad. It doesn’t have to be.
New York City is fixing the relationship between government and technology–and not in the ways you’d expect.
Space Inside NASA’s bid to make spacecraft as small as possible When it comes to exploring the solar system, we must grapple with the hard limits of physics.
The Green Future Index 2023 The Green Future Index 2023 is the third edition of the comparative ranking of 76 nations and territories on their ability to develop a sustainable, low-carbon future.
In association with Kyndryl, Intel, and Iris Ceramica Group The Feed You've seen 32 stories, or 0.07% of our archive The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
