Toggle Navigation News Events TNW Conference 2024 June 20 & 21, 2024 TNW Vision: 2024 All events Spaces Programs Newsletters Partner with us Jobs Contact News news news news Latest Deep tech Sustainability Ecosystems Data and security Fintech and ecommerce Future of work More Startups and technology Investors and funding Government and policy Corporates and innovation Gadgets & apps Early bird Business passes are 90% SOLD OUT ğŸŸï¸ Buy now before they are gone â†’ This article was published on May 2, 2023 Deep tech AI â€˜godfatherâ€™ quits Google and warns of dangers ahead Meanwhile, the EU is moving closer to its landmark AI Act Dr Geoffrey Hinton, widely referred to as AIâ€™s â€œgodfather,â€ has confirmed in an interview with the New York Times that he has quit his job at Google â€” to talk about the dangers of the technology he helped develop.
Hintonâ€™s pioneering work in neural networks â€” for which he won the Turing award in 2018 alongside two other university professors â€” laid the foundations for the current advancement of generative AI.
The lifelong academic and computer scientist joined Google in 2013, after the tech giant spent $44m to acquire a company founded by Hinton and two of his students, Ilya Sutskever (now chief scientist at OpenAI ) and Alex Krishevsky. Their neural network system ultimately led to the creation of ChatGPT and Google Bard.
But Hinton has come to partly regret his lifeâ€™s work, as he told the NYT. â€œI console myself with the normal excuse: If I hadnâ€™t done it, somebody else would have,â€ he said. He decided to leave Google so that he could speak freely about the dangers of AI and ensure that his warnings donâ€™t impact the company itself.
In the NYT today, Cade Metz implies that I left Google so that I could criticize Google. Actually, I left so that I could talk about the dangers of AI without considering how this impacts Google. Google has acted very responsibly.
â€” Geoffrey Hinton (@geoffreyhinton) May 1, 2023 According to the interview, Hinton was prompted by Microsoftâ€™s integration of ChatGPT into its Bing search engine, which he fears will drive tech giants into a potentially unstoppable competition. This could result in an overflow of fake photos, videos, and texts to the extent that an average person wonâ€™t be able to â€œtell whatâ€™s true anymore.â€ But apart from misinformation, Hinton also voiced concerns about AIâ€™s potential to eliminate jobs and even write and run its own code, as itâ€™s seemingly capable of becoming smarter than humans much earlier than expected.
The more companies improve artificial intelligence without control, the more dangerous it becomes, Hinton believes. â€œLook at how it was five years ago and how it is now. Take the difference and propagate it forwards. Thatâ€™s scary.â€ The need to control AI development Geoffry Hinton isnâ€™t alone in expressing fears over AIâ€™s rapid and uncontrolled development.
In late March, more than 2,000 industry experts and executives in North America signed an open letter, calling for a six-month pause in the training of systems more powerful than GPT-4, ChatGPTâ€™s successor.
The signees â€” including researchers at DeepMind, computer scientist Yoshua Bengio, and Elon Musk â€” emphasised the need for regulatory policies, cautioning that â€œpowerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.â€ Across the Atlantic, ChatGPTâ€™s growth has stirred the efforts of EU and national authorities to efficiently regulate AIâ€™s development without stifling innovation.
Individual member states are trying to oversee the operation of advanced models. For instance, Spain, France, and Italy have opened investigations into ChatGPT over data privacy concerns â€” with the latter being the first Western country to regulate its use after imposing a temporary ban of the service.
The union as a whole is also moving closer to the adoption of the anticipated AI Act â€” the worldâ€™s first AI law by a major regulatory body. Last week, Members of the European Parliament agreed to advance the draft to the next stage , called trilogue, in which lawmakers and member states will work out the billâ€™s final details.
According to Margrethe Vestager , the EUâ€™s tech regulation chief, the bloc is likely to agree on the law this year, and businesses could already start considering its implications.
â€œWith these landmark rules, the EU is spearheading the development of new global norms to make sure AI can be trusted. By setting the standards, we can pave the way to ethical technology worldwide and ensure that the EU remains competitive along the way,â€ Vestager said when the bill was first announced.
Unless regulatory efforts in Europe and the globe are sped up, we might risk repeating the approach of Oppenheimer of which Hinton is now sounding the alarm: â€œWhen you see something that is technically sweet, you go ahead and do it and you argue about what to do about it only after you have had your technical success.â€ Story by Ioanna Lykiardopoulou Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainabili (show all) Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainability, green tech, AI, and EU policy. With a background in the humanities, she has a soft spot for social impact-enabling technologies.
Get the TNW newsletter Get the most important tech news in your inbox each week.
Also tagged with Artificial intelligence Europe OpenAI Google neural networks AI Story by Ioanna Lykiardopoulou Popular articles 1 New erotic roleplaying chatbots promise to indulge your sexual fantasies 2 UK plan to lead in generative AI â€˜unrealistic,â€™ say Cambridge researchers 3 New AI tool could make future vaccines â€˜variant-proof,â€™ researchers say 4 3D-printed stem cells could help treat brain injuries 5 New technique makes AI hallucinations wake up and face reality Related Articles deep tech UK police urged to double down on facial recognition deep tech Bedazzled by big tech, the UKâ€™s AI summit is overlooking big issues Join TNW All Access Watch videos of our inspiring talks for free â†’ deep tech German satellite will use AI to detect anomalies on asteroids and planets deep tech UK launches Â£100M AI fund to help treat incurable diseases The heart of tech More TNW Media Events Programs Spaces Newsletters Jobs in tech About TNW Partner with us Jobs Terms & Conditions Cookie Statement Privacy Statement Editorial Policy Masthead Copyright Â© 2006â€”2023, The Next Web B.V. Made with <3 in Amsterdam.
