Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business Google Says It Wants Rules for the Use of AI‚ÄîKinda, Sorta Alyssa Foote; Getty Images Save this story Save Save this story Save Application Ethics Regulation Company Alphabet Google Microsoft Last April, Google cofounder Sergey Brin wrote to shareholders with a warning about the potential downsides of artificial intelligence. In June, Google CEO Sundar Pichai released a set of guiding principles for its AI projects after employee protests forced him to abandon a Pentagon contract creating algorithms to interpret drone footage.
 Now Google has released a white paper that asks governments to suggest some rules for AI‚Äîbut please, not too many! As you might expect, the 30-page document Google released last week extols the power of artificial intelligence. ‚ÄúAI can deliver great benefits for economies and society, and support decision making which is fairer, safer and more inclusive and informed,‚Äù it says. The paper goes on to argue that the downsides of that awesome power can be avoided without additional regulation ‚Äúin the vast majority of instances.‚Äù Lawmakers and governments are showing a growing interest in imposing limits on uses of AI. A San Francisco politician recently proposed a ban on the use of facial recognition by city agencies, and French president Emmanuel Macron has talked about creating new regulations around the technology.
Charina Choi, Google‚Äôs global policy lead for emerging technologies, says one motivation of the report is to offer governments advice on where their input would be most useful. ‚ÄúWe‚Äôve been hearing a lot of governments say, 'What can we do, practically speaking?'" says Choi, a coauthor of the report. For now, she says, the answer isn‚Äôt to immediately draft new rules on where and how AI algorithms can be used.
"At this time, it‚Äôs not necessarily super obvious what things should be regulated and what shouldn't,‚Äù Choi says. "The aim of this paper is to really think about: What are the types of questions that policymakers need to answer and [decisions] we as a society have to make?" To make those decisions, the paper says, input from civil society groups and researchers outside the industry will also be needed.
Areas where Google invites government rules or guidance include safety certifications for some products with AI inside, like the CE mark used to indicate compliance with safety standards on products in Europe. The white paper offers the example of smart locks that use biometric data, such as face images or thumbprints.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker A safety mark might indicate that a lock‚Äôs AI has been tested to work accurately against a representative sample of people, the paper says. Studies have found that machine learning algorithms can pick up and even amplify societal biases , and that facial analysis algorithms perform better on white people than those with darker skin. Experiments by the ACLU last year found that a facial recognition service Amazon has sold to police departments made more errors for black faces.
Google‚Äôs white paper comes amid calls for ethical and regulatory guardrails on uses of the technology from researchers , academics , and, more recently, even tech companies themselves. Amazon has said it is ‚Äú very interested ‚Äù in working with policymakers on guidance or legislation for facial recognition. Microsoft has gone further, calling for federal legislation on facial recognition, including a requirement for ‚Äúconspicuous notice‚Äù where it‚Äôs in use.
Google‚Äôs paper is much broader in scope than Microsoft‚Äôs proposals on facial recognition, and considers more AI uses and concerns. It‚Äôs also more cautious, and doesn‚Äôt strongly advocate for specific new regulations. The search company champions self-regulation, highlighting how it has chosen not to offer a general-purpose facial recognition service‚Äîas Microsoft and Amazon do‚Äîdue to concerns it could be used to ‚Äúcarry out extreme surveillance.‚Äù The paper also says Google has limited some of the AI research code it has released, to reduce the risk of misuse.
The search company asks for government guidance on when and how AI systems should explain their decisions‚Äîfor example, when declaring that a person‚Äôs cancer appears to have returned. The document proposes that governments and civil society groups could set ‚Äúminimum acceptable standards‚Äù for algorithmic explanations for different industries.
Google‚Äôs policy paper also muses on the challenge of balancing the roles of people and algorithms in making decisions; it suggests that humans should always be ‚Äúmeaningfully involved‚Äù in decisions involving criminal law or life-altering medical issues. The company also invites government to consider whether some AI regulation should in fact constrain humans, for example by barring them from turning off AI safety systems that may be more reliable than people.
People thinking about AI policy outside of Google say the company‚Äôs white paper is a positive but still preliminary step toward engaging with the challenges AI may pose to society.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Much discussion of AI ethics and policy from companies and governments has been too platitudinal and insufficiently practical, says Sandra Wachter, a researcher at Oxford University‚Äôs Internet Institute. ‚ÄúWe need to move away from these high-level abstract ideas, where everybody says that AI should be fair,‚Äù she says.
Google‚Äôs paper shows the company attempting to talk more specifically, but doesn‚Äôt go very far, Wachter says. ‚ÄúI think it‚Äôs a good initial list. Where I‚Äôd say there is still a gap is how to govern those things.‚Äù In some cases, such as how AI systems explain critical decisions in areas like health, she advocates firm regulation, something that Google and other companies seem loath to consider. ‚ÄúWith explanations, I don‚Äôt want to see a code of conduct, I want to see hard laws, because it‚Äôs a human rights issue,‚Äù Wachter says.
Google‚Äôs next moves will be watched closely. Eleonore Pauwels, who leads a project on AI governance at the United Nations University Centre for Policy Research, says the document is a good first step, but the company needs to prove it will lead somewhere.
Pauwels would like to see Google engage more meaningfully with outsiders about the uses and societal effects of the technology it is developing. The way Google scrambled to address public and employee outcry over its humanlike phone bots and the Pentagon project last year suggest this impulse doesn‚Äôt come naturally. Pauwels says health care, an area where Google is ramping up AI projects in search of new revenue streams, is an area of particular concern. ‚ÄúWe‚Äôre going to see a lot of incredibly personal and intimate data used in new ways in those products,‚Äù she says.
Why your phone (and other gadgets) fail when it‚Äôs cold The threat that the US can't ignore: itself The Arctic village with satellite TV but no running water A ‚Äúmulticultural toilet‚Äù and other innovations to fix flying Fyre Festival docs dissect attendees'‚Äîand your‚ÄîFOMO üëÄ Looking for the latest gadgets? Check out our picks , gift guides , and best deals all year round üì© Want more? Sign up for our daily newsletter and never miss our latest and greatest stories Senior Editor X Topics artificial intelligence face recognition Google Regulation Microsoft Khari Johnson Will Knight Amit Katwala David Gilbert Andy Greenberg Kari McMahon Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
