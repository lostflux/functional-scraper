Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Robert McMillan Business Google's AI Is Now Smart Enough to Play Atari Like the Pros Google DeepMind Save this story Save Save this story Save Last year Google shelled out an estimated $400 million for a little-known artificial intelligence company called DeepMind. Since then, the company has been pretty tight-lipped about what's been going on behind DeepMind's closed doors, but here's one thing we know for sure: There's a professional videogame tester who's pitted himself against DeepMind's AI software in a kind of digital battle royale.
The battlefield was classic videogames. And according to new research published today in the science magazine Nature , Google's software did pretty well, smoking its human competitor in a range of Atari 2600 games like Breakout, Video Pinball , and Space Invaders and playing at pretty close to the human's level most of the time.
Google didn't spend hundreds of millions of dollars because it's expecting an Atari revival, but this new research does offer a hint as to what Google hopes to achieve with DeepMind. The DeepMind software uses two AI techniques---one called deep learning; and the other, deep reinforcement learning. Deep-learning techniques are already widely used at Google, and also at companies such as Facebook and Microsoft. They help with perception---helping Android understand what you're saying, and Facebook know who's photo you just uploaded. But until now, nobody has really matched Google's success at merging deep learning with reinforcement learning---those are algorithms that make the software improve over time, using a system of rewards.
By merging these two techniques, Google has built a “a general-learning algorithm that should be applicable to many other tasks," says Koray Kavukcuoglu, a Google researcher. The DeepMind team says they're still scoping out the possibilities, but clearly improved search and smartphone apps are on the radar.
But there are other interesting areas as well. Google engineering guru Jeff Dean says that AI techniques being explored by Google---and other companies---could ultimately benefit the kinds of technologies that are being incubated in the Google X research labs. "There are potential application in robots and self-driving-car kinds of things," he says. "Those are all things where computer vision is pretty important." Google says that its AI software, which it's dubbed the "Deep Q network agent," got 75 percent of the score of its professional tester in 29 of the 49 games it tried out. It did best in Video Pinball.
Culture Taylor Swift and Beyoncé Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple’s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden’s Tesla Blockade Is Spreading Morgan Meaker Deep Q works best when it lives in the moment---bouncing balls in Break Out, or trading blows in video boxing---but it doesn't do so well when it needs to plan things out in the long-term: climbing down ladders and then jumping skeletons in order to retrieve keys in Montezuma's Revenge , for example. Poor old Deep Q scored a big fat zero in that game.
But as it improves, the DeepMind work "could be the driving technology for robotics," says Itamar Arel, an artificial intelligence researcher who, like the DeepMind folks, is working on ways to merge deep learning with deep reinforcement techniques. He believes that DeepMind's technology is about 18 to 24 months away from the point where it could be used to experiment with real-world robots---and Google has its fair share of robots to test on, including the dog-like Boston Dynamics 1 machines it acquired in 2013.
The Nature paper doesn't describe any new technical breakthroughs, but it shows what happens when the DeepMind techniques are used on a much broader scale. "We used much bigger neural networks, we came up with better training regimes... and trained the systems for longer," says Demis Hassabis, DeepMind's founder. In 2013, DeepMind described "very early preliminary sample results," he says, "these are the full results complete with a whole bunch of careful controls and benchmarks." Hassabis won't tell us whether Google is running robot simulations too, but it's clear that the Atari 2600 work is only the beginning. "I can't really comment on our current work, but we are indeed running simulations of all kinds of games and environments," he says.
Additional reporting by Marcus Woo and Cade Metz 1 Correction: 02:26:2015 10:00 EST This story originally mis-identified the Google robotics company Boston Dynamics as Boston Robotics.
Senior Writer X Topics artificial intelligence Atari Enterprise Google video games Will Knight Will Knight Khari Johnson Gregory Barber Will Knight Will Knight Will Knight Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
