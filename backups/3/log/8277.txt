Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons David Nield Business How ChatGPT and Other LLMs Work‚Äîand Where They Could Go Next Illustration: James Marshall; Getty Images Save this story Save Save this story Save AI-powered chatbots such as ChatGPT and Google Bard are certainly having a moment‚Äîthe next generation of conversational software tools promise to do everything from taking over our web searches to producing an endless supply of creative literature to remembering all the world's knowledge so we don't have to.
ChatGPT, Google Bard, and other bots like them, are examples of large language models , or LLMs, and it's worth digging into how they work. It means you'll be able to better make use of them, and have a better appreciation of what they're good at (and what they really shouldn't be trusted with).
Like a lot of artificial intelligence systems‚Äîlike the ones designed to recognize your voice or generate cat pictures‚ÄîLLMs are trained on huge amounts of data. The companies behind them have been rather circumspect when it comes to revealing where exactly that data comes from, but there are certain clues we can look at.
For example, the research paper introducing the LaMDA (Language Model for Dialogue Applications) model, which Bard is built on, mentions Wikipedia, ‚Äúpublic forums,‚Äù and ‚Äúcode documents from sites related to programming like Q&A sites, tutorials, etc.‚Äù Meanwhile, Reddit wants to start charging for access to its 18 years of text conversations, and StackOverflow just announced plans to start charging as well. The implication here is that LLMs have been making extensive use of both sites up until this point as sources, entirely for free and on the backs of the people who built and used those resources. It's clear that a lot of what's publicly available on the web has been scraped and analyzed by LLMs.
LLMs use a combination of machine learning and human input.
OpenAI via David Nield Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker All of this text data, wherever it comes from, is processed through a neural network, a commonly used type of AI engine made up of multiple nodes and layers. These networks continually adjust the way they interpret and make sense of data based on a host of factors, including the results of previous trial and error. Most LLMs use a specific neural network architecture called a transformer , which has some tricks particularly suited to language processing. (That GPT after Chat stands for Generative Pretrained Transformer.) Specifically, a transformer can read vast amounts of text, spot patterns in how words and phrases relate to each other, and then make predictions about what words should come next. You may have heard LLMs being compared to supercharged autocorrect engines, and that's actually not too far off the mark: ChatGPT and Bard don't really ‚Äúknow‚Äù anything, but they are very good at figuring out which word follows another, which starts to look like real thought and creativity when it gets to an advanced enough stage.
One of the key innovations of these transformers is the self-attention mechanism. It's difficult to explain in a paragraph, but in essence it means words in a sentence aren't considered in isolation, but also in relation to each other in a variety of sophisticated ways. It allows for a greater level of comprehension than would otherwise be possible.
There is some randomness and variation built into the code, which is why you won't get the same response from a transformer chatbot every time. This autocorrect idea also explains how errors can creep in. On a fundamental level, ChatGPT and Google Bard don't know what's accurate and what isn't. They're looking for responses that seem plausible and natural, and that match up with the data they've been trained on.
So, for example, a bot might not always choose the most likely word that comes next, but the second- or third-most likely. Push this too far, though, and the sentences stop making sense, which is why LLMs are in a constant state of self-analysis and self-correction. Part of a response is of course down to the input, which is why you can ask these chatbots to simplify their responses or make them more complex.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Google via David Nield You might also notice generated text being rather generic or clich√©d‚Äîperhaps to be expected from a chatbot that's trying to synthesize responses from giant repositories of existing text. In some ways these bots are churning out sentences in the same way that a spreadsheet tries to find the average of a group of numbers, leaving you with output that's completely unremarkable and middle-of-the-road. Get ChatGPT to talk like a cowboy, for instance, and it'll be the most unsubtle and obvious cowboy possible.
Human beings are involved in all of this too (so we're not quite redundant, yet): Trained supervisors and end users alike help to train LLMs by pointing out mistakes, ranking answers based on how good they are, and giving the AI high-quality results to aim for. Technically, it's known as ‚Äúreinforcement learning on human feedback‚Äù (RLHF). LLMs then refine their internal neural networks further to get better results next time. (These are still relatively early days for the technology at this level, but we've already seen numerous notices of upgrades and improvements from developers.) Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker As these LLMs get bigger and more complex, their capabilities will improve. We know that ChatGPT-4 has in the region of 1 trillion parameters (although OpenAI won't confirm,) up from 175 billion in ChatGPT 3.5‚Äîa parameter being a mathematical relationship linking words through numbers and algorithms. That's a vast leap in terms of understanding relationships between words and knowing how to stitch them together to create a response.
From the way LLMs work, it's clear that they're excellent at mimicking text they've been trained on, and producing text that sounds natural and informed, albeit a little bland. Through their ‚Äúadvanced autocorrect‚Äù method, they're going to get facts right most of the time. (It's clear what follows ‚Äúthe first president of the USA was ‚Ä¶‚Äù) But it's here where they can start to fall down: The most likely next word isn't always the right one.
Correction, 5/9/2023 : A previous version of this story underestimated how many parameters ChatGPT 3.5 had (it's 175 billion, not 175 million) and stated ChatGPT 4 had upwards of 100 trillion, but reporting between the time this story was published and now indicates the true number may be as low as 1 trillion.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Contributor X Topics artificial intelligence ChatGPT Will Knight Khari Johnson Khari Johnson Gregory Barber Caitlin Harrington Nelson C.J.
Peter Guest Andy Greenberg Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
