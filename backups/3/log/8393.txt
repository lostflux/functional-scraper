Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Pragya Agarwal Ideas Emotional AI Is No Substitute for Empathy Illustration: Scott Balmer Save this story Save Save this story Save In 2023, emotional AI ‚Äîtechnology that can sense and interact with human emotions‚Äîwill become one of the dominant applications of machine learning. For instance, Hume AI, founded by Alan Cowen, a former Google researcher, is developing tools to measure emotions from verbal, facial, and vocal expressions. Swedish company Smart Eyes recently acquired Affectiva, the MIT Media Lab spinoff that developed the SoundNet neural network, an algorithm that classifies emotions such as anger from audio samples in less than 1.2 seconds. Even the video platform Zoom is introducing Zoom IQ, a feature that will soon provide users with real-time analysis of emotions and engagement during a virtual meeting.
This story is from the WIRED World in 2023 , our annual trends briefing. Read more stories from the series here ‚Äîor download or order a copy of the magazine.
In 2023, tech companies will be releasing advanced chatbots that can closely mimic human emotions to create more empathetic connections with users across banking, education, and health care. Microsoft‚Äôs chatbot Xiaoice is already successful in China, with average users reported to have conversed with ‚Äúher‚Äù more than 60 times in a month. It also passed the Turing test, with the users failing to recognize it as a bot for 10 minutes. Analysis from Juniper Research Consultancy shows that chatbot interactions in health care will rise by almost 167 percent from 2018, to reach 2.8 billion annual interactions in 2023. This will free up medical staff time and potentially save around $3.7 billion for health care systems around the world.
In 2023, emotional AI will also become common in schools. In Hong Kong, some secondary schools already use an artificial intelligence program, developed by Find Solutions AI, that measures micro-movements of muscles on the students‚Äô faces and identifies a range of negative and positive emotions. Teachers are using this system to track emotional changes in students, as well as their motivation and focus, enabling them to make early interventions if a pupil is losing interest.
The problem is that the majority of emotional AI is based on flawed science. Emotional AI algorithms, even when trained on large and diverse data sets, reduce facial and tonal expressions to an emotion without considering the social and cultural context of the person and the situation. While, for instance, algorithms can recognize and report that a person is crying, it is not always possible to accurately deduce the reason and meaning behind the tears. Similarly, a scowling face doesn‚Äôt necessarily imply an angry person, but that‚Äôs the conclusion an algorithm will likely reach. Why? We all adapt our emotional displays according to our social and cultural norms, so that our expressions are not always a true reflection of our inner states. Often people do ‚Äúemotion work‚Äù to disguise their real emotions, and how they express their emotions is likely to be a learned response, rather than a spontaneous expression. For example, women often modify their emotions more than men, especially the ones that have negative values ascribed to them such as anger, because they are expected to.
As such, AI technologies that make assumptions about emotional states will likely exacerbate gender and racial inequalities in our society. For example, a 2019 UNESCO report showed the harmful impact of the gendering of AI technologies, with ‚Äúfeminine‚Äù voice-assistant systems designed according to stereotypes of emotional passiveness and servitude.
Facial recognition AI can also perpetuate racial inequalities. Analysis from 400 NBA games with two popular emotion-recognition software programs, Face and Microsoft‚Äôs Face API, were shown to assign more negative emotions on average to Black players, even when they were smiling. These results reaffirm other research showing that Black men have to project more positive emotions in the workplace, because they are stereotyped as aggressive and threatening.
Emotional AI technologies will become more pervasive in 2023, but if left unchallenged and unexamined, they will reinforce systemic racial and gender biases, replicate and strengthen the inequalities in the world, and further disadvantage those who are already marginalized.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker You Might Also Like ‚Ä¶ üì® Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cash‚Äôs Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you üîå Charge right into summer with the best travel adapters , power banks , and USB hubs Topics artificial intelligence algorithms The WIRED World in 2023 Meghan O'Gieblyn Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
