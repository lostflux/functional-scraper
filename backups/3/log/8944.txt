Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Federica Carugati Ideas A Council of Citizens Should Regulate Algorithms Athens‚Äô democracy reminds us that we have been outsourcing governance for two and a half millennia, first to kings, then to experts, and now to machines.
Illustration: WIRED Staff; Getty Images Save this story Save Save this story Save Application Ethics Regulation Safety Technology Machine learning Are machine-learning algorithms biased, wrong, and racist? Let citizens decide.
Essentially rule-based structures for making decisions, machine-learning algorithms play an increasingly large role in our lives. They suggest what we should read and watch, whom we should date, and whether or not we are detained while awaiting trial. Their promise is huge‚Äìthey can better detect cancers. But they can also discriminate based on the color of our skin or the zip code we live in.
Despite their ubiquity in society, no real structure exists to regulate algorithms' use. We rely on journalists or civil society organizations to serendipitously report when things have gone wrong. In the meantime, the use of algorithms spreads to every corner of our lives and many agencies of our government.
 In the post-Covid-19 world, the problem is bound to reach colossal proportions.
Federica Carugati is a program director at the Center for Advanced Study in the Behavioral Sciences at Stanford University. She is the author of Creating a Constitution: Law, Democracy, and Growth in Ancient Athens , and her work has appeared in leading political science journals and academic blogs.
A new report by OpenAI suggests we should create external auditing bodies to evaluate the societal impact of algorithm-based decisions. But the report does not specify what such bodies should look like.
We don‚Äôt know how to regulate algorithms, because their application to societal problems involves a fundamental incongruity. Algorithms follow logical rules in order to optimize for a given outcome. Public policy is all a matter of trade-offs: optimizing for some groups in society necessarily makes others worse off.
Resolving social trade-offs requires that many different voices be heard. This may sound radical, but it is in fact the original lesson of democracy: Citizens should have a say. We don‚Äôt know how to regulate algorithms, because we have become shockingly bad at citizen governance.
Is citizen governance feasible today? Sure, it is. We know from social scientists that a diverse group of people can make very good decisions. We also know from a number of recent experiments that citizens can be called upon to make decisions on very tough policy issues, including climate change , and even to shape constitutions.
 Finally, we can draw from the past for inspiration on how to actually build citizen-run institutions.
The ancient Athenians‚Äîthe citizens of the world‚Äôs first large-scale experiment in democracy‚Äîbuilt an entire society on the principle of citizen governance. One institution stands out for our purposes: the Council of Five Hundred, a deliberative body in charge of all decisionmaking, from war to state finance to entertainment. Every year, 50 citizens from each of the 10 tribes were selected by lot to serve. Selection occurred among those that had not served the year before and had not already served twice.
These simple organizational rules facilitated broad participation, knowledge aggregation, and citizen learning. First, because the term was limited and could not be iterated more than twice, over time a broad section of the population‚Äîrich and poor, educated and not‚Äîparticipated in decisionmaking. Second, because the council represented the whole population (each tribe integrated three different geographic constituencies), it could draw upon the diverse knowledge of its members. Third, at the end of their mandate, councillors returned home with a body of knowledge about the affairs of their city that they could share with their families, friends, and coworkers, some of whom already served and some who soon would. Certainly, the Athenians did not follow through on their commitment to inclusion. As a result, many people‚Äôs voices went unheard, including those of women, foreigners, and slaves. But we don‚Äôt need to follow the Athenian example on this front.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker A citizen council for algorithms modeled on the Athenian example would represent the entire American citizen population. We already do this with juries (although it is possible that, when decisions affect a specific constituency, a better fit with the actual polity might be required). Citizens‚Äô deliberations would be informed by agency self-assessments and algorithmic impact statements for decision systems used by government agencies, and internal auditing reports for industry, as well as reports from investigative journalists and civil society activists, whenever available. Ideally, the council would act as an authoritative body or as an advisory board to an existing regulatory agency. It could evaluate, as OpenAI recommends , a variety of issues including the level of privacy protection, the extent to (and methods by) which the systems were tested for safety, security, or ethical concerns, and the sources of data, labor, and other resources used.
Reports like the one OpenAI just released provide an important first step in the process of getting industry buy-in. The report highlights both the risks of unregulated development of the technology and the benefits of an inclusive process to devise regulatory bodies. For example, industry could play a role in the selection process or in the choice of material available to the councillors, or by providing expert advice.
The council would be a fair and efficient response to the question of how to resolve the societal trade-offs that algorithms create. Unlike proposed technocratic solutions and traditional auditing structures, the council would expand the range of possible solutions to the problems that algorithms create, enhance democratic accountability, and foster citizen participation and learning.
The erosion of commitments to democratic norms and institutions around the world calls for new ideas. The time is ripe for considering creative institutional solutions to tackle some of the greatest challenges society faces. Athens‚Äô democracy reminds us that we have been outsourcing governance for two and a half millennia, first to kings, then to experts, and now to machines. This is an opportunity to reverse the trend.
WIRED Opinion publishes articles by outside contributors representing a wide range of viewpoints. Read more opinions here.
 Submit an op-ed at opinion@wired.com.
A virtual DJ, a drone, and an all-out Zoom wedding Remote work has its perks, until you want a promotion All the tools and tips you need to make bread at home The confessions of Marcus Hutchins, the hacker who saved the internet On the moon, astronaut pee will be a hot commodity üëÅ Is the brain a useful model for AI ? Plus: Get the latest AI news üèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones Topics Wired Opinion artificial intelligence algorithms ethics Meghan O'Gieblyn Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
