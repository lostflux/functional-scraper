Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Peter Guest Business Britainâ€™s Big AI Summit Is a Doom-Obsessed Mess Illustration: Eugene Mymrin/Getty Images Save this story Save Save this story Save The UK government, with its reversals on climate policy and commitment to oil drilling and air pollution , usually seems to be pro-apocalypse. But lately, senior British politicians have been on a save-the-world tour. Prime minister Rishi Sunak, his ministers, and diplomats have been briefing their international counterparts about the existential dangers of runaway artificial superintelligence, which, they warn, could engineer bioweapons, empower autocrats, undermine democracy, and threaten the financial system. â€œI do not believe we can hold back the tide,â€ deputy prime minister Oliver Dowden told the United Nations in late September.
Dowdenâ€™s doomerism is supposed to drum up support for the UK governmentâ€™s global summit on AI governance, scheduled for November 1 and 2. The event is being billed as the moment that the tide turns on the specter of killer AI, a chance to start building international consensus toward mitigating that risk. The summit is an important event for Sunak, who has trumpeted his desire to turn the UK into â€œnot just the intellectual home, but the geographical home of global AI safety regulation,â€ along with broader plans to create a â€œnew Silicon Valleyâ€ and a â€œtechnology superpower.â€ But just over a week before it begins, the summit looks set to be simultaneously doom-laden and underwhelming. Two sources with direct knowledge of the proposed content of discussions say that its flagship initiative will be a voluntary global register of large AI modelsâ€”an essentially toothless initiative. Its ability to capture the full range of leading global AI projects would depend on the good will of large US and Chinese tech companies, which donâ€™t generally see eye to eye.
How is the rest of the summit shaping up? Sources close to negotiations say that the US government is annoyed that the UK has invited Chinese officials (and so are some members of the UKâ€™s ruling Conservative Party). The attendee list hasnâ€™t been released, but leading companies and investors in the UKâ€™s domestic AI sector are angry that theyâ€™ve not been invited, cutting them out of discussions about the future of their industry. And they and other AI experts say that the governmentâ€™s focus on the fringe concern of AI-driven cataclysm means the event will ignore the more immediate real-world risks of the technologyâ€”and all of its potential upsides.
â€œI donâ€™t know what the UK is bringing to the table in all this,â€ says Keegan McBride, lecturer in AI, government, and policy at Oxford Universityâ€™s Internet Institute. â€œTheyâ€™re so narrow in their focus.â€ He and others in the British AI scene argue it would be better for the government to instead look at how it can help British AI companies compete at a moment of rapid change and huge investment in AI.
The summit agenda says that it will cover two types of AI: that which has narrow, but potentially dangerous capabilitiesâ€”such as models that could be used to develop bioweaponsâ€”and â€œfrontier AI,â€ a somewhat nebulous concept that the UK is defining as huge, multipurpose artificial intelligence that matches or exceeds the power of large language models like the one behind OpenAIâ€™s ChatGPT. That filter automatically narrows the list of attendees. â€œOnly a handful of companies are doing this,â€ says McBride. â€œThey're almost all American or Chinese, and the infrastructure that you need to train these sorts of models are basically all owned by American companies like Amazon or Google or Microsoft.â€ WIRED spoke to more than a dozen British AI experts and executives. None had been invited to the summit. The only representative of the UK's AI industry known to be attending is Google DeepMind, which was founded in London but acquired by the search giant in 2014. Thatâ€™s causing a lot of frustration.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œA lot of modern day AI was developed in the UK,â€ says Sachin Dev Duggal, at Builder AI, an AI-powered app development startup based in London. â€œOn one hand weâ€™ll say weâ€™re the AI center of the world, but on the other weâ€™re saying we donâ€™t want to trust our own CEOs and entrepreneurs or researchers to have a more prevalent voice. It doesnâ€™t make sense.â€ Much of the worldâ€™s cloud computing and social media infrastructure is owned by US companies, which already puts UK companiesâ€”and British regulatorsâ€”at a disadvantage, Duggal says. If industry-shaping deals get done without domestic businesses having any input, the next generation of tech could also end up being concentrated in the hands of a few huge US companies. â€œThereâ€™s a group of us that are pretty concerned,â€ he says.
Duggalâ€™s view was shared by others in the UK's AI industry, who complain that the obsession with frontier models misses â€œeverything behind that frontier,â€ as one executive at a unicorn AI startup, speaking anonymously because they still hope for a summit invite, says. That includes every startup, every academic team developing their own AI, and every application of the technology thatâ€™s currently possible, the executive says. The frontier focus also excludes open source language models, the best of which are seen as slightly behind the best available, but can be downloaded and usedâ€”or misusedâ€”by anyone.
The UK government has promised to invest more than $1 billion in AI-related initiatives, including funding to develop the local semiconductor industry, a new supercomputer in Bristol to support AI research, and various task forces and promotion bodies. How much theyâ€™ll help remains to be seenâ€”critics point out that in global terms, itâ€™s not a great deal of money. Powering up both chip and AI industries, while starting well behind the leaders in the US and Asia, with a single billion dollars will be challenging. And the funding is not necessarily flowing into British companies. In May, the CEO of Graphcore, a Bristol-based startup that makes specialist chips for AI, asked the government to earmark some of the funds for UK manufacturers. That didnâ€™t happen, and this month Graphcore warned it needed an injection of cash to stay in business.
â€œWhatâ€™s very weird is the government is saying that AI can do all this sort of stuff, itâ€™s so powerful it can literally end the world,â€ Oxfordâ€™s McBride says. â€œBut you would expect them to also be sort of investigating how to harness its power. The rest of the world is going to be looking to America and to the United Kingdom to figure out how they can use this stuff. And at the moment, the UK doesn't really have much to show the rest of the world.â€ Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker The UKâ€™s parliament hasnâ€™t begun debating any domestic AI regulation on the scale of the European Unionâ€™s AI Act , although the government has released a white paper that recommends a less restrictive set of rules in order to promote growth in the industry. But itâ€™s a long way from being policy or law, and the EU has set the pace.
â€œIt is pretty embarrassing that the UK is not regulating itself,â€ says Mark Brakel, director of policy at the Future of Life Institute, a US think tank that focuses on existential risks. In the US, there are concrete proposals on regulation in the Senate. The EUâ€™s AI Act is close to becoming law. Brazil is developing its own regulations, as is China, Brakel says. â€œBut we have nothing in the UK. If you're the hosts, I think it would make sense if you were able to put something on the table yourself.â€ Brakel, whose institute was behind a headline-grabbing open letter in March that called for a pause on AI developments , is very supportive of the idea of the summit. The institute, which is backed by leading figures in tech, including Skype cocreator Jaan Tallinn, has been very active in lobbying governments to take existential risks seriously. But even Brakelâ€™s hopes for the outcome of the UK event are quite limited. â€œThis is, I think, AI risk 101,â€ Brakel says. â€œI would be really happy if everyone leaving that summit is in agreement about what the most important risks are and what they need to focus on.â€ That may not be enough for Sunak, whose government has expended considerable political capital assembling the summit. US vice president Kamala Harris is set to attend. But the UK has also invited a Chinese delegation, which has reportedly angered US officials, who see Beijing as a strategic threat.
Reports in the UK press suggest that the Chinese officials may now only be allowed to attend half of the summit. European officials will be attendingâ€”although France will host its own AI summit, organized by telecoms billionaire Xavier Niel, two weeks after the UK. On October 18, Chinaâ€™s Cyberspace Administration announced its own global AI governance initiative.
The gatherings hosted by individual countries also have competition from international forums, including the UN and G7, which are looking into multilateral approaches for regulating AI. Itâ€™s not clear how the UKâ€™s approach will differâ€”or if any state-to-state agreement capable of meaningfully changing the course of AI development is possible at such an early stage of development.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œI completely agree with [Sunakâ€™s] strategy, which is to attempt international consensus. But my guess is international consensus will form only around the broadest of principles,â€ says Jeremy Wright, a former UK digital minister for Sunakâ€™s Conservative Party. â€œFeasibly, if you're going to do anything, you probably have to do it nationally before you do it internationally.â€ Two sources with knowledge of discussions confirmed Politicoâ€™s reporting from earlier this month that Sunak will pitch an AI Safety Institute to attendees. And, they said, the British government will propose a register of frontier models that would let governments see inside the black box of frontier AI and get ahead of any potential dangers. The initiative will involve asking model developers to provide early access to their models so they can be â€œred teamedâ€ and their potential risks assessed.
Most of the big US companies have already signed up to an American government pledge on safety.
 Itâ€™s not clear why theyâ€™d feel the need to sign up to a new one, and commit to handing over valuable proprietary information to a UK body.
Critics of the UKâ€™s doom summitâ€”including members of the ruling Conservative Partyâ€”fear it is doomed to, at best, mediocrity. The real reason, they say, that the summit has been rushed through is domestic politics. Itâ€™s something that Sunak can show, or at least pretend, to be leading the world at a time he is trailing in polls and seen as almost certain to lose power in the next election. The evidence of that, several insiders point out, is the choice of venueâ€”a 19th-century country mansion associated with a time when the UK truly was a top global power in computing.
Bletchley Park was where Britainâ€™s World War II cryptographers cracked the Nazi's â€œEnigmaâ€ Code. The site is indelibly linked with one of the most significant figures in British computing, Alan Turingâ€”which is, no doubt, why the government chose it. Practically, it makes less sense. Bletchley Park is 50 miles from London and â€œa pain in the arse to get to,â€ according to one government adviser, speaking on condition of anonymity because they still occasionally work for the Department of Science and Technology. But that distance doesnâ€™t make it conveniently remote and secure either. During the war, the campus was situated away from prying eyes, but it is now on the outskirts of Milton Keynes, a small city built after the war that has long been a punchline in the UK, synonymous with concrete blandness and famed for its profusion of roundabouts.
Itâ€™s a venue that, like the summit itself, suggests to some that symbolism triumphed over substance. One tech executive, speaking on condition of anonymity because he was still hoping to deal with the government, calls it â€œgovernment by photo op.â€ Heâ€™s taking solace in the fact that Sunakâ€™s Conservative Party is likely to lose the next election, which has to be held before January 2025. â€œTheyâ€™ll be gone in 18 months,â€ he says.
You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Topics artificial intelligence Regulation China machine learning UK DeepMind OpenAI ChatGPT Will Knight Khari Johnson Will Knight Will Knight Peter Guest Steven Levy Amanda Hoover Matt Laslo Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
