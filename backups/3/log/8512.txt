Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Paris Martineau Business Maybe Itâ€™s Not YouTubeâ€™s Algorithm That Radicalizes People Play/Pause Button Pause Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save YouTube is the biggest social media platform in the country, and, perhaps, the most misunderstood. Over the past few years, the Google-owned platform has become a media powerhouse where political discussion is dominated by right-wing channels offering an ideological alternative to established news outlets. And, according to new research from Penn State University, these channels are far from fringeâ€”theyâ€™re the new mainstream, and recently surpassed the big three US cable news networks in terms of viewership.
The paper, written by Penn State political scientists Kevin Munger and Joseph Phillips, tracks the explosive growth of alternative political content on YouTube, and calls into question many of the fieldâ€™s established narratives. It challenges the popular school of thought that YouTubeâ€™s recommendation algorithm is the central factor responsible for radicalizing users and pushing them into a far-right rabbit hole.
The authors say that thesis largely grew out of media reports, and hasnâ€™t been rigorously analyzed. The best prior studies, they say, havenâ€™t been able to prove that YouTubeâ€™s algorithm has any noticeable effect. â€œWe think this theory is incomplete, and potentially misleading,â€ Munger and Phillips argue in the paper. â€œAnd we think that it has rapidly gained a place in the center of the study of media and politics on YouTube because it implies an obvious policy solutionâ€”one which is flattering to the journalists and academics studying the phenomenon.â€ Instead, the paper suggests that radicalization on YouTube stems from the same factors that persuade people to change their minds in real lifeâ€”injecting new informationâ€”but at scale. The authors say the quantity and popularity of alternative (mostly right-wing) political media on YouTube is driven by both supply and demand. The supply has grown because YouTube appeals to right-wing content creators, with its low barrier to entry, easy way to make money, and reliance on video, which is easier to create and more impactful than text.
â€œThis is attractive for a lone, fringe political commentator, who can produce enough video content to establish themselves as a major source of media for a fanbase of any size, without needing to acquire power or legitimacy by working their way up a corporate media ladder,â€ the paper says.
According to the authors, that increased supply of right-wing videos tapped a latent demand. â€œWe believe that the novel and disturbing fact of people consuming white nationalist video media was not caused by the supply of this media â€˜radicalizingâ€™ an otherwise moderate audience,â€ they write. â€œRather, the audience already existed, but they were constrainedâ€ by limited supply.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker Other researchers in the field agree, including those whose work has been cited by the press as evidence of the power of YouTubeâ€™s recommendation system. Manoel Ribeiro, a researcher at the Swiss Federal Institute of Technology Lausanne and one of the authors of what the Penn State researchers describe as â€œthe most rigorous and comprehensive analysis of YouTube radicalization to date,â€ says that his work was misinterpreted to fit the algorithmic radicalization narrative by so many outlets that he lost count.
â€œThe novel and disturbing fact of people consuming white nationalist video media was not caused by the supply of this media â€˜radicalizingâ€™ an otherwise moderate audience.â€ Kevin Munger and Joseph Phillips, Penn State University For his study, published in July, Ribeiro and his coauthors examined more othan 330,000 YouTube videos from 360 channels, mostly associated with far right ideology. They broke the channels into four groups, based on their degree of radicalization. They found that a YouTube viewer who watches a video from the second-most-extreme group and follows the algorithmâ€™s recommendations has only a 1-in-1,700 chance of arriving at a video from the most extreme group. For a viewer who starts with a video from the mainstream media, the chance of being shown a video from the most extreme group is roughly 1 in 100,000.
Munger and Phillips cite Ribeiroâ€™s paper in their own, published earlier this month. They looked at 50 YouTube channels that researcher Rebecca Lewis identified in a 2018 paper as the â€œAlternative Influence Network.â€ Munger and Phillipsâ€™ reviewed the metadata for close to a million YouTube videos posted by those channels and mainstream news organizations between January 2008 and October 2018. The researchers also analyzed trends in search rankings for the videos, using YouTubeâ€™s API to obtain snapshots of how they were recommended to viewers at different points over the last decade.
Munger and Phillips divided Lewisâ€™s Alternative Influence Network into five groupsâ€”from â€œLiberalsâ€ to â€œAlt-rightâ€â€”based on their degree of radicalization. Liberals included channels by Joe Rogan and Steven Bonnell II. â€œSkepticsâ€ included Carl Benjamin, Jordan Peterson, and Dave Rubin. â€œConservatives,â€ included YouTubers like Steven Crowder, Dennis Prager of PragerU, and Ben Shapiro. The â€œAlt-Liteâ€ category included both fringe creators that espouse more mainstream conservative views, like InfoWarsâ€™ Paul Joseph Watson, and those that express more explicitly white nationalist messages, like Stefan Molyneux and Lauren Southern. The most exteme category, the â€œAlt-Right,â€ refers to those who push strong anti-Semitic messages and advocate for the genetic superiority of white people, including Richard Spencer, Red Ice TV, and Jean-Francois Gariepy.
This chart shows how total viewership of political videos on YouTube has overtaken the combined viewership on cable news channels.
Illustration: Kevin Munger & Joseph Phillips/Penn State University Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker Munger and Phillips found that every part of the Alternative Influence Network rose in viewership between 2013 and 2016. Since 2017, they say, global hourly viewership of these channels â€œconsistently eclipsedâ€ that of the top three US cable networks combined. To compare YouTubeâ€™s global audience with the cable networksâ€™ US-centric audience, the researchers assumed that each cable viewer watched all three networks for 24 hours straight each day, while each YouTube viewer watched a single video for only 10 minutes.
The sagging red and olive lines show how viewership on YouTube of the most extreme political videos has declined since 2017.
Illustration: Kevin Munger & Joseph Phillips/Penn State University Overall viewership for the Alternative Influence Network has exploded in recent years, mirroring the far-rightâ€™s real-world encroachment on the national stage. But the report found that viewership on YouTube of the most extreme far-right contentâ€”those in the Alt-Lite and Alt-Right groups, specificallyâ€”has actually declined since 2017, while videos in the Conservative category more than doubled in popularity.
Lewis says that the decline could be explained by changes in the universe of right-wing video creators. Some of the creators she included in the list of Alternative Influence Network channels have lost popularity since her study was published, while others have emerged to take their place. However, this latter group was not included in the Penn State researchers' report. Munger said the findings are preliminary and part of a working paper.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker Nonetheless, Lewis praises the Penn State paper as essential reading for anyone studying YouTube politics. She lauded it as the first quantitative study on YouTube to shift focus from the recommendation algorithmâ€”a transition that she says is crucial. Ribeiro agrees, describing it as a fascinating and novel perspective that he believes will encourage broader scholarly analysis in the field.
One thing thatâ€™s clear is that the remaining viewers of Alt-Right videos are significantly more engaged than other viewers, based on an analysis of ratio of likes and comments per video views.
But the most extreme videos still rank highest in engagement, based on an analysis of likes and comments.
Illustration: Kevin Munger & Joseph Phillips/Penn State University Munger and Phillips say they were inspired to illustrate the complexity of YouTubeâ€™s alternative political ecosystem, and to encourage the development of more comprehensive, evidence-based narratives to explain YouTube politics.
â€œFor these far-right groups, the audience is treating it much more as interactive space," said Munger, in reference to the engagement graph above. â€œAnd this could lead to the creation of a community,â€ which is a much more potent persuasive force than any recommendation system. When it comes to radicalization, he says, these are the sorts of factors we should be concerned aboutâ€”not the effects of each algorithmic tweak.
Do you know more about YouTube? Email Paris Martineau at paris_martineau@wired.com.
 Signal: +1 (267) 797-8655. WIRED protects the confidentiality of its sources, but if you wish to conceal your identity, here are the instructions for using SecureDrop.
 You can also mail us materials at 520 Third Street, Suite 350, San Francisco, CA 94107.
The first smartphone war 7 cybersecurity threats that can sneak up on you â€œForever chemicalsâ€ are in your popcornâ€” and your blood EVs fire up pyroswitches to cut risk of shock after a crash The spellbinding allure of Seoul's fake urban mountains ğŸ‘ Prepare for the deepfake era of video ; plus, check out the latest news on AI âœ¨ Optimize your home life with our Gear teamâ€™s best picks, from robot vacuums to affordable mattresses to smart speakers.
Staff Writer X Topics YouTube far-right Social Media research alt right David Gilbert Vittoria Elliott Will Knight Will Knight David Gilbert Christopher Beam Will Knight Susan D'Agostino Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
