Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google’s What-If Tool for TensorBoard helps users visualize AI bias Share on Facebook Share on X Share on LinkedIn Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
With polls showing that more than 70 percent of people in the U.S. remain wary of autonomous machines, the amount of research going into transparency in artificial intelligence (AI) is no surprise. In February, Accenture released a toolkit that automatically detects bias in AI algorithms and helps data scientists mitigate that bias, and in May Microsoft launched a solution of its own. Now, Google is following suit.
The Mountain View company today debuted the What-If Tool , a new bias-detecting feature of the TensorBoard web dashboard for its TensorFlow machine learning framework. With no more than a model and a dataset, users are able to generate visualizations that explore the impact of algorithmic tweaks and adjustments.
“Probing ‘what if’ scenarios [in AI] often means writing custom, one-off code to analyze a specific model,” Google AI software engineer James Wexler wrote in a blog post. “Not only is this process inefficient, it makes it hard for non-programmers to participate in the process of shaping and improving ML models.” Above: Exploring scenarios on a data point within TensorBoard.
Using the What-If Tool, TensorBoard users can manually edit examples from datasets and see the effects of the changes in real time, or generate plots that illustrate how a model’s predictions correspond with any single feature.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Key to this process is counterfactuals and algorithmic fairness analysis. With a button click, the What-If Tool can show a comparison between a data point and the next-closest datapoint where the model predicts a different result. Another click shows the effects of different classification thresholds, and a third has the tool automatically take into account constraints to optimize for fairness.
Wexler wrote that the What-If Tool has been used internally to detect features of datasets that’d been previously ignored and to discover patterns in outputs that contributed to improved models.
The What-If Tool is available in open source starting today. Alongside it, Google published three examples using pretrained models that demonstrate its capabilities.
“One focus … is making it easier for a broad set of people to examine, evaluate, and debug ML systems,” Wexler wrote. “We look forward to people inside and outside of Google using this tool to better understand ML models and to begin assessing fairness.” One needn’t look far for examples of prejudicial AI.
The American Civil Liberties Union in July revealed that Amazon’s Rekognition facial recognition system could, when calibrated a certain way, misidentify 28 sitting members of Congress as criminals, with a strong bias against persons of color. Recent studies commissioned by the Washington Post , meanwhile, revealed that popular smart speakers made by Google and Amazon were 30 percent less likely to understand foreign accents than those of native-born speakers.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
