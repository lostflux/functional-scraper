Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Chris Stokel-Walker Business The Generative AI Race Has a Dirty Secret Illustration: Jacqui VanLiew; Getty Images Save this story Save Save this story Save In early February, first Google, then Microsoft, announced major overhauls to their search engines. Both tech giants have spent big on building or buying generative AI tools, which use large language models to understand and respond to complex questions. Now they are trying to integrate them into search , hoping theyâ€™ll give users a richer, more accurate experience. The Chinese search company Baidu has announced it will follow suit.
But the excitement over these new tools could be concealing a dirty secret. The race to build high-performance, AI-powered search engines is likely to require a dramatic rise in computing power, and with it a massive increase in the amount of energy that tech companies require and the amount of carbon they emit.
â€œThere are already huge resources involved in indexing and searching internet content, but the incorporation of AI requires a different kind of firepower,â€ says Alan Woodward, professor of cybersecurity at the University of Surrey in the UK. â€œIt requires processing power as well as storage and efficient search. Every time we see a step change in online processing, we see significant increases in the power and cooling resources required by large processing centres. I think this could be such a step.â€ Training large language models (LLMs), such as those that underpin OpenAIâ€™s ChatGPT, which will power Microsoftâ€™s souped-up Bing search engine, and Googleâ€™s equivalent, Bard , means parsing and computing linkages within massive volumes of data, which is why they have tended to be developed by companies with sizable resources.
â€œTraining these models takes a huge amount of computational power,â€ says Carlos GÃ³mez-RodrÃ­guez, a computer scientist at the University of CoruÃ±a in Spain.â€œRight now, only the Big Tech companies can train them.â€ While neither OpenAI nor Google, have said what the computing cost of their products is, third-party analysis by researchers estimates that the training of GPT-3, which ChatGPT is partly based on, consumed 1,287 MWh, and led to emissions of more than 550 tons of carbon dioxide equivalentâ€”the same amount as a single person taking 550 roundtrips between New York and San Francisco.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œItâ€™s not that bad, but then you have to take into account [the fact that] not only do you have to train it, but you have to execute it and serve millions of users,â€ GÃ³mez-RodrÃ­guez says.
Thereâ€™s also a big difference between utilizing ChatGPTâ€”which investment bank UBS estimates has 13 million users a day â€”as a standalone product, and integrating it into Bing, which handles half a billion searches every day.
Martin Bouchard, cofounder of Canadian data center company QScale, believes that, based on his reading of Microsoft and Googleâ€™s plans for search, adding generative AI to the process will require â€œat least four or five times more computing per searchâ€ at a minimum. He points out that ChatGPT currently stops its understanding of the world in late 2021, as part of an attempt to cut down on the computing requirements.
In order to meet the requirements of search engine users, that will have to change. â€œIf theyâ€™re going to retrain the model often and add more parameters and stuff, itâ€™s a totally different scale of things,â€ he says.
That is going to require a significant investment in hardware. â€œCurrent data centers and the infrastructure we have in place will not be able to cope with [the race of generative AI],â€ Bouchard says. â€œItâ€™s too much.â€ Data centers already account for around one percent of the worldâ€™s greenhouse gas emissions , according to the International Energy Agency. That is expected to rise as demand for cloud computing increases, but the companies running search have promised to reduce their net contribution to global heating.
â€œItâ€™s definitely not as bad as transportation or the textile industry,â€ GÃ³mez-RodrÃ­guez says. â€œBut [AI] can be a significant contributor to emissions.â€ Microsoft has committed to becoming carbon negative by 2050. The company intends to buy 1.5 million metric tons worth of carbon credits this year. Google has committed to achieving net-zero emissions across its operations and value chain by 2030. OpenAI and Microsoft did not respond to requests for comment.
The environmental footprint and energy cost of integrating AI into search could be reduced by moving data centers onto cleaner energy sources, and by redesigning neural networks to become more efficient, reducing the so-called â€œinference timeâ€â€”the amount of computing power required for an algorithm to work on new data.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œWe have to work on how to reduce the inference time required for such big models,â€ says Nafise Sadat Moosavi, a lecturer in natural language processing at the University of Sheffield, who works on sustainability in natural language processing. â€œNow is a good time to focus on the efficiency aspect.â€ Google spokesperson Jane Park tells WIRED that Google was initially releasing a version of Bard that was powered by a lighter-weight large language model.
â€œWe have also published research detailing the energy costs of state-of-the-art language models, including an earlier and larger version of LaMDA,â€ says Park. â€œOur findings show that combining efficient models, processors, and data centers with clean energy sources can reduce the carbon footprint of a [machine learning] system by as much as 1,000 times.â€ The question is whether itâ€™s worth all the additional computing power and hassle for what could be, in the case of Google at least, minor gains in search accuracy. But Moosavi says that, while itâ€™s important to focus on the amount of energy and carbon being generated by LLMs, there is a need for some perspective.
â€œItâ€™s great that this actually works for end users,â€ she says. â€œBecause previous large language models werenâ€™t accessible to everybody.â€ You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Topics ChatGPT algorithms artificial intelligence climate change environment Magazine-31.05 Gregory Barber Will Knight Will Knight Will Knight Will Knight Peter Guest Steven Levy Vittoria Elliott Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
