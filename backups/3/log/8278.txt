Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business A Letter Prompted Talk of AI Doomsday. Many Who Signed Weren't Actually AI Doomers Photograph: ANNVIPS/Getty Images Save this story Save Save this story Save This March, nearly 35,000 AI researchers, technologists, entrepreneurs, and concerned citizens signed an open letter from the nonprofit Future of Life Institute that called for a ‚Äúpause‚Äù on AI development, due to the risks to humanity revealed in the capabilities of programs such as ChatGPT.
‚ÄúContemporary AI systems are now becoming human-competitive at general tasks, and we must ask ourselves ... Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us?‚Äù I could still be proven wrong, but almost six months later and with AI development faster than ever, civilization hasn‚Äôt crumbled. Heck, Bing Chat , Microsoft‚Äôs ‚Äúrevolutionary,‚Äù ChatGPT-infused search oracle, hasn‚Äôt even displaced Google as the leader in search. So what should we make of the letter and similar sci-fi warnings backed by worthy names about the risks posed by AI? Two enterprising students at MIT, Isabella Struckman and Sofie Kupiec, reached out to the first hundred signatories of the letter calling for a pause on AI development to learn more about their motivations and concerns. The duo‚Äôs write-up of their findings reveals a broad array of perspectives among those who put their name to the document. Despite the letter‚Äôs public reception, relatively few were actually worried about AI posing a looming threat to humanity itself.
Many of the people Struckman and Kupiec spoke to did not believe a six-month pause would happen or would have much effect. Most of those who signed did not envision the ‚Äú apocalyptic scenario ‚Äù that one anonymous respondent acknowledged some parts of the letter evoked.
A significant number of those who signed were, it seems, primarily concerned with the pace of competition between Google , OpenAI , Microsoft , and others, as hype around the potential of AI tools like ChatGPT reached giddy heights. Google was the original developer of several algorithms key to the chatbot‚Äôs creation, but it moved relatively slowly until ChatGPT-mania took hold.
 To these people, the prospect of companies rushing to release experimental algorithms without exploring the risks was a cause for concern‚Äînot because they might wipe out humanity but because they might spread disinformation, produce harmful or biased advice, or increase the influence and wealth of already very powerful tech companies.
Some signatories also worried about the more distant possibility of AI displacing workers at hitherto unseen speed. And a number also felt that the statement would help draw the public‚Äôs attention to significant and surprising leaps in the performance of AI models, perhaps pushing regulators into taking some sort of action to address the near-term risks posed by advances in AI.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Back in May, I spoke to a few of those who signed the letter, and it was clear that they did not all agree entirely with everything it said. They signed out of a feeling that the momentum building behind the letter would draw attention to the various risks that worried them, and was therefore worth backing.
But perhaps it was a mistake to try to cover so many issues potentially raised by existing and recently developed AI in a letter that would inevitably be defined by its most outlandish and scary claim. Some AI researchers have spent the past few years warning presciently about the more immediate societal problems that large language models could cause, including exacerbating ingrained biases. Their concerns were barely audible amid the furor the letter prompted around doomsday scenarios about AI. The prominence of that apocalyptic strand of thinking was reinforced by a follow-up statement in May, also signed by many high-profile AI researchers, that compared the extinction threat of AI to that of nuclear weapons and pandemics.
Nirit Weiss-Blatt , author of The Techlash and Tech Crisis Communication , who reviewed the MIT paper before its publication, says the letter and statement ended up serving the interests of the tech firms building cutting-edge AI, because the focus on far-off worst-case scenarios makes regulators believe the technology is both incredibly valuable and hard to handle. Many of the professors who signed the letter were not thinking about AI as an existential risk as they did so, Weiss-Blatt says. ‚ÄúBut they lent their name to the extreme AI doomers. That‚Äôs the real misinformation here.‚Äù In the end, the letter asking for a pause on AI development may have done the opposite of what many of those who signed wanted. By making discussion of doomsday scenarios more prominent, the letter made it harder for concerns about less-than-superintelligent machines to win notice or inspire action.
Updated 8-17-2023, 1.50 pm EDT: Weiss-Blatt thinks most professors who signed weren't thinking about existential risk, not all.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics Fast Forward artificial intelligence ethics ChatGPT Safety machine learning Will Knight Amit Katwala David Gilbert Khari Johnson Kari McMahon Joel Khalili Andy Greenberg Andy Greenberg Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
