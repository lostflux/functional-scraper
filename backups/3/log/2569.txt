Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business To See the Future of Disinformation, You Build Robo-Trolls Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save Application Identifying Fabrications Text generation Safety Company Open AI Sector Public safety Social media Source Data Text Technology Natural language processing Machine learning Jason Blazakis‚Äô automated far-right propagandist knows the hits. Asked to complete the phrase ‚ÄúThe greatest danger facing the world today,‚Äù the software declared it to be ‚ÄúIslamo-Nazism,‚Äù which it said will cause ‚Äúa Holocaust on the population of Europe.‚Äù The paragraph of text that followed also slurred Jews and admonished that ‚Äúnations who value their peoples [sic] legends need to recognize the magnitude of the Islamic threat.‚Äù Blazakis is director of the Center on Terrorism, Extremism, and Counter-Terrorism at the Middlebury Institute of International Studies, where researchers are attempting to preview the future of online information warfare. The text came from machine-learning software they had fed a collection of manifestos from right-wing terrorists and mass murderers such as Dylann Roof and Anders Breivik. ‚ÄúWe want to see what dangers may lie ahead,‚Äù says Blazakis.
Facebook and other social networks already fight against propaganda and disinformation campaigns , whether originating from terrorist groups like ISIS or accounts that are working on behalf of nation-states. All evidence suggests those information operations are mostly manual, with content written by people. Blazakis says his experiments show it‚Äôs plausible that such groups could one day adapt open source AI software to speed up the work of trolling or spreading their ideology. ‚ÄúAfter playing with this technology, I had a feeling in the pit of my stomach that this is going to have a profound effect on how information is transmitted,‚Äù he says.
Computers are a long way from being able to read or write in the way people do, but in the past two years AI researchers have made significant improvements to algorithms that process language. Companies such as Google and Amazon say their systems have gotten much better at understanding search queries and translating voice commands.
Some people who helped bring about those advances have warned that improved language software could also empower bad actors. Early this year, independent research institute OpenAI said it would not release full code for its latest text-generation software, known as GPT-2, because it might be used to create fake news or spam. This month, the lab released the full software, saying awareness had grown of how next-generation text generators might be abused, and that so far no examples have come to light.
Now some experts in online terrorism and trolling operations‚Äîlike Blazakis‚Äô group at Middlebury‚Äîare using versions of OpenAI‚Äôs GPT-2 to explore those dangers. Their experiments involve testing how well the software can mimic or amplify online disinformation and propaganda material. Although the output can be nonsensical or rambling, it has also shown moments of unnerving clarity. ‚ÄúSome of it is far better-written than right-wing text we have analyzed as scholars,‚Äù says Blazakis.
Philip Tully, a data scientist at security company FireEye, says the notion that text-generating software will become a tool for online manipulation needs to be taken seriously. ‚ÄúAdvanced actors, if they‚Äôre determined enough, are going to use it,‚Äù he says. FireEye, which has helped unmask politically motivated disinformation campaigns on Facebook linked to Iran and Russia , began experimenting with GPT-2 over the summer.
FireEye‚Äôs researchers tuned the software to generate Tweets like those from the Internet Research Agency, a notorious Russian troll farm that used social posts to suppress votes and boost Donald Trump during the 2016 presidential election. OpenAI initially trained GPT-2 on 8 million webpages, a process that gave it a general feeling for language and the ability to generate text in formats ranging from news articles to poetry. FireEye gave the software additional training with millions of tweets and Reddit posts that news organizations and Twitter have linked to the Russian trolls.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Afterwards, the software could reliably generate tweets on political topics favored by the disinformation group, complete with hashtags like #fakenews and #WakeUp America. ‚ÄúThere are errors that crop up, but a user scrolling through a social media timeline is not expecting perfect grammar,‚Äù Tully says.
This was not an especially difficult task: Much of the work was done by a single graduate student, the University of Florida‚Äôs Sajidur Rahman, over the span of a three-month internship. That suggests even a trolling operation without the backing of a nation-state could access the technology. However, a large-scale online disinformation campaign would require much greater effort, since trolls must also maintain and coordinate collections of phony social accounts.
FireEye‚Äôs project also showed AI language software could help clean up disinformation campaigns. The company adapted GPT-2 for use as a kind of disinformation detector that scores new tweets on how similar they were to prior tweets from the IRA. This tool could help FireEye‚Äôs analysts track information operations on Facebook and other sites.
Blazakis and his fellow Middlebury researchers weren‚Äôt focused exclusively on generating extremist right-wing propaganda. The team, to which OpenAI had granted early access to the full version of GPT-2, made three other ideology bots: One was conditioned on speeches from recently deceased ISIS leader Abu Bakr al-Baghdadi, another on writings from Marxist-Leninist thinkers including Mao Zedong, and a third on anarchist books and magazine articles.
Like FireEye, the Middlebury researchers also made tools that attempt to flag machine-generated text. Although the results were promising, it would be a mistake to think spam-style filtering could make the internet immune to this form of disinformation. Blazakis expects such text to get more convincing over time, while filtering will not be deployed widely. ‚ÄúThe average person reading Twitter or a Reddit board is not going to have access to AI detection tools,‚Äù he says.
The Middlebury researchers now plan to test how persuasive AI-made text might be. They will soon begin trials testing whether people in the lab can tell the difference between real extremist writings and those generated by an ideological automaton.
Updated 11-19-19, 7.25 pm EST: This story was updated to correct the spelling of Jason Blazakis's last name.
Meet the immigrants who took on Amazon This martini wants to kill climate change one sip at a time The super-optimized dirt that helps keep racehorses safe 15 gift ideas for anyone who works from home Socked into the puppet-hole on Wikipedia üëÅ A safer way to protect your data ; plus, the latest news on AI üíª Upgrade your work game with our Gear team‚Äôs favorite laptops , keyboards , typing alternatives , and noise-canceling headphones Senior Editor X Topics artificial intelligence trolls online harassment Will Bedingfield Will Knight Matt Burgess Will Knight David Gilbert Will Knight Will Knight Khari Johnson Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
