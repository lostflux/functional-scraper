Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Cade Metz Business Google's AI Wins Pivotal Second Game in Match With Go Grandmaster Geordie Wood for WIRED Save this story Save Save this story Save SEOUL, SOUTH KOREA --- After more than four hours of tight play and a rapid-fire endgame, Google's artificially intelligent Go-playing computer system has won a second contest against grandmaster Lee Sedol, taking a two-games-to-none lead in their historic best-of-five match in downtown Seoul.
The surprisingly skillful Google machine, known as AlphaGo, now needs only one more win to claim victory in the match. The Korean-born Lee Sedol will go down in defeat unless he takes each of the match's last three games. Though machines have beaten the best humans at chess, checkers, Othello, Scrabble, Jeopardy! , and so many other games considered tests of human intellect, they have never beaten the very best at Go. Game Three is set for Saturday afternoon inside Seoul's Four Seasons hotel.
The match is a way of judging the suddenly rapid progress of artificial intelligence.
 One of the machine-learning techniques at the heart of AlphaGo has already reinvented myriad online services inside Google and other big-name Internet companies, helping to identify images, recognize commands spoken into smartphones, improve search engine results, and more. Meanwhile, another AlphaGo technique is now driving experimental robotics at Google and places like the University of California at Berkeley. This week's match can show how far these technologies have come---and perhaps how far they will go.
Created in Asia over 2,500 year ago, Go is exponentially more complex than chess, and at least among humans, it requires an added degree of intuition. Lee Sedol is widely-regarded as the top Go player of the last decade, after winning more international titles than all but one other player. He is currently ranked number five in the world, and according to Demis Hassabis, who leads DeepMind, the Google AI lab that created AlphaGo, his team chose the Korean for this all-important match because they wanted an opponent who would be remembered as one of history's great players.
Although AlphaGo topped Lee Sedol in the match's first game on Wednesday afternoon , the outcome of Game Two was no easier to predict.
In his 1996 match with IBM's Deep Blue supercomputer , world chess champion Gary Kasparov lost the first game but then came back to win the second game and, eventually, the match as a whole. It wasn't until the following year that Deep Blue topped Kasparov over the course of a six-game contest. The thing to realize is that, after playing AlphaGo for the first time on Wednesday, Lee Sedol could adjust his style of play---just as Kasparov did back in 1996. But AlphaGo could not. Because this Google creation relies so heavily on machine learning techniques, the DeepMind team needs a good four to six weeks to train a new incarnation of the system. And that means they can't really change things during this eight-day match.
"This is about teaching and learning," Hassabis told us just before Game Two. "One game is not enough data to learn from---for a machine---and training takes an awful lot of time." Culture Taylor Swift and Beyoncé Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple’s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden’s Tesla Blockade Is Spreading Morgan Meaker Geordie Wood for WIRED Following Game One, Lee Sedol acknowledged he was "shocked" by how well AlphaGo played and said he'd made a notable mistake at the beginning of the game that led to his loss about three hours later. "The failure I made at the very beginning of the game lasted until the the very end," he said, through an interpreter. "I didn’t think that AlphaGo would play the game in such a perfect manner." It's unclear what early mistake he was referring to. The match's English language commentators didn't see one. But they do feel the Korean made a rather large error late in the game, following some particularly skillful play by AlphaGo. In any event, Lee Sedol did resolve to change his approach in Game Two.
The added rub was that, after playing black in Game One, the Korean had to play white in Game Two. At the press conference following Game One, Lee Sedol gave himself a 50-50 chance in the second game---a notable shift in attitude for the Go grandmaster, who was nothing less than adamant earlier in the week that he would defeat Google's artificially intelligent creation. "I am in shock. I can admit that," Lee Sedol said after Game One. "But what's done is done." Culture Taylor Swift and Beyoncé Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple’s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden’s Tesla Blockade Is Spreading Morgan Meaker AlphaGo showed in the first game that it has a taste for the attack---something it didn't necessarily show this past October, when it beat three-time European Go champion Fan Hui during a closed-door match inside DeepMind headquarters. The question going into Game Two was whether it would attack just as aggressively when given the advantage of playing black.
Attack it did. As commentator Michael Redmond put it, AlphaGo started "fast," and seven moves in, the machine made what he called a "slightly unusual move." He wasn't prepared to say whether it was a good move or a bad move, but it was aggressive, as if the machine was trying to force Lee Sedol into action. It soon made another move along the same lines.
But Lee Sedol didn't necessarily bite. At this point in the game, he took a rather long time considering his position and then continued with a comparatively cautious approach, according to Redmond. On the whole, Redmond said, the game was moving slower than it had at the same point in Game One. "White is playing a much more conservative game," Redmond said, referring to Lee Sedol. Perhaps the Korean had adopted an added degree of caution after considering how well AlphaGo performed in Game One, but a certain amount of caution was expected because he was playing white, not black.
Regardless, AlphaGo was showing---once again---that it's significantly more skilled than it was in October when it topped Fan Hui, the European Go champion who was ranked 633rd in the world at the time. For Redmond, the current version of AlphaGo not only plays more aggressively. It makes fewer mistakes.
Then, with its 19th move, AlphaGo made an even more surprising and forceful play, dropping a black piece into some empty space on the right-hand side of the board. Lee Sedol seemed just as surprised as anyone else. He promptly left the match table, taking an (allowed) break as his game clock continued to run. "It's a creative move," Redmond said of AlphaGo's sudden change in tack. "It's something that I don't think I've seen in a top player's game." When Lee Sedol returned to the match table, he took an usually long time to respond, his game clock running down to an hour and 19 minutes, a full twenty minutes less than the time left on AlphaGo's clock. "He's having trouble dealing with a move he has never seen before," Redmond said. But he also suspected that the Korean grandmaster was feeling a certain "pleasure" after the machine's big move. "It's something new and unique he has to think about," Redmond explained. "This is a reason people become pros." Culture Taylor Swift and Beyoncé Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple’s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden’s Tesla Blockade Is Spreading Morgan Meaker Geordie Wood for WIRED Back in 1997, during its second match with Gary Kasparov, IBM Deep Blue made a similar move very early in the second game. But it didn't give Kasparov much pleasure. Kasparov was completely flummoxed, and much to the surprise of the chess world, he soon resigned the game. It highlighted a certain advantage that machines carry in a match like this. They don't get upset. And they can rile opponents simply by doing something that no human would do---or at least that no human would anticipate from a machine. "Computers are able to make moves that are unexpected by people," says Murray Campbell, who was part of the team that built Deep Blue and is closely watching this week's match back in the States.
This is particularly true of AlphaGo, which is driven so heavily by machine learning---technologies that allow it to learn tasks largely on its own. Hassabis and his team originally built AlphaGo using what are called deep neural networks, vast networks of hardware and software that mimic the web of neurons in the human brain. Essentially, they taught AlphaGo to play the game by feeding thousands upon thousands of human Go moves into these neural networks.
But then, using a technique called reinforcement learning, they matched AlphaGo against itself.
 By playing match after match on its own, the system could learn to play at an even higher level---perhaps at a level that eclipses the skills of any human. That's why it produces such unexpected moves.
Culture Taylor Swift and Beyoncé Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple’s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden’s Tesla Blockade Is Spreading Morgan Meaker During Game One, match commentators Michael Redmond and Chris Garlock didn't seem to understand that AlphaGo operated in this way. Redmond kept referring to AlphaGo's "database" of moves---something it doesn't really have. Once the system is trained using those machine learning techniques, it plays entirely on its own. By Game Two, Redmond and Garlock were wise to this, after some coaching from the DeepMind team over breakfast here at the Four Seasons.
During the match, the commentators even invited DeepMind research scientist Thore Graepel onto their stage to explain the system's rather autonomous nature. "Although we have programmed this machine to play, we have no idea what moves it will come up with," Graepel said. "Its moves are an emergent phenomenon from the training. We just create the data sets and the training algorithms. But the moves it then comes up with are out of our hands---and much better than we, as Go players, could come up with." After AlphaGo's rather unexpected play on his 19th move, the Google machine was very much the aggressor. But then things tightened up, with Lee Sedol commanding some notable territory. Match commentators were unable to make a real call on who was ahead and who was behind.
This reflects another aspect of the machine learning technology that underpins AlphaGo. As Graepel explained, AlphaGo does not attempt to maximize its points or its margin of victory. It tries to maximize its probability of winning. So, Graepel said, if AlphaGo must choose between a scenario where it will win by 20 points with 80 percent probability and another where it will win by 1 and a half points with 99 percent probability, it will choose the latter. Thus, late in Game One, the system made some moves that Redmond considered mistakes---"slow" in his terminology. These moves seemed to give up points, but from where Graepel was sitting, AlphaGo was merely trying to maximize its chances.
Near the two-hour mark in Game Two, Lee Sedol made a move in the top left-hand corner, at the heart of the territory commanded by AlphaGo, and Redmond said: "Things are really going to get fun now." The Korean was back on the offensive, and Redmond predicted a "close game"---something he said so often during Game One. "My assessment will likely be changing," Redmond later said, "with every move." Unlike Game One, when Lee Sedol resigned after about three and a half hours, the Korean kept playing as the match approached its fourth hour. At the three and a half hour mark, Redmond felt that Lee Sedol might have a small territorial advantage. Shortly thereafter, the grandmaster's clock ran out, which meant he was forced to play each of his remaining moves in under 60 seconds. But Redmond believed that Lee Sedol had made most of his major decisions, and that he could easily play out the game at speed.
The result was a rapid-fire end game. Lee Sedol began rocking back and forth in his chair during his first 60 seconds of overtime and continued to do so even after he made his move. In terms of territory, the Korean seemed to hold his own. But time was indeed an issue. Twice, he let his 60 second clock run out (on the third time, he forfeits the game), an indication that we was still unsure how things should play out. "I have a feeling---and maybe Lee Sedol has a feeling---that black is ahead," Redmond said.
Lee Sedol started to rock again, and the other English commentator, Chris Garlock, insisted he saw sweat on the Korean's brow. Then the grandmaster began punctuating his moves with an almost despondent shaking of the head. As the match stretched well into its fourth hour, AlphaGo entered overtime as well, and both players were limited to 60 seconds per move. The pace picked up again, before only for so long. Just a few minutes later, Lee Sedol resigned.
Friday is a rest day for the two players. That favors the Korean. And on Saturday, unlike today, he will play black and move first.
Senior Writer X Topics AlphaGo deep learning DeepMind Enterprise Google Gregory Barber Caitlin Harrington Nelson C.J.
Peter Guest Andy Greenberg Khari Johnson Joel Khalili David Gilbert Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
