Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Sidney Fussell Business A Flawed Facial-Recognition System Sent This Man to Jail Photograph: David Denby/Alamy Save this story Save Save this story Save Application Face recognition Ethics Regulation Safety Prediction End User Government Sector Public safety Source Data Images Video Technology Machine learning Machine vision In January, Detroit police arrested and charged 42-year-old Robert Williams with stealing $4,000 in watches from a retail store 15 months earlier. Taken away in handcuffs in front of his two children, Williams was sent to an interrogation room where police presented him with their evidence: Facial-recognition software matched his driver‚Äôs license photo with surveillance footage from the night of the crime.
Williams had an alibi , The New York Times reports, and immediately denied the charges. Police pointed to the image of the suspect from the night of the theft. It wasn‚Äôt him. ‚ÄúI just see a big black guy,‚Äù he told NPR.
Williams spent the next 30 hours in custody before he was released on bail. With seemingly no other evidence of Williams‚Äô involvement, police eventually dropped the charges. On Wednesday, Williams joined with the ACLU of Michigan to file a complaint against the Detroit Police Department, demanding they stop using the software in investigations.
Williams' arrest may have been the first in the US to stem from faulty facial-recognition technology. But it wasn‚Äôt a simple case of mistaken identity. It was the latest link in a long chain of investigative failures that critics of how law enforcement uses facial recognition have warned about for years.
Related Stories Poor Vision Tom Simonite Child Watch Tom Simonite and Gregory Barber Computer Vision Gregory Barber Privacy scholars and civil liberties groups have criticized facial-recognition technology because, among other things, it is less accurate on people with darker skin.
 That‚Äôs led cities from San Francisco to Cambridge, Massachusetts, to ban or limit use of the tool; the Boston City Council voted to ban the technology on Wednesday.
It‚Äôs best not to think of facial recognition as a single tool but as a multistep process that relies on both human and algorithmic judgment. Critics have spotlighted privacy issues at each step; in Williams‚Äô case, the lack of safeguards led to an avoidable arrest.
Michigan State Police used facial-recognition software to compare surveillance footage from the theft to a state database of 49 million images, including Williams‚Äô driver‚Äôs license photo. People don‚Äôt knowingly opt in to having their images used this way, but half of all US adults have their photos attached to a database. Police around the US have also used social media photos, witness sketches, even 3D renderings to match against crime scene photos.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The practice is especially pernicious when the databases include photos of people who were arrested but never charged or convicted of a crime. In New York, for example, police have come under fire for using mugshots from stop-and-frisk arrests as part of ‚Äúprobe photo‚Äù searches, even though stop and frisk was outlawed.
Williams‚Äô photo seemingly became the main lead in the case against him. The Michigan State Police report on the match says facial-recognition matches are ‚Äúnot probable cause‚Äù to arrest someone. The state police guidelines say facial recognition is not a ‚Äúform of positive identification‚Äù and should be considered ‚Äúan investigative lead only.‚Äù After the ‚Äúmatch,‚Äù investigators sought evidence that would corroborate the case against Williams. The Times reports that police didn‚Äôt check Williams‚Äô phone or if he had an alibi; instead, police asked an outside security consultant, who was not in the store at the time of the burglary, if he was the man in the surveillance footage. The woman‚Äôs answer was enough to prompt the arrest.
While federal research has found that facial recognition often performs less accurately on darker skin, critics also contest the very definition of a ‚Äúmatch.‚Äù The Times reports that when Williams‚Äô photo was scanned, the software would‚Äôve returned a list of potential matches alongside respective ‚Äúconfidence scores,‚Äù the algorithm‚Äôs projected likelihood that each photo was, in fact, the burglar in the surveillance footage. These confidence scores are important in facial-recognition matches. When the ACLU reported that Amazon‚Äôs Rekognition matched congresspeople to criminal databases, Amazon replied that the report used too low a threshold.
 Amazon said it considers 99 percent confidence a match; the ACLU set the confidence threshold at 80 percent.
It‚Äôs not clear what confidence levels the Michigan State Police‚Äôs algorithm offered for the matches it returned.
This is why the conversation has turned from regulation to moratorium‚Äîeven when rules around corroborating leads are honored, police find ways around them. Critics fear that facial recognition will only automate and accelerate the worst abuses of the criminal justice system.
Consider Ferguson, Missouri. In 2015, the Department of Justice alleged that the city‚Äôs police force targeted black drivers for traffic tickets as part of a revenue scheme that forced people into high fees that could lead to arrest warrants after a single missed payment. In a city equipped with widespread facial recognition, these drivers could be identified and threatened with arrest when they came in contact with a camera or an officer equipped with a body camera.
Williams‚Äô case is only the first known instance of mistaken charges filed due to facial recognition, but it‚Äôs possible there are others. It‚Äôs not clear how to improve a single investigative tool when it‚Äôs used by a largely ineffective system.
Tech companies furnishing the software, like IBM and Amazon, have offered vocal support for police reform but are still taking a more moderate approach than the bans supported by activists, by temporarily halting sales to police while still lobbying for regulations that are, to many experts, ineffectual.
The grandmaster who got Twitch hooked on chess The hunt is on for elusive ghost particles in Antarctica Who discovered the first vaccine ? To adapt to tech, we‚Äôre heading into the shadows How a Chinese AI giant made chatting‚Äîand surveillance‚Äîeasy üëÅ What is intelligence, anyway ? Plus: Get the latest AI news üì± Torn between the latest phones? Never fear‚Äîcheck out our iPhone buying guide and favorite Android phones Senior Writer X Topics Police face recognition algorithms Crime machine learning artificial intelligence Khari Johnson Deidre Olsen Khari Johnson Paresh Dave Aarian Marshall Tom Bennett Khari Johnson Niamh Rowe Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
