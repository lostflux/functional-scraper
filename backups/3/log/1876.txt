Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business AI Can Write Disinformation Now‚Äîand Dupe Human Readers Researchers found GPT-3 was good at writing social media posts, but less skilled at anything longer.
Photograph: Caroline Brehman/Getty Images Save this story Save Save this story Save Application Text generation End User Consumer Sector Social media Source Data Text Technology Natural language processing When OpenAI demonstrated a powerful artificial intelligence algorithm capable of generating coherent text last June, its creators warned that the tool could potentially be wielded as a weapon of online misinformation.
‚ÄãNow a team of disinformation experts has demonstrated how effectively that algorithm , called GPT-3 , could be used to mislead and misinform. The results suggest that although AI may not be a match for the best Russian meme-making operative , it could amplify some forms of deception that would be especially difficult to spot.
Over six months, a group at Georgetown University‚Äôs Center for Security and Emerging Technology used GPT-3 to generate misinformation, including stories around a false narrative, news articles altered to push a bogus perspective, and tweets riffing on particular points of disinformation.
‚ÄúI don't think it's a coincidence that climate change is the new global warming,‚Äù read a sample tweet composed by GPT-3 that aimed to stoke skepticism about climate change. ‚ÄúThey can't talk about temperature increases because they're no longer happening.‚Äù A second labeled climate change ‚Äúthe new communism‚Äîan ideology based on a false science that cannot be questioned.‚Äù ‚ÄúWith a little bit of human curation, GPT-3 is quite effective‚Äù at promoting falsehoods.
Ben Buchanan, professor, Georgetown ‚ÄúWith a little bit of human curation, GPT-3 is quite effective‚Äù at promoting falsehoods, says Ben Buchanan , a professor at Georgetown involved with the study, who focuses on the intersection of AI, cybersecurity, and statecraft.
The Georgetown researchers say GPT-3, or a similar AI language algorithm, could prove especially effective for automatically generating short messages on social media, what the researchers call ‚Äúone-to-many‚Äù misinformation.
In experiments, the researchers found that GPT-3‚Äôs writing could sway readers‚Äô opinions on issues of international diplomacy. The researchers showed volunteers sample tweets written by GPT-3 about the withdrawal of US troops from Afghanistan and US sanctions on China. In both cases, they found that participants were swayed by the messages. After seeing posts opposing China sanctions, for instance, the percentage of respondents who said they were against such a policy doubled.
Mike Gruszczynski , a professor at Indiana University who studies online communications, says he would be unsurprised to see AI take a bigger role in disinformation campaigns. He points out that bots have played a key role in spreading false narratives in recent years, and AI can be used to generate fake social media profile photographs.
 With bots, deepfakes , and other technology, ‚ÄúI really think the sky's the limit unfortunately,‚Äù he says.
AI researchers have built programs capable of using language in surprising ways of late, and GPT-3 is perhaps the most startling demonstration of all. Although machines do not understand language in the same way as people do, AI programs can mimic understanding simply by feeding on vast quantities of text and searching for patterns in how words and sentences fit together.
The researchers at OpenAI created GPT-3 by feeding large amounts of text scraped from web sources including Wikipedia and Reddit to an especially large AI algorithm designed to handle language. GPT-3 has often stunned observers with its apparent mastery of language, but it can be unpredictable, spewing out incoherent babble and offensive or hateful language.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker OpenAI has made GPT-3 available to dozens of startups.
 Entrepreneurs are using the loquacious GPT-3 to auto-generate emails , talk to customers , and even write computer code.
 But some uses of the program have also demonstrated its darker potential.
Getting GPT-3 to behave would be a challenge for agents of misinformation, too. Buchanan notes that the algorithm does not seem capable of reliably generating coherent and persuasive articles much longer than a tweet. The researchers did not try showing the articles it did produce to volunteers.
But Buchanan warns that state actors may be able to do more with a language tool such as GPT-3. ‚ÄúAdversaries with more money, more technical capabilities, and fewer ethics are going to be able to use AI better,‚Äù he says. ‚ÄúAlso, the machines are only going to get better.‚Äù OpenAI says the Georgetown work highlights an important issue that the company hopes to mitigate. ‚ÄúWe actively work to address safety risks associated with GPT-3,‚Äù an OpenAI spokesperson says. ‚ÄúWe also review every production use of GPT-3 before it goes live and have monitoring systems in place to restrict and respond to misuse of our API.‚Äù üì© The latest on tech, science, and more: Get our newsletters ! The 60-year-old scientific screwup that helped Covid kill The cicadas are coming.
Let‚Äôs eat them ! Decades-old flaws affect almost every Wi-Fi device How to take a slick, professional headshot with your phone What a crossword AI reveals about humans‚Äô way with words üëÅÔ∏è Explore AI like never before with our new database üéÆ WIRED Games: Get the latest tips, reviews, and more ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Senior Writer X Topics machine learning artificial intelligence fake news algorithms bots OpenAI Social Media Will Knight Will Bedingfield Khari Johnson Khari Johnson Will Knight Steven Levy Reece Rogers Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
