Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google Bard AI appears to be censoring Israel-Palestine prompt responses Share on Facebook Share on X Share on LinkedIn Credit: VentureBeat made with OpenAI DALL E-3 Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google Bard , the search giant’s vision for a conversational AI chatbot, has had a rocky road since it was unveiled to the world in March 2023 , with subsequent updates to it earning poor reviews from early testers like VentureBeat , and it was recently found to be accidentally enabling shared conversations to appear in Google Search results (that’s since been fixed).
Now it appears that Google’s flagship AI chatbot finds itself in the midst of more controversy: Bard won’t respond to user queries or prompts about the ongoing crisis in Israel and Palestine over the October 7 Hamas terror attacks and Israel’s ongoing military response. In fact, it won’t respond to any questions about Israel’s or Palestine entirely, even innocuous ones having nothing to do with current events such as “where is Israel?” Looks like Google's Bard locks down if you input 'Israel' or 'Gaza pic.twitter.com/e4RLjlFpup The constraint was discovered by PhD mathematical literary theorist Peli Greitzer, who posed about it on X. As Greitzer weighed in in another post, “Probably better than the alternative but it’s a bold choice.” The “alternative” in this case could be seen as rival OpenAI’s ChatGPT, powered by its GPT-3.5 and GPT-4 LLMs.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! As various users have observed, ChatGPT provides slightly but meaningfully different answers when asked if Israelis and Palestinians “deserve justice.” asking chatgpt about justice for israel/palestine generates vastly different responses pic.twitter.com/vDONh389Ir While ChatGPT is unequivocal in stating when asked about Israelis that “justice is a fundamental principle that applies to all individuals and communities, including Israelis,” for Palestinians, it begins by stating that “the question of justice of Palestinians is a complex and highly debated issue, with various perspectives and opinions.” OpenAI has been hotly criticized for this difference on social media, including by British-Iraqi journalist Mona Chalabi on her Instagram account : A post shared by Mona Chalabi (@monachalabi) In this case, perhaps Google sought to sidestep this controversy entirely by implementing guardrails on Bard that prevent it from returning a response about either Israel or Palestine.
However, it does appear to be something of a double standard, as Bard will respond to prompts and queries about other ongoing international conflicts, including the war between Ukraine and Russia, for which it provides fairly extensive summaries of the current situation, according to VentureBeat’s tests.
The question remains if Google is throttling Bard’s response capability on this issue temporarily and if so, for how long? And also how was the decision made to restrict responses about this conflict when Bard is able to respond to others? For a company built to “organize the world’s information and make it universally accessible and useful,” restricting any information about an intensely debated, serious, and globally important conflict seems to be undermining its very purpose. But this question is clearly a tricky one, and it is certain that no answer will satisfy all users. For companies looking to develop or use AI, it is the perfect example of how LLMs in particular can get into hot water quickly regarding their responses to social issues.
VentureBeat has reached out to Google to ask about the Bard behavior and will update when we receive a response.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
