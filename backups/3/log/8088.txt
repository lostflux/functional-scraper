Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages The quandary of Kubernetes: How Rafay is helping curb cloud spending Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Kubernetes is experiencing record growth — according to one survey, 96% of organizations are using or evaluating the open-source container orchestration system.
But ever-expanding Kubernetes environments result in growing clusters, application teams and infrastructure. In turn, this translates to increased spending, as well as difficulty in understanding just where and how that spending is occurring.
“Without controls or limits, an individual application team can overprovision resources for their application, without knowing the full cost impact of utilizing these resources, resulting in wasted spend,” said Mohan Atreya, SVP of product and solutions at Rafay.
To help mitigate this, Rafay — a Kubernetes management and operations platform — today launched Cost Management Service, a new tool intended to provide real-time visibility and allocation of Kubernetes cloud costs.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! When organizations attempt to do it on their own, “Kubernetes cloud cost management across multiple clusters, application teams and infrastructure is a challenging ambition,” said Atreya.
Increased use, complexity Originally designed by Google, Kubernetes automates software deployment, scaling and management in hybrid and multi-cloud environments.
One of its many advantages is that its workloads can operate in single clouds, private data centers or across multiple cloud environments, said Atreya. This allows organizations to use it to deploy and manage applications in a more agile, scalable way, while simultaneously avoiding cloud vendor lock-in.
Since Kubernetes also provides container integrations and access to different cloud providers, processes are more efficient for devops and platform teams, said Atreya. It is reliable because, if one node in a multi-node cluster fails, an application is redistributed to others without disrupting users of the application.
Furthermore, Kubernetes provides self-healing capabilities and will automatically restart, reschedule or replace an application (or parts of an application) when it fails. And, its autoscaling capabilities allow applications to scale up and down based on actual demand.
“This positively impacts end-user performance, along with budget management,” said Atreya.
But this benefit is only so long as cluster environments are appropriately managed — which, oftentimes, they aren’t, he pointed out.
Cloud cost optimization Today, 81% of organizations are using multi-cloud infrastructures (or will be soon). At the same time, 94% are overspending in the cloud.
Kubernetes’ resource consumption and spending only contribute to this, said Atreya.
Organizations aim to save money by having multiple application and business teams run Kubernetes workloads in the same clusters, he said. But this is ultimately counterintuitive, as it creates a challenge in viewing total cloud spend, evaluating what resources each team is using, and reporting how spend is allocated across departments.
Rafay — which competes with Mirantis Kubernetes Engine, Google Kubernetes Engine, Portainer and D2iQ, among others — has integrated its new cost management service into its existing Kubernetes Operations Platform (KOP).
The new tool provides organizations the ability to accomplish the following: – View and access cost metrics based on roles by pre-integrating with RBAC (application, FinOps and platform see cost metrics upon login).
– Optimize cloud budget by appropriately billing internal teams based on their resource consumption of shared resources.
– Create custom dashboards to view aggregated cost metrics for different internal groups and departments.
– Configure and implement cost management on a fleet of Kubernetes clusters with a single click.
Cost management: A team sport For example, Atreya pointed out, one Rafay customer — a large, global real estate services firm — has standardized on Rafay’s platform to provide application teams a self-service experience. The firm’s strategy is to empower various business units and application teams to select from several deployment options for Kubernetes infrastructure through a centralized platform and provide them visibility into associated costs.
“This level of transparency and flexibility allows the application teams to select the most optimal option, balancing application requirements and their budgets,” said Atreya.
Ultimately, application teams that have visibility into resource utilization metrics as well as associated infrastructure costs are better prepared to make decisions on cost-saving strategies (such as resource requests tuning or cluster sharing), he said.
Organizations should provide incentives to help application teams transition from treating cost management as good hygiene, rather than a burden. For example, Rafay has seen organizations implement internal awards for the most cost-effective application in their portfolio.
Platform teams should also provide well-documented, easy-to-use internal frameworks and best practices that application teams can use without much effort. For instance, a simple application onboarding questionnaire that recommends ideal approaches — such as “namespace on a shared cluster,” “workspace with multiple namespaces on a shared cluster,” or “dedicated cluster.” Rather than limiting access to cost data to a central team that then periodically disseminates this downstream, “it is more effective to democratize access and visibility to cost data,” said Atreya.
“Cost management is a team sport,” said Atreya. “Therefore, it is important to have the application teams be active participants in the process.” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
