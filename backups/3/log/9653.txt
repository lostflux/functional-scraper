Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Aarian Marshall Transportation Teaching Self-Driving Cars to Watch for Unpredictable Humans Photograph: David McGlynn/Getty Images Save this story Save Save this story Save Application Human-computer interaction Safety Autonomous driving End User Research Sector Automotive Technology Machine learning Machine vision If you happen to live in one of the cities where companies are testing self-driving cars, youâ€™ve probably noticed that your new robot overlords can be occasional nervous drivers. In Arizona, where SUVs operated by Waymo are sometimes ferrying passengers without anyone behind the steering wheel, drivers have complained about the robot carsâ€™ too-timid left turns and slow merges on the highway.
 Data compiled by the state of California suggests that the most common self-driving fender benders are rear-end crashes , in part because human drivers donâ€™t expect autonomous cars to follow road rules and come to complete, non-rolling stops at stop signs.
As for human drivers, some are nervous and scrupulous, others are definitely not. In fact, itâ€™s even more complex: Some drivers are careful in some moments and hard-charging in others. Think: casual Sunday drive to the grocery store versus racing to get the kid before the day care late fees kick in. Robot cars might be smoother, and might make better decisions, if they knew exactly what sort of humans were driving near them.
Want the latest news on self-driving cars in your inbox? Sign up here ! Researchers at MITâ€™s Computer Science and Artificial Intelligence Laboratory and Delft Universityâ€™s Cognitive Robotics lab say theyâ€™ve figured out how to teach self-driving vehicles just that. In a recent paper published in the Proceedings of the National Academy of Sciences , they describe a technique that translates sociology and psychology into a mathematical formula that can be used to teach self-driving software how to tell the road ragers from the rule followers. Vehicles equipped with their technique can differentiate between the two in about two seconds, the researchers say, and can use the info to help decide how to proceed on the road. The technique improves self-driving vehiclesâ€™ predictions about human driversâ€™ decisions, and therefore the vehiclesâ€™ on-road performance, by 25 percent, as measured by a test involving merging in a computer simulation.
The idea, the researchers say, is not just to create a system that can differentiate â€œegoisticâ€ drivers from â€œprosocialâ€ driversâ€”that is, the selfish ones from generous ones. The scientists hope to make it easier for robots to adapt to human behavior, and not the other way around.
Courtesy of MIT CSAIL Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œWe are very much interested in how human-driven vehicles and robots can coexist,â€ says Daniela Rus, director of the MIT lab and a coauthor of the paper. â€œItâ€™s a grand challenge for the field of autonomy and a question thatâ€™s applicable not just for robots on roads but in general, for any kind of human-machine interaction.â€ One day, this kind of work might be able to help humans work more smoothly with robots on, say, the factory floor or in a hospital room.
But first, game theory. The research pulls from an approach being applied more frequently in robotics and machine learning: using games to â€œteachâ€ machines to make decisions with imperfect knowledge. Game playersâ€”like driversâ€”often have to reach conclusions without full understanding of what the other playersâ€”or driversâ€”are doing. So more researchers are applying game theory to train self-driving cars how to act in uncertain situations.
Still, the uncertainty is a challenge. â€œUltimately, one of the challenges of self-driving is that youâ€™re trying to predict human behavior, and human behavior tends to not fall into rational agent models we have for game players,â€ says Matthew Johnson-Roberson, assistant professor of engineering at the University of Michigan and the cofounder of Refraction AI, a startup building autonomous delivery vehicles.
 Someone might look like theyâ€™re about to merge but see a flash of something out of the corner of their eye and stop short. Itâ€™s very hard to teach a robot to predict that kind of behavior.
Of course, driving situations could become less uncertain if the researchers were able to collect more information about human driving behavior, which is what theyâ€™re hoping to do next. Data on the speed of vehicles, where they are heading, the angle at which theyâ€™re traveling, how their position changes over timeâ€”all could help traveling robots better understand how the human mind (and personality) operates. Perhaps, the researchers say, an algorithm derived from more precise data could improve predictions about human driving behavior by 50 percent instead of 25 percent.
That might be really hard, says Johnson-Roberson. â€œOne of the reasons I think it's going to be challenging to deploy [autonomous vehicles] is because youâ€™re going to have to get these predictions right when traveling at high speeds in dense urban areas,â€ he says. Being able to tell whether a driver is a selfish driver within two seconds of observation is useful, but a car traveling at 25 mph travels nearly 75 feet in that time. A lot of unfortunate things can happen in 75 feet.
The fact is, even humans donâ€™t understand humans all the time. â€œPeople are just the way they are, and sometimes theyâ€™re not focused on driving, and make decisions we canâ€™t completely explain,â€ says Wilko Schwarting, an MIT graduate student who led the research. Good luck out there, robots.
The strange life and mysterious death of a virtuoso coder Alphabet's dream of an â€œEveryday Robotâ€ is just out of reach An origami artist shows how to fold ultra-realistic creatures Wish List 2019: 52 amazing gifts you'll want to keep for yourself How to lock down your health and fitness data ğŸ‘ A safer way to protect your data ; plus, the latest news on AI ğŸƒğŸ½â€â™€ï¸ Want the best tools to get healthy? Check out our Gear teamâ€™s picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones.
Staff Writer X Topics Self-Driving Cars Autonomous Vehicles Waymo artificial intelligence Aarian Marshall Aarian Marshall Aarian Marshall Will Knight Ben Brubaker Steven Levy Boone Ashworth Gregory Barber Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
