Cohere Website For Business Docs Research Elle Neal, Guest Author Turbocharge Semantic Search With AI in 5 Easy Steps Developers Share: Transform your documentation search experience using Streamlit and powerful language models.
TL;DR: In this post, we walk you through building Cofinder, an AI-powered semantic search app using Cohere's API and Streamlit. The 5-step process includes pre-processing data sources, creating a search index, building the Streamlit front end, adding an AI search function, and adding AI-generated answer functions. Join the NLP dev community and enhance your document search experience with this exciting project! In this article, I will introduce Cofinder , a semantic search application built using Cohere’s technology. I’ll provide you with a repository and explanations of the code snippets to help you follow along and build your own semantic search application.
We will go through the five stages of building your application: Pre-processing your data sources Creating a search index Building your Streamlit front end Adding an AI search function Adding AI-generated answer functions.
In recent years, natural language processing (NLP) has rapidly advanced, thanks to the latest generation of large language models. However, not all developers are able to use these models due to the high computing barriers and the lack of technical expertise required to do so. This is where Cohere comes in.
Cohere provides access for all developers, without the need for ML expertise, all that’s needed to access LLMs via cohere is a simple API call to large language models that can be used to generate or analyze text to do things like write copy, moderate content, classify data and extract information, all at a massive scale. Cohere offers a generous free developer tier, meaning you can build and test your ideas quickly and with no cost.
What is Cofinder? This was a demo project I built for my first hackathon with Lablab.ai , I would recommend hackathons to anyone that wants to learn and push themselves in the space of AI.
Its inspiration comes from Cohere’s mission to give technology language and to put large language models into more hands.
Cofinder is the result of my desire to make it easier for the Cohere community to access the wealth of knowledge and resources available on the platform.
While Cohere provides an incredible variety of resources, such as product explanations, tutorials, open repositories, and a Discord channel , I recognized that finding specific information can still be time-consuming and inefficient. The dataset behind Cofinder is text extracted from these sources. By creating a semantic search tool that brings together information from multiple sources, Cofinder aims to streamline the process and save users valuable time. The goal is to enhance the Cohere community experience by making it easy for developers, entrepreneurs, corporations, and data scientists to find what they need in one place.
Let’s build our own semantic search application to enhance search! Cofinder | Streamlit demo But before we dive into the technical details, let’s take a closer look at the Cohere products we used in building Cofinder. We will use Cofinder to learn more about each product.
Cohere’s Embedding and Generate Endpoints: The Key to Cofinder’s Semantic Search Cofinder uses two of Cohere’s products, co.embed and co.generate , to power its semantic search functionality.
co.embed is an API endpoint that gives easy access to a robust embedding model that generates numeric representations of text, which can be used for various natural language processing (NLP) tasks such as clustering and classification. In Cofinder, co.embed is used to generate vector embeddings for the articles that users can search.
co.generate is an API endpoint that uses a text representation model that generates text based on the given prompt. In Cofinder, co.generate is used to formulate an answer to the user’s question using the context from the search and the question itself.
By leveraging these powerful NLP models, Cofinder is able to provide accurate and relevant search results to users, making it easier and more efficient to find information on Cohere Let’s check out Cofinder to help find relevant Cohere resources.
Question: What are embeddings? Cofinder | What are embeddings? Results: As Cofinder quickly provides the user with content from across multiple platforms. Each relevant document contains: The category (video, blog, user and product documentation) The content title An answer generated using the search query and content as context Link to the content We now have a variety of content to watch and read to help understand what embeddings are and formulate a good solid understanding.
Cofinder | Search response Once you have a better understanding of what embeddings are, you may now want to explore what you can do with embeddings, let’s ask Cofinder again.
Question: What can embeddings be used for? This time, our content is more focused on possible use cases, and each one gives us the opportunity to explore multiple areas in more depth.
Cofinder | Search results Let’s Start Building! 5 Steps to Build your own Semantic Search Application We can breakdown the process into five steps of development: Data Sources: pre-processing the article text into chunks.
Embeddings & Search Index: use co.embed to obtain a vector representation of our data. Store your embeddings in a vector database which we will later use to search for relevant content.
Front End: Streamlit for our users to interact with our search engine.
Search: we use co.embed to get the vector representation of the user query, using nearest neighbors to return relevant content.
Answer: use co.generate to answer the query given the context from the search results and the question.
Github Repository Here is a GitHub repository template to fork and build your own application: ellenealds/streamlit_template_cohere_semantic_search (github.com) Repository Contents cohere_text_preprocessing.csv: contains text prior to pre-processing preprocessing.ipynb: this contains our code for generating embeddings and preparing our search index using the cohere_text_preprocessing.csv file main.py: this contains our code for the Streamlit app These files will be produced when you run preprocessing.ipynb cohere_text_final.csv: text after pre-processing search_index.ann: a search index containing our embeddings You will need your Cohere API key to continue with the development.
Creating our Search Index Our first three stages are to pre-process the text by splitting it into small chunks, we will then generate embeddings using co.embed and finally create a search index using Annoy.
This section of code can be found in preprocessing.ipynb Semantic Search (cohere.ai) 1. Data Sources — Pre-processing Text The repository contains a CSV file called cohere_text_preprocessing.csv with a row for each URL, the title and the text taken from the webpage. Each item contains a category and type which is returned in the search results.
CSV File | cohere_text_preprocessing Note: Some of the information may be outdated as this text was extracted in October 2022 and is for demonstration purposes only.
After importing the CSV file, we need to pre-process the text into chunks, the chunks will be used in a later stage as context where we want to generate an answer. As we will use co.generate for this task, we need to make sure our text chunks are no larger than 1500 words.
To maintain context, we will split the text chunks into 1500 and overlap the chunks using 500 tokens from the previous chunk relevant to the article.
2a. Get embeddings We use the co.embed to obtain a vector representation of our data.import cohere Great! We now have our pre-processed text and embeddings ready for the next stage where we create a search index to store the data.
2b. Search Index We now create a search index using Annoy to store the embeddings.
The final three stages are to create our Streamlit application, we load the relevant libraries, data and search index from the previous stages. We then add functions to generate embeddings to search the Annoy index for the user’s query, and generate an answer from the context.
This is all tied together in the Streamlit app with widgets for user input and markdown to display the results.
This section of code can be found in main.py.
3. Front End — Streamlit In the main.py file , we build our code for the Streamlit application.
Here we import the libraries we need, the API key, initiate our cohere client and load the search index and CSV file.
4. Search Function The search function takes in a query, the number of search results to return n_results , a dataframe df , an index search_index , and an embedding model co.embed().
 Here's a step-by-step breakdown of what the function does: The function uses the co.embed function to get the embedding of the query using the specified model ( "large" ).
The function uses the search_index.get_nns_by_vector function to get the n_results nearest neighbors to the query embedding in the specified index search_index.
 The function returns the indices of the nearest neighbors as well as the similarity scores.
The function filters the original dataframe ( df ) to include only the rows that correspond to the nearest neighbors returned in step 2.
The function adds two new columns to the filtered dataframe: similarity , which contains the similarity scores between the query embedding and the document embeddings; and nearest_neighbors , which contains the indices of the nearest neighbors.
Finally, the function sorts the filtered dataframe by similarity in descending order and returns it.
The results of the search will be used as context to answer the user’s question.
When we run this function, we get a JSON output containing the article title and the context relevant to the query Question: How do I use Cohere to build a chatbot? 5. Answer Function We now want to take the user question and generate an answer to the question given the search results from the previous function.
Overall, the display function below is broken down into two tasks, The gen_answer and gen_better_answer functions are used to generate answers for the query and each of the search results. The gen_answer function generates an initial answer based on a prompt that includes the paragraph and the question, while gen_better_answer generates a better answer by incorporating the initial answers and the question.
The results are displayed in a user-friendly format using the st module from the Streamlit library. The search query is displayed as a subheader, followed by the better answer generated by gen_better_answer.
 The relevant documents are then displayed, one by one. Each document is displayed with its type, category, title, and link, followed by the initial answer generated by gen_answer.
 The text of the document is then collapsed and can be expanded by clicking on "Read more".
Let’s explore the gen_answer and gen_better_answer functions to see what is happening.
Cofinder | search context and generate the best answer Here we create two co.generate() prompts, these functions use Cohere’s pre-trained models to generate text that answers a given question from the context provided from the search results.
gen_answer(q, para) : This function returns an answer to the question given the context returned from our search function. In the display function above, we ran this function by iterating over each of the search results from the JSON output to gather context from multiple sources.
gen_better_answer(ques, ans) : This function takes the question and all of the responses from the gen_answer function, and it uses the combined answers to formulate a more rounded answer taking into account all the available resources.
The max_tokens and temperature parameters can be tuned to control the length and randomness of the generated text.
Finally, we add a Streamlit search input along with some question examples for the user, and a button that runs our functions.
Well done! You are now ready to publish your Streamlit application to the cloud! Calling All Developers The vision for Cofinder was “Built for the community, by the community”, can you help make Cofinder a better search tool for our community? Please contact me on LinkedIn or Discord Elle Neal#0726 to discuss how we can make this happen.
As a starting point, here are some potential features I captured at the end of the hackathon, I am excited to see how we can take this application to the next level! Cofinder | Feature Pipeline Next Steps So there you have it, a step-by-step guide to building an AI-powered semantic search application using Cohere’s API. But this is just the beginning! Cofinder was built for the community, by the community, and we are always looking for ways to make it better. As a community member, your input is crucial in shaping the future of Cofinder. Please reach out to me on LinkedIn or Discord to discuss potential features and how we can work together to take this application to the next level.
Let’s continue to innovate and make the Cohere community experience even better.
This article was originally published on Medium.
Keep reading Cohere — Nov 16, 2023 Cohere’s Enterprise AI Models Coming Soon to Microsoft Azure AI as a Managed Service Newsroom Seraphina Goldfarb-Tarrant , Maximilian Mozes — Nov 14, 2023 The Enterprise Guide to AI Safety For Business Cohere Team — Nov 03, 2023 Emerging Trends in Generative AI Research: A Selection of Recent Papers Research Cohere.com Get Started About Classify Generate Responsibility Documentation Careers
