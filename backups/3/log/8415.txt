Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business Scammers Used ChatGPT to Unleash a Crypto Botnet on X Illustration: sakchai vongsasiripat/Getty Images Save this story Save Save this story Save ChatGPT may well revolutionize web search , streamline office chores , and remake education , but the smooth-talking chatbot has also found work as a social media crypto huckster.
Researchers at Indiana University Bloomington discovered a botnet powered by ChatGPT operating on X‚Äîthe social network formerly known as Twitter‚Äîin May of this year.
The botnet, which the researchers dub Fox8 because of its connection to cryptocurrency websites bearing some variation of the same name, consisted of 1,140 accounts. Many of them seemed to use ChatGPT to craft social media posts and to reply to each other‚Äôs posts. The auto-generated content was apparently designed to lure unsuspecting humans into clicking links through to the crypto-hyping sites.
Micah Musser, a researcher who has studied the potential for AI-driven disinformation, says the Fox8 botnet may be just the tip of the iceberg, given how popular large language models and chatbots have become. ‚ÄúThis is the low-hanging fruit,‚Äù Musser says. ‚ÄúIt is very, very likely that for every one campaign you find, there are many others doing more sophisticated things.‚Äù The Fox8 botnet might have been sprawling, but its use of ChatGPT certainly wasn‚Äôt sophisticated. The researchers discovered the botnet by searching the platform for the tell-tale phrase ‚ÄúAs an AI language model ‚Ä¶‚Äù, a response that ChatGPT sometimes uses for prompts on sensitive subjects. They then manually analyzed accounts to identify ones that appeared to be operated by bots.
‚ÄúThe only reason we noticed this particular botnet is that they were sloppy,‚Äù says Filippo Menczer , a professor at Indiana University Bloomington who carried out the research with Kai-Cheng Yang, a student who will join Northeastern University as a postdoctoral researcher for the coming academic year.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Despite the tic, the botnet posted many convincing messages promoting cryptocurrency sites. The apparent ease with which OpenAI‚Äôs artificial intelligence was apparently harnessed for the scam means advanced chatbots may be running other botnets that have yet to be detected. ‚ÄúAny pretty-good bad guys would not make that mistake,‚Äù Menczer says.
OpenAI had not responded to a request for comment about the botnet by time of posting. The usage policy for its AI models prohibits using them for scams or disinformation.
ChatGPT, and other cutting-edge chatbots, use what are known as large language models to generate text in response to a prompt. With enough training data (much of it scraped from various sources on the web), enough computer power, and feedback from human testers, bots like ChatGPT can respond in surprisingly sophisticated ways to a wide range of inputs. At the same time, they can also blurt out hateful messages, exhibit social biases , and make things up.
A correctly configured ChatGPT-based botnet would be difficult to spot, more capable of duping users, and more effective at gaming the algorithms used to prioritize content on social media.
‚ÄúIt tricks both the platform and the users,‚Äù Menczer says of the ChatGPT-powered botnet. And, if a social media algorithm spots that a post has a lot of engagement‚Äîeven if that engagement is from other bot accounts‚Äîit will show the post to more people. ‚ÄúThat's exactly why these bots are behaving the way they do,‚Äù Menczer says. And governments looking to wage disinformation campaigns are most likely already developing or deploying such tools, he adds.
Researchers have long worried that the technology behind ChatGPT could pose a disinformation risk , and OpenAI even delayed the release of a predecessor to the system over such fears. But, to date, there are few concrete examples of large language models being misused at scale. Some political campaigns are already using AI though, with prominent politicians sharing deepfake videos designed to disparage their opponents.
William Wang , a professor at the University of California, Santa Barbara, says it is exciting to be able to study real criminal usage of ChatGPT. ‚ÄúTheir findings are pretty cool,‚Äù he says of the Fox8 work.
Wang believes that many spam webpages are now generated automatically, and he says it is becoming more difficult for humans to spot this material. And, with AI improving all the time, it will only get harder. ‚ÄúThe situation is pretty bad,‚Äù he says.
This May, Wang‚Äôs lab developed a technique for automatically distinguishing ChatGPT-generated text from real human writing, but he says it is expensive to deploy because it uses OpenAI‚Äôs API, and he notes that the underlying AI is constantly improving. ‚ÄúIt‚Äôs a kind of cat-and-mouse problem,‚Äù Wang says.
X could be a fertile testing ground for such tools. Menczer says that malicious bots appear to have become far more common since Elon Musk took over what was then known as Twitter, despite the tech mogul‚Äôs promise to eradicate them.
 And it has become more difficult for researchers to study the problem because of the steep price hike imposed on usage of the API.
Someone at X apparently took down the Fox8 botnet after Menczer and Yang published their paper in July. Menczer‚Äôs group used to alert Twitter of new findings on the platform, but they no longer do that with X. ‚ÄúThey are not really responsive,‚Äù Menczer says. ‚ÄúThey don‚Äôt really have the staff.‚Äù You Might Also Like ‚Ä¶ üì© Get the long view on tech with Steven Levy's Plaintext newsletter Watch this guy work, and you‚Äôll finally understand the TikTok era How Telegram became a terrifying weapon in the Israel-Hamas War Inside Elon Musk‚Äôs first election crisis ‚Äîa day after he ‚Äúfreed‚Äù the bird The ultra-efficient farm of the future is in the sky The best pickleball paddles for beginners and pros üå≤ Our Gear team has branched out with a new guide to the best sleeping pads and fresh picks for the best coolers and binoculars Senior Writer X Topics bots artificial intelligence cryptocurrency ChatGPT X Will Knight Kari McMahon David Gilbert Amit Katwala Andy Greenberg Andy Greenberg David Gilbert Khari Johnson Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
