Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Intel CTO wants developers to build once, then run on any GPU Share on Facebook Share on X Share on LinkedIn Over two decades ago, the Java programming language, originally developed by Sun Microsystems, offered developers the promise of being able to build an application once and then have it run on any operating system.
Greg Lavender, CTO of Intel , remembers the original promise of Java better than most, as he spent over a decade working at Sun. Instead of needing to build applications for different hardware and operating systems, the promise of Java was more uniform and streamlined development.
The ability to build once and run anywhere, however, is not uniform across the computing landscape in 2022. It’s a situation that Intel is looking to help change, at least when it comes to accelerated computing and the use of GPUs.
The need for a uniform, Java-like language for GPUs “Today in the accelerated computing and GPU world, you can use CUDA and then you can only run on an Nvidia GPU , or you can go use AMD’s CUDA equivalent running on an AMD GPU,” Lavender told VentureBeat. “You can’t use CUDA to program an Intel GPU, so what do you use?” That’s where Intel is contributing heavily to the open-source SYCL specification (SYCL is pronounced like “sickle”) that aims to do for GPU and accelerated computing what Java did decades ago for application development. Intel’s investment in SYCL is not entirely selfless and isn’t just about supporting an open-source effort; it’s also about helping to steer more development toward its recently released consumer and data center GPUs.
SYCL is an approach for data parallel programming in the C++ language and, according to Lavender, it looks a lot like CUDA.
Intel supports standardization for one code to rule them all To date, SYCL development has been managed by the Khronos Group , which is a multi-stakeholder organization that is helping to build out standards for parallel computing, virtual reality and 3D graphics. On June 1, Intel acquired Scottish development firm Codeplay Software , which is one of the leading contributors to the SYCL specification.
“We should have an open programming language with extensions to C++ that are being standardized, that can run on Intel, AMD and Nvidia GPUs without changing your code,” Lavender said.
Automated tool for converting CUDA into SYCL Lavender is also a realist and he knows that there is a lot of code already written specifically for CUDA. That’s why Intel developers built an open-source tool called SYCLomatic , which aims to migrate CUDA code into SYCL. Lavender claimed that SYCLomatic today has coverage for approximately 95% of all the functionality that is present in CUDA. He noted that the 5% SYCLomatic doesn’t cover are capabilities that are specific to Nvidia hardware.
With SYCL, Lavender said that there are code libraries that developers can use that are device independent. The way that works is code is written by a developer once, and then SYCL can compile the code to work with whatever architecture is needed, be it for an Nvidia, AMD or Intel GPU.
Looking forward, Lavender said that he’s hopeful that SYCL can become a Linux Foundation project, to further enable participation and growth of the open-source effort. Intel and Nvidia are both members of the Linux Foundation supporting multiple efforts. Among the projects where Intel and Nvidia are both members today is the Open Programmable Infrastructure (OPI) project , which is all about providing an open standard for infrastructure programming units (IPUs) and data processing units (DPUs).
“We should have write once, run everywhere for accelerated computing, and then let the market decide which GPU they want to use, and level the playing field,” Lavender said.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
