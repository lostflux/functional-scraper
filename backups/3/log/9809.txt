Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Matt Simon Science This Clever Robotic Finger Feels With Light Courtesy of Columbia University Save this story Save Save this story Save Robots already have us beat in some ways: They‚Äôre stronger, more consistent, and they never demand a lunch break. But when it comes to the senses, machines still struggle mightily. They can‚Äôt smell particularly well, or taste (though researchers are making progress on robotic tongues ), or feel with their robotic grips‚Äîand that‚Äôs a serious consideration if we don‚Äôt want them crushing our dishes or skulls.
In a lab at Columbia University, engineers have developed a strange yet clever way for robots to feel: Let‚Äôs call it the finger of light. It‚Äôs got a 3D-printed skeleton embedded with 32 photodiodes and 30 adjacent LEDs, over which is laid a squishy skin of reflective silicone, which keeps the device‚Äôs own light in and outside light out. When the robot finger touches an object, its soft exterior deforms, and the photodiodes in the skeleton detect changing light levels from the LEDs. This allows the system to determine where contact is being made with the finger, and the intensity of that pressure. In other words, if you shook this robot‚Äôs hand, it wouldn‚Äôt feel it, in a traditional sense; it would see it.
For decades, roboticists have been developing ways for machines to feel, a field called tactile sensing. A very basic method is using a transducer to convert pressure into an electrical signal. But, says Columbia roboticist Matei Ciocarlie, ‚Äúthe gap that's been really hard to cross, traditionally, is there is a difference between building a touch sensor and building a finger.‚Äù Courtesy of Columbia University Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker A rigid transducer might sit well on a table, where it can freely sprout all kinds of wires, but fitting all that into a small, deformable finger has been a big challenge. A robot, after all, needs to have flexible digits if it‚Äôs going to pick up objects and feel them. Soft fingertips also help establish a firm grip. So roboticists have had to find workarounds. A company called SynTouch, for example, has pioneered a finger covered in electrodes, which is overlaid with a soft skin. Then, they inject saline in between the skin and the electrodes. When someone touches the finger, the electrodes detect the changing resistance through the saline, registering the location and intensity of that touch.
The Columbia team‚Äôs new finger works in much the same way, but instead of electrodes and saline, it‚Äôs got those LEDs and photodiodes. When someone pokes the finger, all of the photodiodes look for changes in the amount of light they‚Äôre receiving. A photodiode closer to the poke will detect more of a change, while a photodiode on the opposite side of the finger will detect less. The system gets that information in fine detail, because 32 photodiodes times 30 LEDs equals 960 signals, which is a ton of data from a single poke.
‚ÄúExtracting information out of those 1,000 signals in an analytical way‚Äîit's very, very hard to do,‚Äù says Ciocarlie, who developed the system. ‚ÄúI would venture to say that it's impossible without modern machine learning.‚Äù Courtesy of Columbia University Machine learning comes into play when they‚Äôre calibrating the system. They can stick the finger on a table, point it upward, and use a separate robotic arm to prod the finger in precise spots, using a specific amount of pressure. Because they know exactly where the robotic arm is jabbing the finger, they can see how the photodiodes detect light differently at each location. (If you take a look at the GIF above, you can see the system both localizing the touch and the intensity as the red dot swells with more pressure.) Despite the large amount of data collected per jab, with machine learning, the system can crunch it all.
‚ÄúSo that's the missing piece, the thing that's really become available to the field really in the last maybe five years or so,‚Äù says Ciocarlie. ‚ÄúWe now have the machine-learning methods that we can add on top of these many, many optical signals, so that we can decipher the information that's in there.‚Äù This mimics how humans learn to wield our own sense of touch. As children, we grab everything we can, banking our memories of how objects feel. Even as adults, our brains continue to catalog the feel of things‚Äîfor example, how much resistance to expect from a steering wheel when you‚Äôre turning left, or how hard to bang a hammer against a nail. ‚ÄúIf we were to put you into the body of another person somehow, you would have to relearn all the motor skills,‚Äù says Columbia electrical engineer Ioannis Kymissis, who developed the system with Ciocarlie. ‚ÄúAnd that's one of the nice things about the plasticity of the brain, right? You can have a stroke, you can knock out half of the brain and still relearn and then function.‚Äù Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker This new robotic finger, though, has its limits. While it can gauge the pressure it's placing on an object, it‚Äôs missing out on a bunch of other data that people can sense through our own hands but often take for granted, like temperature and texture. But interestingly enough, the researchers think they could listen to the robotic finger‚Äôs slip, or its motion as it slides over a surface.
‚ÄúWhen you have slip, there's a little bit of a singing‚Äîif you ever put your ear against the table and run your finger on the table,‚Äù says Kymissis. If you‚Äôre holding on to, say, a wet glass, the slip might happen on a small scale, then ‚Äúspread‚Äù to your hand‚Äôs entire contact area as the glass slides out of your grasp. By listening to the characteristic noise of an object slipping out of a robot hand equipped with these new fingers, the machine could correct its grip before the slip spreads across the whole hand.
What‚Äôs fascinating about this research is that while the engineers take inspiration from human biology, they mix up the sensory inputs in a decidedly un-human way. Human fingers rely on nerves to feel, but this new robotic finger sees objects, and perhaps one day will hear its contact with the surface.
In the future, this may lead to robots that can better manipulate human objects, because they‚Äôll be able to combine vision with a sense of touch, just as we do. The ability to use both is particularly helpful when dealing with cluttered environments that contain a bunch of objects, or situations in which a direct line of sight is blocked. Think about how you might reach into a messy drawer: Your primary sense is vision, but you switch to your sense of touch as your hand gets deeper into the drawer and closer to the object you want.
A robot might have the same kind of problem: Perhaps the robotic arm can‚Äôt find an object it needs to grab because it‚Äôs at the bottom of a pile. Or maybe the robot arm itself gets in the robot‚Äôs line of sight. To be truly masterful at manipulating objects in the real world, a robot will have to freely switch between vision and touch.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker ‚ÄúTactile sensing can facilitate robot manipulation, especially when the robot gripper occludes objects from cameras,‚Äù says UC Berkeley roboticist Ken Goldberg, who wasn‚Äôt involved in this work. This new system, he adds, is a great improvement over previous robotic fingers that used electrodes overlaid with rubber to sense touch. These collected limited data, like simply determining whether or not the robot was making contact with another object. But thanks to the power of light, the new finger can provide much finer detail about everything it touches.
Robots are a long way from matching the sensitivity of the human hand, sure, but we‚Äôve got a good feeling about this clever new finger.
Algae caviar, anyone? What we'll eat on the journey to Mars Deliver us, Lord, from the startup life A code-obsessed novelist builds a writing bot.
The plot thickens The WIRED Guide to the internet of things How to share files securely online üëÅ The secret history of facial recognition.
 Plus, the latest news on AI üèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones Staff Writer X Topics robotics Tammy Rabideau Matt Simon Jim Robbins Matt Simon Tristan Kennedy Sushmita Pathak Amit Katwala Grace Browne Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
