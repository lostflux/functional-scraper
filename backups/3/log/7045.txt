Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Report: 37% of ML leaders say they don’t have the data needed to improve model performance Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
A new report by Scale AI uncovers what’s working and what’s not working with AI implementation, and the best practices for ML teams to move from just testing to real-world deployment. The report explores every stage of the ML lifecycle – from data collection and annotation to model development, deployment, and monitoring – in order to understand where AI innovation is being bottlenecked, where breakdowns occur, and what approaches are helping companies find success.
The report’s goal is to continue to shed light on the realities of what it takes to unlock the full potential of AI for every business and help empower organizations and ML practitioners to clear their current hurdles, learn and implement best practices, and ultimately use AI as a strategic advantage.
For ML practitioners, data quality is one of the most important factors in their success, and according to respondents, it’s also the most difficult challenge to overcome. In this study, more than one-third (37%) of all respondents said they do not have the variety of data they need to improve model performance. Not only do they not have variety of data, but quality is also an issue — only 9% of respondents indicated their training data is free from noise, bias and gaps.
Most teams, regardless of industry or level of AI advancement, face similar challenges with data quality and variety. Scale’s data suggests that working closely with annotation partners can help ML teams overcome challenges in data curation and annotation quality, accelerating model deployment.
 ML teams that are not at all engaged with annotation partners are the most likely to take greater than three months to get annotated data.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! This survey was conducted online within the United States by Scale AI from March 31, 2022, to April 12, 2022. More than 1,300 ML practitioners including those from Meta, Amazon, Spotify and more were surveyed for the report.
Read the full report by Scale AI.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
