Vox homepage Give Give Newsletters Newsletters Site search Search Vox main menu Explainers Crossword Video Podcasts Politics Policy Culture Science Technology Climate Health Money Life Future Perfect Newsletters More Explainers Israel-Hamas war 2024 election Supreme Court Buy less stuff Open enrollment What to watch All explainers Crossword Video Podcasts Politics Policy Culture Science Technology Climate Health Money Life Future Perfect Newsletters We have a request Vox's journalism is free, because we believe that everyone deserves to understand the world they live in. Reader support helps us do that. Can you chip in to help keep Vox free for all? × Filed under: Technology Artificial Intelligence Microsoft The makers of ChatGPT just released a new AI that can build websites, among other things What you need to know about GPT-4, the latest version of the buzzy generative AI technology.
By Shirin Ghaffary Mar 15, 2023, 9:20am EDT Share this story Share this on Facebook Share this on Twitter Share All sharing options Share All sharing options for: The makers of ChatGPT just released a new AI that can build websites, among other things Reddit Pocket Flipboard Email OpenAI co-founder and President Greg Brockman speaking onstage at SXSW Conference with journalist Laurie Segall on March 10, 2023.
Errich Petersen/Getty Images for SXSW When ChatGPT came out in November, it took the world by storm.
Within a month of its release, some 100 million people had used the viral AI chatbot for everything from writing high school essays to planning travel itineraries to generating computer code.
Built by the San Francisco-based startup OpenAI, the app was flawed in many ways, but it also sparked a wave of excitement (and fear) about the transformative power of generative AI to change the way we work and create.
ChatGPT, which runs on a technology called GPT-3.5, has been so impressive, in part, because it represents a quantum leap from the capabilities of its predecessor from just a few years ago, GPT-2.
On Tuesday, OpenAI released an even more advanced version of its technology: GPT-4.
 The company says this update is another milestone in the advancement of AI. The new technology has the potential to improve how people learn new languages, how blind people process images, and even how we do our taxes.
OpenAI also claims that the new model supports a chatbot that’s more factual, creative, concise, and can understand images, instead of just text.
Sam Altman, the CEO of OpenAI, called GPT-4 “our most capable and aligned model yet.” He also cautioned that “it is still flawed, still limited, and it still seems more impressive on first use than it does after you spend more time with it” GPT4 is capable of turning a picture of a napkin sketch to a fully functioning html/css/javascript website.
pic.twitter.com/q6FLZL6oFO In a livestream demo of GPT-4 on Tuesday afternoon, OpenAI co-founder and president Greg Brockman showed some new use cases for the technology, including the ability to be given a hand-drawn mockup of a website and, from that, generate code for a functional site in a matter of seconds.
Brockman also showcased GPT-4’s visual capabilities by feeding it a cartoon image of a squirrel holding a camera and asking it to explain why the image is funny.
“The image is funny because it shows a squirrel holding a camera and taking a photo of a nut as if it were a professional photographer. It’s a humorous situation because squirrels typically eat nuts, and we don’t expect them to use a camera or act like humans,” GPT-4 responded.
This is the sort of capability that could be incredibly useful to people who are blind or visually impaired. Not only can GPT-4 describe images, but it can also communicate the meaning and context behind them.
Picture of a squirrel that GPT-4 interpreted in its demo.
OpenAI Still, as Altman and GPT-4’s creators have been quick to admit, the tool is nowhere near fully replacing human intelligence. Like its predecessors, it has known problems around accuracy, bias, and context. That poses a growing risk as more people start using GPT-4 for more than just novelty. Companies like Microsoft, which invests heavily in OpenAI, are already starting to bake GPT-4 into core products that millions of people use.
Here are a few things you need to know about the latest version of the buzziest new technology in the market.
It can pass complicated exams One tangible way people are measuring the capabilities of new artificial intelligence tools is by seeing how well they can perform on standardized tests, like the SAT and the bar exam.
GPT-4 has shown some impressive progress here. The technology can pass a simulated legal bar exam with a score that would put it in the top 10 percent of test takers, while its immediate predecessor GPT-3.5 scored in the bottom 10 percent (watch out, lawyers).
GPT-4 can also score a 700 out of 800 on the SAT math test, compared to a 590 in its previous version.
Sample of simulated exam results of GPT-4 compared to GPT 3.5.
OpenAI Still, GPT-4 is weak in certain subjects. It only scored a 2 out of 5 on the AP English Language exams — the same score as the prior version, GPT-3.5, received.
Standardized tests are hardly a perfect measure of human intelligence, but the types of reasoning and critical thinking required to score well on these tests show that the technology is improving at an impressive clip.
It shows promise at teaching languages and helping the visually impaired Since GPT-4 just came out, it will take time before people discover all of the most compelling ways to use it, but OpenAI has proposed a couple of ways the technology could potentially improve our daily lives.
One is for learning new languages. OpenAI has partnered with the popular language learning app Duolingo to power a new AI-based chat partner called Roleplay. This tool lets you have a free-flowing conversation in another language with a chatbot that responds to what you’re saying and steps in to correct you when needed.
Another big use case that OpenAI pitched involves helping people who are visually impaired. In partnership with Be My Eyes, an app that lets visually impaired people get on-demand help from a sighted person via video chat, OpenAI used GPT-4 to create a virtual assistant that can help people understand the context of what they’re seeing around them. One example OpenAI gave showed how, given a description of the contents of a refrigerator, the app can offer recipes based on what’s available. The company says that’s an advancement from the current state of technology in the field of image recognition.
“Basic image recognition applications only tell you what’s in front of you,” said Jesper Hvirring Henriksen, CTO of Be My Eyes, in a press release for GPT-4’s launch. “They can’t have a discussion to understand if the noodles have the right kind of ingredients or if the object on the ground isn’t just a ball, but a tripping hazard — and communicate that.” If you want to use OpenAI’s latest GPT-4 powered chatbot, it isn’t free Right now, you’ll have to pay $20 per month for access to ChatGPT Plus, a premium version of the ChatGPT bot. GPT4’s API is also available to developers who can build apps on top of it for a fee proportionate to how much they’re using the tool.
However, if you want a taste of GPT-4 without paying up, you can use a Microsoft-made chatbot called BingGPT.
 A Microsoft VP confirmed on Tuesday that the latest version of BingGPT is using GPT-4. It’s important to note that BingGPT has limitations on how many conversations you can have a day, and it doesn’t allow you to input images.
GPT-4 still has serious flaws. Researchers worry we don’t know what data it’s being trained on.
While GPT-4 has clear potential to help people, it’s also inherently flawed. Like previous versions of generative AI models, GPT-4 can relay misinformation or be misused to share controversial content, like instructions on how to cause physical harm or content to promote political activism.
OpenAI says that GPT-4 is 40 percent more likely to give factual responses, and 82 percent less likely to respond to requests for disallowed content. While that’s an improvement from before, there’s still plenty of room for error.
Another concern about GPT-4 is the lack of transparency around how it was designed and trained. Several prominent academics and industry experts on Twitter pointed out that the company isn’t releasing any information about the data set it used to train GPT-4. This is an issue, researchers argue, because the large datasets used to train AI chatbots can be inherently biased, as evidenced a few years ago by Microsoft’s Twitter chatbot , Tay. Within a day of its release, Tay gave racist answers to simple questions. It had been trained on social media posts, which can often be hateful.
OpenAI says it’s not sharing its training data in part because of competitive pressure. The company was founded as a nonprofit but became a for-profit entity in 2019, in part because of how expensive it is to train complex AI systems. OpenAI is now heavily backed by Microsoft, which is engaged in a fierce battle with Google over which tech giant will lead on generative AI technologies.
Without knowing what’s under the hood, it’s hard to immediately validate OpenAI’s claims that its latest tool is more accurate and less biased than before. As more people use the technology in the coming weeks, we’ll see if it ends up being not only meaningfully more useful but also more responsible than what came before it.
Will you support Vox’s explanatory journalism? Most news outlets make their money through advertising or subscriptions. But when it comes to what we’re trying to do at Vox, there are a couple reasons that we can't rely only on ads and subscriptions to keep the lights on.
First, advertising dollars go up and down with the economy. We often only know a few months out what our advertising revenue will be, which makes it hard to plan ahead.
Second, we’re not in the subscriptions business. Vox is here to help everyone understand the complex issues shaping the world — not just the people who can afford to pay for a subscription. We believe that’s an important part of building a more equal society. We can’t do that if we have a paywall.
That’s why we also turn to you, our readers, to help us keep Vox free.
If you also believe that everyone deserves access to trusted high-quality information, will you make a gift to Vox today? One-Time Monthly Annual $5 /month $10 /month $25 /month $50 /month Other $ /month /month We accept credit card, Apple Pay, and Google Pay. You can also contribute via Next Up In Technology Most Read The controversy over TikTok and Osama bin Laden’s “Letter to America,” explained Is the green texting bubble about to burst? Formula 1 grew too fast. Now its new fans are tuning out.
The Ballad of Songbirds & Snakes might be the best Hunger Games movie yet Why are so few people getting the latest Covid-19 vaccine? vox-mark Sign up for the newsletter Sentences The day's most important news stories, explained in your inbox.
Thanks for signing up! Check your inbox for a welcome email.
Email (required) Oops. Something went wrong. Please enter a valid email and try again.
The Latest Most of Israel’s weapons imports come from the US. Now Biden is rushing even more arms.
By Jonathan Guyer Formula 1 grew too fast. Now its new fans are tuning out.
By Izzie Ramirez The controversy over TikTok and Osama bin Laden’s “Letter to America,” explained By A.W. Ohlheiser and Li Zhou Your phone is the key to your digital life. Make sure you know what to do if you lose it.
By Sara Morrison Alex Murdaugh stands guilty of killing his wife and son. That’s just scratching the surface.
By Aja Romano Is the green texting bubble about to burst? By Sara Morrison Chorus Facebook Twitter YouTube About us Our staff Privacy policy Ethics & Guidelines How we make money Contact us How to pitch Vox Contact Send Us a Tip Vox Media Terms of Use Privacy Notice Cookie Policy Do Not Sell or Share My Personal Info Licensing FAQ Accessibility Platform Status Advertise with us Jobs @ Vox Media
