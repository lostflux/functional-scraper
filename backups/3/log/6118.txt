Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Researchers find race, gender, and style biases in art-generating AI systems Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
As research pushes the boundaries of what’s possible with AI, the popularity of art created by algorithms — generative art — continues to grow. From creating paintings to inventing new art styles, AI-based generative art has been showcased in a range of applications. But a new study from researchers at Fujitsu investigates whether biases might creep into the AI tools used to create art. Leveraging models, they claim that current AI methods fail to take into account socioeconomic impacts and exhibit clear prejudices.
In their work, the researchers surveyed academic papers, online platforms, and apps that generate art using AI, selecting examples that focused on simulating established art schools and styles. To investigate biases, they considered state-of-the-art AI systems trained on movements (e.g., Renaissance art, cubism, futurism, impressionism, expressionism, post-impressionism, and romanticism), genres (landscapes, portraits, battle paintings, sketches, and illustrations), materials (woodblock prints, engravings, paint), and artists (Clementine Hunter, Mary Cassatt, Vincent van Gogh, Gustave Doré, Gino Severini).
By using causal models called directed acrylic graphs, or DAGs, the coauthors say they were able to identify aspects relevant to AI-generated pieces of art and how these different aspects influenced each other. In one example, they found that DeepArt, a platform that lets users repaint pictures in the style of other artists, failed to account for movement in translating the Cubism artwork Propellers by Fernand Léger into a Futurist style. In another, they report that a piece of realism translated into expressionism by DeepArt — Mary Cassatt’s Miss Mary Ellison — didn’t have the hallmark distorted subjects of expressionism.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Some of these biases are more harmful than others. GoArt, a platform similar to DeepArt, changes the face color of Clementine Hunter’s Black Matriarch from Black to red in translating it to an expressionist style while preserving the color of artwork with white faces like Desiderio da Settignano’s Giovinetto, a sculpture. And another generative art tool, Abacus, mistook young men with long hair in artwork by Raphael and Piero di Cosimo as women.
The researchers peg the blame on imbalances in the datasets used to train generative AI models, which they note might be influenced by dataset curators’ preferences. One app referenced in the study, AI Portraits, was trained using 45,000 Renaissance portraits of mostly white people, for example. Another potential source of bias could be inconsistencies in the labeling process, or the process of annotating the datasets with labels from which the models learn, according to the researchers. Different annotators have different preferences, cultures, and beliefs that might be reflected in the labels that they create.
“There may be imbalances with respect to art genres (e.g. large number of photographs vs few sculptures), artists (e.g. mostly European artists vs few native artists), art movements (large number of works concerning Renaissance and modern art movements as opposed to others), and so on,” the coauthors wrote. “Faces depicting different races, appearances, etc. have not been pooled into the dataset, thus contributing to representational bias.” The researchers warn that by wrongly modeling or overlooking certain subtle components, generative art can contribute to false perceptions about social, cultural, and political aspects of past times and hinder awareness about important historical events. For this reason, they urge AI researchers and practitioners to inspect the design choices and systems and the sociopolitical contexts that shape their use.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
