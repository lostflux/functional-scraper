Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Early Black Friday Deals Best USB-C Accessories for iPhone 15 All the ‚ÄòBest‚Äô T-Shirts Put to the Test What to Do If You Get Emails for the Wrong Person Get Our Deals Newsletter Gadget Lab Newsletter Reece Rogers Business How to Detect AI-Generated Text, According to Researchers Play/Pause Button Pause Illustration: James Marshall Save this story Save Save this story Save AI-generated text, from tools like ChatGPT, is starting to impact daily life. Teachers are testing it out as part of classroom lessons.
 Marketers are champing at the bit to replace their interns.
 Memers are going buck wild.
 Me? It would be a lie to say I‚Äôm not a little anxious about the robots coming for my writing gig. ( ChatGPT , luckily, can‚Äôt hop on Zoom calls and conduct interviews just yet.) With generative AI tools now publicly accessible, you‚Äôll likely encounter more synthetic content while surfing the web. Some instances might be benign, like an auto-generated BuzzFeed quiz about which deep-fried dessert matches your political beliefs. ( Are you Democratic beignet or a Republican zeppole? ) Other instances could be more sinister, like a sophisticated propaganda campaign from a foreign government.
Academic researchers are looking into ways to detect whether a string of words was generated by a program like ChatGPT. Right now, what‚Äôs a decisive indicator that whatever you‚Äôre reading was spun up with AI assistance? A lack of surprise.
Algorithms with the ability to mimic the patterns of natural writing have been around for a few more years than you might realize. In 2019, Harvard and the MIT-IBM Watson AI Lab released an experimental tool that scans text and highlights words based on their level of randomness.
Why would this be helpful? An AI text generator is fundamentally a mystical pattern machine: superb at mimicry, weak at throwing curve balls. Sure, when you type an email to your boss or send a group text to some friends, your tone and cadence may feel predictable, but there's an underlying capricious quality to our human style of communication.
Edward Tian, a student at Princeton, went viral earlier this year with a similar, experimental tool, called GPTZero , targeted at educators. It gauges the likeliness that a piece of content was generated by ChatGPT based on its ‚Äúperplexity‚Äù (aka randomness) and ‚Äúburstiness‚Äù (aka variance). OpenAI, which is behind ChatGPT, dropped another tool made to scan text that‚Äôs over 1,000 characters long and make a judgment call. The company is up-front about the tool‚Äôs limitations, like false positives and limited efficacy outside English. Just as English-language data is often of the highest priority to those behind AI text generators, most tools for AI-text detection are currently best suited to benefit English speakers.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Could you sense if a news article was composed, at least in part, by AI? ‚ÄúThese AI generative texts, they can never do the job of a journalist like you Reece,‚Äù says Tian. It‚Äôs a kind-hearted sentiment. CNET, a tech-focused website, published multiple articles written by algorithms and dragged across the finish line by a human. ChatGPT, for the moment, lacks a certain chutzpah, and it occasionally hallucinates , which could be an issue for reliable reporting. Everyone knows qualified journalists save the psychedelics for after-hours.
While these detection tools are helpful for now, Tom Goldstein, a computer science professor at the University of Maryland , sees a future where they become less effective, as natural language processing grows more sophisticated. ‚ÄúThese kinds of detectors rely on the fact that there are systematic differences between human text and machine text,‚Äù says Goldstein. ‚ÄúBut the goal of these companies is to make machine text that is as close as possible to human text.‚Äù Does this mean all hope of synthetic media detection is lost? Absolutely not.
Goldstein worked on a recent paper researching possible watermark methods that could be built into the large language models powering AI text generators. It‚Äôs not foolproof, but it‚Äôs a fascinating idea. Remember, ChatGPT tries to predict the next likely word in a sentence and compares multiple options during the process. A watermark might be able to designate certain word patterns to be off-limits for the AI text generator. So, when the text is scanned and the watermark rules are broken multiple times, it indicates a human being likely banged out that masterpiece.
Micah Musser, a research analyst at Georgetown University‚Äôs Center for Security and Emerging Technology , expresses skepticism about whether this watermarking style will actually work as intended. Wouldn‚Äôt a bad actor try to get their hands on a non-watermarked version of the generator? Musser contributed to a paper studying mitigation tactics to counteract AI-fueled propaganda. OpenAI and the Stanford Internet Observatory were also part of the research, laying out key examples of potential misuse as well as detection opportunities.
One of the paper‚Äôs core ideas for synthetic-text spotting builds off Meta‚Äôs 2020 look into the detection of AI-generated images.
 Instead of relying on changes made by those in charge of the model, developers and publishers could flick a few drops of poison into their online data and wait for it to be scraped up as part of the big ole data set that AI models are trained on. Then, a computer could attempt to find trace elements of the poisoned, planted content in a model‚Äôs output.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The paper acknowledges that the best way to avoid misuse would be to not create these large language models in the first place. And in lieu of going down that path, it posits AI-text detection as a unique predicament: ‚ÄúIt seems likely that, even with the use of radioactive training data, detecting synthetic text will remain far more difficult than detecting synthetic image or video content.‚Äù Radioactive data is a difficult concept to transpose from images to word combinations. A picture brims with pixels; a Tweet can be 5 words.
What unique qualities are left to human-composed writing? Noah Smith, a professor at the University of Washington and NPL researcher at the Allen Institute for AI , points out that while the models may appear to be fluent in English, they still lack intentionality. ‚ÄúIt really messes with our heads, I think,‚Äù Smith says. ‚ÄúBecause we've never conceived of what it would mean to have fluency without the rest. Now we know.‚Äù In the future, you may need to rely on new tools to determine whether a piece of media is synthetic, but the advice for not writing like a robot will remain the same.
Avoid the rote, and keep it random.
You Might Also Like ‚Ä¶ üì© Get the long view on tech with Steven Levy's Plaintext newsletter Watch this guy work, and you‚Äôll finally understand the TikTok era How Telegram became a terrifying weapon in the Israel-Hamas War Inside Elon Musk‚Äôs first election crisis ‚Äîa day after he ‚Äúfreed‚Äù the bird The ultra-efficient farm of the future is in the sky The best pickleball paddles for beginners and pros üå≤ Our Gear team has branched out with a new guide to the best sleeping pads and fresh picks for the best coolers and binoculars Service Writer X Topics artificial intelligence research how-to language Creative writing Morgan Meaker Matt Reynolds Amy Martyn Aarian Marshall Amanda Hoover Paresh Dave Gregory Barber Niamh Rowe Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
