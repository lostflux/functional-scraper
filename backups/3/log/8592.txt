Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts How we covered the evolution of computing To flip through the archives of MIT Technology Review is to see the development of the computer unfold as it happened.
By The Editors archive page February 1969 From “Man, Machine, and Information Flight Systems”: The flight of Apollo 8 to the moon involved obtaining and processing more bits of data than were used by all fighting forces in World War II. The technological achievement in developing advanced rockets for flying to the moon is reasonably well known. Much less understood, but perhaps of even greater significance, is the information management system. The work of thousands of people in real time, and the data processed by many powerful computers, is organized, processed, filtered, and channeled through one to three people in the cockpit in understandable and digestible form. With this information the pilots can take action with confidence knowing that they are in league with powerful logic systems and an overwhelmingly large number of cells of memory storage.
February 1986 From “The Multiprocessor Revolution: Harnessing Computers Together”: By harnessing many relatively inexpensive VLSI processors together into a multiprocessor system we may significantly reduce the cost of achieving today’s fastest computing speeds. Many of us harbor expectations that this new breed of machines will make possible some of our most romantic and ambitious aspirations: these new machines may recognize images, understand speech, and behave more intelligently. Even anthropomorphic evidence suggests that if computers are to perform intelligently, many processors must work together. Consider the human eye, where millions of neurons cooperate to help us see. What arrogant reasoning led us to believe that a single processor capable of only a few million instructions per second could ever exhibit intelligence? May 1999 From “Cyborg Seeks Community”: People find me peculiar. They think it’s odd that I spend most of my waking hours wearing eight or nine Internet-connected computers sewn into my clothing and that I wear opaque wrap-around glasses day and night, inside and outdoors. They find it odd that to sustain wireless communications during my travels, I will climb to the hotel roof to rig my room with an antenna and Internet connection. They wonder why I sometimes seem detached and lost, but at other times I exhibit vast knowledge of their specialty. A physicist once said he felt that I had the intelligence of a dozen experts in his discipline; a few minutes later, someone else said they thought l was mentally handicapped. Despite the peculiar glances I draw, I wouldn’t live any other way.
hide by The Editors Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window This story was part of our November/December 2021 issue.
Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard Deepfakes of Chinese influencers are livestreaming 24/7 Zeyi Yang How to fix the internet Katie Notopoulos Deep Dive Computing What’s next for the world’s fastest supercomputers Scientists have begun running experiments on Frontier, the world’s first official exascale machine, while facilities worldwide build other machines to join the ranks.
By Sophia Chen archive page AI-powered 6G networks will reshape digital interactions The convergence of AI and communication technologies will create 6G networks that make hyperconnectivity and immersive experiences an everyday reality for consumers.
By MIT Technology Review Insights archive page The power of green computing Sustainable computing practices have the power to both infuse operational efficiencies and greatly reduce energy consumption, says Jen Huffstetler, chief product sustainability officer at Intel.
By MIT Technology Review Insights archive page How this Turing Award–winning researcher became a legendary academic advisor Theoretical computer scientist Manuel Blum has guided generations of graduate students into fruitful careers in the field.
By Sheon Han archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
