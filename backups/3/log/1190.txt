Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google CEO bans autonomous weapons in new AI guidelines Share on Facebook Share on X Share on LinkedIn Google's Android Chief Sundar Pichai Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google today released guidelines for the creation of artificial intelligence , which includes a ban on making autonomous weaponry and most applications of AI with the potential to harm people. The guidelines emerge just days after Google announced it would not renew its contract with the U.S. Department of Defense to analyze drone footage.
As a self-described AI-first company, proprietor of popular open source frameworks like Kaggle and TensorFlow, and employer of prominent researchers, Google is one of the most influential companies in AI.
“We want to be clear that while we are not developing AI for use in weapons, we will continue our work with governments and the military in many other areas. These include cybersecurity, training, military recruitment, veterans’ healthcare, and search and rescue,” CEO Sundar Pichai said in a blog post.
In the post, Pichai spells out the principles that should be considered when creating AI, as well as applications of AI that Google will not pursue. In addition to a ban on designing autonomous weaponry, the company will also seek to avoid the creation of AI whose principal purpose is to injure or harm human beings, as well as “Technologies that gather or use information for surveillance violating internationally accepted norms.” VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! AI made by Google, Pichai states, should uphold standards of scientific excellence, be accountable to people, be tested for safety, and avoid reinforcing bias.
Google AI chief Jeff Dean and more than 3,000 employees signed a petition urging the company to commit to never create autonomous weapons.
About a dozen Google employees reportedly resigned due to the company’s involvement in the Department of Defense’s Project Maven.
The petition urged Google to get out of Maven and that failure to do so could “irreparably damage Google’s brand and its ability to compete for talent” at a time when Google is “already struggling to keep the public’s trust.” Aware of the potential controversy, in emails between executives last fall obtained by the New York Times , Google Cloud chief scientist Dr. Fei-Fei Li reportedly urged the company to avoid mention of AI “at all costs” when considering public mention of its involvement with Maven, and called weaponized AI “probably one of the most sensitized topics of AI — if not THE most.” Pichai’s insistence that Google will continue to work with the military may be a signal that Google still plans to vie for Joint Enterprise Defense Infrastructure (JEDI), a 10-year, $10 billion cloud contract with the U.S. military that drew the attention of major tech companies like Amazon and Google.
An internal memo also revealed that a member of Google’s defense sales team believed that participation in Maven was directly tied to a government contract worth billions of dollars, according to The Intercept.
Google reportedly believed its contract with the Pentagon could bring in up to $250 million a year, though employees were initially told it was only worth $9 million.
News first emerged that Google was involved with Project Maven in March. Other companies, such as IBM, have also been approached to participate in the project. Last week, the Pentagon announced plans to expand Project Maven and open a Joint Artificial Intelligence Center.
Google isn’t the only venture out there to be impacted by employee revolt due to autonomous weaponry. In April in South Korea, more than 50 researchers boycotted what they called an AI weapons lab at KAIST , one of the nation’s top universities.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
