Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Cathy O'Neil Ideas How Shame Defines Our Digital Lives Photo-Illustration: Sam Whitney; Getty Images Save this story Save Save this story Save One day in 2012, an extremely heavy woman was reaching for a case of soda in a Missouri Walmart when her motorized cart tipped over. After she tumbled in a heap to the floor, she saw a flash of light and heard girls giggling.
Courtesy of Crown Buy This Book At: Amazon Bookshop.org Target If you buy something using links in our stories, we may earn a commission. This helps support our journalism.
Learn more.
To protect her from further shaming, I‚Äôll call her Joanna McCabe. A mother of two, McCabe suffered from a spinal condition known as spondylolisthesis. This made it painful to walk. She was clinically depressed and hardly surprised to find herself the object of scorn and laughter. But someone had taken her picture.
It quickly found its way onto a mocking website called People of Walmart, and from there to Reddit and Facebook. Joanna McCabe went viral. In comments on social networks, people had fun with her and ridiculed her life choices. The ignorance of a fat woman reaching for soda pop! But the most damning element was the photo. With social media as a potent force accelerator, the image of a large woman splayed on the floor of a supermarket spread to a significant chunk of humanity.
McCabe fell victim to a new and potent variety of shame machines. Digital titans, led by Facebook and Google, not only profit from shame events but are engineered to exploit and diffuse them. In their massive research labs, mathematicians work closely with psychologists and anthropologists, using our behavioral data to train their machines. Their objective is to spur customer participation and to mine advertising gold. When it comes to this type of intense engagement, shame is one of the most potent motivators. It‚Äôs right up there with sex. So even if the data scientists and their bosses in the executive suites might not map out a strategy based on shaming, their automatic algorithms zero in on it. It spurs traffic and boosts revenue.
You could argue that the people mocking Joanna McCabe didn‚Äôt intend to hurt her. They were just having a laugh. And yes, this was largely performative shaming. However, looking at the incident through the lens of shame, the online horde was punching down on the fallen shopper to no constructive end. It was hardly an attempt to prod a wayward soul back to shared norms. For most people, she was just a digital pi√±ata.
This is the toxic nature of shame networks, and their appeal is potent. When we express indignation in a tweet or zap some miscreant on Facebook, it makes us feel good. The reward circuits in the striatum, a section of the forebrain, light up, says Molly Crockett, a psychology researcher at Yale. It‚Äôs similar to the neural feedback we get when we eat or have sex or snort a line of cocaine. Crockett says that the brain evolved to reward behaviors that propagate the species. And keeping fellow community members in line passes that test. Outrage satisfies, even if it‚Äôs the product of a vile and baseless accusation.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker In the pre-internet age, an embarrassing moment like a fall in the soda aisle might have generated some jokes among friends and neighbors. But today a single slip can send the networked shame machinery into overdrive, turning it into a global event. Egged on by algorithms, millions of us participate in these dramas, providing the tech giants with free labor. The activity they market has an outsize role in defining the lives we lead and the society we create.
Let‚Äôs say you open Facebook and see an alert. You click, and to your horror you see that someone has posted a terribly unflattering picture and tagged you. That tag is nefarious, because it means that whenever anyone searches the internet for you or anyone else tagged in that photo, or for that matter anything related to the event you were attending, that cringeworthy image will show up. It sticks to your identity and is dragged along, like a piece of toilet paper on a shoe.
The misery we inflict on others via digital shame machines, often without knowing it, accounts for only the most obvious grief. The more pervasive abuses are engineered to whir away on their own. And this automated poison is progressing at such a furious pace that science fiction from only a few years ago now reads like today‚Äôs news. Gary Shteyngart‚Äôs 2010 novel, Super Sad True Love Story, for example, describes a futuristic world in which radically open data is the norm, and the possibility of shaming lurks around every corner. Credit scores appear on a public display when characters walk past a ‚Äúcredit pole‚Äù in the neighborhood. The advanced cellphones, or √§pp√§r√§ts, can scan the net worth and financial history of each passerby. If someone in a bar tells a joke that falls flat, their ‚Äúhotness‚Äù and ‚Äúpersonality‚Äù scores plummet in real time.
Abuses very much like these are already spreading, especially in China, where state surveillance operates without even a hint of restraint. There are constellations of government-sanctioned social credit scores, some of which ding a given person if a surveillance camera catches them lighting up in a no-smoking zone or playing too many video games. Others use cameras equipped with AI that can identify individuals based on a combination of facial features, posture, and gait. So if, say, someone is heading to work and gets caught jaywalking, the smart cam can tag the name and personal information of the offender and flash it across a digital billboard. Or likewise you might get punished for littering in the subway or denigrating the ruling party online. Your various infractions might also be announced, by name, on Weibo or WeChat, internet giants in China.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker No matter where we live, some of us fare far better than others in our relations with the expanding network linking data to shame and stigma. The easiest people to exploit tend to be the most desperate, the ones who lack the money, the knowledge, or the leisure time to tend to the digital baggage that trails them, or simply those who have traditionally been treated badly. These are folks who are disproportionately poor or otherwise marginalized and have the least control over their identities. Their lives can be defined, and poisoned, by shame machines: the diet industry, opioid merchants, for-profit prisons, welfare bureaucracies, the list goes on. Those machines punch down on them relentlessly.
But shame has a second life in the data economy. Evictions, brushes with child protective services or the law, trips to casinos‚Äîall leave rich trails of information, creating a bonanza for the many institutions that feed on shame data. These stretch far beyond the social networks to the formal economy of credit rating companies, mortgage brokers, and parole boards, as well as a vast who‚Äôs who of hucksters and scam artists. The episodes that trigger the most shame are digitized, codified, and then processed by hundreds or thousands of different algorithms to size up the people involved, make money from them, and deprive them of opportunities, often permanently.
In this modern incarnation of Scarlet Letter , the red A is digital. No longer pinned to a dress, it endures as myriad risk scores in the mammoth data centers stored in computer clouds.
Wiping these digital scarlet letters clean is no simple matter. While it‚Äôs true that the criminal justice system in the United States enables people who have been cleared of a crime to expunge the charge from their official records, the mugshots and charges persist on the internet and show up in search engine results. One New Jersey man named Alan was charged in 2017 with a crime resulting from a misunderstanding: A summons to appear in municipal court had been sent to the wrong address. The judge understood this and promptly vacated the charge. Yet Alan, as described in Slate, struggled mightily to remove his (false) arrest record from the internet. After contacting lots of website administrators and the state police, he had limited success. But all the while, he kept receiving come-ons from ‚Äúreputation management‚Äù consultants who offered to erase his mugshots for a fee. The vast economic ecosystem of digital shame offers endless opportunities to make a buck.
Excerpted from The Shame Machine: Who Profits in the New Age of Humiliation by Cathy O'Neil. Copyright ¬© 2022 by Cathy O'Neil. Excerpted by permission of Crown Publishing, an imprint of Penguin Random House LLC. All rights reserved. No part of this excerpt may be reproduced or reprinted without permission in writing from the publisher.
üì© The latest on tech, science, and more: Get our newsletters ! The infinite reach of Facebook's man in Washington Of course we're living in a simulation A big bet to kill the password for good How to block spam calls and text messages The end of infinite data storage can set you free üëÅÔ∏è Explore AI like never before with our new database ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Topics Book Excerpt Books Social Media algorithms Meghan O'Gieblyn Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
