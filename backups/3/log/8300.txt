Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business AI Giants Pledge to Allow External Probes of Their Algorithms, Under a New White House Pact Photograph: Yasin Ozturk/Getty Images Save this story Save Save this story Save The White House has struck a deal with major AI developers‚Äîincluding Amazon, Google, Meta, Microsoft, and OpenAI‚Äîthat commits them to take action to prevent harmful AI models from being released into the world.
Under the agreement, which the White House calls a ‚Äúvoluntary commitment,‚Äù the companies pledge to carry out internal tests and permit external testing of new AI models before they are publicly released. The test will look for problems including biased or discriminatory output, cybersecurity flaws, and risks of broader societal harm. Startups Anthropic and Inflection , both developers of notable rivals to OpenAI‚Äôs ChatGPT, also participated in the agreement.
‚ÄúCompanies have a duty to ensure that their products are safe before introducing them to the public by testing the safety and capability of their AI systems,‚Äù White House special adviser for AI Ben Buchanan told reporters in a briefing yesterday. The risks that companies were asked to look out for include privacy violations and even potential contributions to biological threats. The companies also committed to publicly reporting the limitations of their systems and the security and societal risks they could pose.
The agreement also says the companies will develop watermarking systems that make it easy for people to identify audio and imagery generated by AI. OpenAI already adds watermarks to images produced by its Dall-E image generator , and Google has said it is developing similar technology for AI-generated imagery. Helping people discern what‚Äôs real and what‚Äôs fake is a growing issue as political campaigns appear to be turning to generative AI ahead of US elections in 2024.
Recent advances in generative AI systems that can create text or imagery have triggered a renewed AI arms race among companies adapting the technology for tasks like web search and writing recommendation letters. But the new algorithms have also triggered renewed concern about AI reinforcing oppressive social systems like sexism or racism, boosting election disinformation, or becoming tools for cybercrime. As a result, regulators and lawmakers in many parts of the world‚Äî including Washington, DC ‚Äîhave increased calls for new regulation, including requirements to assess AI before deployment.
It‚Äôs unclear how much the agreement will change how major AI companies operate. Already, growing awareness of the potential downsides of the technology has made it common for tech companies to hire people to work on AI policy and testing. Google has teams that test its systems, and it publicizes some information, like the intended use cases and ethical considerations for certain AI models.
 Meta and OpenAI sometimes invite external experts to try and break their models in an approach dubbed red-teaming.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker ‚ÄúGuided by the enduring principles of safety, security, and trust, the voluntary commitments address the risks presented by advanced AI models and promote the adoption of specific practices‚Äîsuch as red-team testing and the publication of transparency reports‚Äîthat will propel the whole ecosystem forward,‚Äù Microsoft president Brad Smith said in a blog post.
The potential societal risks the agreement pledges companies to watch for do not include the carbon footprint of training AI models , a concern that is now commonly cited in research on the impact of AI systems. Creating a system like ChatGPT can require thousands of high-powered computer processors, running for extended periods of time.
Andrew Burt, managing partner at law firm BNH, which specializes in AI, says the potential risks of generative AI systems are becoming clear to everyone involved with the technology. The Federal Trade Commission began a probe into OpenAI‚Äôs business practices last week, alleging that the company participated in ‚Äúunfair or deceptive privacy or data security practices.‚Äù The White House agreement‚Äôs stipulation that companies should commission external assessments of their technology adds to evidence that outside audits are becoming ‚Äúthe central way governments exert oversight for AI systems,‚Äù Burt says.
The White House also promoted the use of audits in the voluntary AI Bill of Rights issued last year, and it is supporting a hacking contest centered on generative AI models at the Defcon security conference next month. Audits are also a requirement of the EU‚Äôs sweeping AI Act , which is currently being finalized.
Jacob Appel, chief strategist at ORCAA, a company that audits algorithms for businesses and government, says the agreement is welcome but that general assessments of large language models like those behind ChatGPT are insufficient. Specific, high risk use cases of AI, such as a chatbot fine tuned to generate medical or legal advice, should get their own tailored assessments, he says. And systems from smaller companies also need scrutiny.
President Joe Biden will meet at the White House today with executives from the companies that joined the new AI agreement, including Anthropic CEO Dario Amodei, Microsoft president Brad Smith, and Inflection AI CEO Mustafa Suleyman. His administration is also developing an executive order to govern the use of AI through actions by federal agencies, but the White House gave no specific timeline for its release.
Updated 7-21-2023, 2:20 pm EDT: This article was updated with comment from Jacob Appel at ORCAA.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics White House artificial intelligence ChatGPT OpenAI Google Microsoft Meta machine learning algorithms Regulation Will Knight Will Knight Vittoria Elliott Will Knight Susan D'Agostino Christopher Beam Niamh Rowe Reece Rogers Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
