Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages MIT, Cohere for AI, others launch platform to track and filter audited AI datasets Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Researchers from MIT, Cohere for AI and 11 other institutions launched the Data Provenance Platform today in order to “tackle the data transparency crisis in the AI space.” They audited and traced nearly 2,000 of the most widely used fine-tuning datasets, which collectively have been downloaded tens of millions of times, and are the “backbone of many published NLP breakthroughs,” according to a message from authors Shayne Longpre, a Ph.D candidate at MIT Media Lab, and Sara Hooker, head of Cohere for AI.
“The result of this multidisciplinary initiative is the single largest audit to date of AI dataset,” they said. “For the first time, these datasets include tags to the original data sources, numerous re-licensings, creators, and other data properties.” To make this information practical and accessible, an interactive platform, the Data Provenance Explorer , allows developers to track and filter thousands of datasets for legal and ethical considerations, and enables scholars and journalists to explore the composition and data lineage of popular AI datasets.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Dataset collections do not acknowledge lineage The group released a paper, T he Data Provenance Initiative: A Large Scale Audit of Dataset Licensing & Attribution in AI , which says: “Increasingly, widely used dataset collections are treated as monolithic, instead of a lineage of data sources, scraped (or model generated), curated, and annotated, often with multiple rounds of re-packaging (and re-licensing) by successive practitioners. The disincentives to acknowledge this lineage stem both from the scale of modern data collection (the effort to properly attribute it), and the increased copyright scrutiny. Together, these factors have seen fewer Datasheets, non-disclosure of training sources and ultimately a decline in understanding training data.
This lack of understanding can lead to data leakages between training and test data; expose personally identifiable information (PII), present unintended biases or behaviours; and generally result in lower quality models than anticipated. Beyond these practical challenges, information gaps and documentation debt incur substantial ethical and legal risks. For instance, model releases appear to contradict data terms of use. As training models on data is both expensive and largely irreversible, these risks and challenges are not easily remedied.” Training datasets have been under scrutiny in 2023 VentureBeat has deeply covered issues related to data provenance and transparency of training datasets: Back in March, Lightning AI CEO William Falcon slammed OpenAI’s GPT-4 paper as ‘masquerading as research.” Many said the report was notable mostly for what it did not include. In a section called Scope and Limitations of this Technical Report, it says: “Given both the competitive landscape and the safety implications of large-scale models like GPT-4, this report contains no further details about the architecture (including model size), hardware, training compute, dataset construction, training method, or similar.” And in September, we published a deep dive into the copyright issues looming in generative AI training data.
The explosion of generative AI over the past year has become an “‘oh, shit!” moment when it comes to dealing with the data that trained large language and diffusion models, including mass amounts of copyrighted content gathered without consent, Dr. Alex Hanna, director of research at the Distributed AI Research Institute (DAIR) , told VentureBeat.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
