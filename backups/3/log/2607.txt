Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Amit Katwala Science Why DeepMind Is Sending AI Humanoids to Soccer Camp Photograph: Paul Taylor/Getty Images Save this story Save Save this story Save Application Games Robotics End User Research Big company Sector Research Source Data Images Video Technology Machine learning Robotics DeepMindâ€™s attempt to teach an AI to play soccer started with a virtual player writhing around on the floorâ€”so it nailed at least one aspect of the game right from kickoff.
But pinning down the mechanics of the beautiful gameâ€”from basics like running and kicking to higher-order concepts like teamwork and tacklingâ€”proved a lot more challenging, as new research from the Alphabet-backed AI firm demonstrates. The workâ€”published this week in the journal Science Robotics â€”might seem frivolous, but learning the fundamentals of soccer could one day help robots to move around our world in more natural, more human ways.
â€œIn order to â€˜solveâ€™ soccer, you have to actually solve lots of open problems on the path to artificial general intelligence [AGI],â€ says Guy Lever, a research scientist at DeepMind. â€œThereâ€™s controlling the full humanoid body, coordinationâ€”which is really tough for AGIâ€”and actually mastering both low-level motor control and things like long-term planning.â€ An AI has to re-create everything human players doâ€”even the things we donâ€™t have to consciously think about, like precisely how to move each limb and muscle in order to connect with a moving ballâ€”making hundreds of decisions a second. The timing and control required for even the most basic movements can actually be surprisingly tricky to nail down, as anyone who has ever played the browser game QWOP will remember. â€œWe do that without thinking about it, but thatâ€™s a really hard problem for AI, and weâ€™re not really sure exactly how humans do that,â€ Lever says.
DeepMindâ€™s simulated humanoid agents were modeled on real humans, with 56 points of articulation and a constrained range of motionâ€”meaning that they couldnâ€™t, for instance, rotate their knee joint through impossible angles Ã  la Zlatan Ibrahimovic. To start with, the researchers simply gave the agents a goalâ€”run, for example, or kick a ballâ€”and let them try and figure out how to get there through trial and error and reinforcement learning, as was done in the past when researchers taught simulated humanoids to navigate obstacle courses (with comical, quite unnatural results).
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker â€œThis didnâ€™t really work,â€ says Nicolas Heess, also a research scientist at DeepMind, and one of the paperâ€™s coauthors with Lever. Because of the complexity of the problem, the huge range of options available, and the lack of prior knowledge about the task, the agents didnâ€™t really have any idea where to startâ€”hence the writhing and twitching.
So instead, Heess, Lever, and colleagues used neural probabilistic motor primitives (NPMP), a teaching method that nudged the AI model towards more human-like movement patterns, in the expectation that this underlying knowledge would help to solve the problem of how to move around the virtual football pitch. â€œIt basically biases your motor control toward realistic human behavior, realistic human movements,â€ says Lever. â€œAnd thatâ€™s learnt from motion captureâ€”in this case, human actors playing football.â€ This â€œreconfigures the action space,â€ Lever says. The agentsâ€™ movements are already constrained by their humanlike bodies and joints that can bend only in certain ways, and being exposed to data from real humans constrains them further, which helps simplify the problem. â€œIt makes useful things more likely to be discovered by trial and error,â€ Lever says. NPMP speeds up the learning process. There is a â€œsubtle balanceâ€ to be struck between teaching the AI to do things the way humans do them, while also giving it enough freedom to discover its own solutions to problemsâ€”which may be more efficient than the ones we come up with ourselves.
Basic training was followed by single-player drills: running, dribbling, and kicking the ball, mimicking the way that humans might learn to play a new sport before diving into a full match situation. The reinforcement learning rewards were things like successfully following a target without the ball, or dribbling the ball close to a target. This curriculum of skills was a natural way to build toward increasingly complex tasks, Lever says.
The aim was to encourage the agents to reuse skills they might have learned outside of the context of soccer within a soccer environmentâ€”to generalize and be flexible at switching between different movement strategies. The agents that had mastered these drills were used as teachers. In the same way that the AI was encouraged to mimic what it had learned from human motion capture, it was also rewarded for not deviating too far from the strategies the teacher agents used in particular scenarios, at least at first. â€œThis is actually a parameter of the algorithm which is optimized during training,â€ Lever says. â€œOver time they can in principle reduce their dependence on the teachers.â€ Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker With their virtual players trained, it was time for some match action: starting with 2v2 and 3v3 games to maximize the amount of experience the agents accumulated during each round of simulation (and mimicking how young players start off with small-sided games in real life). The highlightsâ€” which you can watch here â€”have the chaotic energy of a dog chasing a ball in the park: players donâ€™t so much run as stumble forward, perpetually on the verge of tumbling to the ground. When goals are scored, itâ€™s not from intricate passing moves, but hopeful punts upfield and foosball-like rebounds off the back wall.
However, although in games the agents were rewarded only for scoring goals, the researchers quickly saw properties like teamwork starting to emerge. â€œAt the very beginning of training all of the agents just run to the ball, and at some point after a few days weâ€™d actually see that the agents would realize that one of its teammates was in control of the ball and would turn around and run up the pitch, anticipating that its teammate would try and score or maybe pass the ball,â€ says Lever. Itâ€™s the first time such coordination and teamwork has been seen in such a complex and quick-acting AI. â€œThatâ€™s one of the breakthroughs thatâ€™s interesting to me,â€ Lever says.
Culture Taylor Swift and BeyoncÃ© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Appleâ€™s Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Swedenâ€™s Tesla Blockade Is Spreading Morgan Meaker As for the point of all this? Itâ€™s not about dominating the Robot World Cup ; Heess is working on imbuing some of the lower-level skills the agents have learned into physical robots to make them move in ways that are more â€œsafe and naturalisticâ€ in the real world. Thatâ€™s not just so they donâ€™t freak out humans that interact with them, but also because the jittery, irregular motions that may be produced by unstructured reinforcement learning could damage robots that werenâ€™t optimized to move in those ways, or just waste energy.
Itâ€™s all part of work on â€œembodied intelligenceâ€â€”the idea that a general artificial intelligence might be required to move around the world in some sort of physical form, and that the nature of that form might determine the way it behaves. â€œItâ€™s interesting both in simulated worlds, which increasingly feature physics-based simulation, but also to develop methods for robot learning,â€ says Heess.
Eventually these slightly slapstick digital players could help both robots and metaverse avatars move in ways that seem more humanâ€”even if theyâ€™ll still never beat us at soccer. â€œFootball is not really an end goal in itself,â€ says Lever. â€œThere are just lots of things you need to solve in order to get there.â€ You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Senior writer X Topics DeepMind artificial intelligence robotics robots soccer Erica Kasper Tammy Rabideau Matt Simon Jim Robbins Matt Simon Tristan Kennedy Sushmita Pathak Amit Katwala Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
