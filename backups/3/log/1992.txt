Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts Google says its new chatbot Meena is the best in the world By Will Douglas Heaven archive page person using a laptop NeONBRAND | Unsplash Google has released a neural-network-powered chatbot called Meena that it claims is better than any other chatbot out there.
Data slurp: Meena was trained on a whopping 341 gigabytes of public social-media chatter—8.5 times as much data as OpenAI’s GPT-2.
 Google says Meena can talk about pretty much anything, and can even make up (bad) jokes.
Why it matters: Open-ended conversation that covers a wide range of topics is hard, and most chatbots can’t keep up. At some point most say things that make no sense or reveal a lack of basic knowledge about the world. A chatbot that avoids such mistakes will go a long way toward making AIs feel more human, and make characters in video games more lifelike.
Sense and specificity: To put Meena to the test, Google has developed a new metric it calls the Sensibleness and Specificity Average (SSA), which captures important attributes for natural conversations, such as whether each utterance makes sense in context—which many chatbots can do—and is specific to what has just been said, which is harder.
What do you mean? For example, if you say “I like tennis” and a chatbot replies “That’s nice,” the response makes sense but is not specific. Many chatbots rely on tricks like this to hide the fact that they don’t know what you’re talking about. On the other hand, a response such as “Me too—I can’t get enough of Roger Federer” is specific. Google used crowdworkers to generate sample conversations and to score utterances in around 100 conversations. Meena got an SSA score of 79%, compared with 56% for Mitsuku, a state-of-the-art chatbot that has won the Loebner Prize for the last four years. Even human conversation partners only scored 86% in this new test.
Can I talk to Meena? Not yet. Google says it won’t be releasing a public demo until it has vetted the model for safety and bias, which is probably a good thing. When Microsoft released its chatbot Tay on Twitter in 2016, it started spewing racist, misogynistic invective within hours.
hide by Will Douglas Heaven Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard Deepfakes of Chinese influencers are livestreaming 24/7 Zeyi Yang How to fix the internet Katie Notopoulos Deep Dive Artificial intelligence This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Deepfakes of Chinese influencers are livestreaming 24/7 With just a few minutes of sample video and $1,000, brands never have to stop selling their products.
By Zeyi Yang archive page Driving companywide efficiencies with AI Advanced AI and ML capabilities revolutionize how administrative and operations tasks are done.
By MIT Technology Review Insights archive page Rogue superintelligence and merging with machines: Inside the mind of OpenAI’s chief scientist An exclusive conversation with Ilya Sutskever on his fears for the future of AI and why they’ve made him change the focus of his life’s work.
By Will Douglas Heaven archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
