Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Zachary Fryer-Biggs Backchannel Inside the Pentagon‚Äôs Plan to Win Over Silicon Valley's AI Experts Play/Pause Button Pause Elena Lacey; Getty Images Save this story Save Save this story Save The American military is desperately trying to get a leg up in the field of artificial intelligence, which top officials are convinced will deliver victory in future warfare. But internal Pentagon documents and interviews with senior officials make clear that the Defense Department is reeling from being spurned by a tech giant and struggling to develop a plan that might work in a new sort of battle‚Äîfor hearts and minds in Silicon Valley.
The battle began with an unexpected loss. In June, Google announced it was pulling out of a Pentagon program‚Äîthe much-discussed Project Maven ‚Äîthat used the tech giant‚Äôs artificial intelligence software. Thousands of the company‚Äôs employees had signed a petition two months earlier calling for an end to its work on the project, an effort to create algorithms that could help intelligence analysts pick out military targets from video footage.
Inside the Pentagon, Google‚Äôs withdrawal brought a combination of frustration and distress‚Äîeven anger‚Äîthat has percolated ever since, according to five sources familiar with internal discussions on Maven, the military‚Äôs first big effort to utilize AI in warfare.
This article was produced in partnership with the Center for Public Integrity , a nonprofit, nonpartisan news organization.
‚ÄúWe have stumbled unprepared into a contest over the strategic narrative,‚Äù said an internal Pentagon memo circulated to roughly 50 defense officials on June 28. The memo depicted a department caught flat-footed and newly at risk of alienating experts critical to the military‚Äôs artificial intelligence development plans.
‚ÄúWe will not compete effectively against our adversaries if we do not win the ‚Äòhearts and minds‚Äô of the key supporters,‚Äù it warned.
Maven was actually far from complete and cost only about $70 million in 2017, a molecule of water in the Pentagon‚Äôs oceanic $600 billion budget that year. But Google‚Äôs announcement exemplified a larger public relations and scientific challenge the department is still wrestling with. It has responded so far by trying to create a new public image for its AI work and by seeking a review of the department‚Äôs AI policy by an advisory board of top executives from tech companies.
The reason for the Pentagon‚Äôs anxiety is clear: It wants a smooth path to use artificial intelligence in weaponry of the future, a desire already backed by the promise of several billion dollars to try to ensure such systems are trusted and accepted by military commanders, plus billions more in expenditures on the technologies themselves.
The exact role that AI will wind up playing in warfare remains unclear. Many weapons with AI will not involve decision-making by machine algorithms, but the potential for them to do so will exist. As a Pentagon strategy document said in August: ‚ÄúTechnologies underpinning unmanned systems would make it possible to develop and deploy autonomous systems that could independently select and attack targets with lethal force.‚Äù Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Developing artificial intelligence, officials say, is unlike creating other military technologies. While the military can easily turn to big defense contractors for cutting-edge work on fighter jets and bombs, the heart of innovation in AI and machine learning resides among the non-defense tech giants of Silicon Valley. Without their help, officials worry, they could lose an escalating global arms race in which AI will play an increasingly important role, something top officials say they are unwilling to accept.
‚ÄúIf you decide not to work on Maven, you‚Äôre not actually having a discussion on if artificial intelligence or machine learning are going to be used for military operations,‚Äù Chris Lynch, a former tech entrepreneur who now runs the Pentagon‚Äôs Defense Digital Service, said in an interview. AI is coming to warfare, he says, so the question is, which American technologists are going to engineer it? Lynch, who recruits technical experts to spend several years working on Pentagon problems before returning to the private sector, said that AI technology is too important, and that the agency will proceed even if it has to rely on lesser experts. But without the help of the industry‚Äôs best minds, Lynch added, ‚Äúwe‚Äôre going to pay somebody who is far less capable to go build a far less capable product that may put young men and women in dangerous positions, and there may be mistakes because of it.‚Äù Google isn‚Äôt likely to shift gears soon. Less than a week after announcing that the company would not seek to renew the Maven contract in June, Google released a set of AI principles which specified that the company would not use AI for ‚Äúweapons or other technologies whose principal purpose or implementation is to cause or directly facilitate injury to people.‚Äù Some defense officials have complained since then that Google was being unpatriotic , noting that the company was still pursuing work with the Chinese government, the top US competitor in artificial intelligence technology.
‚ÄúI have a hard time with companies that are working very hard to engage in the market inside of China, and engaging in projects where intellectual property is shared with the Chinese, which is synonymous with sharing it with the Chinese military, and then don't want to work for the US military,‚Äù General Joe Dunford, chairman of the Joint Chiefs of Staff, commented while speaking at a conference in November.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker In December testimony before congress, Google CEO Sundar Pichai acknowledged that Google had experimented with a program involving China, Project Dragonfly , aimed at developing a model of what government-censored search results would look like in China. However, Pichai testified that Google currently ‚Äúhas no plans to launch in China.‚Äù Project Maven‚Äôs aim was to simplify work for intelligence analysts by tagging object types in video footage from drones and other platforms, helping analysts gather information and narrow their focus on potential targets, according to sources familiar with the partly classified program. But the algorithms did not select the targets or order strikes, a longtime fear of those worried about the intersection of advanced computing and new forms of lethal violence.
Many at Google nonetheless saw the program in alarming terms.
‚ÄúThey immediately heard drones and then they thought machine learning and automatic target recognition, and I think it escalated for them pretty quickly about enabling targeted killing, enabling targeted warfare,‚Äù said a former Google employee familiar with the internal discussions.
Google is just one of the tech giants that the Pentagon has sought to enlist in its effort to inject AI into modern warfare technology. Among the others: Microsoft and Amazon. After Google‚Äôs announcement in June more than a dozen large defense firms approached defense officials, offering to take over the work, according to current and former Pentagon officials.
But Silicon Valley activists also say the industry cannot easily ignore the ethical qualms of tech workers. ‚ÄúThere‚Äôs a division between those who answer to shareholders, who want to get access to Defense Department contracts worth multimillions of dollars, and the rank and file who have to build the things and who feel morally complicit for things they don‚Äôt agree with,‚Äù the former Google employee said.
In an effort to bridge this gulf and dampen hard-edged opposition from AI engineers, the Defense Department has so far undertaken two initiatives.
The first, formally begun in late June, was to create a Joint Artificial Intelligence Center meant to oversee and manage all of the military‚Äôs AI efforts, with an initial focus on PR-friendly humanitarian missions. It‚Äôs set to be run by Lieutenant General Jack Shanahan, whose last major assignment was running Project Maven. In a politically shrewd decision, its first major initiative is to figure out a way to use AI to help organize the military‚Äôs search and rescue response to natural disasters.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker ‚ÄúOur goal is to save lives,‚Äù Brendan McCord, one of the chief architects of the Pentagon‚Äôs AI strategy, said while speaking at a technical conference in October. ‚ÄúOur military‚Äôs fundamental role, its mission, is to keep the peace. It is to deter war and protect our country. It is to improve global stability, and it‚Äôs to ultimately protect the set of values that came out of the Enlightenment.‚Äù The second initiative is to order a new review of AI ethics by an advisory panel of tech experts, the Defense Innovation Board, which includes former Google CEO Eric Schmidt and LinkedIn cofounder Reid Hoffman.
That review, designed to develop principles for the use of AI by the military, is being managed by Joshua Marcuse, a former adviser to the secretary of defense on innovation issues who is now executive director of the board. Set to take about nine months, the advisory panel will hold public meetings with AI experts, while an internal Pentagon group also considers questions. Then it will forward recommendations to secretary of defense James Mattis about the ways that AI should or should not be injected into weapons programs.
‚ÄúThis has got to be about actually looking in the mirror and being willing to impose some constraints on what we will do, on what we won‚Äôt do, knowing what the boundaries are,‚Äù Marcuse said in an interview.
To make sure the debate is robust, Marcuse said that the board is seeking out critics of the military‚Äôs role in AI.
‚ÄúThey have a set of concerns, I think really valid and legitimate concerns, about how the Department of Defense is going to apply these technologies, because we have legal authority to invade people‚Äôs privacy in certain circumstances, we have legal authority to commit violence, we have legal authority to wage war,‚Äù he said.
Resolving those concerns is critical, officials say, because of the difference in how Washington and Beijing manage AI talent. China can conscript experts to work on military problems, whereas the United States has to find a way to interest and attract outside experts.
‚ÄúThey have to choose to work with us, so we need to offer them a meaningful, verifiable commitment that there are real opportunities to work with us where they can feel confident that they‚Äôre the good guys,‚Äù Marcuse said.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Despite his willingness to discuss potential future constraints on AI usage, Marcuse said he didn‚Äôt think the board would try to change the Pentagon‚Äôs existing policy on autonomous weapons that depend on AI, which was put in place by the Obama administration in 2012.
That policy, which underwent a minor technical revision by the Trump administration in May 2017, doesn‚Äôt prevent the military from using artificial intelligence in any of its weapons systems. It mandates that commanders have ‚Äúappropriate levels of human judgment‚Äù over any AI-infused weapons systems, although the phrase isn‚Äôt further defined and remains a source of confusion within the Pentagon, according to multiple officials there.
It does, however, require that before a computer could be programmed to initiate deadly action, the weapons system that contains it must undergo special review by three senior Pentagon officials‚Äîin advance of its purchase. To date that special review hasn‚Äôt been undertaken.
In late 2016, during the waning days of the Obama administration, the Pentagon took a new look at the 2012 policy and decided in a classified report that no major change was needed, according to a former defense official familiar with the details. ‚ÄúThere was nothing that was held up, there was no one who thought, ‚ÄòOh we have to update the directives,‚Äô‚Äù the former official said.
The Trump administration nonetheless has internally discussed making it clearer to weapons engineers within the military‚Äîwho it fears have been reluctant to inject AI into their designs‚Äîthat the policy doesn‚Äôt ban the use of autonomy in weapons systems. The contretemps in Silicon Valley over Project Maven at least temporarily halted that discussion, prompting the department‚Äôs leaders to try first to win the support of the Defense Innovation Board.
But one way or another, the Pentagon intends to integrate more AI into its weaponry. ‚ÄúWe‚Äôre not going to sit on the sidelines as a new technology revolutionizes the battlefield,‚Äù Marcuse said. ‚ÄúIt‚Äôs not fair to the American people, it‚Äôs not fair to our service members who we send into harm‚Äôs way, and it‚Äôs not fair to our allies who depend on us.‚Äù The Center for Public Integrity is a nonprofit, nonpartisan, investigative newsroom in Washington, DC. More of its national security reporting can be found here.
Alexa grew up this year, mostly because we talked to it 8 sci-fi writers imagine the bold and new future of work The mad scramble for the world's most coveted meteorite Galileo, krypton, and how the true meter came to be Everything you want to know about the promise of 5G üëÄ Looking for the latest gadgets? Check out our picks , gift guides , and best deals all year round üì© Get even more of our inside scoops with our weekly Backchannel newsletter Brendan I. Koerner Andy Greenberg Brandi Collins-Dexter Angela Watercutter Steven Levy Lauren Smiley Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
