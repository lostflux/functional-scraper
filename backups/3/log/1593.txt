Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business To Power AI, This Startup Built a Really, Really Big Chip Cerebras Save this story Save Save this story Save Application Hardware End User Big company Research Sector IT Semiconductors Technology Chips Computer chips are usually small. The processor that powers the latest iPhones and iPads is smaller than a fingernail; even the beefy devices used in cloud servers aren‚Äôt much bigger than a postage stamp. Then there‚Äôs this new chip from a startup called Cerebras: It‚Äôs bigger than an iPad all by itself.
The silicon monster is almost 22 centimeters‚Äîroughly 9 inches‚Äîon each side, making it likely the largest computer chip ever, and a monument to the tech industry‚Äôs hopes for artificial intelligence. Cerebras plans to offer it to tech companies trying to build smarter AI more quickly.
Eugenio Culurciello, a fellow at chipmaker Micron who has worked on chip designs for AI but was not involved in the project, calls the scale and ambition of Cerebras‚Äô chip ‚Äúcrazy.‚Äù He also believes that it makes sense, because of the intense computing power demanded by large scale AI projects such as virtual assistants and self-driving cars. ‚ÄúIt will be expensive, but some people will probably use it,‚Äù he says.
The current boom in all things AI is driven by a technology called deep learning.
 AI systems built on it are developed using a process called training, in which algorithms optimize themselves to a task by analyzing example data.
The training data might be medical scans annotated to mark tumors or a bot‚Äôs repeated attempts to win a videogame.
 Software made this way is generally more powerful when it has more data to learn from or the learning system itself is larger and more complex.
Computing power has become a limiting factor for some of the most ambitious AI projects. A recent study on the energy consumption of deep-learning training found it could cost $350,000 to develop a single piece of language-processing software. The for-profit AI lab OpenAI has estimated that between 2012 and 2018, the amount of computing power expended on the largest published AI experiments doubled roughly every three and a half months.
AI experts yearning for more oomph typically use graphics processors, or GPUs. The deep-learning boom originated in the discovery that GPUs are well suited to the math underpinning the technique, a coincidence that has boosted the stock price of leading GPU supplier Nvidia eight-fold in the past five years. More recently, Google has developed its own AI chips customized to deep learning called TPUs, and a raft of startups have begun work on their own AI hardware.
To train deep-learning software on tasks like recognizing images, engineers use clusters of many GPUs wired together. To make a bot that took on the videogame Dota 2 last year , OpenAI tied up hundreds of GPUs for weeks.
Cerebras' chip, left, is many times the size of an Nvidia graphics processor, right, popular with AI researchers.
Cerebras Cerebras‚Äô chip covers more than 56 times the area of Nvidia‚Äôs most powerful server GPU, claimed at launch in 2017 to be the most complex chip ever. Cerebras founder and CEO Andrew Feldman says the giant processor can do the work of a cluster of hundreds of GPUs, depending on the task at hand, while consuming much less energy and space.
Feldman says the chip will allow AI researchers‚Äîand the science of AI‚Äîto move faster. ‚ÄúYou can ask more questions,‚Äù he says. ‚ÄúThere are things we simply haven‚Äôt been able to try.‚Äù Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Those claims are built in part on the Cerebras chip‚Äôs large stocks of onboard memory, allowing the training of more complex deep-learning software. Feldman says his oversized design also benefits from the fact that data can move around a chip around 1,000 times faster than it can between separate chips that are linked together.
Making such a large and powerful chip brings problems of its own. Most computers keep cool by blowing air around, but Cerebras had to design a system of water pipes that run close by the chip to prevent it from overheating.
Feldman says ‚Äúa handful‚Äù of customers are trying the chip, including on drug design problems. He plans to sell complete servers built around the chip, rather than chips on their own, but declined to discuss price or availability.
To construct its giant chip, Cerebras worked closely with contract chip manufacturer TSMC, whose other customers include Apple and Nvidia. Brad Paulsen, a senior vice president at TSMC who has worked in the semiconductor industry since the early 1980s, says it‚Äôs the largest chip he has ever seen.
TSMC had to adapt its manufacturing equipment to create such a large continuous slab of working circuitry. Fabs, as semiconductor factories are known, make chips from circular wafers of pure silicon. The usual process places a grid of many chips onto a wafer and then slices the wafer to create the finished devices.
Modern fabs use wafers measuring 300 millimeters, about 12 inches, in diameter. Such a wafer typically yields more than 100 chips. Making Cerebras‚Äô giant chip required TSMC to adapt its equipment to make one continuous design, instead of a grid of many separate ones, Paulsen says. Cerebras‚Äô chip is the largest square that can be cut from a 300-millimeter wafer. ‚ÄúI think people are going to see this and say ‚ÄòWow that‚Äôs possible? Maybe we need to explore in that direction,‚Äô‚Äù he says.
Intel, the world‚Äôs largest chipmaker, is also working on specialized chips for deep learning, including one to accelerate training being developed in partnership with the Chinese search company Baidu.
Naveen Rao, a vice president at Intel, says Google‚Äôs work on AI chips has convinced Google‚Äôs AI rivals that they need new hardware too. ‚ÄúGoogle is setting the bar for new capabilities‚Äù with its TPUs, he says.
Intel will discuss its design‚Äîwhich is the size of a typical chip, and planned to fit into existing computing systems‚ÄîMonday at the same conference where Cerebras is showing off its giant chip. Intel plans to deliver them to customers this year. Rao says unusually shaped chips are a ‚Äútough sell,‚Äù because customers don‚Äôt like to abandon their existing hardware. ‚ÄúTo shift the industry we‚Äôve got to do it in increments,‚Äù he says.
Jim McGregor, founder of Tirias Research, agrees that not every tech company will rush to buy an exotic chip like Cerebras‚Äô. McGregor estimates that Cerebras‚Äô system could cost millions of dollars, and existing data centers may need modifying to accommodate them. Cerebras also must develop software that makes it easy for AI developers to adapt to the new chip.
Still, he expects the largest tech companies, who see their destinies riding on competing in AI‚Äîfirms like Facebook, Amazon, and Baidu‚Äîto take a serious look at Cerebras‚Äô big, weird chip. ‚ÄúFor them it could make a lot of sense,‚Äù he says.
Listen, here‚Äôs why the value of China‚Äôs yuan really matters High drama: A cannabis biotech firm roils small growers Are super-automatic espresso machines worth it? These chaotic games are a referee's worst nightmare The twisted paths of ‚ÄúGlobal Girl‚Äù and the Lolita Express üëÅ Facial recognition is suddenly everywhere.
 Should you worry? Plus, read the latest news on artificial intelligence üéß Things not sounding right? Check out our favorite wireless headphones , soundbars , and bluetooth speakers Senior Editor X Topics artificial intelligence chips deep learning Intel Steven Levy Niamh Rowe Will Knight Steven Levy Khari Johnson Will Knight Peter Guest Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
