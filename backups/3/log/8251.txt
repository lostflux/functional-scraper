Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Paresh Dave Business How Microsoft‚Äôs Bing Chatbot Came to Be‚Äîand Where It‚Äôs Going Next Illustration: Jacqui VanLiew Save this story Save Save this story Save Jordi Ribas hasn‚Äôt taken a day off since last September. That month, the Microsoft search and AI chief got the keys to GPT-4 , a then secret version of OpenAI‚Äôs text-generation technology that now powers ChatGPT. As Ribas had with GPT-4‚Äôs predecessors, the Barcelona native wrote in Spanish and Catalan to test the AI‚Äôs knowledge of cities like his hometown and nearby Manresa. When quizzed about history, churches, and museums, its responses hit the mark. Then he asked GPT-4 to solve an electronics problem about the current flowing through a circuit. The bot nailed it. ‚ÄúThat's when we had that ‚Äòaha‚Äô moment,‚Äù Ribas says.
Ribas asked some of Microsoft‚Äôs brightest minds to probe further. In October, they showed him a prototype of a search tool the company calls Prometheus, which combines the general knowledge and problem-solving abilities of GPT-4 and similar language models with the Microsoft Bing search engine. Ribas again challenged the system in his native languages, posing Prometheus complex problems like vacation planning. Once again, he came away impressed. Ribas‚Äô team hasn‚Äôt let up since. Prometheus became the foundation for Bing‚Äôs new chatbot interface, which launched in February.
 Since then, millions of people spanning 169 countries have used it for over 100 million conversations.
It hasn‚Äôt gone perfectly. Some users held court with Bing chat for hours , exploring conversational paths that led to unhinged responses ; Microsoft responded by instituting usage limits.
 Bing chat‚Äôs answers occasionally are misleading or outdated , and the service, like other chatbots, can be annoyingly slow to respond.
 Critics, including some of Microsoft‚Äôs own employees, warn of potential harms such as AI-crafted misinformation, and some have called for a pause in further development of systems like Bing chat. ‚ÄúThe implementation in the real world of OpenAI models should be slowed down until all of us, including OpenAI and Microsoft, better study and mitigate the vulnerabilities,‚Äù says Jim Dempsey, an internet policy scholar at Stanford University researching AI safety risks.
Microsoft isn‚Äôt commenting on those pleas, but Ribas and others working on the revamped Bing have no plans to stop development, having already worked through weekends and fall, winter, and spring holidays so far. ‚ÄúThings are not slowing down. If anything, I would say things are probably speeding up,‚Äù says Yusuf Mehdi, who oversees marketing for Bing.
‚ÄúThat's when we had that ‚Äòaha‚Äô moment.‚Äù Jordi Ribas, Microsoft's head of search and AI, on OpenAI's GPT-4.
With just over 100 million daily Bing users, compared to well over 1 billion using Google search, Microsoft has thrown itself headlong into a rare opportunity to reimagine what web search can be. That has involved junking some of the 48-year-old company‚Äôs usual protocol. Corporate vice presidents such as Ribas attended meetings for Bing chat‚Äôs development every day, including weekends, to make decisions faster. Policy and legal teams were brought in more often than is usual during product development.
The project is in some ways a belated realization of the idea, dating from Bing‚Äôs 2009 launch , that it should provide a ‚Äúdecision engine,‚Äù not just a list of links. At the time, Microsoft's current CEO, Satya Nadella, ran the online services division. The company has tried other chatbots over the years, including recent tests in Asia , but none of the experiments sunk in right with testers or executives, in part because they used language models less sophisticated than GPT-4. ‚ÄúThe technology just wasn't ready to do the things that we were trying to do,‚Äù Mehdi says.
Executives such as Ribas consider Bing‚Äôs new chat mode a success‚Äîone that has driven hundreds of thousands of new users to Bing, shown a payoff for the reported $13 billion the company invested in OpenAI, and demonstrated the giant‚Äôs nimbleness at a time when recession fears have increased Wall Street scrutiny of management. ‚ÄúWe took the big-company scale and expertise but operated like a startup,‚Äù says Sarah Bird, who leads ethics and safety for AI technologies at Microsoft. Microsoft shares have risen 12 percent since Bing chat‚Äôs introduction, well more than Google parent Alphabet, Amazon, Apple, and the S&P 500 market index.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The company‚Äôs embrace of OpenAI‚Äôs technology has seen Microsoft endanger some existing search ad revenue by prominently promoting a chat box in Bing results. The tactic has ended up being a key driver of Bing chat usage. ‚ÄúWe are being, I would say, innovative and taking some risks,‚Äù Mehdi says.
At the same time, Microsoft has held back from going all-in on OpenAI‚Äôs technology. Bing‚Äôs conversational answers do not always draw on GPT-4 , Ribas says. For prompts that Microsoft‚Äôs Prometheus system judges as simpler, Bing chat generates responses using Microsoft‚Äôs homegrown Turing language models , which consume less computing power and are more affordable to operate than the bigger and more well-rounded GPT-4 model.
Peter Sarlin, CEO and cofounder of Silo AI , a startup developing generative AI systems for companies, says he suspects penny pinching explains why he has noticed Bing‚Äôs initial chat responses can lack sophistication but follow-up questions elicit much better answers. Ribas disputes that Bing chat‚Äôs initial responses can be of lower quality, saying that users‚Äô first queries can lack context.
Bing has not traditionally been a trendsetter in search, but the launch of Bing chat prompted competitors to hustle.
Google , which abandoned a more cautious approach, China‚Äôs Baidu , and a growing bunch of startups have followed with their own search chatbot competitors.
None of those search chatbots, nor Bing chat, has garnered the buzz or apparently the usage of OpenAI‚Äôs ChatGPT , the free version of which is still based on GPT-3.5. But when Stanford University researchers reviewed four leading search chatbots , Bing‚Äôs performed best at backing up its responses with corresponding citations, which it does by putting links at the bottom of chat responses to the websites from which Prometheus drew information.
Google and a growing bunch of startups have followed Microsoft with their own search chatbots.
Microsoft is now fine-tuning its new search service. It's giving users more options, trying to make vetting answers easier, and starting to generate some revenue by including ads. Weeks after Bing chat launched, Microsoft added new controls that allow users to dictate how precise or creative generated answers are. Ribas says that setting the chatbot to Precise mode yields results at least as factually accurate as does a conventional Bing search.
Expanding Prometheus‚Äô power helped. Behind the scenes, the system originally could ingest about 3,200 words of content from Bing results each time it performed a search before generating a response for a user. Soon after launch, that limit was increased to about 128,000 words, Ribas says, providing responses that are more ‚Äúgrounded‚Äù in Bing‚Äôs crawl of the web. Microsoft also took feedback from users clicking thumbs-up and -down icons on Bing chat answers to improve Prometheus.
Culture Taylor Swift and Beyonc√© Are Resurrecting the American Movie Theater Angela Watercutter Gear The Best Home Depot Black Friday Deals Matt Jancer Gear Apple‚Äôs Pledge to Support RCS Messaging Could Finally Kill SMS Boone Ashworth Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker Two weeks in , 71 percent of the feedback was thumbs up, but Ribas declines to share fresher information on Microsoft‚Äôs measures of user satisfaction. He will say that the company is getting a strong signal that people like the full range of Bing chat‚Äôs capabilities. Across different world regions, about 60 percent of Bing chat users are focused on looking up information, 20 percent are asking for creative help like writing poems or making art, and another 20 percent are chatting to no apparent end, he says. The art feature, powered by an advanced version of OpenAI‚Äôs DALL-E generative AI software, has been used to generate 200 million images, Microsoft CEO Nadella announced yesterday.
For searches, one priority for Microsoft is helping users spot when its chatbot fabricates information, a tendency known as hallucination. The company is exploring making the chatbot‚Äôs source citations more visible by moving them to the right of its AI-generated responses, so users can more easily cross-check what they‚Äôre reading, says Liz Danzico, who directs design of the new Bing.
Her team also has begun working to better label ads in chat and increase their prominence.
Posts on social media show links to brands potentially relevant to the chatbot‚Äôs answer tucked into sentences with an ‚ÄúAd‚Äù label attached. Another test features a photo-heavy carousel of product ads below a chat answer related to shopping, Danzico says. Microsoft has said it wants to share ad revenue with websites whose information contributes to responses , a move that could diffuse tensions with publishers that aren‚Äôt happy with the chatbot regurgitating their content without compensation.
Despite those grumbles and Bing chat‚Äôs sometimes weird responses, it has received a much warmer reception than Microsoft‚Äôs experimental bot Tay, which was withdrawn in 2016 after it generated hate speech. Bird, the ethics and safety executive, says she and her colleagues working in what Microsoft calls ‚Äúresponsible AI‚Äù were the first to get access to GPT-4 after top engineering brass such as Ribas. Her team granted access to outside experts to try to push the system do stupid things , and Microsoft units working on cybersecurity and national security got involved too.
Bird‚Äôs team also took pointers from misuse of ChatGPT, launched by OpenAI in November. They added protections inspired from watching users ‚Äújailbreak‚Äù ChatGPT into giving inappropriate answers by asking it to role-play or write stories.
 Microsoft and OpenAI also created a more sanitized version of GPT-4 by giving the model additional training on Microsoft's content guidelines. Microsoft tested the new version by directing it to score the toxicity of Bing chat conversations generated by AI, providing more to review than human workers could.
Those guardrails are not flawless, but Microsoft has made embracing imperfection a theme of its recent AI product launches. When Microsoft‚Äôs GitHub unit launched code-completion software Copilot last June, powered by OpenAI technology, software engineers who paid for the service didn‚Äôt mind that it made errors, Bird says, a lesson she now applies to Bing chat.
‚ÄúThey were planning to edit the code anyway. They weren't going to use it exactly as is,‚Äù Bird says. ‚ÄúAnd so as long as we're close, it's very valuable.‚Äù Bing chat is wrong sometimes‚Äîbut it has stolen the spotlight from Google, delivered the long-promised decision engine, and influenced a wave of GPT-4-powered services across the company. To Microsoft‚Äôs leaders, that‚Äôs a good start.
You Might Also Like ‚Ä¶ üì® Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cash‚Äôs Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you üîå Charge right into summer with the best travel adapters , power banks , and USB hubs Topics artificial intelligence machine learning Google Microsoft bots programming ChatGPT Bing search engines David Gilbert Joel Khalili David Gilbert Will Knight Andy Greenberg Kari McMahon Joel Khalili Khari Johnson Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
