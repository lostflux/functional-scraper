The Verge homepage The Verge homepage The Verge The Verge logo.
/ Tech / Reviews / Science / Entertainment / More Menu Expand Menu Artificial Intelligence / Tech / Web OpenAI can’t tell if something was written by AI after all OpenAI can’t tell if something was written by AI after all / OpenAI shuts down a tool meant to detect AI-written text due to low accuracy.
By Emilia David , a reporter who covers AI. Prior to joining The Verge, she covered the intersection between technology, finance, and the economy.
| Share this story OpenAI shuttered a tool that was supposed to tell human writing from AI due to a low accuracy rate. In an (updated) blog , OpenAI said it decided to end its AI classifier as of July 20th. “We are working to incorporate feedback and are currently researching more effective provenance techniques for text,” the company said.
As it shuts down the tool to catch AI-generated writing, OpenAI said it plans to “develop and deploy mechanisms that enable users to understand if audio or visual content is AI-generated.” There’s no word yet on what those mechanisms might be, though.
OpenAI fully admitted the classifier was never very good at catching AI-generated text and warned that it could spit out false positives, aka human-written text tagged as AI-generated. OpenAI, before it added its update shutting down the tool, said the classifier could get better with more data.
After OpenAI’s ChatGPT burst into the scene and became one of the fastest-growing apps ever, people scrambled to grasp the technology. Several sectors raised the alarm around AI-generated text and art, particularly educators who were worried students would no longer study and just let ChatGPT write their homework.
New York schools even banned access to ChatGPT on school grounds amid concerns about accuracy, safety, and cheating.
Misinformation via AI has also been a concern, with studies showing AI-generated text, like tweets , might be more convincing than ones written by humans. Governments haven’t yet figured out how to rein in AI and, thus far, are leaving it to individual groups and organizations to set their own rules and develop their own protective measures to handle the onslaught of computer-generated text. And it seems that for now, no one, not even the company that helped kickstart the generative AI craze in the first place, has answers on how to deal with it all. Though some people get caught , it’s only going to get harder to easily differentiate AI and human work.
OpenAI also recently lost its trust and safety leader amid a time when the Federal Trade Commission is investigating OpenAI to see how it vets information and data. OpenAI declined to comment beyond its blog post.
Sam Altman fired as CEO of OpenAI Windows is now an app for iPhones, iPads, Macs, and PCs Screens are good, actually Apple pulls its ads from X after Musk’s antisemitic posts What happened to Sam Altman? Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.
From our sponsor Advertiser Content From More from this stream Bing, Bard, and ChatGPT: How AI is rewriting the internet OpenAI’s flagship AI model has gotten more trustworthy but easier to trick Oct 17, 2023, 9:38 PM UTC The environmental impact of the AI revolution is starting to come into focus Oct 10, 2023, 3:00 PM UTC The BBC is blocking OpenAI data scraping but is open to AI-powered journalism Oct 6, 2023, 8:16 PM UTC OpenAI may make its own chips to power future generative AI growth.
Oct 6, 2023, 1:52 PM UTC Terms of Use Privacy Notice Cookie Policy Do Not Sell Or Share My Personal Info Licensing FAQ Accessibility Platform Status How We Rate and Review Products Contact Tip Us Community Guidelines About Ethics Statement The Verge is a vox media network Advertise with us Jobs @ Vox Media © 2023 Vox Media , LLC. All Rights Reserved
