Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Activ Surgical harnesses AI and machine learning to collaborate with surgeons Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
In 2016, Dr. Peter Kim, founder of Activ Surgical, a digital surgery company, demonstrated a proof of concept of fully autonomous robotic surgery on soft tissue, suturing, or stitching up a wound. Since then, Activ Surgical has been working on harnessing machine learning , augmented reality, and other advanced technologies to develop new ways of collaborating with surgeons. “We want to keep surgeons in the loop, to give them more data than they ever had before,” says CEO Todd Usen.
Usen likens Activ Surgical’s work in surgery to crossing goalposts in the drive toward autonomous driving : It might take a while to get there, but the industry is ramping up systematically. Parking assists and side-view mirrors that alert drivers to vehicles in a blind spot are examples of rungs on the road toward autonomy. Such collaborations with the driver are similar to how Activ Surgical envisions its role with surgeons today.
An example of such a collaboration: an FDA 510(k)-approved hardware component called ActivSight, which fits between an endoscope and a camera system and helps surgeons in real time as they perform operations.
Activ Surgical is betting that giving surgeons a clearer picture of blood flow, known in medical terms as perfusion, might improve outcomes in laparoscopic surgeries. Take the case of an anastomotic leak in colorectal procedures, which can be devastating. It occurs because of inadequate blood flow at a surgical site that has been cut and sewn back together. Pressing a button labeled “Perfusion View” gives a clearer picture of blood flow — or lack thereof. The vessels with blood flow cut off show up in different colors. Typically, surgeons use dyes to track perfusion, but there is a time lag between injection of dye and when results can actually be seen. Usen says that using ActivSight allows for both real-time visualization of perfusion and without any dyes.
Event GamesBeat at the Game Awards We invite you to join us in LA for GamesBeat at the Game Awards event this December 7. Reserve your spot now as space is limited! The Perfusion tool is the first “Insight” delivered through the company’s augmented reality-based software suite, ActivInsights. Usen expects it to be the first of many coming down the pike, feeding on a foundation of annotated imaging data from actual surgeries.
Pressing machine learning into service “We’re allowing surgeons all over the world to collaborate, to identify and label data so our machine learning algorithms can take over and route the results to all users,” Usen says.
In effect, surgeons help build a repository of annotated anatomy components on the company’s ActivEdge platform. Activ Surgical can use machine learning on this foundation to train data models and develop future insights.
 Identifying veins and arteries, nerves, and lymph nodes without dyes are among the many possibilities. “Just like over time autonomous cars can identify a red octagonal sign and know to eventually stop, we need to identify all critical organs as critical organs even though an individual’s organs might look different from another,” Usen says.
Driven by machine learning, Activ Surgical’s autonomous annotation model can annotate a one-hour surgical video in just about 10 minutes. That’s about 20,000 times faster than if it were all done by humans.
The ActivInsights software suite uses AR to overlay critical information such as blood flow over actual imagery of the organs.
A TaaS model of delivery Activ Surgical packages the ActivInsights software suite and the ActivSight hardware together. Hospitals can subscribe to the package through a technology-as-a-service (TaaS) model and access new insights as they roll in.
The market for laparoscopic surgeries — the kind where ActivSight can be pressed into service — is sizable, with more than 13 million such procedures conducted annually over the world. The surgical robotics market is also booming; it is expected to grow at a compounded annual rate of 44% until 2028. Investors are betting on Activ Surgical’s digital surgery approach: In late September, the company announced a $45 million series B financing round. It plans to use part of the new capital to develop its first ML-based insights.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
