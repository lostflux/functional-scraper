Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts Banning ChatGPT will do more harm than good A high school senior argues that ChatGPT can help reshape education for the better.
By Rohan Mehta archive page Stephanie Arnett/MITTR | Envato Related Story The narrative around cheating students doesn’t tell the whole story. Meet the teachers who think generative AI could actually make learning better.
The release of ChatGPT has sent shock waves through the halls of higher education. Universities have rushed to release guidelines on how it can be used in the classroom. Professors have taken to social media to share a spectrum of AI policies. And students—whether or not they’ll admit it—have cautiously experimented with the idea of allowing it to play a part in their academic work.
But the notion of a measured response to the emergence of this powerful chatbot seems to have barely penetrated the world of K–12 education. Instead of transparent, well-defined expectations, high schoolers across the country have been confronted with a silent coup of blocked AI websites.
1 That’s a shame. If educators actively engage with students about the technology’s capabilities and limitations—and work with them to define new academic standards—ChatGPT, and generative AI more broadly, could both democratize and revitalize K–12 education on an unprecedented scale.
A bold claim, I know. But after a few months of putting generative AI to the test (a nerdy case of senioritis, if you will), I’m optimistic. Exhibit A? College applications.
Few things are as mentally draining as applying to college these days, and as I slaved away at my supplemental essays, the promise of using ChatGPT as a real-time editor was attractive—partly as a potential productivity boost, but mostly as a distraction.
I had ChatGPT carefully review my cloying use of semicolons, grade my writing on a 0–10 scale (the results were erratic and maddening) 2 , and even role-play as an admissions counselor. Its advice was fundamentally incompatible with the creative demands of the modern college essay, and I mostly ignored it. But the very act of discussing my writing “out loud,” albeit with a machine, helped me figure out what I wanted to say next. Using ChatGPT to verbalize the space of possibilities—from the scale of words to paragraphs—strengthened my own thinking. And I’ve experienced something similar across every domain I’ve applied it to, from generating fifth-grader-level explanations of the French pluperfect to deciphering the Latin names of human muscles.
All this adds up to a simple but profound fact: anyone with an internet connection now has a personal tutor, without the costs associated with private tutoring. Sure, an easily hoodwinked, slightly delusional tutor, but a tutor nonetheless. The impact of this is hard to overstate, and it is as relevant in large public school classrooms where students struggle to receive individual attention as it is in underserved and impoverished communities without sufficient educational infrastructure. As the psychologist Benjamin Bloom demonstrated in the early 1980s, one-on-one instruction until mastery allowed almost all students to outperform the class average by two standard deviations (“about 90% … attained the level … reached by only the highest 20%”).
ChatGPT certainly can’t replicate human interaction, but even its staunchest critics have to admit it’s a step in the right direction on this front. Maybe only 1% of students will use it in this way, and maybe it’s only half as effective as a human tutor, but even with these lowball numbers, its potential for democratizing educational access is enormous. I would even go so far as to say that if ChatGPT had existed during the pandemic, many fewer students would have fallen behind.
Of course, those decrying ChatGPT as the end of critical thinking would likely protest that the bot will only exacerbate the lazy academic habits students might have formed over the course of the pandemic. I have enough experience with the tips and tricks we high schoolers employ on a regular basis to know that this is a valid concern—one that shouldn’t be brushed off by casting ChatGPT as just the latest in a long line of technological revolutions in the classroom, from the calculator to the internet.
That said, ChatGPT has just as much potential in the classroom as it does for improving individual educational outcomes. English teachers could use it to rephrase the notoriously confusing answer keys to AP test questions, to help students prepare more effectively. They could provide each student with an essay antithetical to the one they turned in, and have them pick apart these contrary arguments in a future draft. No human teacher could spend the time or energy needed to explain pages upon pages of lengthy reading comprehension questions or compose hundreds of five-page essays, but a chatbot can.
Educators can even lean into ChatGPT’s tendency to falsify, misattribute, and straight-out lie as a way of teaching students about disinformation. Imagine using ChatGPT to pen essays that conceal subtle logical fallacies or propose scientific explanations that are almost, but not quite, correct. Learning to discriminate between these convincing mistakes and the correct answer is the very pinnacle of critical thinking, and this new breed of academic assignment will prepare students for a world fraught with everything from politically correct censorship to deepfakes.
There are certainly less optimistic visions for the future. But the only way we avoid them—the only way this technology gets normalized and regulated alongside its similarly disruptive forebears—is with more discussion, more guidance, and more understanding. And it’s not as if there’s no time to catch up. ChatGPT won’t be acing AP English classes anytime soon, and with the recent release of GPT-4 , we are already seeing an explosion of ed-tech companies that reduce the effort and expertise needed for teachers and students to operate the bot.
So here’s my pitch to those in power. Regardless of the specific policy you choose to employ at your school, unblock and unban. The path forward starts by trusting students to experiment with the tool, and guiding them through how, when, and where it can be used. You don’t need to restructure your whole curriculum around it, but blocking it will only send it underground. That will lead to confusion and misinterpretation in the best of cases, and misuse and abuse in the worst.
ChatGPT is the only beginning. There are simply too many generative AI tools to try to block them all, and doing so sends the wrong message. What we need is a direct discourse between students, teachers, and administrators. I’m lucky enough to be at a school that has taken the first steps in this direction, and it’s my hope that many more will follow suit.
At least in my case, the entirety of openai.com has been blocked, not just chat.openai.com. Kind of annoying if I want to access the fine-­tuning docs.
The most impressive thing I have seen ChatGPT do is revise one of my essays. In it, I discussed two global political figures, but concealed their identities through personification. To “make my essay a 10/10” and “increase clarity,” ChatGPT filled their names in. The fact that it has emergent abilities like this blew my mind! Rohan Mehta is a high school senior at Moravian Academy in Bethlehem, Pennsylvania.
hide by Rohan Mehta Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window This story was part of our May/June 2023 issue.
Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard Deepfakes of Chinese influencers are livestreaming 24/7 Zeyi Yang How to fix the internet Katie Notopoulos Keep Reading Most Popular This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Everything you need to know about artificial wombs Artificial wombs are nearing human trials. But the goal is to save the littlest preemies, not replace the uterus.
By Cassandra Willyard archive page Deepfakes of Chinese influencers are livestreaming 24/7 With just a few minutes of sample video and $1,000, brands never have to stop selling their products.
By Zeyi Yang archive page How to fix the internet If we want online discourse to improve, we need to move beyond the big platforms.
By Katie Notopoulos archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
