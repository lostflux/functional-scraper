Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business Researchers Blur Faces That Launched a Thousand Algorithms Photograph: Mads Perch/Getty Images Save this story Save Save this story Save End User Research Sector Research Source Data Images Technology Machine learning Machine vision In 2012, artificial intelligence researchers engineered a big leap in computer vision thanks, in part, to an unusually large set of images‚Äîthousands of everyday objects, people, and scenes in photos that were scraped from the web and labeled by hand. That data set, known as ImageNet , is still used in thousands of AI research projects and experiments today.
But last week every human face included in ImageNet suddenly disappeared‚Äîafter the researchers who manage the data set decided to blur them.
Just as ImageNet helped usher in a new age of AI, efforts to fix it reflect challenges that affect countless AI programs, data sets, and products.
‚ÄúWe were concerned about the issue of privacy,‚Äù says Olga Russakovsky , an assistant professor at Princeton University and one of those responsible for managing ImageNet.
ImageNet was created as part of a challenge that invited computer scientists to develop algorithms capable of identifying objects in images. In 2012, this was a very difficult task. Then a technique called deep learning , which involves ‚Äúteaching‚Äù a neural network by feeding it labeled examples, proved more adept at the task than previous approaches.
Since then, deep learning has driven a renaissance in AI that also exposed the field‚Äôs shortcomings. For instance, facial recognition has proven a particularly popular and lucrative use of deep learning, but it's also controversial. A number of US cities have banned government use of the technology over concerns about invading citizens‚Äô privacy or bias, because the programs are less accurate on nonwhite faces.
Today ImageNet contains 1.5 million images with around 1,000 labels. It is largely used to gauge the performance of machine learning algorithms, or to train algorithms that perform specialized computer vision tasks. Blurring the faces affected 243,198 of the images.
Russakovsky says the ImageNet team wanted to determine if it would be possible to blur faces in the data set without changing how well it recognizes objects. ‚ÄúPeople were incidental in the data since they appeared in the web photos depicting these objects,‚Äù she says. In other words, in an image that shows a beer bottle, even if the face of the person drinking it is a pink smudge, the bottle itself remains intact.
In a research paper , posted along with the update to ImageNet, the team behind the data set explains that it blurred the faces using Amazon‚Äôs AI service Rekognition ; then, they paid Mechanical Turk workers to confirm selections and adjust them.
Blurring the faces did not affect the performance of several object-recognition algorithms trained on ImageNet, the researchers say. They also show that other algorithms built with those object-recognition algorithms are similarly unaffected. ‚ÄúWe hope this proof-of-concept paves the way for more privacy-aware visual data collection practices in the field,‚Äù Russakovsky says.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight It isn‚Äôt the first effort to adjust the famous library of images. In December 2019, the ImageNet team deleted biased and derogatory terms introduced by human labelers after a project called Excavating AI drew attention to the issue.
By Tom Simonite In July 2020 Vinay Prabhu , a machine learning scientist at UnifyID and Abeba Birhane , a PhD candidate at University College Dublin in Ireland, published research showing they could identify individuals, including computer science researchers, in the data set. They also found pornographic images included in it.
Prabhu says blurring faces is good but is disappointed that the ImageNet team did not acknowledge the work that he and Birhane did. Russakovsky says a citation will appear in an updated version of the paper.
Blurring faces still might have unintended consequences for algorithms trained on the ImageNet data. Algorithms might, for example, learn to look for blurred faces when searching for particular objects.
‚ÄúOne important problem to consider is what happens when you deploy a model that was trained on a face-blurred data set,‚Äù Russakovsky says. For example, a robot trained on the data set might be thrown off by faces in the real world.
Aleksander Madry, a research scientist at MIT who has identified limitations of ImageNet, says an AI model trained on a dataset containing blurred faces might perform strangely when shown images containing faces. "Biases in data can be very subtle while having significant consequences," he says. "That's what makes thinking about robustness and fairness in the context of machine learning so tricky." Updated, 3-15-21, 11:25am ET: This article has been updated to include additional comment from Olga Russakovsky and Aleksander Madry.
üì© The latest on tech, science, and more: Get our newsletters ! The Lion, the polygamist, and the biofuel scam Clubhouse is booming. So is the ecosystem around it How Google's grand plan to make its own games fell apart Why can't I stop staring at my own face on Zoom ? Perseverance‚Äôs eyes see a different Mars üéÆ WIRED Games: Get the latest tips, reviews, and more üì± Torn between the latest phones? Never fear‚Äîcheck out our iPhone buying guide and favorite Android phones Senior Writer X Topics machine learning artificial intelligence algorithms face recognition deep learning Will Knight Khari Johnson Peter Guest Will Bedingfield Gregory Barber Niamh Rowe Khari Johnson Matt Burgess Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
