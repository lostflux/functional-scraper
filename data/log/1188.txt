Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Stanford and NYU: Only 15% of AI federal agencies use is highly sophisticated Share on Facebook Share on X Share on LinkedIn U.S. Capitol Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
More than 40% of U.S. federal agencies and departments have experimented with AI tools, but only 15% currently use highly sophisticated AI, according to analysis by Stanford University computer scientists published today in “Government by Algorithm,” a joint report from Stanford and New York University.
“This is concerning because agencies will find it harder to realize gains in accuracy and efficiency with less sophisticated tools. This result also underscores AI’s potential to widen, not narrow, the public-private technology gap,” the report reads.
The warning comes from an analysis released today of 142 federal agencies and departments and the legal and policy implications of government use of machine learning or “algorithmic governance.” The report excludes analysis of military and intelligence agencies and any federal agency with less than 400 employees.
AI in use today include an autonomous vehicle project at the U.S. Postal Service; Food and Drug Administration detection of adverse drug events ; and facial recognition by the U.S. Department of Homeland Security and ICE. Major use cases today focus heavily on enforcement of regulatory mandates, adjudicating benefits and privileges, service delivery, citizen engagement, regulation analysis, and personnel management.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! The “Government by Algorithm” report found that 53% of AI use is a product of in-house use by agency technologists, and the remainder comes from contractors. It recommends that federal agencies get more in-house AI talent to vet systems from contractors and create AI that’s policy compliant, customized to meet agency needs, and accountable.
It also warns that AI use by government raises the potential to “fuel political anxieties” and creates the risk of AI systems being gamed by “better-heeled groups with resources and know-how.” “An enforcement agency’s algorithmic predictions, for example, may fall more heavily on smaller businesses that, unlike larger firms, lack a stable of computer scientists who can reverse-engineer the agency’s model and keep out of its cross-hairs. If citizens come to believe that AI systems are rigged, political support for a more effective and tech-savvy government will evaporate quickly,” the report reads.
The report, put together by a group of lawyers, computer scientists, and social scientists, also acknowledges concerns that more use of AI in the public sector can lead to the growth of government power and the disempowerment of marginalized groups, something AI Now Institute’s Meredith Whittaker and Algorithmic Justice League’s Joy Buolamwini talked about in relation to facial recognition in testimony before Congress over the course of the past year.
The report calls its systematic survey of federal government use of AI essential for lawmakers to create “sensible and working prescriptions.” “To achieve meaningful accountability, concrete and technically informed thinking within and across contexts — not facile calls for prohibition, nor blind faith in innovation — is urgently needed,” the report reads.
Drawing on resources from Stanford Law School, the Stanford Institute for Human-Centered AI, and Stanford Institute for Economic Policy Research, the report comes at a time when lawmakers from Washington state to Washington D.C. are considering facial recognition regulation. Last week, Senators Cory Booker (D-NJ) and Jeff Merkley (D-OR) proposed the Ethical Use of AI Act, which would require a facial recognition moratorium for federal agencies and employees until limits can be put in place.
The European Union Commission today presented a set of initiatives to attract billions in AI investment in member nations and require that high-risk AI used by police and law enforcement, health care, or things related to people’s rights be tested and certified.
“We want the application of these new technologies to deserve the trust of our citizens,” EU Commission president Ursula von der Leyen said in a statement.
The Trump administration is drafting its own set of regulatory AI principles for federal agencies that White House CTO Michael Kratsios said other nations should emulate.
A previous Stanford Institute for Human-Centered AI report called for a $120 billion federal government investment in AI by the federal government to maintain U.S. supremacy in AI, something government officials have called essential to U.S. national defense and economy.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
