Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google debuts AutoML Video and AutoML Tables for structured data Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google today made its biggest updates in nearly a year for AutoML with the introduction of AutoML Video and AutoML Tables for structured data, two new classes for Google’s suite of services that automate the creation of automated AI systems.
Cloud AutoML for the creation of custom AI models was first introduced in January 2018.
AutoML Tables is a new way for people with no coding experience to create custom AI models using structured tabular datasets. Tables can ingest data from GCP’s BigQuery data warehouse and other storage providers.
“We’re also seeing in most industries things like demand forecasting, all the way through to things like price optimization. All of those are structured data problems and things AutoML Tables can be applied to,” Google Cloud senior director of product management Rajen Sheth told reporters ahead of the release.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! There’s also AutoML Video, which, like the AutoML Video Intelligence service first introduced in late 2017, will be able to use natural language and translation to transcribe conversations, and computer vision to recognize things like scene changes and explicit content. AutoML can be used to create custom classification models that serve customers’ unique needs.
Objection detection for AutoML Video is coming soon, Sheth said.
News announced today amounts to the biggest changes for AutoML since the last Cloud Next took place. Last July, Google introduced AutoML Vision’s drag-and-drop tool for training visual systems in public beta, and introduced AutoML Natural Language and AutoML Translate as well.
Today, AutoML Vision Edge, a subset of AutoML Vision, was introduced to give AI practitioners a way to create low latency image recognition models for remote or on-premises edge deployments. AutoML Vision Edge can utilize edge tensor processing units for faster speeds.
Beta releases introduced today that add to existing AutoML services include AutoML Vision object detection for finding objects in visual imagery, AutoML Natural Language custom entity extraction to find specific keywords and phrases in documents, and AutoML Natural Language custom sentiment analysis for detection of a person’s mood or emotional state.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
