Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts Emotion recognition technology should be banned, says an AI research institute By Charlotte Jee archive page face Unsplash There’s little scientific basis to emotion recognition technology, so it should be banned from use in decisions that affect people’s lives, says research institute AI Now in its annual report.
A booming market: Despite the lack of evidence that machines can work out how we’re feeling, emotion recognition is estimated to be at least a $20 billion market, and it’s growing rapidly.
 The technology is currently being used to assess job applicants and people suspected of crimes, and it’s being tested for further applications, such as in VR headsets to deduce gamers’ emotional states.
Further problems: There’s also evidence emotion recognition can amplify race and gender disparities.
 Regulators should step in to heavily restrict its use, and until then, AI companies should stop deploying it, AI Now said. Specifically, it cited a recent study by the Association for Psychological Science, which spent two years reviewing more than 1,000 papers on emotion detection and concluded it’s very hard to use facial expressions alone to accurately tell how someone is feeling.
Other concerns: In its report, AI Now called for governments and businesses to stop using facial recognition technology for sensitive applications until the risks have been studied properly, and attacked the AI industry for its “systemic racism, misogyny, and lack of diversity.” It also called for mandatory disclosure of the AI’s industry environmental impact.
hide by Charlotte Jee Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard How to fix the internet Katie Notopoulos New approaches to the tech talent shortage MIT Technology Review Insights Deep Dive Artificial intelligence This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Driving companywide efficiencies with AI Advanced AI and ML capabilities revolutionize how administrative and operations tasks are done.
By MIT Technology Review Insights archive page Rogue superintelligence and merging with machines: Inside the mind of OpenAI’s chief scientist An exclusive conversation with Ilya Sutskever on his fears for the future of AI and why they’ve made him change the focus of his life’s work.
By Will Douglas Heaven archive page Generative AI deployment: Strategies for smooth scaling Our global poll examines key decision points for putting AI to use in the enterprise.
By MIT Technology Review Insights archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
