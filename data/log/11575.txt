Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Report: Data engineers spend 2 days per week firefighting bad data quality Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Past industry surveys have shown that most data professionals struggle with poor data quality , despite the amount of time and resources invested in fixing it. To expand on these insights and help data leaders understand where and how to invest resources, data reliability company, Monte Carlo , partnered with Wakefield Research to survey more than 300 data professionals to reveal the state of data quality in the broader market.
Results from the study show that teams are still struggling with the quality of data and wasting precious time, money and resources to fix issues that arise. Respondents reported that on average, 40% of their time is spent evaluating or checking data quality. Additionally, more than half of respondents ranked building or fixing pipelines as taking the most amount of their time throughout the day.
When data incidents occurred, the majority of data pros — 62% — said their time to detection was five to eight hours. The average time for resolving data incidents was nine hours.
Data quality and the bottom line Poor data quality was also shown as affecting the bottom line — with 47% of respondents estimating that bad data affected 25% or more of their company revenue.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Of the 300 data professionals surveyed: 75% take four or more hours to detect a data quality incident.
About half said it takes an average of nine hours to resolve the issue once identified.
58% said the total number of incidents has increased somewhat or greatly over the past year, often as a result of more complex pipelines, bigger data teams, greater volumes of data, and other factors.
However, there is some positive news. Roughly 90% of respondents reported they were already investing or planning to invest in data quality solutions, like data observability , within six months.
The survey of more than 300 data professionals was conducted between April 28 and May 11, 2022, using an email invitation and an online survey.
Read the full report from Monte Carlo.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
