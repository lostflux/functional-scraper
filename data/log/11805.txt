Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Amazon shifts some Alexa and Rekognition computing to its own Inferentia chip Share on Facebook Share on X Share on LinkedIn Amazon's Echo smart speaker with Alexa.
Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
( Reuters ) — Amazon on Thursday said it shifted part of the computing for its Alexa voice assistant to its own custom-designed chips, aiming to make the work faster and cheaper while moving it away from chips supplied by Nvidia.
When users of devices such as Amazon’s Echo line of smart speakers ask the voice assistant a question, the query is sent to one of Amazon’s datacenters for several steps of processing. When Amazon’s computers spit out an answer, that reply is in a text format that must be translated into audible speech for the voice assistant.
Amazon previously handled that computing using chips from Nvidia, but now the “majority” of it will happen using its own Inferentia computing chip. First announced in 2018 , the Amazon chip is custom-designed to speed up large volumes of machine learning tasks, such as translating text to speech or recognizing images.
Cloud computing customers such as Amazon, Microsoft, and Alphabet’s Google have become some of the biggest buyers of computing chips, driving booming datacenter sales at Intel, Nvidia, and others.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! But major technology companies are increasingly ditching traditional silicon providers to design their own chips. Apple on Tuesday introduced its first Mac computers with its own central processors, moving away from Intel chips.
Amazon said the shift to the Inferentia chip for some of its Alexa work has resulted in 25% better latency, which is a measure of speed, at a 30% lower cost.
Amazon has also said that “Rekognition,” its cloud-based facial recognition service , has started to adopt its own Inferentia chips. However, the company did not say which chips the facial recognition service had previously used or how much of the work had shifted to its own chips.
The service has come under scrutiny from civil rights groups because of its use by law enforcement. Amazon in June put a one-year moratorium on its use by police after the killing of George Floyd.
( Reporting by Stephen Nellis in San Francisco. Editing by Tom Brown.
) VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
