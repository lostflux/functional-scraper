Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Intel’s new hardware puts AI computation on a USB stick Share on Facebook Share on X Share on LinkedIn Intel Movidius Neural Compute Stick Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Hoping to lower the bar to entry for those making artificial intelligence apps, Intel launched the Movidius Neural Compute Stick, the world’s first USB-based deep learning inference kit and self-contained AI accelerator.
The compute stick, which is akin to other Intel PC-on-a-USB products, can deliver deep learning neural network processing capabilities to a wide range of host devices at the edge of a network. It is designed for product developers, researchers, makers, and hardware hobbyists.
Intel acquired vision processing startup Movidius for an undisclosed price in 2016.
The Movidius Neural Compute Stick aims to reduce barriers to developing, tuning, and deploying AI applications by delivering dedicated high-performance deep neural network processing in a small form.
Intel, which is investing heavily in all sorts of AI products, wants to ensure developers are “retooling for an AI-centric digital economy.” VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “The Myriad 2 Vision Processing Unit (VPU) housed inside the Movidius Neural Compute Stick provides powerful, yet efficient performance — more than 100 gigaflops of performance within a 1W power envelope — to run real-time deep learning neural networks directly from the device,” said Remi El-Ouazanne, vice president and general manager of Movidius, in a statement. “This enables a wide range of AI applications to be deployed offline.” Machine intelligence development is fundamentally composed of two stages: (1) training an algorithm on large sets of sample data via modern machine learning techniques and (2) running the algorithm in an end-application that needs to interpret real-world data. This second stage is referred to as “inference,” and performing inference at the edge — or natively inside the device — brings numerous benefits in terms of latency, power consumption, and privacy, Intel said.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
