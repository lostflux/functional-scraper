Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Justin Sherman Ideas The Protests Prove the Need to Regulate Surveillance Tech Surveillance in the US goes back to the transatlantic slave trade, and its use has entirely targeted or had the worst impact on marginalized and systemically oppressed communities.
Photograph: Mike Segar/Reuters Save this story Save Save this story Save Law enforcement has used surveillance technology to monitor participants of the ongoing Black Lives Matter protests, as it has with many other protests in US history. License plate readers, facial recognition, and wireless text message interception are just some of the tools at its disposal.
 While none of this is new, the exposure that domestic surveillance is getting in this moment is further exposing a great fallacy among policymakers.
All too often, there is a tendency among the policy community, particularly for those whose work involves national security, to discuss democratic tech regulation purely in terms of geopolitical competition. There are arguments that regulating big tech is vital to national security. There are counterarguments pushing the exact opposite‚Äîthat promoting big US tech ‚Äúchampions‚Äù with minimal regulation is vital to US geopolitical interest, especially vis-√†-vis ‚Äúcompeting with China.‚Äù Many permutations abound.
Justin Sherman ( @jshermcyber ) is an op-ed contributor at WIRED and a fellow at the Atlantic Council‚Äôs Cyber Statecraft Initiative.
Claiming these arguments don‚Äôt hold water in Washington would suggest a certain naivete‚Äîthat‚Äôs not what I‚Äôm saying. That major tech firms use these narratives to argue for lax regulatory oversight recognizes its worth. But with these framings, policymakers and commentators shouldn‚Äôt miss that democratically regulating technology is inherently vital to democracy.
Those who claim the United States does not have a history of oppressive surveillance need to read books like Simone Browne‚Äôs Dark Matters: On the Surveillance of Blackness or articles like Alvaro M. Bedoya‚Äôs ‚Äú The Color of Surveillance.
‚Äù Surveillance in the US goes back to the transatlantic slave trade, and its use has entirely targeted or had the worst impact on marginalized and systemically oppressed communities.
Post-9/11 surveillance of Muslim communities‚Äîincluding through CIA-NYPD cooperation‚Äîand the FBI‚Äôs COINTELPRO from 1956 to 1971, which targeted, among others, Black civil rights activists and supporters of Puerto Rican independence (though also the KKK), are notable state surveillance programs that may come to mind. But the history of surveillance in the US is much richer, from custodial detention lists of Japanese Americans to intense surveillance of labor movements to stop-and-frisk programs that routinely target people of color.
Thus, ‚Äúrather than seeing surveillance as something inaugurated by new technologies, such as automated facial recognition or unmanned autonomous vehicles (or drones),‚Äù Browne writes, ‚Äúto see it as ongoing is to insist that we factor in how racism and antiblackness undergird and sustain the intersecting surveillances of our present order.‚Äù Browne, along with numerous other scholars, lays bare the origins of digital surveillance and harm that still today has oppressive and disparate effects.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Virginia Eubanks‚Äô Automating Inequality details the use of improperly regulated algorithms in state benefit programs, often with errors and unfairness that reinforce a ‚Äúdigital poorhouse.‚Äù These algorithms monitor, profile, and ultimately punish the poor across the US‚Äîlike in Indiana, where a program rejecting public benefit applications sees application mistakes as ‚Äúfailure to cooperate.‚Äù Ruha Benjamin‚Äôs Race After Technology explores how automation can deepen discrimination while appearing neutral‚Äîthe sinister myth of algorithmic objectivity. The obvious example might be facial recognition, but it‚Äôs much more than that: sexist r√©sum√©-reviewing algorithms , skin cancer predictors that can be trained mostly on lighter-toned skin, gender and ethnic stereotypes literally quantified in word embeddings used in machine learning.
Safiya Umoja Noble is another scholar who has revealed these deep-seated issues. In Algorithms of Oppression , she writes that search engine queries for ‚Äú‚ÄòBlack women‚Äô offer sites on ‚Äòangry Black women‚Äô and articles on ‚Äòwhy Black women are less attractive,‚Äô‚Äù digitally perpetuating ‚Äúnarratives of the exotic or pathetic black woman, rooted in psychologically damaging stereotypes.‚Äù Algorithmic unfairness goes well beyond technical design, reflective as well of US digital culture that forgoes discussion of how tech is interwoven with structural inequalities. Noble writes, ‚ÄúWhen I teach engineering students at UCLA about the histories of racial stereotyping in the US and how these are encoded in computer programming projects, my students leave the class stunned that no one has ever spoken of these things in their courses.‚Äù Despite clear and innumerable examples of how digital surveillance and algorithmic decisionmaking perpetuates harm, it is far too often that policymakers and policy wonks call attention to digital abuses in other countries while ignoring the need for democratic tech regulation in our own. Perhaps most notably, some members of Congress continue framing needed regulatory action against large tech firms as a trade-off with US global competitiveness. None of this is to support political relativism; the United States is not, as some dictators like to suggest, as unfree as many other countries. But the US needs to curb digital harms for its own sake‚Äîto protect its own citizens‚Äînot just because of geopolitical considerations.
The United States doesn‚Äôt have adequate federal privacy protections to restrict rampant data collection, sale, and exploitation by private companies. Law enforcement facial recognition use is rapidly growing with few clear and consistent rules and little transparency in the first place. Dependencies have been built on platforms like Facebook whose chief executive, as Siva Vaidhyanathan recently argued , refuses to address fundamental issues with the platform. And much of this digital surveillance and algorithmic decisionmaking occurs with government organizations and companies intertwined: smart doorbell cameras and police partnerships, racist risk assessment algorithms in US courts, data brokerage firms fueling deportations.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight While there again may be geopolitical considerations around tech regulations and governance best-practices (e.g., contrary to how some might frame it, could privacy rules make US firms more trustworthy overseas?), overfocusing on those points ignores the inherent need to curb these digital abuses at home. As a nation that should strive to uphold democratic ideals, democratic tech regulation is critical in and of itself.
Fixating purely on geopolitical reasons to curb digital harms in the US can also do damage beyond distracting from its normative importance. In her book The Known Citizen: A History of Privacy in Modern America , Sarah E. Igo notes that during the Cold War, ‚Äúfrom the vantage point of those charged with the nation‚Äôs security, the risks inherent in A-bombs and subversive activity explained the need to know, test, and vet people as thoroughly as possible.‚Äù In a fashion akin to the present, policymakers were so concerned about real and perceived threats to state security that they expanded surveillance powers. But this, Igo writes, raised a question: ‚ÄúThe inquisitorial procedures of the House Un-American Activities Committee, the use of political informants, the state controls over information and the press, and the policing of dissent, all in the name of staunching the Communist threat, led some to ask: Was the United States approximating its totalitarian foe in the effort to contain it?‚Äù It shouldn‚Äôt have taken recent protests to bring surveillance issues to the fore; many scholars and activists have been raising alarms for years. But it is time that those speaking of democratic tech regulation only because of geopolitical competition, or only because we don‚Äôt want ‚Äúdigital authoritarianism‚Äù (though we shouldn‚Äôt), explicitly recognize the inherent importance of curbing digital harms to equitably protect everyone in the US. A functioning democracy requires it.
WIRED Opinion publishes articles by outside contributors representing a wide range of viewpoints. Read more opinions here.
 Submit an op-ed at opinion@wired.com.
A virtual DJ, a drone, and an all-out Zoom wedding Remote work has its perks, until you want a promotion All the tools and tips you need to make bread at home The confessions of Marcus Hutchins, the hacker who saved the internet On the moon, astronaut pee will be a hot commodity üëÅ Is the brain a useful model for AI ? Plus: Get the latest AI news üèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones Op-ed contributor X Topics Wired Opinion surveillance Tech Policy and Law protests Meghan O'Gieblyn Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
