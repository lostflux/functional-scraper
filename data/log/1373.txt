Photographs were seen as less realistic than computer images but there was no difference with pictures of people of colour US edition US edition UK edition Australia edition International edition Europe edition The Guardian - Back to home The Guardian News Opinion Sport Culture Lifestyle Show More Show More document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('News-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('News-checkbox-input').click(); } }) }) News View all News US news World news Environment US politics Ukraine Soccer Business Tech Science Newsletters Wellness document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Opinion-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Opinion-checkbox-input').click(); } }) }) Opinion View all Opinion The Guardian view Columnists Letters Opinion videos Cartoons document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Sport-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Sport-checkbox-input').click(); } }) }) Sport View all Sport Soccer NFL Tennis MLB MLS NBA NHL F1 Golf document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Culture-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Culture-checkbox-input').click(); } }) }) Culture View all Culture Film Books Music Art & design TV & radio Stage Classical Games document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Lifestyle-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Lifestyle-checkbox-input').click(); } }) }) Lifestyle View all Lifestyle Wellness Fashion Food Recipes Love & sex Home & garden Health & fitness Family Travel Money Search input google-search Search Support us Print subscriptions document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('US-edition-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('US-edition-checkbox-input').click(); } }) }) US edition UK edition Australia edition International edition Europe edition Search jobs Digital Archive Guardian Puzzles app Guardian Licensing The Guardian app Video Podcasts Pictures Inside the Guardian Guardian Weekly Crosswords Wordiply Corrections Facebook Twitter Search jobs Digital Archive Guardian Puzzles app Guardian Licensing US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness The results from the international study found that 66% of AI images were rated as human compared with 51% of real images.
Photograph: Dall-E/Alan Connor The results from the international study found that 66% of AI images were rated as human compared with 51% of real images.
Photograph: Dall-E/Alan Connor Artificial intelligence (AI) White faces generated by AI are more convincing than photos, finds survey Photographs were seen as less realistic than computer images but there was no difference with pictures of people of colour Science correspondent Mon 13 Nov 2023 12.10 EST It sounds like a scenario straight out of a Ridley Scott film: technology that not only sounds more “real” than actual humans, but looks more convincing, too. Yet it seems that moment has already arrived.
A new study has found people are more likely to think pictures of white faces generated by AI are human than photographs of real individuals.
“Remarkably, white AI faces can convincingly pass as more real than human faces – and people do not realise they are being fooled,” the researchers report.
The team, which includes researchers from Australia, the UK and the Netherlands, said their findings had important implications in the real world, including in identity theft, with the possibility that people could end up being duped by digital impostors.
However, the team said the results did not hold for images of people of colour, possibly because the algorithm used to generate AI faces was largely trained on images of white people.
Dr Zak Witkower, a co-author of the research from the University of Amsterdam, said that could have ramifications for areas ranging from online therapy to robots.
“It’s going to produce more realistic situations for white faces than other race faces,” he said.
The team caution such a situation could also mean perceptions of race end up being confounded with perceptions of being “human”, adding it could also perpetuate social biases, including in finding missing children, given this can depend on AI-generated faces.
Writing in the journal Psychological Science , the team describe how they carried out two experiments. In one, white adults were each shown half of a selection of 100 AI white faces and 100 human white faces. The team chose this approach to avoid potential biases in how own-race faces are recognised compared with other-race faces.
The participants were asked to select whether each face was AI-generated or real, and how confident they were on a 100-point scale.
The results from 124 participants reveal that 66% of AI images were rated as human compared with 51% of real images.
The team said re-analysis of data from a previous study had found people were more likely to rate white AI faces as human than real white faces. However, this was not the case for people of colour, where about 51% of both AI and real faces were judged as human. The team added that they did not find the results were affected by the participants’ race.
Sign up to First Edition Free daily newsletter Our morning email breaks down the key stories of the day, telling you what’s happening and why it matters Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy.
 We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.
after newsletter promotion In a second experiment, participants were asked to rate AI and human faces on 14 attributes, such as age and symmetry, without being told some images were AI-generated.
The team’s analysis of results from 610 participants suggested the main factors that led people to erroneously believe AI faces were human included greater proportionality in the face, greater familiarity and less memorability.
Somewhat ironically, while humans seem unable to tell apart real faces from those generated by AI, the team developed a machine learning system that can do so with 94% accuracy.
Dr Clare Sutherland, co-author of the study from the University of Aberdeen, said the study highlighted the importance of tackling biases in AI.
“As the world changes extremely rapidly with the introduction of AI, it’s critical that we make sure that no one is left behind or disadvantaged in any situation – whether due to ethnicity, gender, age, or any other protected characteristic,” she said.
Explore more on these topics Artificial intelligence (AI) Race Computing news Most viewed Most viewed US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness News Opinion Sport Culture Lifestyle About us Help Complaints & corrections SecureDrop Work for us Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Back to top
