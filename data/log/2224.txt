Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business Google Offers to Help Others With the Tricky Ethics of AI Google CEO Sundar Pichai has navigated challenges around artificial intelligence such as an app that mislabeled gorillas as Black people, and employee protests over a Pentagon project.
Photograph: Jens Gyarmaty/VISUM/Redux Save this story Save Save this story Save Application Ethics Company Alphabet Google End User Research Small company Sector IT Technology Machine learning Companies pay cloud computing providers like Amazon , Microsoft , and Google big money to avoid operating their own digital infrastructure. Google’s cloud division will soon invite customers to outsource something less tangible than CPUs and disk drives—the rights and wrongs of using artificial intelligence.
The company plans to launch new AI ethics services before the end of the year. Initially, Google will offer others advice on tasks such as spotting racial bias in computer vision systems , or developing ethical guidelines that govern AI projects. Longer term, the company may offer to audit customers’ AI systems for ethical integrity, and charge for ethics advice.
Google’s new offerings will test whether a lucrative but increasingly distrusted industry can boost its business by offering ethical pointers. The company is a distant third in the cloud computing market behind Amazon and Microsoft, and positions its AI expertise as a competitive advantage. If successful, the new initiative could spawn a new buzzword: EaaS, for ethics as a service, modeled after cloud industry coinages such as SaaS, for software as a service.
Google has learned some AI ethics lessons the hard way—through its own controversies. In 2015, Google apologized and blocked its Photos app from detecting gorillas after a user reported the service had applied that label to photos of him with a Black friend. In 2018, thousands of Google employees protested a Pentagon contract called Maven that used the company’s technology to analyze surveillance imagery from drones.
By Tom Simonite Soon after, the company released a set of ethical principles for use of its AI technology and said it would no longer compete for similar projects, but did not rule out all defense work. In the same year, Google acknowledged testing a version of its search engine designed to comply with China’s authoritarian censorship , and said it would not offer facial recognition technology, as rivals Microsoft and Amazon had for years, because of the risks of abuse.
Google’s struggles are part of a broader reckoning among technologists that AI can harm as well as help the world. Facial recognition systems, for example, are often less accurate for Black people and text software can reinforce stereotypes.
 At the same time, regulators, lawmakers, and citizens have grown more suspicious of technology’s influence on society.
In response, some companies have invested in research and review processes designed to prevent the technology going off the rails.
Microsoft and Google say they now review both new AI products and potential deals for ethics concerns, and have turned away business as a result.
Business What Sam Altman’s Firing Means for the Future of OpenAI Steven Levy Business Sam Altman’s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity’s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Tracy Frey, who works on AI strategy at Google’s cloud division, says the same trends have prompted customers who rely on Google for powerful AI to ask for ethical help, too. “The world of technology is shifting to saying not ‘I’ll build it just because I can’ but ‘Should I?’” she says.
“The world of technology is shifting to saying not ‘I’ll build it just because I can’ but ‘Should I?’” Tracy Frey, AI Strategy, Google Google has already been helping some customers, such as global banking giant HSBC , think about that. Now, it aims before the end of the year to launch formal AI ethics services. Frey says the first will likely include training courses on topics such as how to spot ethical issues in AI systems, similar to one offered to Google employees, and how to develop and implement AI ethics guidelines. Later, Google may offer consulting services to review or audit customer AI projects, for example to check if a lending algorithm is biased against people from certain demographic groups. Google hasn’t yet decided whether it will charge for some of those services.
Google, Facebook, and Microsoft have all recently released technical tools, often free, that developers can use to check their own AI systems for reliability and fairness. IBM launched a tool last year with a “Check fairness” button that examines whether a system’s output shows potentially troubling correlation with attributes such as ethnicity or zip code.
Going a step further to help customers define their ethical limits for AI could raise ethical questions of its own. “It is very important to us that we don’t sound like the moral police,” Frey says. Her team is working through how to offer customers ethical advice without dictating or taking on responsibility for their choices.
By Tom Simonite Another challenge is that a company seeking to make money from AI may not be the best moral mentor on curbing the technology, says Brian Green, director of technology ethics at the Markkula Center for Applied Ethics at Santa Clara University. “They’re legally compelled to make money and while ethics can be compatible with that, it might also cause some decisions not to go in the most ethical direction,” he says.
Frey says that Google and its customers are all incentivized to deploy AI ethically because to be broadly accepted the technology has to function well. “Successful AI is dependent on doing it carefully and thoughtfully,” she says. She points to how IBM recently withdrew its facial recognition service amid nationwide protests over police brutality against Black people; it was apparently prompted in part by work like the Gender Shades project, which showed facial analysis algorithms were less accurate on darker skin tones.
 Microsoft and Amazon quickly said they would pause their own sales to law enforcement until more regulation was in place.
Business What Sam Altman’s Firing Means for the Future of OpenAI Steven Levy Business Sam Altman’s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity’s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg In the end, signing up customers for AI ethics services may depend on convincing companies who turned to Google to move faster into the future that they should in fact move more slowly.
Late last year, Google launched a facial recognition service limited to celebrities that is aimed primarily at companies that need to search or index large collections of entertainment video. Celebrities can opt out, and Google vets which customers can use the technology.
The ethical review and design process took 18 months, including consultations with civil rights leaders and fixing a problem with training data that caused reduced accuracy for some Black male actors. By the time Google launched the service, Amazon’s celebrity recognition service, which also lets celebs opt out, had been open to all for more than two years.
How to undo gender stereotypes in math—with math ! The furious hunt for the MAGA bomber Tips to make remote learning work for your children “Real” programming is an elitist myth AI magic makes century-old films look new ✨ Optimize your home life with our Gear team’s best picks, from robot vacuums to affordable mattresses to smart speakers Senior Editor X Topics artificial intelligence machine learning Google ethics Khari Johnson Will Knight Khari Johnson Will Knight Will Knight Khari Johnson Steven Levy Vittoria Elliott Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
