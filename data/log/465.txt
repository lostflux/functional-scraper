Vox homepage Give Give Newsletters Newsletters Site search Search Vox main menu Explainers Crossword Video Podcasts Politics Policy Culture Science Technology Climate Health Money Life Future Perfect Newsletters More Explainers Israel-Hamas war 2024 election Supreme Court Buy less stuff Open enrollment What to watch All explainers Crossword Video Podcasts Politics Policy Culture Science Technology Climate Health Money Life Future Perfect Newsletters We have a request Vox's journalism is free, because we believe that everyone deserves to understand the world they live in. Reader support helps us do that. Can you chip in to help keep Vox free for all? × Filed under: Future Perfect Technology Artificial Intelligence AI leaders (and Elon Musk) urge all labs to press pause on powerful AI We got GPT-4. We could stop there for now, placing a moratorium on new AI systems more powerful than that.
By Sigal Samuel Mar 29, 2023, 10:30am EDT Share this story Share this on Facebook Share this on Twitter Share All sharing options Share All sharing options for: AI leaders (and Elon Musk) urge all labs to press pause on powerful AI Reddit Pocket Flipboard Email Elon Musk speaks onstage during the the World Artificial Intelligence Conference in Shanghai on August 29, 2019.
Hector Retamal/AFP via Getty Images This story is part of a group of stories called Finding the best ways to do good.
Part of Some of the biggest names in AI are raising the alarm about their own creations. In an open letter published Tuesday, more than 1,100 signatories called for a moratorium on state-of-the-art AI development.
“We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4 (including the currently-being-trained GPT-5),” reads the letter, released by the Future of Life Institute, a nonprofit that works to reduce catastrophic and existential risks. “This pause should be public and verifiable, and include all key actors. If such a pause cannot be enacted quickly, governments should step in and institute a moratorium.” These are powerful words from powerful people. Signatories include Elon Musk, who helped co-found GPT-4 maker OpenAI before breaking with the company in 2018 , along with Apple co-founder Steve Wozniak and Skype co-founder Jaan Tallinn.
More to the point, the signatories include foundational figures in artificial intelligence, including Yoshua Bengio, who pioneered the AI approach known as deep learning; Stuart Russell, a leading researcher at UC Berkeley’s Center for Human-Compatible AI; and Victoria Krakovna, a research scientist at DeepMind.
These are people who know AI. And they’re warning that society is not ready for the increasingly advanced systems that labs are racing to deploy.
Related The case for slowing down AI There’s an understandable impulse here to eye-roll. After all, the signatories include some of the very people who are pushing out the generative AI models that the letter warns about. People like Emad Mostaque, the CEO of Stability AI, which released the text-to-image model Stable Diffusion last year.
But given the high stakes around rapid AI development, we have two options. Option one is to object, “These are the people who got us into this mess!” Option two is to object, “These are the people who got us into this mess!” — and then put pressure on them to do everything we can to stop the mess from spiraling out of control.
The letter is right to argue that there’s still a lot we can do.
We can — and should — slow down AI progress Some people assume that we can’t slow down technological progress. Or that even if we can, we shouldn’t, because AI can bring the world so many benefits.
Both those assumptions start to fall apart when you think about them.
The rise of artificial intelligence, explained How does AI actually work? How is AI changing our society? Is AI coming for your job? Should we be worried about AI? Who will regulate AI? As I wrote in my piece laying out the case for slowing down AI , there is no technological inevitability, no law of nature, declaring that we must get GPT-5 next year and GPT-6 the year after. Which types of AI we choose to build or not build, how fast or how slow we choose to go — these are decisions that are up to us humans to make.
Although it might seem like an AI race is inevitable because of the profit and prestige incentives in the industry — and because of the geopolitical competition — all that really means is that the true challenge is to change the underlying incentive structure that drives all actors.
The open letter echoes this point. We need a moratorium on powerful AI, it says, so we have a chance to ask ourselves: Should we let machines flood our information channels with propaganda and untruth? Should we automate away all the jobs, including the fulfilling ones? Should we develop nonhuman minds that might eventually outnumber, outsmart, obsolete and replace us? Should we risk loss of control of our civilization? In other words: We don’t have to build robots that will steal our jobs and maybe kill us.
Slowing down a new technology is not some radical idea, destined for futility. Humanity has done this before — even with economically valuable technologies. Just think of human cloning or human germline modification. The recombinant DNA researchers behind the Asilomar Conference of 1975 famously organized a moratorium on certain experiments. Scientists definitely can modify the human germline, and they probably could engage in cloning. But with rare exceptions like the Chinese scientist He Jiankui — who was sentenced to three years in prison for his work on modifying human embryos — they don’t.
What about the other assumption — that we shouldn’t slow down AI because it can bring the world so many benefits? Related Finally, a realistic roadmap for getting AI companies in check The key point here is that we’ve got to strike a wise balance between potential benefits and potential risks. It doesn’t make sense to barrel ahead with developing ever-more-powerful AI without at least some measure of confidence that the risks will be manageable. And those risks aren’t just about whether advanced AI could one day pose an existential threat to humanity , but about whether they’ll change the world in ways many of us would reject. The more power the machinery has to disrupt life, the more confident we’d better be that we can handle the disruptions and think they’re worthwhile.
Exactly what we would do with a six-month pause is less clear. Congress, and the federal government more broadly, lacks deep expertise in artificial intelligence , and the unprecedented pace and power of AI makes developing standards to control it that much more difficult. But if anything, this uncertainty bolsters the case for taking a breath.
Again, this is not a radical position. Sam Altman, OpenAI’s CEO, has said as much. He recently told ABC News that he’s “a little bit scared” of the tech his company is creating, including how quickly it may replace some jobs.
“I think over a couple of generations, humanity has proven that it can adapt wonderfully to major technological shifts,” Altman said. “But if this happens in a single-digit number of years, some of these shifts ... That is the part I worry about the most.” In fact, OpenAI said in a recent statement that “At some point, it may be important to get independent review before starting to train future systems, and for the most advanced efforts to agree to limit the rate of growth of compute used for creating new models.” The tech heavyweights who signed the open letter agree. That point, they say, is now.
Will you support Vox’s explanatory journalism? Most news outlets make their money through advertising or subscriptions. But when it comes to what we’re trying to do at Vox, there are a couple reasons that we can't rely only on ads and subscriptions to keep the lights on.
First, advertising dollars go up and down with the economy. We often only know a few months out what our advertising revenue will be, which makes it hard to plan ahead.
Second, we’re not in the subscriptions business. Vox is here to help everyone understand the complex issues shaping the world — not just the people who can afford to pay for a subscription. We believe that’s an important part of building a more equal society. We can’t do that if we have a paywall.
That’s why we also turn to you, our readers, to help us keep Vox free.
If you also believe that everyone deserves access to trusted high-quality information, will you make a gift to Vox today? One-Time Monthly Annual $5 /month $10 /month $25 /month $50 /month Other $ /month /month We accept credit card, Apple Pay, and Google Pay. You can also contribute via The rise of artificial intelligence, explained How does AI actually work? 4 What is generative AI, and why is it suddenly everywhere? What happens when ChatGPT starts to feed on its own writing? The exciting new AI transforming search — and maybe everything — explained The tricky truth about how generative AI uses your data How is AI changing society? 19 What the stories we tell about robots tell us about ourselves Silicon Valley’s vision for AI? It’s religion, repackaged.
What will love and death mean in the age of machine intelligence? What if AI treats humans the way we treat animals? Can AI learn to love — and can we learn to love it? Black Mirror’s big AI episode has the wrong villain The ad industry is going all-in on AI The looming threat of AI to Hollywood, and why it should matter to you Can AI kill the greenscreen? What gets lost in the AI debate: It can be really fun How unbelievably realistic fake images could take over the internet Robot priests can bless you, advise you, and even perform your funeral AI art freaks me out. So I tried to make some.
How fake AI images can expand your mind AI art looks way too European An AI artist explains his workflow What will stop AI from flooding the internet with fake images? You’re going to see more AI-written articles whether you like it or not How “windfall profits” from AI companies could fund a universal basic income Show More Is AI coming for your job? 7 AI is flooding the workplace, and workers love it If you’re not using ChatGPT for your writing, you’re probably making a mistake Maybe AI can finally kill the cover letter Americans think AI is someone else’s problem Mark Zuckerberg’s not-so-secret plan to join the AI race The hottest new job is “head of AI” and nobody knows what they do Why Meta is giving away its extremely powerful AI model Should we be worried about AI? 9 Four different ways of understanding AI — and its risks AI experts are increasingly afraid of what they’re creating The case for slowing down AI Are we racing toward AI catastrophe? The promise and peril of AI, according to 5 experts An unusual way to figure out if humanity is toast How AI could spark the next pandemic AI is supposedly the new nuclear weapons — but how similar are they, really? Don’t let AI fears of the future overshadow present-day causes Who will regulate AI? 9 The $1 billion gamble to ensure AI doesn’t destroy humanity Finally, a realistic roadmap for getting AI companies in check Biden sure seems serious about not letting AI get out of control Can you safely build something that may kill you? Why an Air Force colonel — and many other experts — are so worried about the existential risk of AI Scared tech workers are scrambling to reinvent themselves as AI experts Panic about overhyped AI risk could lead to the wrong kind of regulation AI is a “tragedy of the commons.” We’ve got solutions for that.
The AI rules that US policymakers are considering, explained Most Read The controversy over TikTok and Osama bin Laden’s “Letter to America,” explained Formula 1 grew too fast. Now its new fans are tuning out.
The Ballad of Songbirds & Snakes might be the best Hunger Games movie yet Why are so few people getting the latest Covid-19 vaccine? What are Israel and Palestine? Why are they fighting? vox-mark Sign up for the newsletter Sentences The day's most important news stories, explained in your inbox.
Thanks for signing up! Check your inbox for a welcome email.
Email (required) Oops. Something went wrong. Please enter a valid email and try again.
Chorus Facebook Twitter YouTube About us Our staff Privacy policy Ethics & Guidelines How we make money Contact us How to pitch Vox Contact Send Us a Tip Vox Media Terms of Use Privacy Notice Cookie Policy Do Not Sell or Share My Personal Info Licensing FAQ Accessibility Platform Status Advertise with us Jobs @ Vox Media
