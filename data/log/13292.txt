Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Cade Metz Business Google Has Open Sourced SyntaxNet, Its AI for Understanding Language Getty Images Save this story Save Save this story Save If you tell Siri to set an alarm for 5 am, she'll set an alarm for 5 am. But if you start asking her which prescription pain killer is least likely to upset your stomach, she's not really gonna know what to do---just because that's a pretty complicated sentence. Siri is a long way from what computer scientists call "natural language understanding." She can't truly understand the natural way we humans talk---despite the way Apple portrays her in all those TV ads. In fact, we shouldn't really be talking about her as a "her" at all. Siri's personhood is a marketing fiction concocted by Apple---and not a very convincing one, at that.
Google Just Open Sourced TensorFlow, Its Artificial Intelligence Engine Facebook Open Sources Its AI Hardware as It Races Google The Sadness and Beauty of Watching Google’s AI Play Go Which is not to say that our digital assistants will never live up to their simulated humanity. So many researchers working at so many tech giants, startups, and universities are pushing computers towards true natural language understanding. And the state-of-the-art keeps getting better, thanks in large part to deep neural networks ---networks of hardware and software that mimic the web of neurons in the brain. Google, Facebook, and Microsoft, among others, are already using deep neural nets to identify objects in photos and recognize the individual words we speak into digital assistants like Siri.
 The hope is that this same breed of artificial intelligence can dramatically improve a machine's ability to grasp the significance of those words , to understand how those words interact to form meaningful sentences.
Google is among those at the forefront of this research---such tech plays into both its primary search engine and the Siri-like assistant it operates on Android phones---and today, the company signaled just how big of a role this technology will play in its future. It open sourced the software that serves as the foundation for its natural language work, freely sharing it with the world at large. Yes, that's the way it now works in the tech world.
Companies will give away some of their most important stuff as a way of driving a market forward.
This newly open source software is called SyntaxNet, and among natural language researchers, it's known as a syntactic parser.
 Using deep neural networks, SyntaxNet parses sentences in an effort to understand what role each word plays and how they all come together to create real meaning. The system tries to identify the underlying grammatical logic---what's a noun, what's a verb, what the subject refers to, how it relates to the object---and then, using this info, it tries to extract what the sentence is generally about--- the gist , but in a form machines can read and manipulate.
"The accuracy we get substantially better than what we were able to get without deep learning," says Google research director Fernando Pereira, who helps oversee the company's work with natural language understanding. He estimates that the tool has cut the company's error rate by between 20 and 40 percent compared to previous methods. This is already helping to drive live Google services, including the company's all-important search engine.
According to at least some researchers outside Google, SyntaxNet is the most advanced system of its kind---if not exactly leaps and bounds over the competition. Google previously released a research paper describing this work. "The results of that paper are quite good. They're pushing us forward a little bit," says Noah Smith, a professor of computer science at the University of Washington who specializing in natural language understanding. "But there are a lot of people who continue to work on this problem." What's perhaps the most interesting about this project is that Google---an enormously powerful company that previously kept so much of its most important research to itself---continues to openly share such tools.
In sharing SyntaxNet, Google aims to accelerate the progress of natural language research.
In sharing SyntaxNet, Google aims to accelerate the progress of natural language research, much as when it open sourced the software engine known as TensorFlow that drives all its AI work. By letting anyone use and modify SyntaxNet (which runs atop TensorFlow), Google gets more human brains attacking the problem of natural language understanding than if it kept the technology to itself. In the end, that could benefit Google as a business. But an open source SyntaxNet is also a way for the company to, well, advertise its work with natural language understanding. That could also benefit Google as a business.
Undoubtedly, with technology like SyntaxNet, Google is intent on pushing computers as far as it can towards real conversation. And in a competitive landscape that includes not just Apple's Siri but many other would-be conversant computers, Google wants the world to know just how good its tech really is.
Google is far from alone in the personal assistant race. Microsoft has its digital assistant called Cortana. Amazon is finding success with its voice-driven Echo, a standalone digital assistant. And countless startups have also entered the race, including most recently Viv , a company started by two of the original designers of Siri. Facebook has even broader ambitions with a project it calls Facebook M, a tool that chats with you via text rather than voice and aims to do everything from schedule your next appointment at the DMV or plan your next vacation.
Still, despite so many impressive names working on the problem, digital assistants and chatbots are still such a long way from perfect. That's because the underlying technologies that handle natural language understanding are still such a long way from perfect. Facebook M relies partly on AI, but more on real-life humans who help complete more complex tasks---and help train the AI for the future. "We are very far from where we want to be," Pereira says.
Indeed, Pereira describes SyntaxNet as a stepping stone to much bigger things. Syntactic parsing, he says, merely provides a foundation. So many other technologies are needed to take the output of SyntaxNet and truly grasp meaning. Google is opening sourcing the tool in part to encourage the community to look beyond syntactic parsing. "We want to encourage the research community---and everyone who works on natural language understanding---to move beyond parsing, towards the deeper semantic reasoning that is necessary," he says. "We're basically telling them: ‘You don’t have to worry about parsing. You can take that as a given. And now you can explore harder.'" Using deep neural networks, SyntaxNet and similar systems do take syntactic parsing to a new level. A neural net learns by analyzing vast amounts of data. It can learn to identify a photo of a cat, for instance, by analyzing millions of cat photos. In the case of SyntaxNet, it learns to understand sentences by analyzing millions of sentences. But these aren't just any sentences. Humans have carefully labelled them, going through all the examples and carefully identifying the role that each word plays. After analyzing all these labeled sentences, the system can learn to identify similar characteristics in other sentences.
Though SyntaxNet is a tool for engineers and AI researchers, Google is also sharing a pre-built natural language processing service that it has already trained with the system. They call it, well, Parsey McParseface, and it's trained for English, learning from a carefully labeled collection of old newswire stories.
 According to Google, Parsey McParseface is about 94 percent accurate in identifying how a word relates the rest of a sentence, a rate the company believes is close to the performance of a human (96 to 97 percent).
Smith points out that such a dataset can be limiting, just because it's Wall Street Journal -speak. "It's a very particular kind of language," he says. "It doesn't look like a lot of the language people want to parse." The eventual hope is to train these types of systems on a broader array of data drawn straight from the web, but this is much harder, because people use language on the web in so many different ways. When Google trains its neural nets with this kind of dataset , the accuracy rate drops to about 90 percent. The research here just isn't as far along. The training data isn't as good. And it's a harder problem. What's more, as Smith point out, research using languages other than English isn't as far along either.
In other words, a digital assistant that works like a real person sitting next isn't by no means reality, but we are getting closer. "We are a very long way from building human capabilities," Pereira says. "But we're building technologies that are ever more accurate." Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX’s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X’s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Senior Writer X Topics artificial intelligence Enterprise Google neural networks Siri Will Knight Amit Katwala Khari Johnson Kari McMahon Andy Greenberg David Gilbert Andy Greenberg Joel Khalili Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
