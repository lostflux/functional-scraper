Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google to release third generation of its tensor processing units for faster AI Share on Facebook Share on X Share on LinkedIn Tensor pods in operating running intent Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
Google CEO Sundar Pichai today announced it will release a third generation of its tensor processing unit that will be eight times faster than tensor processing unit (TPU) chips released last year to help AI practitioners make larger, more accurate AI models.
“These chips are so powerful that for the first time we’ve had to introduce liquid cooling in our data centers,” Pichai said.
The news was announced onstage at I/O, Google’s annual developer conference being held Tuesday to Thursday, May 8-10, at the Shoreline Amphitheater in Mountain View, California.
Pichai began to refer to Google as an AI-first company at I/O last year, but artificial intelligence has been part of things at Google for some time now.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! First conceived at Google in 2013 , TPUs, specialized chips for the inference of AI data, have been in use internally at Google since 2015 to power things like Google Photos, Google search results, or Google Cloud Vision API calls.
TPUs were first publicly acknowledged by Google in 2016. Second-generation TPUs for cloud computing were introduced at I/O one year ago.
ML Kit was also introduced today to make it easy for Android and iOS developers to bring AI services into their apps.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
