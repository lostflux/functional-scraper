Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business If AI's So Smart, Why Can't It Grasp Cause and Effect? Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save Application Prediction End User Research Sector Research Source Data Text Video Technology Machine learning Machine vision Neural Network Here‚Äôs a troubling fact. A self-driving car hurtling along the highway and weaving through traffic has less understanding of what might cause an accident than a child who‚Äôs just learning to walk.
A new experiment shows how difficult it is for even the best artificial intelligence systems to grasp rudimentary physics and cause and effect. It also offers a path for building AI systems that can learn why things happen.
The experiment was designed ‚Äúto push beyond just pattern recognition,‚Äù says Josh Tenenbaum , a professor at MIT‚Äôs Center for Brains Minds & Machines , who who worked on the project with Chuang Gan, a researcher at MIT, and Kexin Yi, a PhD student at Harvard. ‚ÄúBig tech companies would love to have systems that can do this kind of thing.‚Äù The most popular cutting-edge AI technique, deep learning , has delivered some stunning advances in recent years, fueling excitement about the potential of AI. It involves feeding a large approximation of a neural network copious amounts of training data. Deep-learning algorithms can often spot patterns in data beautifully, enabling impressive feats of image and voice recognition. But they lack other capabilities that are trivial for humans.
To demonstrate the shortcoming, Tenenbaum and his collaborators built a kind of intelligence test for AI systems. It involves showing an AI program a simple virtual world filled with a few moving objects, together with questions and answers about the scene and what‚Äôs going on. The questions and answers are labeled, similar to how an AI system learns to recognize a cat by being shown hundreds of images labeled ‚Äúcat.‚Äù Systems that use advanced machine learning exhibited a big blind spot. Asked a descriptive question such as ‚ÄúWhat color is this object?‚Äù a cutting-edge AI algorithm will get it right more than 90 percent of the time. But when posed more complex questions about the scene, such as ‚ÄúWhat caused the ball to collide with the cube?‚Äù or ‚ÄúWhat would have happened if the objects had not collided?‚Äù the same system answers correctly only about 10 percent of the time.
By Tom Simonite David Cox , IBM director of the MIT-IBM Watson AI Lab , which was involved with the work, says understanding causality is fundamentally important for AI. ‚ÄúWe as humans have the ability to reason about cause and effect, and we need to have AI systems that can do the same.‚Äù A lack of causal understanding can have real consequences, too. Industrial robots can increasingly sense nearby objects, in order to grasp or move them. But they don't know that hitting something will cause it to fall over or break unless they‚Äôve been specifically programmed‚Äîand it‚Äôs impossible to predict every possible scenario.
If a robot could reason causally, however, it might be able to avoid problems it hasn‚Äôt been programmed to understand. The same is true for a self-driving car. It could instinctively know that if a truck were to swerve and hit a barrier, its load could spill onto the road.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Causal reasoning would be useful for just about any AI system. Systems trained on medical information rather than 3-D scenes need to understand the cause of disease and the likely result of possible interventions. Causal reasoning is of growing interest to many prominent figures in AI.
 ‚ÄúAll of this is driving towards AI systems that can not only learn but also reason,‚Äù Cox says.
The test devised by Tenenbaum is important, says Kun Zhang , an assistant professor who works on causal inference and machine learning at Carnegie Mellon University, because it provides a good way to measure causal understanding, albeit in a very limited setting. ‚ÄúThe development of more-general-purpose AI systems will greatly benefit from methods for causal inference and representation learning,‚Äù he says.
Besides showing weaknesses in existing AI programs, Tenenbaum and his colleagues built a new kind of AI system capable of learning about cause and effect that scores much higher on their intelligence test. Their approach combines several AI techniques. The system uses deep learning to recognize objects in a scene. The output of this is fed to software that builds a 3D model of the scene and how objects interact.
The approach requires more hand-built components than many machine learning algorithms, and Tenenbaum cautions that it‚Äôs brittle and won‚Äôt scale well. But it seems to suggest that a mix of approaches‚Äîalong with some new ideas‚Äîwill be needed to take AI forward.
‚ÄúOur minds build causal models and use these models to answer arbitrary queries, while the best AI systems are far from emulating these capabilities,‚Äù says Brenden Lake , an assistant professor of psychology and data science at NYU.
Samuel Gershman , an associate professor at Harvard who has collaborated with Tenenbaum on other projects, adds that approaching human intelligence will be impossible for machines without some grasp of causal reasoning. He points to a well-known medical fact‚Äîthat women are less likely to die from increased alcohol use than men. ‚ÄúAn AI system with no notion of causality might infer that the way to reduce mortality is to administer sex-change operations to men,‚Äù he says.
Silicon Valley ruined work culture Going the distance (and beyond) to catch marathon cheaters NASA‚Äôs epic gamble to get martian dirt back to Earth Plane contrails have a surprising effect on global warming Can you spot the idioms in these photographs ? üëÅ A defeated chess champ makes peace with AI.
 Plus, the latest AI news ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Senior Writer X Topics artificial intelligence deep learning neural networks machine learning Steven Levy Steven Levy Will Knight Khari Johnson Will Knight Niamh Rowe Will Knight Khari Johnson Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
