Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Paresh Dave Business In Sudden Alarm, Tech Doyens Call for a Pause on ChatGPT Photograph: N Rotteveel/Getty Images Save this story Save Save this story Save An open letter signed by hundreds of prominent artificial intelligence experts, tech entrepreneurs, and scientists calls for a pause on the development and testing of AI technologies more powerful than OpenAI ‚Äôs language model GPT-4 so that the risks it may pose can be properly studied.
It warns that language models like GPT-4 can already compete with humans at a growing range of tasks and could be used to automate jobs and spread misinformation. The letter also raises the distant prospect of AI systems that could replace humans and remake civilization.
‚ÄúWe call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4 (including the currently-being-trained GPT-5),‚Äù states the letter, whose signatories include Yoshua Bengio, a professor at the University of Montreal considered a pioneer of modern AI, historian Yuval Noah Harari, Skype cofounder Jaan Tallinn, and Twitter CEO Elon Musk.
The letter, which was written by the Future of Life Institute , an organization focused on technological risks to humanity, adds that the pause should be ‚Äúpublic and verifiable,‚Äù and should involve all those working on advanced AI models like GPT-4. It does not suggest how a halt on development could be verified, but adds that ‚Äúif such a pause cannot be enacted quickly, governments should step in and institute a moratorium,‚Äù something that seems unlikely to happen within six months.
Microsoft and Google did not respond to requests for comment on the letter. The signatories seemingly include people from numerous tech companies that are building advanced language models, including Microsoft and Google. Hannah Wong, a spokesperson for OpenAI, says the company spent more than six months working on the safety and alignment of GPT-4 after training the model. She adds that OpenAI is not currently training GPT-5.
The letter comes as AI systems make increasingly bold and impressive leaps. GPT-4 was only announced two weeks ago, but its capabilities have stirred up considerable enthusiasm and a fair amount of concern.
 The language model, which is available via ChatGPT , OpenAI‚Äôs popular chatbot, scores highly on many academic tests , and can correctly solve tricky questions that are generally thought to require more advanced intelligence than AI systems have previously demonstrated. Yet GPT-4 also makes plenty of trivial, logical mistakes.
 And, like its predecessors, it sometimes ‚Äúhallucinates‚Äù incorrect information, betrays ingrained societal biases, and can be prompted to say hateful or potentially harmful things.
Part of the concern expressed by the signatories of the letter is that OpenAI, Microsoft, and Google, have begun a profit-driven race to develop and release new AI models as quickly as possible. At such pace, the letter argues, developments are happening faster than society and regulators can come to terms with.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg The pace of change‚Äîand scale of investment‚Äîis significant. Microsoft has poured $10 billion into OpenAI and is using its AI in its search engine Bing as well as other applications. Although Google developed some of the AI needed to build GPT-4, and previously created powerful language models of its own, until this year it chose not to release them due to ethical concerns.
But excitement around ChatGPT and Microsoft‚Äôs maneuvers in search appear to have pushed Google into rushing its own plans. The company recently debuted Bard , a competitor to ChatGPT, and it has made a language model called PaLM, which is similar to OpenAI‚Äôs offerings, available through an API. ‚ÄúIt feels like we are moving too quickly,‚Äù says Peter Stone , a professor at the University of Texas at Austin, and the chair of the One Hundred Year Study on AI , a report aimed at understanding the long-term implications of AI.
Stone, a signatory of the letter, says he does not agree with everything in it, and is not personally concerned about existential dangers.
 But he says advances are happening so quickly that the AI community and the general public barely had time to explore the benefits and possible misuses of ChatGPT before it was upgraded with GPT-4. ‚ÄúI think it is worth getting a little bit of experience with how they can be used and misused before racing to build the next one,‚Äù he says. ‚ÄúThis shouldn‚Äôt be a race to build the next model and get it out before others.‚Äù To date, the race has been rapid. OpenAI announced its first large language model, GPT-2 in February 2019. Its successor, GPT-3, was unveiled in June 2020. ChatGPT, which introduced enhancements on top of GPT-3, was released in November 2022.
Some letter signatories are parts of the current AI boom‚Äîreflecting concerns within the industry itself that the technology is moving at a potentially dangerous pace. ‚ÄúThose making these have themselves said they could be an existential threat to society and even humanity, with no plan to totally mitigate these risks,‚Äù says Emad Mostaque, founder and CEO of Stability AI , a company building generation AI tools, and a signatory of the letter. ‚ÄúIt is time to put commercial priorities to the side and take a pause for the good of everyone to assess rather than race to an uncertain future,‚Äù he adds.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Recent leaps in AI‚Äôs capabilities coincide with a sense that more guardrails may be needed around its use. The EU is currently considering legislation that would limit the use of AI depending on the risks involved. The White House has proposed an AI Bill of Rights that spells out protections that citizens should expect from algorithm discrimination, data privacy breaches, and other AI-related problems. But these regulations began taking shape before the recent boom in generative AI even began.
‚ÄúWe need to hit the pause button and consider the risks of rapid deployment of generative AI models,‚Äù says Marc Rotenberg, founder and director of the Center for AI and Digital Policy, who was also a signatory of the letter. His organization plans to file a complaint this week with the US Federal Trade Commission calling for it to investigate OpenAI and ChatGPT and ban upgrades to the technology until ‚Äúappropriate safeguards‚Äù are in place, according to its website. Rotenberg says the open letter is ‚Äútimely and important‚Äù and that he hopes it receives ‚Äúwidespread support.‚Äù When ChatGPT was released late last year, its abilities quickly sparked discussion around the implications for education and employment.
 The markedly improved abilities of GPT-4 have triggered more consternation. Musk, who provided early funding for OpenAI, has recently taken to Twitter to warn about the risk of large tech companies driving advances in AI.
An engineer at one large tech company who signed the letter, and who asked not to be named because he was not authorized to speak to media, says he has been using GPT-4 since its release. The engineer considers the technology a major shift but also a major worry. ‚ÄúI don‚Äôt know if six months is enough by any stretch but we need that time to think about what policies we need to have in place,‚Äù he says.
Others working in tech also expressed misgivings about the letter's focus on long-term risks, as systems available today including ChatGPT already pose threats. ‚ÄúI find recent developments very exciting,‚Äù says Ken Holstein , an assistant professor of human-computer interaction at Carnegie Mellon University, who asked his name be removed from the letter a day after signing it as debate emerged among scientists about the best demands to make at this moment.
‚ÄúI worry that we are very much in a ‚Äòmove fast and break things‚Äô phase,‚Äù says Holstein, adding that the pace might be too quick for regulators to meaningfully keep up. ‚ÄúI like to think that we, in 2023, collectively, know better than this.‚Äù Updated 03/29/2023, 10:40 pm EST: This story has been updated to reflect the final version of the open letter, and that Ken Holstein asked to be removed as a signatory. An earlier draft of the letter contained an error. A comment from OpenAI has also been added.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics ChatGPT Microsoft Google OpenAI Elon Musk artificial intelligence Will Knight Khari Johnson Amit Katwala David Gilbert Andy Greenberg Kari McMahon Andy Greenberg Joel Khalili Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
