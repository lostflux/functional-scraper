Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Lydia Morrish Business Fact-Checkers Are Scrambling to Fight Disinformation With AI Play/Pause Button Pause Illustration: Jacqui VanLiew Save this story Save Save this story Save Spainâ€™s regional elections are still nearly four months away, but Irene Larraz and her team at Newtral are already braced for impact. Each morning, half of Larrazâ€™s team at the Madrid-based media company sets a schedule of political speeches and debates, preparing to fact-check politiciansâ€™ statements. The other half, which debunks disinformation, scans the web for viral falsehoods and works to infiltrate groups spreading lies. Once the May elections are out of the way, a national election has to be called before the end of the year, which will likely prompt a rush of online falsehoods. â€œItâ€™s going to be quite hard,â€ Larraz says. â€œWe are already getting prepared.â€ The proliferation of online misinformation and propaganda has meant an uphill battle for fact-checkers worldwide, who have to sift through and verify vast quantities of information during complex or fast-moving situations, such as the Russian invasion of Ukraine , the Covid-19 pandemic , or election campaigns. That task has become even harder with the advent of chatbots using large language models, such as OpenAIâ€™s ChatGPT, which can produce natural-sounding text at the click of a button, essentially automating the production of misinformation.
Faced with this asymmetry, fact-checking organizations are having to build their own AI-driven tools to help automate and accelerate their work. Itâ€™s far from a complete solution, but fact-checkers hope these new tools will at least keep the gap between them and their adversaries from widening too fast, at a moment when social media companies are scaling back their own moderation operations.
â€œThe race between fact-checkers and those they are checking on is an unequal one,â€ says Tim Gordon, cofounder of Best Practice AI, an artificial intelligence strategy and governance advisory firm, and a trustee of a UK fact-checking charity.
â€œFact-checkers are often tiny organizations compared to those producing disinformation,â€ Gordon says. â€œAnd the scale of what generative AI can produce, and the pace at which it can do so, means that this race is only going to get harder.â€ Newtral began developing its multilingual AI language model, ClaimHunter, in 2020, funded by the profits from its TV wing, which produces a show fact-checking politicians , and documentaries for HBO and Netflix.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Using Microsoftâ€™s BERT language model , ClaimHunterâ€™s developers used 10,000 statements to train the system to recognize sentences that appear to include declarations of fact, such as data, numbers, or comparisons. â€œWe were teaching the machine to play the role of a fact-checker,â€ says Newtralâ€™s chief technology officer, RubÃ©n MÃ­guez.
Simply identifying claims made by political figures and social media accounts that need to be checked is an arduous task. ClaimHunter automatically detects political claims made on Twitter, while another application transcribes video and audio coverage of politicians into text. Both identify and highlight statements that contain a claim relevant to public life that can be proved or disprovedâ€”as in, statements that arenâ€™t ambiguous, questions, or opinionsâ€”and flag them to Newtralâ€™s fact-checkers for review.
The system isnâ€™t perfect, and occasionally flags opinions as facts, but its mistakes help users to continually retrain the algorithm. It has cut the time it takes to identify statements worth checking by 70 to 80 percent, MÃ­guez says.
â€œHaving this technology is a huge step to listen to more politicians, find more facts to check, [and] debunk more disinformation,â€ Larraz says. â€œBefore, we could only do a small part of the work we do today.â€ Newtral is also working with the London School of Economics and the broadcaster ABC Australia to develop a claim â€œmatchingâ€ tool that identifies repeated false statements made by politicians, saving fact-checkers time by recycling existing clarifications and articles debunking the claims.
The quest to automate fact-checking isnâ€™t new. The founder of the American fact-checking organization Politifact, Bill Adair, first experimented with an instant verification tool called Squash at Duke University Reportersâ€™ Lab in 2013. Squash live-matched politiciansâ€™ speeches with previous fact-checks available online, but its utility was limited. It didnâ€™t have access to a big enough library of fact-checked pieces to cross-reference claims against, and its transcriptions were full of errors that humans needed to double-check.
â€œSquash was an excellent first step that showed us the promise and challenges of live fact-checking,â€ Adair tells WIRED. â€œNow, we need to marry what weâ€™ve done with new advances in AI and develop the next generation.â€ But a decade on, fact-checking is still a long way from being fully automated. While large language models (LLMs) like ChatGPT can produce text that looks like it was written by a person, it cannot detect nuance in language, and has a tendency to make things up and amplify biases and stereotypes.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg â€œ[LLMs] donâ€™t know what facts are,â€ says Andy Dudfield, head of AI at Full Fact, a UK fact-checking charity, which has also used a BERT model to automate parts of its fact-checking workflow. â€œ[Fact-checking] is a very subtle world of context and caveats.â€ While the AI may appear to be formulating arguments and conclusions, it isnâ€™t actually making complex judgements, meaning it canâ€™t, for example, give a rating of how truthful a statement is.
LLMs also lack knowledge of day-to-day events, meaning they arenâ€™t particularly useful when fact-checking breaking news. â€œThey know the whole of Wikipedia but they donâ€™t know what happened last week,â€ says Newtralâ€™s MÃ­guez. â€œThatâ€™s a big issue.â€ As a result, fully automated fact-checking is â€œvery far off,â€ says Michael Schlichtkrull, a postdoctoral research associate in automated fact verification at the University of Cambridge. â€œA combined system where you have a human and a machine working together, like a cyborg fact-checker, [is] something thatâ€™s already happening and weâ€™ll see more of in the next few years.â€ But MÃ­guez sees further breakthroughs within reach. â€œWhen we started to work on this problem in Newtral, the question was if we can automate fact-checking. Now the question for us is when we can fully automate fact-checking. Our main interest now is how we can accelerate this because the fake technologies are moving forward quicker than technologies to detect disinformation.â€ Fact-checkers and researchers say there is a real urgency to the search for tools to scale up and speed up their work, as generative AI increases the volume of misinformation online by automating the process of producing falsehoods.
In January 2023, researchers at NewsGuard , a fact-checking technology company, put 100 prompts into ChatGPT relating to common false narratives around US politics and health care. In 80 percent of its responses, the chatbot produced false and misleading claims.
OpenAI declined to give an attributable comment.
Because of the volume of misinformation already online, which feeds into the training models for large language models, people who use them may also inadvertently spread falsehoods. â€œGenerative AI creates a world where anybody can be creating and spreading misinformation. Even if they do not intend to,â€ Gordon says.
As the problem of automated misinformation grows, the resources available to tackle it are under pressure.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg While there are now nearly 400 fact-checking initiatives in over 100 countries, with two-thirds of those within traditional news organizations, growth has slowed, according to Duke Reportersâ€™ Labâ€™s latest fact-checking census.
 On average, around 12 fact-checking groups shut down each year, according to Mark Stencel, the labâ€™s codirector. New launches of fact-checking organizations have slowed since 2020, but the space is far from saturated, Stencel saysâ€”particularly in the US, where 29 out of 50 states still have no permanent fact-checking projects.
With massive layoffs across the tech industry, the burden of identifying and flagging falsehoods is likely to fall more on independent organizations. Since Elon Musk took over Twitter in October 2022, the company has cut back its teams overseeing misinformation and hate speech.
 Meta reportedly restructured its content moderation team amid thousands of layoffs in November.
With the odds stacked against them, fact-checkers say they need to find innovative ways to scale up without major investment. â€œAround 130,000 fact-checks have been written by all fact-checkers around the world,â€ says Dudfield, citing a 2021 paper , â€œwhich is a number to be really proud of, but in the scale of the web is a really small number. So everything we can do to make each one of those work as hard as possible is really important.â€ You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Topics algorithms disinformation artificial intelligence elections content moderation Caitlin Harrington Morgan Meaker Aarian Marshall Aarian Marshall Tom Bennett Morgan Meaker Paresh Dave Gregory Barber Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
