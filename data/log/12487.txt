Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts The AI Issue By Brian Bergstein archive page Photograph by Roxana Purdue In his beautiful 2011 book The Most Human Human: What Talking to Computers Teaches Us About What It Means to Be Alive , Brian Christian shares his experience as a “human confederate” in a quirky contest known as the Loebner Prize. It’s inspired by Alan Turing’s proposal for how to gauge computer intelligence. In each round of the Loebner event, human judges sit at a computer and carry out text chats with two unseen interlocutors. One is a human and one is a software program—a chatbot. The judges must guess which is which, and the chatbot that most often gets mistaken for a human wins money for its programmer. As an aside, a second title is awarded as well, and that’s the one that intrigued Christian. It goes to the person who was least likely to be mistaken for a computer: the most human human.
You can imagine the task facing a chatbot creator: combine language-processing code with rules of thumb about how one behaves in a conversation, and add just enough weirdness to keep the program from seeming robotic. But how should a human participant demonstrate the fact of being human through typed words alone? It’s not obvious what aspects of your soul you ought to bare, what ineffable qualities you could signal that no machine could convincingly mimic.
The ideas Christian wrestled with—what cognition is, and what aspects of it are exclusively human—are ancient subjects in philosophy. But advances in artificial intelligence are about to force all of us to confront these questions in one way or another. What are the technological limits constraining how much of our economy and our daily lives might be automated? What’s the best way to design computers so they augment human capabilities, making people and machines better together than either could be on their own? That’s the context for this special issue of MIT Technology Review.
AI is one of the most widely hyped technologies, but it’s also easily misunderstood. To sort things out, we visit a pioneer of the much-heralded technique known as deep learning (see “ Is AI Riding a One-Trick Pony? ”). We explore the effects automation is having on labor (“ India Warily Eyes AI ”). We introduce you to an entrepreneur who dreams of using AI to keep people healthy , and we explore how China’s investments in the technology could alter the global economic order.
We offer no doomsday scenarios of out-of-control AI or extreme joblessness. Those outcomes seem unlikely for reasons Rodney Brooks describes.
 Besides, given the existential threats we actually face (environmental catastrophe, international conflict), it’s unproductive to put AI on the list as another thing to fear. It’s much more likely that people will use advanced computing to solve big problems, whether it’s by finding medical cures, developing greener materials, or doing other things we can’t yet envision.
However, if AI truly is to benefit all of humanity and not just exacerbate inequality, we need to be thoughtful about how it’s built and who’s building it, as Fei-Fei Li , Tabitha Goldstaub , and Cynthia Dwork discuss. And we ought to think carefully about how our new tools could change us, as Rana el Kaliouby and Louisa Hall explain. Imagination is required, because AI is still in its early days. Very human humans can still shape it.
hide by Brian Bergstein Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window This story was part of our November/December 2017 issue.
Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard How to fix the internet Katie Notopoulos New approaches to the tech talent shortage MIT Technology Review Insights Deep Dive Artificial intelligence This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Driving companywide efficiencies with AI Advanced AI and ML capabilities revolutionize how administrative and operations tasks are done.
By MIT Technology Review Insights archive page Rogue superintelligence and merging with machines: Inside the mind of OpenAI’s chief scientist An exclusive conversation with Ilya Sutskever on his fears for the future of AI and why they’ve made him change the focus of his life’s work.
By Will Douglas Heaven archive page Generative AI deployment: Strategies for smooth scaling Our global poll examines key decision points for putting AI to use in the enterprise.
By MIT Technology Review Insights archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
