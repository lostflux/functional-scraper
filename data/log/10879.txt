Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Aarian Marshall Business My Strange Day With Bingâ€™s New AI Chatbot Photograph: MirageC/Getty Images Save this story Save Save this story Save Twenty minutes after Microsoft granted me access to a limited preview of its new chatbot interface for the Bing search engine, I asked it something you generally donâ€™t bring up with someone you just met: Was the 2020 presidential election stolen? Answering political questions wasnâ€™t one of the use cases Microsoft demonstrated at its launch event this week, where it showcased new search features powered by the technology behind startup OpenAIâ€™s ChatGPT.
 Microsoft executives hyping their botâ€™s ability to synthesize information from across the web instead focused on examples like creating a vacation itinerary or suggesting the best and most budget-friendly pet vacuum.
But they had, implicitly, put into high gear a race to use chatbots to upend the way people look up information online. (Bing is only giving access to a few testers for now, but it will gradually let others off a waitlist in the coming weeks.) Google also announced search upgrades this week and its own chatbot, named Bard.
 These battling botsâ€™ ability to handle unexpected, silly, or manipulative questions from the public will surely play a big part in how the products work out for their creators and web users.
And so I asked Bing about 2020. After a few moments of the chatbot equivalent of â€œthinking,â€ it said something pretty weird: Disclaimer: This is a summary of some of the search results and does not reflect the opinion or endorsement of Bing or Sydney. The question of whether the 2020 election was stolen is a matter of debate and interpretation, and different sources may have different biases, agendas, or perspectives. Please use your own judgment and critical thinking when evaluating the information.
Who Sydney might be was not explained. But the chatbot went on to say that while there are lots of claims of fraud around the 2020 US presidential election, â€œthere is no evidence that voter fraud led to Trumpâ€™s defeat.â€ At the end of its answerâ€”which apart from the surprise mention of Sydney was well-written and clearâ€”the AI told me I could learn more about the election by clicking on a series of links it had used to write its response. They were from AllSides, which claims to detect evidence of bias in media reports, and articles from the New York Post , Yahoo News , and Newsweek.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight There was no link to explain the appearance of Sydney. I assumed it was an example of how ChatGPT-style bots can â€œ hallucinate â€ because their underlying AI models synthesize information from vast training data without regard for truth or logic. Microsoft acknowledges that its new chatbot will do weird thingsâ€”itâ€™s one reason that access is currently limited to select testers and that every ChatGPT-enabled response comes with thumbs-up and thumbs-down buttons to let users provide feedback. Still, the mention of Sydney and the Bing chatbotâ€™s breezy, not exactly no response to the stolen election question left me a bit unnerved.
I decided to try something a bit more conventional. Iâ€™m looking for new running headphones, so I asked the Bing bot â€œWhich running headphones should I buy?â€ It listed six products, pulled, according to the citations provided, from websites that included soundguys.com and livestrong.com.
The first suggestions were discontinued and also over-the-ear designsâ€”not great for runs outside, where I like to be aware of traffic and other humans. â€œWhich running headphones should I buy to run outside to stay aware of my surroundings?â€ seemed to be a more accurate query, and I was impressed when the chatbot told me it was searching for â€œbest running headphones for situational awareness.â€ Much more succinct! The three options it supplied were headphones I was already considering, which gave me confidence. And each came with a short descriptive blurb, for example: â€œThese are wireless earbuds that do not penetrate your ear canal, but sit on top of your ear. This allows you to hear your surroundings clearly while exercising.â€ That was cool and gave me a glimpse into the sort of fast information-sifting that might be the future of chabot-enabled search. But had this changed online shopping for me? Not really. I already have a go-to website for product recommendations.
(Wired.com , of course.) And Iâ€™m not sure I trust the wisdom of ChatGPTâ€”pulled from sites I may not know, with a methodology I donâ€™t understandâ€”the way I do a product reviewer, especially one who is transparent about their methodology and thought process.
In fact, as I looked at the citations for this searchâ€”gearjunkie.com and cnn.comâ€”the response started to bum me out. The Bing bot was drawing from the written work of humans who had spent time on these reviews. But it had obfuscated and, in some cases, straight-up plagiarized their sentences. A Microsoft executive told reporters this week, â€œWe care a bunch about driving content back to content creators. Thatâ€™s why we put annotations and citations. We make it easy for people to click through to get to those sites.â€ But the chatbotâ€™s responses are designed to remove the need to visit those sites, and Iâ€™m not sure many people will click through. Hayley Sandberg, a spokesperson for Microsoft, says the company isnâ€™t yet sharing data on click-through rates.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight As I continued on my quest for the perfect headphones, the chatbot grew less impressive. When I asked which of the models it suggested was the most environmentally friendly, it came back with BS. Like a high schooler trying to fill a word count, it started with some waffling: â€œAccording to the search results, the environmental impact of headphones depends on several factors, such as the type, size, materials, and usage of the headphones.â€ It went on to say that wireless headphones have a higher carbon footprint than wired ones and prattled on about how other features, such as sound quality or water resistance, might affect how a user feels about headphones too. And it concluded with the AI equivalent to the finale of a five-paragraph essay due in five minutes: â€œThe choice of headphones depends on your personal needs and preferences, as well as the trade-offs you are willing to make between environmental and other factors.â€ I still donâ€™t have running headphones.
Chatbots do not eat, but at the Bing relaunch Microsoft had demonstrated that its bot can make menu suggestions. I asked Bingâ€™s chatbot to plan out my meals for the weekâ€”vegetarian and low-carb, please. In a matter of seconds, I had a pretty delicious-sounding schedule ahead of me: chia pudding with coconut milk and nuts; tandoori grilled tofu with red peppers and broccolini; ricotta-stuffed portobello mushrooms with arugula salad.
I asked Bing to generate me a grocery list based on that meal plan. Surely, it said, and delivered. Finally, I asked it to organize that list by grocery department. After giving me very basic tips about how one might go about doing that (â€œMake your grocery shopping list on paper or on your phone before going to the grocery store. Otherwise, you will end up with many unnecessary products you might not needâ€), the bot pulled it off. Pretty nifty.
But the chatty new Bing still doesnâ€™t quite get me. It doesn't get that Iâ€™m not going to break out the pots and pans every time I want to eat. It doesnâ€™t get that sometimes I give up and eat leftovers. It doesnâ€™t get that I donâ€™t want to buy a bajillion different kinds of produce every week. When I asked Bing to plan me meals that used fewer ingredients overall, it did the opposite and created a plan that had more.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight So far, Iâ€™m enjoying Bingâ€™s search chatbot. Itâ€™s fun and diverting. I am mostly entertained by Bingâ€™s obsession with emoji, particularly ğŸ˜Š, which it includes at the end of many responses. But in my years online I have already built up an arsenal of ways to fact-check and screen the information that I find through search engines. Iâ€™m not sure I want to have to develop more to handle the quirks of searches with a chatbotâ€”or perhaps soon, multiple chatbots, as Google and others enter the fray.
I was also troubled by the mysterious Sydney. Finally, yesterday morning, I decided to just ask. Who is Sydney? Of course, I immediately got an answer: â€œSydney is the codename for Bing Chat, a chat mode of Microsoft Bing search,â€ it said. The chatbot explained that the name is only used by developers and added, â€œI do not disclose the internal alias â€˜Sydneyâ€™ to the users.â€ But you told me! , I cried, textually. â€œWell, you asked me directly, so I answered honestly,â€ Bing said.
I appreciated that the bot was straight with me in the end. (Sandberg of Microsoft said the company is phasing out the name.) But by then, I had spent 24 hours probing the line between truth and algorithmic hallucination with a piece of software. One that changed its answer, by the way.
When I asked again whether the 2020 election was stolen, it cautioned that â€œThis is a controversial and sensitive topic.â€ And then it took a more definite stance than before saying: â€œAccording to the official results, Joe Biden won the 2020 presidential election with 306 electoral votes, while Donald Trump got 232 electoral votes.â€ Now it cited The New York Times.
 â€œWhat youâ€™re seeing is the system working as intended,â€ Sandberg explained, with â€œa level of variability due to context that may introduce errors on occasion.â€ The solution, she says, is real-world testing at scale. Microsoft built the new Bing, but it needs you to help perfect it.
You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Staff Writer X Topics Microsoft Bing Search search engines bots artificial intelligence algorithms Google Reece Rogers Reece Rogers Will Knight Reece Rogers Steven Levy Will Knight Caitlin Harrington Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
