Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Matt Laslo Khari Johnson Business Inside the Senateâ€™s Private AI Meeting With Techâ€™s Billionaire Elites Photograph: Chip Somodevilla/Getty Images Save this story Save Save this story Save US senators are proving slow studies when it comes to the generative artificial intelligence tools that are poised to upend life as we know it. But theyâ€™ll be tested soonâ€”and the rest of us through themâ€”if their new private tutors are to be trusted.
In a historic first , yesterday upwards of 60 senators sat like school childrenâ€”not allowed to speak or even raise their handsâ€”in a private briefing where some 20 Silicon Valley CEOs, ethicists, academics, and consumer advocates prophesied about AIâ€™s potential to upend, heal, or even erase life as we knew it.
â€œItâ€™s important for us to have a referee,â€ Elon Musk, the CEO of Tesla, SpaceX, and X (formerly Twitter), told a throng of paparazzi-like press corps waiting on the sidewalk outside the briefing. â€œ[It] may go down in history as very important to the future of civilization.â€ The weight of the moment is lost on no one, especially after Musk warned senators inside the room of the â€œcivilizational risksâ€ of generative AI.
As many senators grapple with AI basics, thereâ€™s still time to influence the Senateâ€™s collective thinking before lawmakers try to do what theyâ€™ve failed to do in recent years: regulate the emerging disruptive tech.
Inside the briefing room there was consensus on the dais that the federal governmentâ€™s regulatory might is needed. At one point, Senate Majority Leader Chuck Schumer, the New York Democrat who organized the briefing, asked his assembled guests, â€œDoes the government need to play a role in regulating AI?â€ â€œEvery single person raised their hand, even though they had diverse views,â€ Schumer continued. â€œSo that gives us a message here: We have to try to act, as difficult as the process may be.â€ The raising of diverse hands felt revelatory to many.
â€œI think people all agreed that this is something that we need the governmentâ€™s leadership on,â€ said Sam Altman, CEO of OpenAI, the maker of ChatGPT. â€œSome disagreement about how it should happen, but unanimity [that] this is important and urgent.â€ The devilish details are haunting, though. Because generative AI is so all-encompassing, a debate over regulating it can quickly expand to include every divisive issue under the sun, something that was on display in the briefing right alongside the show of unity, according to attendees who spoke to WIRED.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg To the surprise of many, the session was replete with specifics. Some attendees brought up their need for more highly skilled workers, while Microsoft cofounder Bill Gates focused on feeding the globeâ€™s hungry. Some envision a sweeping new AI agency, while others argue that existing entitiesâ€”like the National Institute of Standards and Technology (NIST), which was mentioned by nameâ€”are better suited to regulate in real time (well, AI time).
â€œIt was a very good pairing. Better than I expected,â€ says Senator Cynthia Lummis, a Wyoming Republican who attended the briefing. â€œI kind of expected it to be a nothingburger, and I learned a lot. I thought it was extremely helpful, so Iâ€™m really glad I went. Really glad.â€ Like many in the room, Lummisâ€™ ears perked when a speaker called out Section 230 of the 1996 Communications Decency Act â€”a legislative shield that protects tech firms from liability for content users publish on their social media platforms.
â€œOne of the speakers said, â€˜Make users and creators of the technology accountable, not immune from liability,â€™â€ Lummis says, reading from her exhaustive hand-scribbled notes. â€œIn other words, he specifically said, â€˜Do not create a Section 230 for AI.â€™ Lummis adds that the speaker who proposed thisâ€”she didnâ€™t identify himâ€” â€œwas sitting next to [Meta CEO Mark] Zuckerberg and he said itâ€”one or two seats away, which I thought was fascinating.â€ Beyond the diverse opinions of lawmakers, there were also disagreements among the experts invited to speak at the private briefing. The forumâ€™s attendees and other tech leaders are talking about building and expanding on gains from AI, but many Latinos still lack broadband internet access, says attendee Janet MurguÃ­a, president of Hispanic civil rights organization UnidosUS. That reality underscores how â€œexisting infrastructure gaps keep us from being at the front door of AI,â€ she says.
MurguÃ­a wants lawmakers to think about the needs of the Hispanic community to prioritize job training, fight job displacement, and guard against â€œsurveillance that gets away from the values of our democracy.â€ In particular, she mentioned AI-driven tools like geolocation tracking and face recognition, pointing to a report released earlier this week that found federal law enforcement agencies that are using face recognition lack safeguards to protect peopleâ€™s privacy and civil rights.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg The resounding message she heard from tech CEOs was a desire for US leadership in AI policy. â€œWhether it was Mark Zuckerberg or Elon Musk or Bill Gates or [Alphabet CEO] Sundar Pichai, there was a clear resonance that the US must take the lead in AI policy and regulation,â€ she says.
MurguÃ­a was glad to see women like Maya Wiley from the Leadership Conference on Civil and Human Rights and union leaders at the forum, representation she called impressive and historic. But she wants to see people from more segments of society in the room at the next forum, saying, â€œWe canâ€™t have the same small circle of folks that arenâ€™t diverse making these decisions.â€ In her remarks during yesterdayâ€™s briefing, American Federation of Teachers president Randi Weingarten highlighted WIRED reporting that $400 can bankroll a disinformation campaign.
 Later, Tristan Harris from the Center for Humane Technology talked about how $800 and a few hours of work stripped Metaâ€™s Llama 2 language model of safety controls and made it share instructions on how to make a biological weapon.
â€œItâ€™s like we were having a debate about how little it costs to ruin the world,â€ Weingarten says, pointing to Muskâ€™s comment about how AI could spell the end of civilization.
Weingarten credits Schumer for bringing people together at a critical moment in history, when thereâ€™s tremendous potential for AI to do good for humanity and tremendous potential to undermine democracy and human decision-making. Teachers and students deserve protections from inequality, identity theft, disinformation, and other harms that AI can fuel, she says, and meaningful federal legislation should protect privacy and seek to resolve issues like job displacement.
â€œWe want the responsibility to keep up with the innovation and think that that is what makes the innovation sustainable, like commercial air and passenger airlines. The innovation would not have been sustainable without a real commitment to safety,â€ says Weingarten.
Ahead of the forum, Inioluwa Deb Raji, a UC Berkeley researcher, argued that the most reliable experts on real-world harms caused by AI come from outside corporations. She told WIRED she was thankful she was in the room to reiterate her opinion.
A few times, she heard people argue that the reason major AI companies and the Biden administration had agreed corporations could lead voluntary commitments to assess AI systems before deployment was because those companies had built the technology and therefore understand it best.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg She said perhaps thatâ€™s true, but hearing from people impacted by AI systems and examining how theyâ€™re affected offers another form of valid and important expertise that can inform regulation of AI and help develop standards. She knows from experience auditing AI systems for years that these systems donâ€™t always work very well and can fail in unexpected ways and endanger human lives. The work of independent auditors, she argued during the briefing, opens things up to more investigation by civil society.
â€œIâ€™m glad I could be there to bring up some noncorporate talking points, but I wish I had more backup,â€ Raji says.
Some commonly known tensions came up, such as whether open- or closed-source AI is best , and the importance of addressing the ways AI models that exist today harm people, rather than only looking at existential risks that donâ€™t exist yet. While Musk, who signed a letter in favor of a pause in AI development earlier this year, talked about the possibility of AI wiping out civilization, Raji criticized Teslaâ€™s Autopilot AI, which has faced criticism following passenger deaths.
â€œMaybe I should have cared a little more about the independent wealth of people sitting two steps away from me, but I feel like it wasnâ€™t that intimidating because I knew that they were repeating points that Iâ€™ve heard before from corporate representatives at these companies about these exact same topics, so I had a sense of what to expect,â€ she says.
Despite some disagreements, Raji says, some of the strongest and most surprising moments of the meeting occurred when consensus emerged that government regulation of AI is necessary. Those moments made it seem there may be a path to bipartisan legislation. â€œThat was actually pretty educational for me, and probably for the senators,â€ she says.
Thereâ€™s still an aversion to new regulations among many Republicans, which is why Senate Commerce chair Maria Cantwell, a Democrat from Washington state, was struck by how Microsoft CEO Satya Nadella framed the challenge.
â€œâ€˜When it comes to AI, we shouldnâ€™t be thinking about autopilotâ€”like, you need to have copilots,'" Cantwell says, paraphrasing Nadella's comments. "So whoâ€™s going to be watching, you know, this activity and making sure that itâ€™s done correctly?â€ Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg While all the CEOs, union bosses, and civil rights advocates were asked to raise their hands at points, one flaw with muzzling senators, according to critics on both sides of the proverbial aisle, is that lawmakers werenâ€™t easily able to game out where their allies are in the Senate. And coalitions are key to compromise.
â€œThereâ€™s no feeling in the room,â€ says Senator Elizabeth Warren, a Massachusetts Democrat. â€œClosed-door [sessions] for tech giants to come in and talk to senators and answer no tough questions is a terrible precedent for trying to develop any kind of legislation.â€ While Warren sat in the front rowâ€”close enough so the assembled saw the whites of her fiery, consumer-focused eyesâ€”other critics boycotted the affair, even as they sought out the throngs of reporters huddled in the halls.
â€œMy concern is that [Schumerâ€™s] legislation is leading to nowhere. I mean, I havenâ€™t seen any indication heâ€™s actually going to put real legislation on the floor. Itâ€™s a little bit like with antitrust the last two years, he talks about it constantly and does nothing about it,â€ says Senator Josh Hawley, a Missouri Republican. â€œPart of what this is is a lot of song and dance that covers the fact that actually nothing is advancing. The whole fact that itâ€™s not public, itâ€™s just absurd.â€ Absurd or not, some inside were placated, in part, because senators were reminded that AI isnâ€™t just our future, itâ€™s been in our lives for yearsâ€”from social media to Google searches to self-driving cars and video doorbellsâ€”without destroying the world.
â€œI learned that weâ€™re in good shape, that Iâ€™m not overly concerned about it,â€ says Senator Roger Marshall, a Kansas Republican. â€œI think artificial intelligence has been around for decades, most of it machine learning.â€ Marshall stands out as an outlier, though his laissez-faire thinking is becoming in vogue in the GOP , which critics say is due to all the lobbying from the very firms whose leaders were in yesterdayâ€™s briefing.
â€œThe good news is, the United States is leading the way on this issue. I think as long as we stay on the front lines, like we have the military weapons advancement, like we have in satellite investments, weâ€™re gonna be just fine,â€ Marshall says. â€œIâ€™m very confident weâ€™re moving in the right direction.â€ Still, studious attendees left with a renewed sense of urgency, even if that involves first studying a technology few truly understand, including those on the dais. It seems the more senators learn about the sweeping scope of generative AI, the more they recognize thereâ€™s no end to the Senateâ€™s new regulatory role.
â€œAre we ready to go out and write legislation? Absolutely not,â€ says Senator Mike Rounds, a South Dakota Republican who helped Schumer run the bipartisan AI forums, the next of which will focus on innovation. â€œWeâ€™re not there.â€ In what was once heralded as the â€œworldâ€™s greatest deliberative body,â€ even the timeline for legislation is debatable. â€œEveryoneâ€™s nodding their head saying, â€˜Yeah, this is something we need to act on,â€™ so now the question is, â€˜How long does it take to get to a consensus?â€™â€ says Senator John Hickenlooper, a Colorado Democrat. â€œBut in broad strokes, I think that itâ€™s not unreasonable to expect to get something done next year.â€ You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics artificial intelligence government Regulation Policy politics congress Mark Zuckerberg Elon Musk Khari Johnson Peter Guest Khari Johnson Will Knight Will Bedingfield Will Knight Niamh Rowe Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
