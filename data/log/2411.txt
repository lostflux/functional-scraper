Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages In shadow of ChatGPT, diverse Nvidia technology grows at GTC 2023 Share on Facebook Share on X Share on LinkedIn Nvidia's Earth-2 will be a digital twin of the planet.
It was hard to discern amid the ChatGPT news that dominated at last week’s Nvidia GTC 2023 event, but it’s worth noting that Nvidia technology continues to push forward a broad array of initiatives.
Technical sessions and product announcements in radar design simulation, streaming sensor array data processing and computational lithography don’t fit in the spirited ChatGPT chorus, but some of these announcements may prove equally important in the long term.
>>Follow VentureBeat’s ongoing Nvidia GTC spring 2023 coverage<< Even as he evangelizes ChatGPT , Nvidia CEO Jensen Huang continues to show enthusiasm for a range of undertakings under the banner of “accelerated computing.” Pedal-to-the-metal for accelerated computing Steady progress has held Nvidia in good stead as it expanded GPU technology from graphics cards and video games to crypto-mining and supercomputing, and now, enterprise AI.
Even at its inception in the 1990s, Nvidia proclaimed that its GPU technology had applications beyond graphics processing. That was somewhat retro at the time, as standalone floating-point coprocessors were being added to CPUs. All along, Nvidia’s mission has been to accelerate computing.
The company was careful to nurture products that could be used in the near term, but also to seed long-term uses. Nvidia had to continually create software that eased such evolution. A very notable case is the CUDA programming platform.
That paid off as industry began to pursue AI and deep learning , where GPUs’ very high memory bandwidth thrived. On the hardware front, Nvidia chips have a significant lead in AI in the data center. Despite a slew of specialized ASICs, little has curbed general GPU enthusiasm in deep learning.
Nvidia continues to spice up its product line. In the shadow of varied ChatGPT advances at GTC, Nvidia’s notable announcements included: Open-sourcing its Modulus framework Nvidia is making its Modulus framework available for use with physics-ML under the simple Apache 2.0 license. This can advance efforts to combine physical modeling and numerical simulation.
Why is that important? In recent years Nvidia Modulus has forged a family of neural operators, which now include physics-informed neural networks.
 Success with physics-ML could translate into better results in modeling physical systems. That would lead to better fidelity, for example, for digital twins across industries, or avatars across metaverses.
cuLitho: a software library to speed computational lithography workloads Speeding up computational lithography is important as the late Gordon Moore’s Law runs its course. Circuit features are now ultra-small, and it is an incredibly complex job to calculate precise manipulation of mask patterns used to draw them on silicon wafers.
The cuLitho library runs on GPUs and increases speed of nanoscale computational lithography to 40 times greater than today’s alternatives, according to the company. Nvidia foresees dramatic speed-ups in the work of semiconductor fabs with cuLitho.
A quantum-classical computing platform Nvidia together with Tel Aviv-based Quantum Machines announced a platform that will match an OPX+ quantum control system with a Nvidia Grace Hopper system. The goal is to create a system that can scale from a few-qubit rig to a quantum-accelerated supercomputer.
Quantum-classical computing would fill a gap as quantum computing advocates work to extend coherence times, improve error correction and scale-up qubit counts.
A payback on these efforts will be hard won. In the case of quantum computing, Nvidia’s Huang was pretty clear that he sees full-fledged adaptations as a longer-term goal.
Quantum computing is “solidly a decade and two decades away to have … broadly useful quantum systems,” he said at a GTC press conference.
Nvidia and the next computer overlord Huang is not alone in his prediction that true quantum computing is 10 years off of more. That is not altogether surprising given Nvidia’s post on the farthest frontier of classical computing today.
Since Nvidia is focused on accelerated computing, it seems in a position to embrace quantum computing if and when it outpaces GPU-based machines.
For me, it’s not hard to picture Huang echoing game-show king Ken Jennings’s bemused words when Watson won their Jeopardy match: “I for one welcome our new computer overlords.” After all, speeding computation is the true quest.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
