Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Khari Johnson Morgan Meaker Business Meet the Humans Trying to Keep Us Safe From AI Play/Pause Button Pause Video: Sam Cannon Save this story Save Save this story Save A year ago, the idea of holding a meaningful conversation with a computer was the stuff of science fiction. But since OpenAIâ€™s ChatGPT launched last November, life has started to feel more like a techno-thriller with a fast-moving plot. Chatbots and other generative AI tools are beginning to profoundly change how people live and work. But whether this plot turns out to be uplifting or dystopian will depend on who helps write it.
Thankfully, just as artificial intelligence is evolving, so is the cast of people who are building and studying it. This is a more diverse crowd of leaders, researchers, entrepreneurs, and activists than those who laid the foundations of ChatGPT. Although the AI community remains overwhelmingly male, in recent years some researchers and companies have pushed to make it more welcoming to women and other underrepresented groups. And the field now includes many people concerned with more than just making algorithms or making money, thanks to a movementâ€”led largely by womenâ€”that considers the ethical and societal implications of the technology. Here are some of the humans shaping this accelerating storyline.
â€”Will Knight â€œI wanted to use generative AI to capture the potential and unease felt as we explore our relationship with this new technology,â€ says artist Sam Cannon, who worked alongside four photographers to enhance portraits with AI-crafted backgrounds. â€œIt felt like a conversationâ€”me feeding images and ideas to the AI, and the AI offering its own in return.â€ Rumman Chowdhury PHOTOGRAPH: CHERIL SANCHEZ; AI Art by Sam Cannon Rumman Chowdhury led Twitterâ€™s ethical AI research until Elon Musk acquired the company and laid off her team. She is the cofounder of Humane Intelligence, a nonprofit that uses crowdsourcing to reveal vulnerabilities in AI systems, designing contests that challenge hackers to induce bad behavior in algorithms. Its first event, scheduled for this summer with support from the White House, will test generative AI systems from companies including Google and OpenAI. Chowdhury says large-scale, public testing is needed because of AI systemsâ€™ wide-ranging repercussions: â€œIf the implications of this will affect society writ large, then arenâ€™t the best experts the people in society writ large?â€ â€”Khari Johnson Sarah Bird Photograph: Annie Marie Musselman; AI art by Sam Cannon Sarah Birdâ€™s job at Microsoft is to keep the generative AI that the company is adding to its office apps and other products from going off the rails. As she has watched text generators like the one behind the Bing chatbot become more capable and useful, she has also seen them get better at spewing biased content and harmful code. Her team works to contain that dark side of the technology. AI could change many lives for the better, Bird says, but â€œnone of that is possible if people are worried about the technology producing stereotyped outputs.â€ â€”K.J.
Yejin Choi Photograph: Annie Marie Musselman; AI art by Sam Cannon Yejin Choi, a professor in the School of Computer Science & Engineering at the University of Washington, is developing an open source model called Delphi, designed to have a sense of right and wrong. Sheâ€™s interested in how humans perceive Delphiâ€™s moral pronouncements. Choi wants systems as capable as those from OpenAI and Google that donâ€™t require huge resources. â€œThe current focus on the scale is very unhealthy for a variety of reasons,â€ she says. â€œItâ€™s a total concentration of power, just too expensive, and unlikely to be the only way.â€ â€”W.K.
Margaret Mitchell Photograph: Annie Marie Musselman; AI art by Sam Cannon Margaret Mitchell founded Googleâ€™s Ethical AI research team in 2017. She was fired four years later after a dispute with executives over a paper she coauthored. It warned that large language modelsâ€”the tech behind ChatGPTâ€”can reinforce stereotypes and cause other ills. Mitchell is now ethics chief at Hugging Face, a startup developing open source AI software for programmers. She works to ensure that the companyâ€™s releases donâ€™t spring any nasty surprises and encourages the field to put people before algorithms. Generative models can be helpful, she says, but they may also be undermining peopleâ€™s sense of truth: â€œWe risk losing touch with the facts of history.â€ â€”K.J.
Inioluwa Deborah Raji Photograph: AYSIA STIEB; AI art by Sam Cannon When Inioluwa Deborah Raji started out in AI, she worked on a project that found bias in facial analysis algorithms: They were least accurate on women with dark skin. The findings led Amazon, IBM, and Microsoft to stop selling face-recognition technology. Now Raji is working with the Mozilla Foundation on open source tools that help people vet AI systems for flaws like bias and inaccuracyâ€”including large language models. Raji says the tools can help communities harmed by AI challenge the claims of powerful tech companies. â€œPeople are actively denying the fact that harms happen,â€ she says, â€œso collecting evidence is integral to any kind of progress in this field.â€ â€”K.J.
Daniela Amodei Photograph: AYSIA STIEB; AI art by Sam Cannon Daniela Amodei previously worked on AI policy at OpenAI, helping to lay the groundwork for ChatGPT. But in 2021, she and several others left the company to start Anthropic, a public-benefit corporation charting its own approach to AI safety. The startupâ€™s chatbot, Claude, has a â€œconstitutionâ€ guiding its behavior, based on principles drawn from sources including the UNâ€™s Universal Declaration of Human Rights. Amodei, Anthropicâ€™s president and cofounder, says ideas like that will reduce misbehavior today and perhaps help constrain more powerful AI systems of the future: â€œThinking long-term about the potential impacts of this technology could be very important.â€ â€”W.K.
Lila Ibrahim Photograph: Ayesha Kazim; AI art by Sam Cannon Lila Ibrahim is chief operating officer at Google DeepMind, a research unit central to Googleâ€™s generative AI projects. She considers running one of the worldâ€™s most powerful AI labs less a job than a moral calling. Ibrahim joined DeepMind five years ago, after almost two decades at Intel, in hopes of helping AI evolve in a way that benefits society. One of her roles is to chair an internal review council that discusses how to widen the benefits of DeepMindâ€™s projects and steer away from bad outcomes. â€œI thought if I could bring some of my experience and expertise to help birth this technology into the world in a more responsible way, then it was worth being here,â€ she says.
â€”Morgan Meaker This article appears in the Jul/Aug 2023 issue.
Subscribe now.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Topics longreads artificial intelligence ethics magazine-31.07/31.08 ChatGPT machine learning DeepMind algorithms Will Knight Amit Katwala Khari Johnson Kari McMahon David Gilbert David Gilbert Andy Greenberg Joel Khalili Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
