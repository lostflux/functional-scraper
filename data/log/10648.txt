Toggle Navigation News Events TNW Conference 2024 June 20 & 21, 2024 TNW Vision: 2024 All events Spaces Programs Newsletters Partner with us Jobs Contact News news news news Latest Deep tech Sustainability Ecosystems Data and security Fintech and ecommerce Future of work More Startups and technology Investors and funding Government and policy Corporates and innovation Gadgets & apps Early bird Business passes are 90% SOLD OUT üéüÔ∏è Buy now before they are gone ‚Üí This article was published on January 30, 2023 Deep tech What Greek myths can teach us about the dangers of AI Ancient literature can provide us with valuable insights into our modern discourse on artificial intelligence We might think that the conception of robots, AI , and automated machines is a modern phenomenon, but, in fact, the idea had already appeared in Western literature nearly 3,000 years ago. Long before Isaac Asimov conceived the Laws of Robotics (1942) and John McCarthy coined the term ‚ÄúArtificial Intelligence‚Äù (1995), Ancient Greeks myths were full of stories about intelligent humanoids.
The fact that these mythical humanoids meet the criteria of modern definitions on robotics and AI is impressive in itself. But what‚Äôs even more astonishing is that these old tales can provide us with valuable teachings and insights into our modern discourse on artificial intelligence.
Such stories ‚Äúperpetuated over millennia, are a testament to the persistence of thinking and talking about what it is to be human and what it means to simulate life,‚Äù historian Adrienne Mayor, writes in her book Gods and Robots: Myths, Machines, and Ancient Dreams of Technology.
In other words, the desire to reach beyond humans and create non-biological life by endowing intelligence into machines seems an innate part of our nature. And this is why we can find wisdom to inform contemporary discourse in age-old myths.
Get your ticket NOW for TNW Conference - Super Earlybird is 90% sold out! Unleash innovation, connect with thousands of tech lovers and shape the future on June 20-21, 2024.
Through the dread, hope, and moral dilemmas they express, these stories can provide us with an alternative way to process some of the most pressing questions regarding intelligent machines: how far should we go with AI? And what are the looming moral and practical implications of this technology? To revisit these questions, we‚Äôll look into three intelligent humanoids in Greek myth: the Golden Maidens, Talos, and Pandora.
The Golden Maidens: the inherent need for labor-saving technology The Golden Maidens were built by Hephaestus, the god of fire. They‚Äôre described as female assistants made of gold who look like living young women, and can anticipate and respond to their maker‚Äôs needs.
But most importantly, ‚Äúthey‚Äôre endowed with the hallmarks of human beings: consciousness, intelligence, learning, reason, and speech,‚Äù Mayor remarks in her book.
Hephaestus presenting Thetis with armor for her son Achilles. The divine smith holds a hammer in one hand and a helm in the other. The painting illustrates a scene from Homer‚Äôs Iliad.
 Credit: ArchaiOptix via Wikimedia There‚Äôs an immediate parallel we can draw between ancient myth and modern society: one of the main reasons for the creation of intelligent, automated machines is economic, or rather, labor-saving.
The idea that robots and self-acting devices could act as servants (or slaves) was a point also stressed by the famous Greek philosopher, Aristotle. In the first book of his Politics , he contemplates: If every tool could perform its own work obeying or anticipating the needs of others, [‚Ä¶] and if [‚Ä¶] shuttles could weave and picks could play the lyre by themselves, then craftsmen wouldn‚Äôt need servants and masters wouldn‚Äôt need slaves.
The idea, though well ahead of its time, is actually very simple: a society in which people don‚Äôt have to do the drudge work, and instead, delegate it to machines. And as much as Greek society depended on the institution of slavery to function , we are now creating a new class of mechanical servants.
Think of the vacuum bot cleaners that may stroll across your floors, the surgical robots that perform complex surgical procedures, or the military bots designed to disarm bombs.
This does raise an interesting question though. While we have personal robots that can help us with small tasks, the real wealth of automation will come when entire industries are destroyed and replaced by free workers. Think of self-driving cars removing truckers from work for instance. But unless the money generated from such moves go to the dispossessed, the privileged and wealthy (i.e. those similar to Hephaestus) will benefit most.
This idea is explored further in the continuing myths.
Talos: intelligent machines in the hands of tyrants Unlike the Golden Maiden, Talos was created to cause harm (as was Pandora, but more on that later).
Talos was a bronze giant robot, again made by Hephaestus. He was gifted by Zeus to his son Minos, the mythical king of Crete, to guard and protect the island.
The guardian robot would throw huge rocks at foreign ships approaching the island, and enemies managed to get on land, he would hug them and burn them alive thanks to his ability to heat up his bronze body.
Talos doesn‚Äôt seem to possess a human level of intelligence, but he‚Äôs able to interact with his environment and perform various tasks.
In fact, some mythological variations of his demise hint significantly at the possibility that he‚Äôs conscious of his existence and that he has a kind of agency.
As Mayor notes, ‚ÄùIn these versions, Talos is portrayed as susceptible to human fears and hopes, with a kind of volition and intelligence.‚Äù If one looks at the relevant mythological corpus, they will notice that all such machines used to cause harm belonged to tyrannical rulers; in our example, King Minos of Crete, and Zeus, the father of gods and men, in the case of Pandora.
And there‚Äôs a notable moral in these stories: superior technology can help exercise control.
Think of military robots, for instance, which have been in use since World War II. To give a more recent example, the war in Ukraine has become the largest testbed for AI-powered autonomous and uncrewed combat vehicles , highlighting the excitement of military leaders about the potential usefulness of artificial intelligence technology.
And it‚Äôs not just war that AI can serve those in power.
It can also be used by authoritarian regimes to track citizens, influence the flow of information, and marginalize dissident voices, as the example of China shows.
At the same time, AI‚Äôs breadth of applications (in healthcare, finance, e-commerce and so on) is shaping a new battleground of geopolitical power ‚Äî as big technological breakthroughs have historically done.
Domination of AI by powerful nations is expected to deepen structural inequalities and contribute to new forms of social and economic imbalance. Similarly, as AI is mostly centralized (meaning that it‚Äôs limited to the ownership of a single entity), it will further empower the leading Big Tech companies creating it, enabling them to pursue their own agendas.
But have these consequences been debated enough by the nations‚Äô regulatory bodies or the companies that are currently developing AI? ‚ÄúI think the Silicon Valley and Big Tech companies and billionaires control the narrative over AI so much that it creates little space for that kind of debate that‚Äôs necessary for a technology that grows so massively,‚Äù George Zarkadakis , AI engineer, futurist, and writer, told TNW.
Unless controlled, legally regulated, and removed from the individual, AI tools won‚Äôt benefit society in the way we envision. And the danger of them falling into the hands of nefarious actors who could use them to assert dominance is highlighted by the following myth where Zeus‚Äô fear of losing his ruling power led to the creation of a perilous weapon: Pandora.
Pandora: surpassing the limits Pandora was created as an instrument of punishment. After the Titan Prometheus (his name means ‚Äúforesight‚Äù) stole fire from the gods and gave it to mankind to help it create technology, Zeus commanded Hephaestus to fabricate Pandora.
The mythical humanoid was designed to be an evil disguised as a gift, something that would make humankind pay for reaching closer to the divine level, as up until then, fire and technology were unique privileges of the gods.
Hephaestus fabricated Pandora, molding earth and water into the shape of a beautiful woman. She was also endowed with treachery, deceit, and seduction. At the end, Zeus gave her a mysterious jar.
After her completion, Pandora was sent to Prometheus‚Äô brother, Epimetheus (his name meaning ‚Äúhindsight‚Äù), who forgot the warning never to accept a gift from Zeus. Once on Earth, Pandora opened the jar unleashing all kinds of evil that would plague humankind forever. Following Zeus‚Äô instructions, she sealed the jar right before hope could escape, trapping it inside.
‚ÄúIt‚Äôs unclear whether Pandora has the ability to learn, choose, or act autonomously,‚Äù Mayor notes. ‚ÄúHer only mission is to open the jar of all human misfortune.‚Äù In modern terms, ‚Äúshe does what she‚Äôs programmed to do.‚Äù There is a pressing question we can explore using this mythological context: are we suffering from a god complex? And, with AI, dealing with elements we simply don‚Äôt understand? An integral element of Greek mythology, which is fully expressed in Pandora‚Äôs myth, is the notion of hubris. This refers to an act that violates the natural order by disregarding the divinely fixed limits on human action in the cosmos. Such an act is always followed by god-sent punishment to restore balance, as in the case of Pandora‚Äôs jar.
According to Zarkadakis, there‚Äôs a lot of hubris in AI as well.
‚ÄúI think the purpose of God is to remind people that they‚Äôre not gods themselves. And you know, in the absence of gods, we have this problem, right? We think we are gods because we don‚Äôt need God anymore. So we‚Äôre building our own gods that will be our gods in the future,‚Äù he explained. And machines that would be almost impossible to discern from a human being could also be infinitely smarter , ‚Äúthey would be like a god,‚Äù he added.
Zarkadakis believes that the ancient myths were trying to prevent us from going down that slippery path; but we‚Äôre heading there anyway.
This recalls Steven Hawking‚Äôs warning over the potential danger of AI. ‚ÄúThe development of full artificial intelligence could spell the end of the human race,‚Äù he said during an interview with BBC. ‚ÄúIt would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldn‚Äôt compete, and would be superseded.‚Äù So should we open Pandora‚Äôs jar? Our choice doesn‚Äôt differ too much from the one Epimetheus had to make. Much like the ancient humanoid, AI comes with a black box , the Deep Neural Networks (DNN) systems machine learning is based on. This means that while scientists have access to the inputs and outputs AI uses, they don‚Äôt know how its decision-making process works.
We don‚Äôt know what‚Äôs inside the black box, the same way Epimetheus didn‚Äôt know what was inside the jar. The moral of the myth is clear: think before you act, or act before you think ‚Äî and suffer the consequences. And to relate this to our modern debate, unless we seriously consider the possible negative outcomes, it‚Äôs dangerous to rush into creating something we don‚Äôt fully understand just because we can.
To avoid opening the jar recklessly, Zarkadakis suggests posing a vital question supported by ethical and philosophical considerations: ‚ÄúWhat‚Äôs the end game?‚Äù And based on that, ‚Äúwhat might be the cost and consequences of the technology?‚Äù ‚ÄúA machine that has full autonomy and is conscious means it‚Äôs completely free, it can think in any way, and, thus, that it can be potentially dangerous,‚Äù he explained. ‚ÄúThe number one risk is extinction, and it‚Äôs bad enough in theory to try to build such AI and see what happens.‚Äù Zarkadakis remarked that the reason why we‚Äôre fully autonomous is because as biological social beings we are equipped with ethics and morality.
But teaching ethics and morality to AI systems has been so far unsuccessful. Think of the racism scandals of Microsoft‚Äôs Tay and ScatterLab‚Äôs Lee Luda.
 Or, most recently, Meta‚Äôs Galactica.
Zarkadakis believes that we don‚Äôt actually need conscious AI. ‚ÄúI think what we need as human society is to live a better life and having more free time is a big goal to that,‚Äù he added.
‚ÄúThere‚Äôs a massive usefulness for artificial intelligence to help us reach that point. What we need for AI is social integration and we should absolutely rethink the autonomy of machines and revise their manifesto.‚Äù With this approach, AI could, in fact, be the inverse of Pandora ‚Äî a democratic tool that could help make ourselves and the world better. And shouldn‚Äôt this be technology‚Äôs mission? From myth to reality Thousands of years ago, these three myths illuminated the potential of intelligent machines to serve a good purpose (as in the case of the Golden Maidens) or cause harm (as in the case of Talos and Pandora) ‚Äî a potential we‚Äôre already seeing materializing today.
Most notably, though, they bring forth a set of questions that are vital for our pursuit of AI: whose aspirations will it serve, from whom will it learn, what do we want it to be, and how far should we go with it before surpassing the limits? Ultimately, AI is much like Pandora‚Äôs mysterious jar. We don‚Äôt know what‚Äôs inside and we can assume it contains both good and evil. In the end, it‚Äôs all about the role we‚Äôll play: will we be like Prometheus and demonstrate the required foresight, or will we be like Epimetheus and act before examining the consequences? Ancient Greek myth has told us the dangers of AI, it‚Äôs now up to us to listen.
Story by Ioanna Lykiardopoulou Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainabili (show all) Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainability, green tech, AI, and EU policy. With a background in the humanities, she has a soft spot for social impact-enabling technologies.
Get the TNW newsletter Get the most important tech news in your inbox each week.
Also tagged with Artificial intelligence AI Story by Ioanna Lykiardopoulou Popular articles 1 New erotic roleplaying chatbots promise to indulge your sexual fantasies 2 UK plan to lead in generative AI ‚Äòunrealistic,‚Äô say Cambridge researchers 3 New AI tool could make future vaccines ‚Äòvariant-proof,‚Äô researchers say 4 3D-printed stem cells could help treat brain injuries 5 New technique makes AI hallucinations wake up and face reality Related Articles deep tech UK won‚Äôt regulate AI anytime soon, minister says deep tech AI is transforming the English dictionary Join TNW All Access Watch videos of our inspiring talks for free ‚Üí deep tech A prisoner‚Äôs dilemma shows AI‚Äôs path to human cooperation data security Deepfake fraud attempts are up 3000% in 2023 ‚Äî here‚Äôs why The heart of tech More TNW Media Events Programs Spaces Newsletters Jobs in tech About TNW Partner with us Jobs Terms & Conditions Cookie Statement Privacy Statement Editorial Policy Masthead Copyright ¬© 2006‚Äî2023, The Next Web B.V. Made with <3 in Amsterdam.
