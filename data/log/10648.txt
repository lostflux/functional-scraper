Toggle Navigation News Events TNW Conference 2024 June 20 & 21, 2024 TNW Vision: 2024 All events Spaces Programs Newsletters Partner with us Jobs Contact News news news news Latest Deep tech Sustainability Ecosystems Data and security Fintech and ecommerce Future of work More Startups and technology Investors and funding Government and policy Corporates and innovation Gadgets & apps Early bird Business passes are 90% SOLD OUT ğŸŸï¸ Buy now before they are gone â†’ This article was published on January 30, 2023 Deep tech What Greek myths can teach us about the dangers of AI Ancient literature can provide us with valuable insights into our modern discourse on artificial intelligence We might think that the conception of robots, AI , and automated machines is a modern phenomenon, but, in fact, the idea had already appeared in Western literature nearly 3,000 years ago. Long before Isaac Asimov conceived the Laws of Robotics (1942) and John McCarthy coined the term â€œArtificial Intelligenceâ€ (1995), Ancient Greeks myths were full of stories about intelligent humanoids.
The fact that these mythical humanoids meet the criteria of modern definitions on robotics and AI is impressive in itself. But whatâ€™s even more astonishing is that these old tales can provide us with valuable teachings and insights into our modern discourse on artificial intelligence.
Such stories â€œperpetuated over millennia, are a testament to the persistence of thinking and talking about what it is to be human and what it means to simulate life,â€ historian Adrienne Mayor, writes in her book Gods and Robots: Myths, Machines, and Ancient Dreams of Technology.
In other words, the desire to reach beyond humans and create non-biological life by endowing intelligence into machines seems an innate part of our nature. And this is why we can find wisdom to inform contemporary discourse in age-old myths.
Get your ticket NOW for TNW Conference - Super Earlybird is 90% sold out! Unleash innovation, connect with thousands of tech lovers and shape the future on June 20-21, 2024.
Through the dread, hope, and moral dilemmas they express, these stories can provide us with an alternative way to process some of the most pressing questions regarding intelligent machines: how far should we go with AI? And what are the looming moral and practical implications of this technology? To revisit these questions, weâ€™ll look into three intelligent humanoids in Greek myth: the Golden Maidens, Talos, and Pandora.
The Golden Maidens: the inherent need for labor-saving technology The Golden Maidens were built by Hephaestus, the god of fire. Theyâ€™re described as female assistants made of gold who look like living young women, and can anticipate and respond to their makerâ€™s needs.
But most importantly, â€œtheyâ€™re endowed with the hallmarks of human beings: consciousness, intelligence, learning, reason, and speech,â€ Mayor remarks in her book.
Hephaestus presenting Thetis with armor for her son Achilles. The divine smith holds a hammer in one hand and a helm in the other. The painting illustrates a scene from Homerâ€™s Iliad.
 Credit: ArchaiOptix via Wikimedia Thereâ€™s an immediate parallel we can draw between ancient myth and modern society: one of the main reasons for the creation of intelligent, automated machines is economic, or rather, labor-saving.
The idea that robots and self-acting devices could act as servants (or slaves) was a point also stressed by the famous Greek philosopher, Aristotle. In the first book of his Politics , he contemplates: If every tool could perform its own work obeying or anticipating the needs of others, [â€¦] and if [â€¦] shuttles could weave and picks could play the lyre by themselves, then craftsmen wouldnâ€™t need servants and masters wouldnâ€™t need slaves.
The idea, though well ahead of its time, is actually very simple: a society in which people donâ€™t have to do the drudge work, and instead, delegate it to machines. And as much as Greek society depended on the institution of slavery to function , we are now creating a new class of mechanical servants.
Think of the vacuum bot cleaners that may stroll across your floors, the surgical robots that perform complex surgical procedures, or the military bots designed to disarm bombs.
This does raise an interesting question though. While we have personal robots that can help us with small tasks, the real wealth of automation will come when entire industries are destroyed and replaced by free workers. Think of self-driving cars removing truckers from work for instance. But unless the money generated from such moves go to the dispossessed, the privileged and wealthy (i.e. those similar to Hephaestus) will benefit most.
This idea is explored further in the continuing myths.
Talos: intelligent machines in the hands of tyrants Unlike the Golden Maiden, Talos was created to cause harm (as was Pandora, but more on that later).
Talos was a bronze giant robot, again made by Hephaestus. He was gifted by Zeus to his son Minos, the mythical king of Crete, to guard and protect the island.
The guardian robot would throw huge rocks at foreign ships approaching the island, and enemies managed to get on land, he would hug them and burn them alive thanks to his ability to heat up his bronze body.
Talos doesnâ€™t seem to possess a human level of intelligence, but heâ€™s able to interact with his environment and perform various tasks.
In fact, some mythological variations of his demise hint significantly at the possibility that heâ€™s conscious of his existence and that he has a kind of agency.
As Mayor notes, â€In these versions, Talos is portrayed as susceptible to human fears and hopes, with a kind of volition and intelligence.â€ If one looks at the relevant mythological corpus, they will notice that all such machines used to cause harm belonged to tyrannical rulers; in our example, King Minos of Crete, and Zeus, the father of gods and men, in the case of Pandora.
And thereâ€™s a notable moral in these stories: superior technology can help exercise control.
Think of military robots, for instance, which have been in use since World War II. To give a more recent example, the war in Ukraine has become the largest testbed for AI-powered autonomous and uncrewed combat vehicles , highlighting the excitement of military leaders about the potential usefulness of artificial intelligence technology.
And itâ€™s not just war that AI can serve those in power.
It can also be used by authoritarian regimes to track citizens, influence the flow of information, and marginalize dissident voices, as the example of China shows.
At the same time, AIâ€™s breadth of applications (in healthcare, finance, e-commerce and so on) is shaping a new battleground of geopolitical power â€” as big technological breakthroughs have historically done.
Domination of AI by powerful nations is expected to deepen structural inequalities and contribute to new forms of social and economic imbalance. Similarly, as AI is mostly centralized (meaning that itâ€™s limited to the ownership of a single entity), it will further empower the leading Big Tech companies creating it, enabling them to pursue their own agendas.
But have these consequences been debated enough by the nationsâ€™ regulatory bodies or the companies that are currently developing AI? â€œI think the Silicon Valley and Big Tech companies and billionaires control the narrative over AI so much that it creates little space for that kind of debate thatâ€™s necessary for a technology that grows so massively,â€ George Zarkadakis , AI engineer, futurist, and writer, told TNW.
Unless controlled, legally regulated, and removed from the individual, AI tools wonâ€™t benefit society in the way we envision. And the danger of them falling into the hands of nefarious actors who could use them to assert dominance is highlighted by the following myth where Zeusâ€™ fear of losing his ruling power led to the creation of a perilous weapon: Pandora.
Pandora: surpassing the limits Pandora was created as an instrument of punishment. After the Titan Prometheus (his name means â€œforesightâ€) stole fire from the gods and gave it to mankind to help it create technology, Zeus commanded Hephaestus to fabricate Pandora.
The mythical humanoid was designed to be an evil disguised as a gift, something that would make humankind pay for reaching closer to the divine level, as up until then, fire and technology were unique privileges of the gods.
Hephaestus fabricated Pandora, molding earth and water into the shape of a beautiful woman. She was also endowed with treachery, deceit, and seduction. At the end, Zeus gave her a mysterious jar.
After her completion, Pandora was sent to Prometheusâ€™ brother, Epimetheus (his name meaning â€œhindsightâ€), who forgot the warning never to accept a gift from Zeus. Once on Earth, Pandora opened the jar unleashing all kinds of evil that would plague humankind forever. Following Zeusâ€™ instructions, she sealed the jar right before hope could escape, trapping it inside.
â€œItâ€™s unclear whether Pandora has the ability to learn, choose, or act autonomously,â€ Mayor notes. â€œHer only mission is to open the jar of all human misfortune.â€ In modern terms, â€œshe does what sheâ€™s programmed to do.â€ There is a pressing question we can explore using this mythological context: are we suffering from a god complex? And, with AI, dealing with elements we simply donâ€™t understand? An integral element of Greek mythology, which is fully expressed in Pandoraâ€™s myth, is the notion of hubris. This refers to an act that violates the natural order by disregarding the divinely fixed limits on human action in the cosmos. Such an act is always followed by god-sent punishment to restore balance, as in the case of Pandoraâ€™s jar.
According to Zarkadakis, thereâ€™s a lot of hubris in AI as well.
â€œI think the purpose of God is to remind people that theyâ€™re not gods themselves. And you know, in the absence of gods, we have this problem, right? We think we are gods because we donâ€™t need God anymore. So weâ€™re building our own gods that will be our gods in the future,â€ he explained. And machines that would be almost impossible to discern from a human being could also be infinitely smarter , â€œthey would be like a god,â€ he added.
Zarkadakis believes that the ancient myths were trying to prevent us from going down that slippery path; but weâ€™re heading there anyway.
This recalls Steven Hawkingâ€™s warning over the potential danger of AI. â€œThe development of full artificial intelligence could spell the end of the human race,â€ he said during an interview with BBC. â€œIt would take off on its own, and re-design itself at an ever increasing rate. Humans, who are limited by slow biological evolution, couldnâ€™t compete, and would be superseded.â€ So should we open Pandoraâ€™s jar? Our choice doesnâ€™t differ too much from the one Epimetheus had to make. Much like the ancient humanoid, AI comes with a black box , the Deep Neural Networks (DNN) systems machine learning is based on. This means that while scientists have access to the inputs and outputs AI uses, they donâ€™t know how its decision-making process works.
We donâ€™t know whatâ€™s inside the black box, the same way Epimetheus didnâ€™t know what was inside the jar. The moral of the myth is clear: think before you act, or act before you think â€” and suffer the consequences. And to relate this to our modern debate, unless we seriously consider the possible negative outcomes, itâ€™s dangerous to rush into creating something we donâ€™t fully understand just because we can.
To avoid opening the jar recklessly, Zarkadakis suggests posing a vital question supported by ethical and philosophical considerations: â€œWhatâ€™s the end game?â€ And based on that, â€œwhat might be the cost and consequences of the technology?â€ â€œA machine that has full autonomy and is conscious means itâ€™s completely free, it can think in any way, and, thus, that it can be potentially dangerous,â€ he explained. â€œThe number one risk is extinction, and itâ€™s bad enough in theory to try to build such AI and see what happens.â€ Zarkadakis remarked that the reason why weâ€™re fully autonomous is because as biological social beings we are equipped with ethics and morality.
But teaching ethics and morality to AI systems has been so far unsuccessful. Think of the racism scandals of Microsoftâ€™s Tay and ScatterLabâ€™s Lee Luda.
 Or, most recently, Metaâ€™s Galactica.
Zarkadakis believes that we donâ€™t actually need conscious AI. â€œI think what we need as human society is to live a better life and having more free time is a big goal to that,â€ he added.
â€œThereâ€™s a massive usefulness for artificial intelligence to help us reach that point. What we need for AI is social integration and we should absolutely rethink the autonomy of machines and revise their manifesto.â€ With this approach, AI could, in fact, be the inverse of Pandora â€” a democratic tool that could help make ourselves and the world better. And shouldnâ€™t this be technologyâ€™s mission? From myth to reality Thousands of years ago, these three myths illuminated the potential of intelligent machines to serve a good purpose (as in the case of the Golden Maidens) or cause harm (as in the case of Talos and Pandora) â€” a potential weâ€™re already seeing materializing today.
Most notably, though, they bring forth a set of questions that are vital for our pursuit of AI: whose aspirations will it serve, from whom will it learn, what do we want it to be, and how far should we go with it before surpassing the limits? Ultimately, AI is much like Pandoraâ€™s mysterious jar. We donâ€™t know whatâ€™s inside and we can assume it contains both good and evil. In the end, itâ€™s all about the role weâ€™ll play: will we be like Prometheus and demonstrate the required foresight, or will we be like Epimetheus and act before examining the consequences? Ancient Greek myth has told us the dangers of AI, itâ€™s now up to us to listen.
Story by Ioanna Lykiardopoulou Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainabili (show all) Ioanna is a writer at TNW. She covers the full spectrum of the European tech ecosystem, with a particular interest in startups, sustainability, green tech, AI, and EU policy. With a background in the humanities, she has a soft spot for social impact-enabling technologies.
Get the TNW newsletter Get the most important tech news in your inbox each week.
Also tagged with Artificial intelligence AI Story by Ioanna Lykiardopoulou Popular articles 1 New erotic roleplaying chatbots promise to indulge your sexual fantasies 2 UK plan to lead in generative AI â€˜unrealistic,â€™ say Cambridge researchers 3 New AI tool could make future vaccines â€˜variant-proof,â€™ researchers say 4 3D-printed stem cells could help treat brain injuries 5 New technique makes AI hallucinations wake up and face reality Related Articles deep tech UK wonâ€™t regulate AI anytime soon, minister says deep tech AI is transforming the English dictionary Join TNW All Access Watch videos of our inspiring talks for free â†’ deep tech A prisonerâ€™s dilemma shows AIâ€™s path to human cooperation data security Deepfake fraud attempts are up 3000% in 2023 â€” hereâ€™s why The heart of tech More TNW Media Events Programs Spaces Newsletters Jobs in tech About TNW Partner with us Jobs Terms & Conditions Cookie Statement Privacy Statement Editorial Policy Masthead Copyright Â© 2006â€”2023, The Next Web B.V. Made with <3 in Amsterdam.
