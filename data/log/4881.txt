Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Amazon drops Alexa skills recommendation error rate 12% Share on Facebook Share on X Share on LinkedIn Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
Amazon’s Alexa assistant has lots of skills — more than 50,000, at last count. That makes it tough to discover new ones if you’re not sure where to start, but fortunately, scientists at the Seattle company are tackling the problem with artificial intelligence (AI).
In a blog post this morning, Young-Bum Kim, a data scientist at Amazon’s Alexa AI division, detailed the machine learning system that automatically selects the best skill to handle a particular request. Recent modifications made to it — the results of which will be presented at the 2018 Conference on Empirical Methods in Natural Language Processing this week in Brussels — noticeably decreased errors.
As Kim explained, the model comprises two neural networks, or layers of mathematical functions that mimic the behavior of neurons in the brain.
The first — dubbed the “shortlister” — produces a list of candidate skills that might be appropriate for a given request, taking into account skills already linked to the requester’s Alexa account. (Kim notes that linking is a strong corollary for preference.) Meanwhile, an “attention mechanism” dynamically assigns a weight to each of the linked skills, modifying the probability any one of them will make it onto the shortlist.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! The second uses more detailed information — including whether the skills’ developers indicated which actions their skills are able to perform in metadata — to choose among those skills.
Previously, Alexa researchers trained the shortlister network end-to-end; every component of the network was evaluated based on how it contributed to the accuracy of the output. But the newly improved AI model also considers intended skills — i.e., linked skills invoked when a user requests something — in determining probability. As a result, the network now more reliably selects linked skills when a user intends them, Kim wrote.
To test the improved AI system’s robustness, the Alexa AI team tested three different versions that used two distinct functions to generate the weights applied to linked skills — softmax, which generates weights with values between 0 and 1 that must sum to 1, and sigmoid, which also produces weights ranging from 0 to 1 but that has no restrictions on their sum. (The previous version of the shortlist neural network used softmax exclusively.) The best-performing model of the three reduced the error rate by 12 percent when tasked with producing shortlists of three candidate skills, Kim wrote.
Amazon’s use of AI extends beyond skills selection. Its context carryover model allows Alexa to understand “multi-turn utterances” — in essence, follow-up requests with explicit pronoun references (for example, “Alexa, what was Adele’s first album?” “Alexa, play it.”) A separate AI system allows Amazon’s Echo speakers to recognize up to ten distinct user voices. Moreover, back in November, Amazon’s Alexa team said it’s beginning to analyze the sound of users’ voices to recognize mood or emotional state.
That’s just the tip of the iceberg. In August, the Alexa Machine Learning team at Amazon made headway in bringing key voice recognition models offline.
 And at a September hardware event where it launched 11 new and refreshed Alexa-powered products, the Seattle company showed off Hunches , which proactively recommends actions based on data from connected devices and sensors, and whisper mode, which responds to whispered speech with a quieter tone. ( Whisper mode launched this month in the U.S.) VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
