Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Sofia Barnett Culture ChatGPT Is Making Universities Rethink Plagiarism Photograph: Getty Images Save this story Save Save this story Save In late December of his sophomore year, Rutgers University student Kai Cobbs came to a conclusion he never thought possible: Artificial intelligence might just be dumber than humans.
After listening to his peers rave about the generative AI tool ChatGPT , Cobbs decided to toy around with the chatbot while writing an essay on the history of capitalism. Best known for its ability to generate long-form written content in response to user input prompts, Cobbs expected the tool to produce a nuanced and thoughtful response to his specific research directions. Instead, his screen produced a generic, poorly written paper heâ€™d never dare to claim as his own.
â€œThe quality of writing was appalling. The phrasing was awkward and it lacked complexity,â€ Cobbs says. â€œI just logically canâ€™t imagine a student using writing that was generated through ChatGPT for a paper or anything when the content is just plain bad.â€ Cheat Code Pia Ceres Ideas Nick Vincent and Hanlin Li Ideas Nabeel Gillani Not everyone shares Cobbsâ€™ disdain. Ever since OpenAI launched the chatbot in November, educators have been struggling with how to handle a new wave of student work produced with the help of artificial intelligence. While some public school systems, like New York Cityâ€™s, have banned the use of ChatGPT on school devices and networks to curb cheating, universities have been reluctant to follow suit. In higher education, the introduction of generative AI has raised thorny questions about the definition of plagiarism and academic integrity on campuses where new digital research tools come into play all the time.
Make no mistake, the birth of ChatGPT does not mark the emergence of concerns relating to the improper use of the internet in academia. When Wikipedia launched in 2001 , universities nationwide were scrambling to decipher their own research philosophies and understandings of honest academic work, expanding policy boundaries to match pace with technological innovation. Now, the stakes are a little more complex, as schools figure out how to treat bot-produced work rather than weird attributional logistics. The world of higher education is playing a familiar game of catch-up, adjusting their rules, expectations, and perceptions as other professions adjust, too. The only difference now is that the internet can think for itself.
According to ChatGPT, the definition of plagiarism is the act of using someone elseâ€™s work or ideas without giving proper credit to the original author. But when the work is generated by some thing rather than some one , this definition is tricky to apply. As Emily Hipchen, a board member of Brown Universityâ€™s Academic Code Committee, puts it, the use of generative AI by students leads to a critical point of contention. â€œIf [plagiarism] is stealing from a person,â€ she says, â€œthen I donâ€™t know that we have a person who is being stolen from.â€ Hipchen is not alone in her speculation. Alice Dailey, chair of the Academic Integrity Program at Villanova University, is also grappling with the idea of classifying an algorithm as a person, specifically if the algorithm involves text generation.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy Dailey believes that eventually professors and students are going to need to understand that digital tools that generate text, rather than just collect facts, are going to need to fall under the umbrella of things that can be plagiarized from.
Although Dailey acknowledges that this technological growth incites new concerns in the world of academia, she doesnâ€™t find it to be a realm entirely unexplored. â€œI think weâ€™ve been in a version of this territory for a while already,â€ Dailey says. â€œStudents who commit plagiarism often borrow material from a â€˜somewhereâ€™â€”a website, for example, that doesnâ€™t have clear authorial attribution. I suspect the definition of plagiarism will expand to include things that produce.â€ Eventually, Dailey believes, a student who uses text from ChatGPT will be seen as no different than one that copies and pastes chunks of text from Wikipedia without attribution.
Studentsâ€™ views on ChatGPT are another issue entirely. There are those, like Cobbs, who canâ€™t imagine putting their name on anything bot-generated, but there are others who see it as just another tool, like spellcheck or even a calculator. For Brown University sophomore Jacob Gelman, ChatGPT exists merely as a convenient research assistant and nothing more.
â€œCalling the use of ChatGPT to pull reliable sources from the internet â€˜cheatingâ€™ is absurd. Itâ€™s like saying using the internet to conduct research is unethical,â€ Gelman says. â€œTo me, ChatGPT is the research equivalent of [typing assistant] Grammarly. I use it out of practicality and thatâ€™s really all.â€ Cobbs expressed similar sentiment, comparing the AI bot to â€œan online encyclopedia.â€ But while students like Gelman use the bot to speed up research, others take advantage of the high-capacity prompt input feature to generate completed works for submission. It might seem obvious what qualifies as cheating here, but different schools across the country offer contrasting takes.
According to Carlee Warfield, chair of Bryn Mawr Collegeâ€™s Student Honor Board, the school considers any use of these AI platforms as plagiarism. The toolâ€™s popularization just calls for greater focus in evaluating the intent behind studentsâ€™ violations. Warfield explains that students who turn in essays entirely produced by AI are categorically different from those who borrow from online tools without knowledge of standard citations. Because the ChatGPT phenomenon is still new, studentsâ€™ confusion surrounding the ethics is understandable. And it's unclear what policies will remain in place once the dust settlesâ€”at any school.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy In the midst of fundamental change in both the academic and technological spheres, universities are forced to reconsider their definitions of academic integrity to reasonably reflect the circumstances of society. The only problem is, society shows no stagnance.
â€œVillanovaâ€™s current academic integrity code will be updated to include language that prohibits the use of these tools to generate text that then students represent as text they generated independently,â€ Dailey explained. â€œBut I think itâ€™s an evolving thing. And what it can do and what we will then need in order to keep an eye on will also be kind of a moving target.â€ In addition to increasingly complex questions about whether ChatGPT is a research tool or a plagiarism engine, thereâ€™s also the possibility that it can be used for learning. In other educational settings, teachers see it as a way to show students the shortcomings of AI. Some instructors are already modifying how they teach by giving students assignments bots couldnâ€™t complete, like those that require personal details or anecdotes. Thereâ€™s also the matter of detecting AI use in studentsâ€™ work, which is a burgeoning cottage industry all its own.
Ultimately, Dailey says, schools may need rules that reflect a range of variables.
â€œMy guess is that there will be the development of some broad blanket policies that essentially say, unless you have permission from a professor to use AI tools, using them will be considered a violation of the academic integrity code,â€ Dailey says. â€œThat then gives faculty broad latitude to use it in their teaching or in their assignments, as long as they are stipulating explicitly that they are allowing it.â€ As for ChatGTP, the program agrees. â€œAdvances in fields such as artificial intelligence are expected to drive significant innovation in the coming years,â€ it says, when asked how schools can combat academic dishonesty. â€œSchools should constantly review and update their academic honor codes as technology evolves to ensure they are addressing the current ways in which technology is being used in academic settings.â€ But, a bot would say that.
You Might Also Like â€¦ ğŸ“© Get the long view on tech with Steven Levy's Plaintext newsletter Watch this guy work, and youâ€™ll finally understand the TikTok era How Telegram became a terrifying weapon in the Israel-Hamas War Inside Elon Muskâ€™s first election crisis â€”a day after he â€œfreedâ€ the bird The ultra-efficient farm of the future is in the sky The best pickleball paddles for beginners and pros ğŸŒ² Our Gear team has branched out with a new guide to the best sleeping pads and fresh picks for the best coolers and binoculars Topics artificial intelligence education ChatGPT Gregory Barber Matt Kamen Jennifer M. Wood Reece Rogers Brendan I. Koerner Matt Kamen Angela Watercutter Megan Farokhmanesh Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
