Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Steven Levy Business Joe Biden Has a Secret Weapon Against Killer AI. It's Bureaucrats US President Joe Biden signing an executive order on Monday, October 30, 2023.
Photograph: Al Drago/Bloomberg/Getty Images Save this story Save Save this story Save As ChatGPT‚Äôs first birthday approaches, presents are rolling in for the large language model that rocked the world.
From President Joe Biden comes an oversized ‚ÄúExecutive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.
‚Äù And UK prime minister Rishi Sunak threw a party with a cool extinction-of-the-human-race theme, wrapped up with a 28-country agreement (counting the EU as a single country) promising international cooperation to develop AI responsibly. Happy birthday! Before anyone gets too excited, let‚Äôs remember that it has been over half a century since credible studies predicted disastrous climate change. Now that the water is literally lapping at our feet and heat is making whole chunks of civilization uninhabitable, the international order has hardly made a dent in the gigatons of fossil fuel carbon dioxide spewing into the atmosphere. The United States has just installed a climate denier as the second in line to the presidency. Will AI regulation progress any better? There‚Äôs some reason to think so. In contrast to the climate issue, where a multitrillion-dollar industry mounted an all-out campaign to discredit the threats and thwart necessary measures to cut carbon, the big powers of AI seem to be begging for regulation. They surely have their own interests at heart, but at least there‚Äôs an acceptance that rules are needed. Also, unlike the case with the climate, governments are taking seriously the threats to AI relatively early in the technology‚Äôs development. Both the Biden plan and the international agreement represent commendably serious efforts to handle AI before it handles us.
Given that, it almost seems petty to nitpick about the actual content. But I will anyway. Let‚Äôs start with Biden's executive order. I read all 19,811 words of government-speak, so you won‚Äôt have to. By the end, I was jonesing for Dramamine. How does the president intend to encourage the benefits of AI while taming its dark side? By unleashing a human wave of bureaucracy. The document wantonly calls for the creation of new committees, working groups, boards, and task forces. There‚Äôs also a consistent call to add AI oversight to the tasks of current civil servants and political appointees.
Among the things the document lacks are a firm legal backing for all the regulations and mandates that may result from the plan: Executive orders are often overturned by the courts or superseded by Congress, which is contemplating its own AI regulation. (Although, don‚Äôt hold your breath, as a government shutdown looms.) And many of Biden‚Äôs solutions depend on self-regulation by the industry that‚Äôs under examination‚Äîwhose big powers had substantial input into the initiative.
You can‚Äôt fault Biden‚Äôs order for a lack of breadth. Pretty much every AI hot button is dealt with in some way, if only to make a vow to come up with solutions later. (That‚Äôs how it handles the tricky issue of generative AI and copyright.
) Overall, it‚Äôs a stunning commitment to mobilize government bureaucracy to grapple with every worrisome aspect of a new class of technology, including ones most of us never thought of. In paragraph after subparagraph, the White House orders up complicated multi-agency studies, each one involving deep interaction with industry and consultation with experts. Biden‚Äôs order assigns bureaucrats to produce complicated reports as casually as some order DoorDash meals.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The Department of Homeland Security will start an Artificial Intelligence Safety and Security Board; the Department of Health and Human Services will organize an AI Task Force; the director of the Office of Management and Budget will convene an interagency council to coordinate the use of AI. And so on. It‚Äôs going to be a beast to make sure that the groups including outsiders won‚Äôt be plagued by conflicts of interest. (The people serving on boards and committees consisting only of government people will have to wait until later to take jobs in the DC offices of AI powers.) The mother of all AI working groups will be the White House AI Council, including over 30 bureaucratic bigwigs, from the Chairman of the Joint Chiefs of Staff to the Director of the Gender Policy Council. This is going to be a bonanza for Zoom! Reading the order, one might think that for the next year, half of the executive branch will be buried in AI homework. Before this year is out, everyone from the Attorney General to the Secretary of Agriculture will need Sam Altman on speed dial to fill in some blanks. I counted the deadlines for the various reports and tasks Biden has ordered up. Two must be completed in 30 days, six are due within 60 days, five within 45 days, 11 in 90 days, seven in 120 days, three in 150 days, 38 in 180 days, 11 in 270 days, and 11 more within 365 days. To spare you the math, I totaled up all those big asks: 94. And there‚Äôs a whole bunch of other reports and tasks required without deadlines. One typical example: The chairman of the Council of Economic Advisors must prepare and submit what is presumably a thesis-level report on ‚Äúlabor-market effects of AI.‚Äù Sounds like a job for GPT-4! Some of the requests are vague, like ‚Äúencouraging‚Äù the Federal Communications Commission and the Federal Trade Commission to consider a laundry list of actions. But every single one will require tedious execution. including meetings, drafts, interviews, consultations with industry leaders and academics, and last-minute ass-covering.
It‚Äôs not clear the people currently on government payrolls are up to these assignments. Silicon Valley is desperate for AI talent, and fiercely competes to recruit it. To perform some of the highly technical tasks requested‚Äîlike vetting ‚Äúfrontier‚Äù LLMs even more powerful than the current mindblowing chatbots‚Äîwill require A-level programmers familiar with red-teaming, eliminating bias from datasets, and, as the order puts it, the mechanics of ‚Äúmachines physically located in a single datacenter, transitively connecting by data center networking over 100 Gbit/s, and having a theoretical maximum computing capacity of 10 20 integer or floating-point operations per second for training AI.‚Äù That‚Äôs a big ask for the government. The Biden order also instructs every big agency to designate a Chief Artificial Intelligence officer within 60 days‚Äîa requirement handed down by a White House that for three years has failed to fill its vacancy for a Chief Technology Officer.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The order does mandate that the official website AI.gov should devote some pages to recruitment. The front page urges visitors to ‚Äújoin the national AI talent surge.‚Äù But even the snappiest memes might have difficulty snaring AI-trained recent graduates considering offers of high six-figure salaries from Google or OpenAI. One excellent idea in the EO suggests changing immigration policy to remove current hurdles for AI talent seeking to work in the US. But I suspect that those opposed to any exceptions that increase immigration‚Äîthat is, every Republican‚Äîmight push back on this. Maybe, like other presidential mandates on immigration, it will be challenged in court. Jennifer Pahlka, who helped create the US Digital Service , has written that in order to fill the sudden need for AI experts, the government should simply overhaul its archaic hiring practices. ‚ÄúAI is about to hit us like a Mac truck,‚Äù she writes, ‚ÄúWe need a civil service that works, and we need it now.‚Äù It‚Äôs unlikely that the overhaul she suggests will occur in time to meet all those 60, 90, or even 270-day deadlines.
In contrast to the thick, detailed to-do list that is the Biden executive order, Rishi Sunak‚Äôs Bletchley Declaration comes off as an expression of good intentions. The achievement isn‚Äôt specifying any action to be taken but getting all those countries to put their signature on a single statement before going home. Many of the individual signers, notably the EU and China, are well along on their journey to regulate AI, but as a united entity, the international community is still at the starting gate. In less than 1,200 words‚Äîshorter than this essay‚Äîthe declaration acknowledges the promise and risk of AI, and cautions people building it to do it responsibly. Of course, Google, Microsoft, and the rest will tell you they already are. And the lack of specifics seems to contradict the declaration‚Äôs premise that the situation is urgent. ‚ÄúThere is potential for serious, even catastrophic harm‚Äù from AI models, it says, apparently referring to human extinction. But issues including bias transparency, privacy, and data are also acknowledged, and the signatories ‚Äúaffirm the necessity and urgency of addressing them.‚Äù The only deadline in this document, however, is a promise to meet again in 2024. By then, the Biden administration will be waist deep in reports, interagency committees, and recruiting efforts. Meanwhile, nothing in either document seems likely to impede AI from getting more powerful and useful, or potentially more dangerous.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The struggle to contain AI while reaping its benefits has been going on for decades. I pondered this dialectic when writing my curtain-raiser to the now-famous match between chess champion Garry Kasparov and IBM‚Äôs Deep Blue computer in May 1997.
Newsweek ‚Äôs cover line ran, ‚ÄúThe Brain‚Äôs Last Stand.‚Äù There's a deep irony in this epochal clash between cell and circuitry. Deep Blue is a machine, but its training consists of programming and chess lessons from impassioned human beings. Kasparov is the standard-bearer for humankind, but he's sparring against a computer running a sophisticated program. The preparations on both sides mirror the relationship that all of us have developed with the silicon interlopers into domains we once controlled. We're not competing but collaborating. If computers were yanked from our presence, planes would be grounded, cars would stall, phones would go dead, cash registers would fall silent, printing presses would stop and the bull market would be hamburger. Silicon is our ultimate prosthesis; the industrialized world is a cyborg culture, and much of humanity's intelligent work is performed, however uneasily, with our digital companions. Computers and people are in this together. At least for now.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker That's why we approach this week's historic matchup with more than a little trepidation. The terms of the partnership are subject to change. We humans may be cagier, but they are getting smarter by quantum leaps and bounds. And there's one word that we dread hearing from our silicon counterparts: checkmate.
Gabor asks, ‚ÄúWhat share of news and newsletters will be written by LLMs a year from now and how will that change the news industry?‚Äù Thanks, Gabor. Glad I grabbed this question from you before T2/Pebble sadly closed.
Now for your answer: I don‚Äôt know whether AI will dramatically change the journalistic landscape in a year. I have no doubt that percentage-wise, plenty of AI-generated articles will appear, but most of what people actually read will still be produced by humans. That‚Äôs because right now, the output from ChatGPT and others doesn‚Äôt approach what even an average journalist can produce. When publications try to get away with using AI content, it‚Äôs usually subpar. And using AI content is going to royally tick off the real journalists who work for a publication.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker In the mid-term, maybe three to five years out, I think that a combination of better LLMs and smarter approaches to using them will probably change that equation somewhat, particularly those clickbaity articles with tempting headlines. I wouldn‚Äôt be surprised if generative AI actually becomes more effective at luring people to click on those bottom-feeder stories than even the most cynical copy-churners and headline writers. But that won‚Äôt affect higher-quality outlets. Right now the winners in the news industry seem to be publications where high-quality reporting and writing wins subscribers, as opposed to those that simply court traffic.
Long-term, the answer is fuzzier. I simply don‚Äôt know how good those systems will get at producing journalism. Ten or 20 years from now, Plaintext may well be written by one of those advanced AI scribes. Would people notice? God, I hope so.
You can submit questions to mail@wired.com.
 Write ASK LEVY in the subject line.
Meet the kilonova ‚Äîa collision of two neutron stars. If one of these happens within 36 light years of Earth, all life will be eradicated for thousands of years. At least we wouldn‚Äôt have to worry about AI.
Here‚Äôs another overview of Biden‚Äôs executive order.
WIRED‚Äôs reporting from London on the UK‚Äôs AI Safety Summit Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Early Black Friday Deals We've Found Nena Farrell Gear The Best Black Friday Tech Deals Nena Farrell Business Sweden‚Äôs Tesla Blockade Is Spreading Morgan Meaker The director of Deadpool and A Night at the Museum weighs in on streaming and Taylor Swift.
It‚Äôs better in the Bahamas‚Äînow that Sam Bankman-Fried is gone.
You Might Also Like ‚Ä¶ üì© Get the long view on tech with Steven Levy's Plaintext newsletter Watch this guy work, and you‚Äôll finally understand the TikTok era How Telegram became a terrifying weapon in the Israel-Hamas War Inside Elon Musk‚Äôs first election crisis ‚Äîa day after he ‚Äúfreed‚Äù the bird The ultra-efficient farm of the future is in the sky The best pickleball paddles for beginners and pros üå≤ Our Gear team has branched out with a new guide to the best sleeping pads and fresh picks for the best coolers and binoculars Editor at Large X Topics Plaintext artificial intelligence government National Affairs Jobs machine learning Regulation Joe Biden Khari Johnson Khari Johnson Matt Laslo Nelson C.J.
Peter Guest Andy Greenberg Joel Khalili David Gilbert Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
