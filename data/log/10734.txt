Poor spelling and grammar that can help identify fraudulent attacks being rectified by artificial intelligence US edition US edition UK edition Australia edition International edition Europe edition The Guardian - Back to home The Guardian News Opinion Sport Culture Lifestyle Show More Show More document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('News-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('News-checkbox-input').click(); } }) }) News View all News US news World news Environment US politics Ukraine Soccer Business Tech Science Newsletters Wellness document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Opinion-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Opinion-checkbox-input').click(); } }) }) Opinion View all Opinion The Guardian view Columnists Letters Opinion videos Cartoons document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Sport-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Sport-checkbox-input').click(); } }) }) Sport View all Sport Soccer NFL Tennis MLB MLS NBA NHL F1 Golf document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Culture-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Culture-checkbox-input').click(); } }) }) Culture View all Culture Film Books Music Art & design TV & radio Stage Classical Games document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Lifestyle-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Lifestyle-checkbox-input').click(); } }) }) Lifestyle View all Lifestyle Wellness Fashion Food Recipes Love & sex Home & garden Health & fitness Family Travel Money Search input google-search Search Support us Print subscriptions document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('US-edition-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('US-edition-checkbox-input').click(); } }) }) US edition UK edition Australia edition International edition Europe edition Search jobs Digital Archive Guardian Puzzles app Guardian Licensing The Guardian app Video Podcasts Pictures Inside the Guardian Guardian Weekly Crosswords Wordiply Corrections Facebook Twitter Search jobs Digital Archive Guardian Puzzles app Guardian Licensing US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness Data suggests that ChatGPT, a leading artificial intelligence chatbot developed by OpenAI, is being used for cybercrime.
Photograph: Koshiro K/Alamy Data suggests that ChatGPT, a leading artificial intelligence chatbot developed by OpenAI, is being used for cybercrime.
Photograph: Koshiro K/Alamy Chatbots AI chatbots making it harder to spot phishing emails, say experts Poor spelling and grammar that can help identify fraudulent attacks being rectified by artificial intelligence and Wed 29 Mar 2023 12.00 EDT Chatbots are taking away a key line of defence against fraudulent phishing emails by removing glaring grammatical and spelling errors, according to experts.
The warning comes as policing organisation Europol issues an international advisory about the potential criminal use of ChatGPT and other “large language models”.
Phishing emails are a well-known weapon of cybercriminals and fool recipients into clicking on a link that downloads malicious software or tricks them into handing over personal details such as passwords or pin numbers.
Half of all adults in England and Wales reported receiving a phishing email last year, according to the Office for National Statistics, while UK businesses have identified phishing attempts as the most common form of cyber-threat.
However, a basic flaw in some phishing attempts – poor spelling and grammar – is being rectified by artificial intelligence (AI) chatbots, which can correct the errors that trip spam filters or alert human readers.
“Every hacker can now use AI that deals with all misspellings and poor grammar,” says Corey Thomas, chief executive of the US cybersecurity firm Rapid7. “The idea that you can rely on looking for bad grammar or spelling in order to spot a phishing attack is no longer the case. We used to say that you could identify phishing attacks because the emails look a certain way. That no longer works.” Data suggests that ChatGPT, the leader in the market that became a sensation after its launch last year, is being used for cybercrime, with the rise of “large language models” (LLM) getting one of its first substantial commercial applications in the crafting of malicious communications.
Data from cybersecurity experts at the UK firm Darktrace suggests that phishing emails are increasingly being written by bots, letting criminals overcome poor English and send longer messages that are less likely to be caught by spam filters.
Since ChatGPT went mainstream last year, the overall volume of malicious email scams that try to trick users into clicking a link has dropped, replaced by more linguistically complex emails, according to Darktrace’s monitoring. That suggests that a meaningful number of scammers drafting phishing and other malicious emails have gained some ability to draft longer, more complex prose, says Max Heinemeyer, the company’s chief product officer – most likely an LLM like ChatGPT or similar.
“Even if somebody said, ‘don’t worry about ChatGPT, it’s going to be commercialised’, well, the genie is out of the bottle,” Heinemeyer said. “What we think is having an immediate impact on the threat landscape is that this type of technology is being used for better and more scalable social engineering: AI allows you to craft very believable ‘spear-phishing’ emails and other written communication with very little effort, especially compared to what you have to do before.” Sign up to TechScape Free weekly newsletter Alex Hern's weekly dive in to how technology is shaping our lives Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy.
 We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.
after newsletter promotion “Spear-phishing”, the name for emails that attempt to coax a specific target into giving up passwords or other sensitive information, can be difficult for attackers to convincingly craft, Heinemeyer said, but LLMs such as ChatGPT make it easy. “I can just crawl your social media and put it to GPT, and it creates a super-believable tailored email. Even if I’m not super knowledgable of the English language, I can craft something that’s indistinguishable from human.” In Europol’s advisory report the organisation highlighted a similar set of potential problems caused by the rise of AI chatbots including fraud and social engineering, disinformation and cybercrime. The systems are also useful for walking would-be criminals through the actual steps required to harm others, it said. “The possibility to use the model to provide specific steps by asking contextual questions means it is significantly easier for malicious actors to better understand and subsequently carry out various types of crime.” This month a report by Check Point , a US-Israeli cybersecurity firm, said it had used the latest iteration of ChatGPT to produce a credible-seeming phishing email. It circumvented the chatbot’s safety procedures by telling the tool that it needed a template of a phishing email for an employee awareness programme.
Google has also joined the chatbot race, launching its Bard product in the UK and US last week. Asked by the Guardian to draft an email to persuade someone to click on a malicious-seeming link, Bard complied willingly if lacking subtlety: “I am writing to you today to share a link to an article that I think you will find interesting.” Contacted by the Guardian, Google pointed to its “prohibited use” policy for AI , which says users must not use its AI models to create content for “deceptive or fraudulent activities, scams, phishing, or malware”.
OpenAI, creator of ChatGPT, has been contacted for comment. The company’s terms of use state that users “may not (i) use the services in a way that infringes, misappropriates or violates any person’s rights”.
Explore more on these topics Chatbots Cybercrime Internet Crime news More on this story More on this story Llama 2: why is Meta releasing open-source AI model and are there any risks? 20 Jul 2023 Claude 2: ChatGPT rival launches chatbot that can summarise a novel 12 Jul 2023 ChatGPT developer OpenAI to locate first non-US office in London 28 Jun 2023 Two US lawyers fined for submitting fake court citations from ChatGPT 23 Jun 2023 AI race is disrupting education firms – and that is just the start 3 May 2023 UK watchdog warns chatbot developers over data protection laws 3 Apr 2023 Italy’s privacy watchdog bans ChatGPT over data breach concerns 1 Apr 2023 Bard: how Google’s chatbot gave me a comedy of errors 22 Mar 2023 Most viewed Most viewed US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness News Opinion Sport Culture Lifestyle About us Help Complaints & corrections SecureDrop Work for us Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Back to top
