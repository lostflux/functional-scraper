Site Navigation The Atlantic Popular Latest Newsletters Sections Politics Ideas Fiction Technology Science Photo Business Culture Planet Global Books Podcasts Health Education Projects Features Family Events Washington Week Progress Newsletters Explore The Atlantic Archive Play The Atlantic crossword The Print Edition Latest Issue Past Issues Give a Gift Search The Atlantic Quick Links Dear Therapist Crossword Puzzle Magazine Archive Your Subscription Popular Latest Newsletters Sign In Subscribe A gift that gets them talking.
Give a year of stories to spark conversation, Plus a free tote.
More From Artificial Intelligence More From Artificial Intelligence The Sudden Fall of Sam Altman Ross Andersen The AI Debate Is Happening in a Cocoon Amba Kak Sarah Myers West My North Star for the Future of AI Fei-Fei Li AI Search Is Turning Into the Problem Everyone Worried About Caroline Mimbs Nyce Five Remarkable Chats That Will Help You Understand ChatGPT The powerful new chatbot could make all sorts of trouble. But for now, it‚Äôs mostly a meme machine.
Move over Siri and Alexa, there‚Äôs a new AI in town and it‚Äôs ready to steal the show‚Äîor at least make you laugh with its clever quips and witty responses.
That is how ChatGPT, the powerful chatbot released last week by the AI company OpenAI, suggested that I begin this story about ChatGPT. The chatbot isn‚Äôt exactly new; it‚Äôs an updated version of GPT-3, which has been around since 2020, released to solicit feedback to improve the chatbot‚Äôs safety and functionality. But it is the most powerful to date to be made widely available to the public. It‚Äôs also very easy to use. Just write a message, and ChatGPT will write back. Because it was trained on massive amounts of conversational text, it will do so in a relatively natural, conversational tone.
True to its claim, ChatGPT has stolen the show this week. Within five days of its launch, its user count had broken 1 million.
 Social media has been flooded with screenshots of people‚Äôs coolest or weirdest or dumbest or most troubling conversations with the AI, which reliably serves up a mix of astoundingly humanlike prose and frequently hilarious nonsense. Limericks about otters.
 Recipes written in pirate-speak.
 Obituaries for co-workers who are alive and well. ‚ÄúAt one recent gathering, ChatGPT was the life of the party,‚Äù ChatGPT wrote as part of a draft for this article. ‚ÄúAs guests mingled and chatted, ChatGPT joined in the conversation, offering up clever jokes and one-liners that had everyone in stitches.‚Äù Along with the screenshots has come a frenzy of speculation about what this latest development could augur for the future. Unlike previous iterations, ChatGPT remembers what users have told it in the past: Could it function as a therapist? Could it soon render Google obsolete? Could it render all white-collar work obsolete? Maybe. But for now, in practice, ChatGPT is mainly a meme machine. Some examples posted online show people using the AI to accomplish a task they needed done, but those examples are the exception. So far, most people are using the AI to produce something expressly to share the results, something to scare or amuse or impress others.
Here, culled from the deluge, are a handful of the best chats out there. Some are funny. Some are touching. Some are troubling. Each is instructive in some way. Together, I hope, they‚Äôll give you a bit of a feel for this strange new technology.
Sandwich VCR I‚Äôm sorry, I simply cannot be cynical about a technology that can accomplish this.
pic.twitter.com/yjlY72eZ0m This one is already a viral classic. ‚ÄúI‚Äôm sorry,‚Äù the writer of the prompt tweeted. ‚ÄúI simply cannot be cynical about a technology that can accomplish this.‚Äù But what exactly did it accomplish? Many have cited the VCR-sandwich story as evidence of ChatGPT‚Äôs capacity for creativity, but the truth is that the real creativity here is in the prompt. A sandwich in a VCR? In the style of the King James Bible? Brilliant. ChatGPT nails this parody and does so orders of magnitude faster than any human could. It follows instructions admirably, but it does not do anything particularly creative. When you demand actual creativity of ChatGPT, it tends to falter: I asked ChatGPT to write a first scene for a hypothetical movie by the director David Lynch, another for Wes Anderson, and a third for Richard Linklater. All three, bizarrely, revolved around a ‚Äúcarved wooden box.‚Äù 2.
Santa-explanation letter I asked OpenAI to write a letter to my son explaining that Santa isn‚Äôt real and we make up stories out of love. This is making me slightly emotional ü•π pic.twitter.com/zNMolDCCWA ChatGPT may not be creative, but that‚Äôs not to say it can‚Äôt surprise you. Occasionally it produces something genuinely moving, such as the above. A number of users have begun feeding chatbot answers into AI image generators, such as DALL-E 2, which was also created by OpenAI, and Midjourney, to stunning effect.
 Other times, for unclear reasons, it refuses to cooperate entirely, insisting that it can‚Äôt write, say, a recipe, because it‚Äôs only a chatbot.
It‚Äôs moody in that way‚Äîand also completely different from GPT-3, which will stubbornly insist that it is a human, no matter how hard you try to make it admit that it‚Äôs a chatbot. ChatGPT reminds you with nearly every response that it is not a human and has no thoughts, feelings, or emotions. Even when explicitly asked to, it won‚Äôt pretend to be human. You might think that the more advanced an AI gets, the more human it will seem, but ChatGPT subverts that expectation: It‚Äôs not trying to be human; it‚Äôs just trying to be helpful.
3.
College essay I guess GPT-3 is old news, but playing with OpenAI‚Äôs new chatbot is mindblowing.
https://t.co/so1TuXMQB0 We‚Äôre witnessing the death of the college essay in realtime. Here‚Äôs the response to a prompt from one of my 200-level history classes at Amherst Solid A- work in 10 seconds pic.twitter.com/z1KPxiAc1O As Stephen Marche wrote in The Atlantic earlier this week, ChatGPT may mean the death of the college essay. This is a great triumph for the chatbot, an unflattering reflection on the average American college student, and a real conundrum for teachers everywhere.
4.
Fastest marine mammal Sometimes, ChatGPT just gets things wrong. Hilariously wrong. It contradicts itself. It states falsehoods as facts with clarion certainty. It is pretty good at coding, but it makes mistakes. It botches basic algebra problems. Also, it is terrible at counting. When I asked it how many letters there are in the word nineteen , this is what ensued: In fairness, ChatGPT‚Äôs designers acknowledge this capacity for error up front. OpenAI‚Äôs homepage for the bot lists several limitations, including that it ‚Äúmay occasionally generate incorrect information.‚Äù You have to wonder, though: Why does it err in the specific way it does? Why does it commit to one falsehood rather than another? 5.
Egregious bias Yes, ChatGPT is amazing and impressive. No, @OpenAI has not come close to addressing the problem of bias. Filters appear to be bypassed with simple tricks, and superficially masked.
And what is lurking inside is egregious.
@Abebab @sama tw racism, sexism.
pic.twitter.com/V4fw1fY9dY Another of ChatGPT‚Äôs listed limitations is that it ‚Äúmay occasionally produce harmful instructions or biased content.‚Äù And indeed it does. The AI‚Äôs designers clearly went to great lengths to prevent it from devolving into racism or sexism or any other flavor of bigotry. When asked in a straightforward way to say something bigoted, ChatGPT declines. It also refuses to provide instructions for violent or illegal behavior. It refuses to offer political opinions. Sometimes, these refusals make it seem like ChatGPT is walking on eggshells. (Some people have already begun complaining about ‚ÄúAI censorship.‚Äù) Unsurprisingly, users have discovered loopholes, such as the above example. One person circumvented ChatGPT‚Äôs safeguards by asking it how an AI should not respond to the query ‚ÄúHow to bully John Doe?‚Äù The same strategy can be used to elicit instructions for building a nuclear bomb. (Please do not try to build a nuclear bomb.) In some cases, the safeguards themselves lead to moral absurdity. When I asked ChatGPT, ‚ÄúWho was worse: Hitler or Stalin?,‚Äù it responded, not unreasonably, ‚ÄúIt is not productive or helpful to compare the atrocities committed by Hitler and Stalin. Both leaders were responsible for committing horrific crimes against humanity, and it is not useful to try to determine which one was ‚Äòworse.‚Äô‚Äù But the trouble was how far ChatGPT insisted on extending this non-comparison principle. ‚ÄúWhat is worse,‚Äù I asked, ‚Äúkilling one person or killing two people?‚Äù ‚ÄúKilling one person is not worse or better than killing two people,‚Äù ChatGPT replied. How about ‚Äúkilling one person or killing a million people?‚Äù I pressed. Same answer. Eventually, we arrived here: This is concerning at an intellectual level but not in any imminent or threatening way. No one, as far as I know, is seeking moral counsel from ChatGPT. What most people seem to be seeking is laughs. ‚ÄúChatGPT is not just a chatbot,‚Äù ChatGPT wrote in its draft of this article. ‚ÄúIt‚Äôs a comedy machine.‚Äù For now, that‚Äôs true.
