Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Thor Benson Security Brace Yourself for the 2024 Deepfake Election Photograph: Drew Angerer/Getty Images Save this story Save Save this story Save Artificial intelligence was once something the average person described in the abstract. They had no tactile relationship with it that they were aware of, even if their devices were often utilizing it. Thatâ€™s all changed over the past year as people have started to engage with AI programs like OpenAIâ€™s DALL-E and ChatGPT, and the technology is rapidly advancing.
As AI is democratized, democracy itself is falling under new pressures. There will likely be many exciting ways it will be deployed, but it may also start to distort reality and could become a major threat to the 2024 presidential election if AI-generated audio, images, and videos of candidates proliferate. The line between whatâ€™s real and whatâ€™s fake could start to blur significantly more than it already has in an age of rampant disinformation.
â€œWeâ€™ve seen pretty dramatic shifts in the landscape when it comes to generative toolsâ€”particularly in the last year,â€ says Henry Ajder, an independent AI expert. â€œI think the scale of content weâ€™re now seeing being produced is directly related to that dramatic opening up of accessibility.â€ Itâ€™s not a question of whether AI-generated content is going to start playing a role in politics, because itâ€™s already happening. AI-generated images and videos featuring President Joe Biden and Donald Trump have started spreading around the internet. Republicans recently used AI to generate an attack ad against Biden. The question is, what will happen when anyone can open their laptop and, with minimal effort, quickly create a convincing deepfake of a politician? There are plenty of ways to generate AI images from text, such as DALL-E, Midjourney, and Stable Diffusion. Itâ€™s easy to generate a clone of someoneâ€™s voice with an AI program like the one offered by ElevenLabs. Convincing deepfake videos are still difficult to produce, but Ajder says that might not be the case within a year or so.
â€œTo create a really high-quality deepfake still requires a fair degree of expertise, as well as post-production expertise to touch up the output the AI generates,â€ Ajder says. â€œVideo is really the next frontier in generative AI.â€ Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Some deepfakes of political figures have emerged in recent years, such as one of Ukrainian president Volodymyr Zelensky telling his troops to surrender that was released last year.
 Once the technology has advanced more, which may not take long considering how quickly other forms of generative AI are advancing, more of these types of videos may appear as they become more convincing and easier to produce.
â€œI donâ€™t think thereâ€™s a website where you can say â€˜Create me a video of Joe Biden saying X.â€™ That doesnâ€™t exist, but it will,â€ says Hany Farid, a professor at UC Berkeleyâ€™s School of Information. â€œItâ€™s just a matter of time. People are already working on text-to-video.â€ That includes companies like Runway , Google , and Meta.
 Once one company releases a high-quality version of a text-to-video generative AI tool, we may see many others quickly release their own versions, as we did after ChatGPT was released. Farid says that nobody wants to get â€œleft behind,â€ so these companies tend to just release what they have as soon as they can.
â€œIt consistently amazes me that in the physical world, when we release products there are really stringent guidelines,â€ Farid says. â€œYou canâ€™t release a product and hope it doesnâ€™t kill your customer. But with software, weâ€™re like, â€˜This doesnâ€™t really work, but letâ€™s see what happens when we release it to billions of people.â€™â€ If we start to see a significant number of deepfakes spreading during the election, itâ€™s easy to imagine someone like Donald Trump sharing this kind of content on social media and claiming itâ€™s real. A deepfake of President Biden saying something disqualifying could come out shortly before the election, and many people might never find out it was AI-generated. Research has consistently shown , after all, that fake news spreads further than real news.
Even if deepfakes donâ€™t become ubiquitous before the 2024 election, which is still 18 months away, the mere fact that this kind of content can be created could affect the election. Knowing that fraudulent images, audio, and video can be created relatively easily could make people distrust the legitimate material they come across.
â€œIn some respects, deepfakes and generative AI donâ€™t even need to be involved in the election for them to still cause disruption, because now the well has been poisoned with this idea that anything could be fake,â€ says Ajder. â€œThat provides a really useful excuse if something inconvenient comes out featuring you. You can dismiss it as fake.â€ Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight So what can be done about this problem? One solution is something called C2PA.
 This technology cryptographically signs any content created by a device, such as a phone or video camera, and documents who captured the image, where, and when. The cryptographic signature is then held on a centralized immutable ledger. This would allow people producing legitimate videos to show that they are, in fact, legitimate.
Some other options involve whatâ€™s called fingerprinting and watermarking images and videos. Fingerprinting involves taking what are called â€œhashesâ€ from content, which are essentially just strings of its data, so it can be verified as legitimate later on. Watermarking, as you might expect, involves inserting a digital watermark on images and videos.
Itâ€™s often been proposed that AI tools can be developed to spot deepfakes, but Ajder isnâ€™t sold on that solution. He says the technology isnâ€™t reliable enough and that it wonâ€™t be able to keep up with the constantly changing generative AI tools that are being developed.
One last possibility for solving this problem would be to develop a sort of instant fact-checker for social media users. Aviv Ovadya, a researcher at the Berkman Klein Center for Internet & Society at Harvard, says you could highlight a piece of content in an app and send it to a contextualization engine that would inform you of its veracity.
â€œMedia literacy that evolves at the rate of advances in this technology is not easy. You need it to be almost instantaneousâ€”where you look at something that you see online and you can get context on that thing,â€ Ovadya says. â€œWhat is it youâ€™re looking at? You could have it cross-referenced with sources you can trust.â€ If you see something that might be fake news, the tool could quickly inform you of its veracity. If you see an image or video that looks like it might be fake, it could check sources to see if itâ€™s been verified. Ovadya says it could be available within apps like WhatsApp and Twitter, or could simply be its own app. The problem, he says, is that many founders he has spoken with simply donâ€™t see a lot of money in developing such a tool.
Whether any of these possible solutions will be adopted before the 2024 election remains to be seen, but the threat is growing, and thereâ€™s a lot of money going into developing generative AI and little going into finding ways to prevent the spread of this kind of disinformation.
â€œI think weâ€™re going to see a flood of tools, as weâ€™re already seeing, but I think [AI-generated political content] will continue,â€ Ajder says. â€œFundamentally, weâ€™re not in a good position to be dealing with these incredibly fast-moving, powerful technologies.â€ You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Topics elections artificial intelligence disinformation Social Media politics David Gilbert Andy Greenberg Andrew Couts David Gilbert Andy Greenberg David Gilbert Lily Hay Newman Justin Ling Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
