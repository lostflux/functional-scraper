Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Brandie M. Nonnecke Security Opinion: California‚Äôs Anti-Deepfake Law Is Far Too Feeble Deepfakes are a serious threat to democracy. Unfortunately, lawmakers' current efforts to combat them will largely be ineffective.
Photograph: AP Save this story Save Save this story Save Imagine it‚Äôs late October 2020, and that there's fierce competition for the remaining undecided voters in the presidential election. In a matter of hours, a deepfake video depicting a candidate engaged in unsavory behavior goes viral, and thanks to microtargeting, reaches those who are most susceptible to changing their vote. Deepfakes‚Äîthe use of AI to generate deceptive audio or visual media depicting real people saying or doing things they did not‚Äîare a serious threat to democracy and lawmakers are aggressively responding. Unfortunately, their current efforts will largely be ineffective.
Brandie M. Nonnecke ( @BNonnecke ), PhD, is founding director of the CITRIS Policy Lab at UC Berkeley and a fellow at the Aspen Institute‚Äôs Tech Policy Hub and the World Economic Forum. She studies human rights at the intersection of law, policy, and emerging technologies, with her current work focusing on issues of fairness and accountability in AI.
Last month, Governor Gavin Newsom signed California‚Äôs AB 730 , known as the ‚ÄúAnti-Deepfake Bill,‚Äù into law. The intention to quell the spread of malicious deepfakes before the 2020 election is laudable. But four major flaws will significantly impede the law‚Äôs success: timing, misplaced responsibility, burden of proof, and inadequate remedies.
Timing The law applies only to deepfake content distributed with ‚Äúactual malice‚Äù within 60 days of an election‚Äîa forced time constraint that does not reflect the enduring nature of material posted online. ‚ÄúWhat happens if content is created or posted 61 days before an election and remains online for months, years?‚Äù asks Hany Farid , a professor and digital forensics expert at UC Berkeley who works on deepfake detection.
To ensure that the law does not infringe upon free speech rights, it incorporates exemptions for satire and parody. However, AB 730 is ambiguous on how to efficiently and effectively determine these criteria‚Äîambiguity that nefarious actors are likely to game. By claiming satire and parody when the material is contested, a deepfake could be tied up in a lengthy review process for removal. Like the manipulated video of House Speaker Nancy Pelosi to make her appear intoxicated, a drawn-out review process to determine the video‚Äôs intent enables it to further gain virality and spur a contagion of negative effects.
Misplaced Responsibility The law exempts platforms from the responsibility to monitor and stem the spread of deepfakes. This is due to Section 230 of the Communications Decency Act , which provides platforms with a liability safeguard against being sued for harmful user-generated content, especially if they are acting in good faith to remove the content.
 Court interpretations since the law‚Äôs passing in 1996 have broadened platforms‚Äô immunity, even if they deliberately encourage the posting of harmful user-generated content.
Instead, the law places responsibility on producers of deepfakes to self-identify manipulated content and on users to flag suspicious content. This is like having a Wall Street broker trading on inside information to self-identify intentions and suspicious transactions, or asking a con artist to make victims sign a terms of service agreement before they get swindled. These tactics will be unenforceable and ineffectual. Nefarious actors will not voluntarily disclose their creations as deepfakes. They‚Äôll use botnets‚Äîconnected communities of bots that interact with each other to quickly spread content through a social network‚Äîto evade detection. The damage to public perception will be done well before the content is flagged and reviewed for takedown.
According to the law , any registered voter may seek a temporary restraining order and an injunction prohibiting the spread of material in violation. It is not hard to imagine this being manipulated by special interest groups to tie up contentious content in a lengthy review process for removal, as well as inviting public skepticism regarding its veracity. By introducing doubt, the damage to public perception will be done without needing removal. This is especially problematic for content that truthfully depicts a candidate engaging in unsavory or illegal behavior, but is being claimed by supporters to be a malicious deepfake. When there is no definitive truth, everything is a lie.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Content spread through platforms has tangible effects on our democracy and public safety. To mitigate the spread and impact of malicious deepfakes, platforms must be required to play a more proactive role. Last month, senators Mark Warner, the Democrat of Virginia, and Marco Rubio, the Republican of Florida, sent identical letters to leading social media platform companies urging them to establish industry standards to deal with deepfakes. If the California legislature really wants to address the spread of malicious deepfakes, they must put pressure on platforms.
Burden of Proof Again, the law only pertains to deepfakes posted with ‚Äúactual malice‚Äù or ‚Äúthe knowledge that the image of a person has been superimposed on a picture or photograph to create a false representation,‚Äù and that there is an ‚Äúintent to injure the candidate‚Äôs reputation or to deceive a voter into voting for or against the candidate.‚Äù Proving actual malice will not be straightforward. Clear and convincing evidence, which is often difficult to obtain, will be necessary to determine intent. Because of the high burden of proof to determine actual malice, a lengthy review process will likely ensue and allow the deepfake to continue to spread.
Inadequate Remedies When a malicious deepfake is detected, remediation should also be implemented. Like the spreading of a virus, only those who receive the immunization will be spared. Under the law, malicious deepfake videos will have the opportunity to spread widely before detection and removal, and there is no mechanism to ensure those who were exposed also receive a notification of its intent and accuracy.
The ‚ÄúAnti-Deepfake Law‚Äù isn‚Äôt without value. According to Deeptrace , an Amsterdam-based company that specializes in the detection of deepfakes, the prevalence of deepfakes online has increased by a staggering 84 percent over the past year. The law raises awareness of the risks of malicious deepfakes on election integrity and creates an initial framework to monitor and stem their spread and impact‚Äîa critical step before the 2020 presidential election. Yet significantly more needs to be done, including the following: reconsidering the 60-day time constraint and defining a review mechanism to efficiently and effectively determine satire and parody; placing greater responsibility on platforms to monitor their content; establishing a credible review process to determine intent; and developing robust mechanisms to remedy the harms caused by malicious deepfakes.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight California‚Äôs progressive tech legislation has a history of influencing other state and federal efforts, and the ‚ÄúAnti-Deepfake Law‚Äù is no exception. Language in the law restricting the spread of malicious deepfakes within 60 days of an election has made its way into an amendment to a federal bill on foreign interference in elections that is under review by the House Committee on Rules. The passing of the ‚ÄúAnti-Deepfake Law‚Äù in the tech sector‚Äôs beating heart may be a blow to the implementation of adequate mechanisms to mitigate the harms of deepfakes before the 2020 presidential election. Future bills, especially those at the federal level, must do more.
WIRED Opinion publishes articles by outside contributors representing a wide range of viewpoints. Read more opinions here.
 Submit an op-ed at opinion@wired.com.
The super-optimized dirt that helps keep racehorses safe What's blockchain actually good for, anyway? For now, not much How to free up space in Gmail Trying to plant a trillion trees won't solve anything The untold story of Olympic Destroyer, the most deceptive hack in history üëÅ Prepare for the deepfake era of video ; plus, check out the latest news on AI üèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones.
Op-ed contributor Topics real or fake California elections Deepfakes K.G. Orphanides Vittoria Elliott Vas Panagiotopoulos Lily Hay Newman Lily Hay Newman Andrew Couts Dell Cameron Dhruv Mehrotra Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
