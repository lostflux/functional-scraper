Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business How 10 Skin Tones Will Reshape Google‚Äôs Approach to AI Photograph: VPanteon/Getty Images Save this story Save Save this story Save Application Face recognition Ethics Personal services Recommendation algorithm End User Consumer Big company Sector Consumer services Health care Social media Source Data Images Video Technology Machine vision For years, tech companies have relied on something called the Fitzpatrick scale to classify skin tones for their computer vision algorithms. Originally designed for dermatologists in the 1970s, the system comprises only six skin tones, a possible contributor to AI‚Äôs well-documented failures in identifying people of color. Now Google is beginning to incorporate a 10-skin tone standard across its products, called the Monk Skin Tone ( MST ) scale, from Google Search Images to Google Photos and beyond. The development has the potential to reduce bias in data sets used to train AI in everything from health care to content moderation.
Google first signaled plans to go beyond the Fitzpatrick scale last year.
 Internally, the project dates back to a summer 2020 effort by four Black women at Google to make AI ‚Äúwork better for people of color,‚Äù according to a Twitter thread from Xango Eye√©, a responsible AI product manager at the company. At today‚Äôs Google I/O conference , the company detailed how wide an impact the new system could have across its many products. Google will also open source the MST, meaning it could replace Fitzpatrick as the industry standard for evaluating the fairness of cameras and computer vision systems.
‚ÄúThink anywhere there are images of people‚Äôs faces being used where we need to test the algorithm for fairness,‚Äù says Eye√©.
The Monk Skin Tone scale is named after Ellis Monk, a Harvard University sociologist who has spent decades researching colorism‚Äôs impact on the lives of Black people in the United States. Monk created the scale in 2019 and worked with Google engineers and researchers to incorporate it into the company‚Äôs product development.
‚ÄúThe reality is that life chances, opportunities, all these things are very much tied to your phenotypical makeup,‚Äù Monk said in prepared remarks in a video shown at I/O. ‚ÄúWe can weed out these biases in our technology from a really early stage and make sure the technology we have works equally well across all skin tones. I think this is a huge step forward.‚Äù An initial analysis by Monk and Google research scientists last year found that participants felt better represented by the MST than by the Fitzpatrick scale. In an FAQ published Wednesday, Google says that having more than 10 skin tones can add complexity without extra value, unlike industries like makeup, where companies like Rihanna‚Äôs Fenty Beauty offer more than 40 shades. Google is continuing work to validate the Monk Skin Tone scale in places like Brazil, India, Mexico, and Nigeria, according to a source familiar with the matter. Further details are expected soon in an academic research article.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight The company will now expand its use of the MST. Google Images will offer an option to sort makeup-related search results by skin tone based on the scale, and filters for people with more melanin are coming to Google Photos later this month. Should Google adopt the 10-skin-tone scale across its product lines, it could have implications for fairly evaluating algorithms used in Google search results, Pixel smartphones, YouTube classification algorithms, Waymo self-driving cars, and more.
Colorism encoded into technology can lead to undignified outcomes for people with dark skin, such as Google Photos mislabeling pictures of Black people as gorillas, racist soap dispensers , and automatically generated stereotypical images.
 An algorithm that Google developed to identify lesions lacked inclusion for people with dark skin. Autonomous driving systems have been found to identify people with dark skin much less reliably than those with white skin. Most famously, a 2018 research paper coauthored by former Ethical AI team colead Timnit Gebru concluded that facial recognition algorithms made by major companies performed worse on women with dark skin, work detailed in the documentary Coded Bias.
In the wake of Google firing Gebru in late 2020 , Black in AI and Queer in AI groups pledged to no longer receive funds from Google , and the company‚Äôs 2021 Diversity Report found that its attrition rates are highest among Black and Native American women.
Eye√© says further study is needed to validate results that indicate a Monk over Fitzpatrick preference, or whether a Monk approach leads to more equitable algorithms for dermatologists.
 But early results, especially for groups poorly represented in computer vision data sets, are promising.
You Might Also Like ‚Ä¶ üì® Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cash‚Äôs Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you üîå Charge right into summer with the best travel adapters , power banks , and USB hubs Senior Writer X Topics machine learning algorithms artificial intelligence bias Paresh Dave Gregory Barber Amanda Hoover Will Knight Caitlin Harrington Peter Guest Will Knight Vittoria Elliott Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
