Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google releases new generative AI products and features for Google Cloud and Vertex AI Share on Facebook Share on X Share on LinkedIn Image Credit: Google Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google announced a variety of new products and features today that give customers access to new generative AI modalities and expanded ways to use and tune custom models, at its annual developer conference, Google I/O 2023.
Among the new offerings are three new foundation models that are available in Vertex AI , Google Cloud’s end-to-end machine learning platform. These models are Codey, a text-to-code model that can help developers with code completion, generation, and chat; Imagen, a text-to-image model that can help customers generate and edit high-quality images for any business need; and Chirp, a speech-to-text model that can help organizations engage with customers and constituents more inclusively in their native languages.
New tools for generative AI Google’s new offerings — which in total include three brand-new foundation models, an Embeddings API, and a unique tuning feature — aim to empower developers and data scientists with more capabilities to build generative AI applications more quickly.
The first of the new foundation models released today, Codey, aims to accelerate software development by providing real-time code completion and code generation. Perhaps best of all, it can be customized to a user’s own codebase. The model supports more than 20 coding languages and is able to streamline a wide variety of coding tasks. It essentially helps developers ship products faster, generating code based on natural language prompts, and offers code chat for assistance with debugging and documentation.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Imagen, the second foundation model, helps organizations generate and edit high-quality images for a wide variety of use cases. This text-to-image model simplifies the creation and editing of images at scale, offering low latency and enterprise-grade data governance capabilities.
In one of the most exciting capabilities launched today, mask-free edit allows users to make changes to a generated image through natural language processing.
 This essentially means you can have a conversation with the user interface about how to generate the perfect photo, continuously iterating on the output. The model also offers image upscaling and captioning in over 300 languages. Users can quickly generate production-ready images, while built-in content moderation ensures safety.
The third foundation model, Chirp, focuses on enhancing customer engagement through speech-to-text. Trained on millions of hours of audio, Chirp supports more than 100 languages, with additional languages and dialects being added today. Chirp is a new version of Google’s 2 billion-parameter speech model that now boasts 98% accuracy in English and up to 300% relative improvement in languages with fewer than 10 million speakers.
Finding new relationships in data To complement its new foundation models, Google introduced the Embeddings API for text and images, which is now available in Vertex AI as well. This API converts text and image data into multi-dimensional numerical vectors that map semantic relationships, which allows developers to create more engaging apps and user experiences. Applications range from powerful semantic search and text classification functionality to Q&A chatbots based on an organization’s data.
Another standout feature of Vertex AI’s update is reinforcement learning from human feedback (RLHF), which Google claims makes Vertex AI the first end-to-end machine learning platform among hyperscalers to offer RLHF as a managed service. This feature enables organizations to incorporate human feedback to train a reward model for fine-tuning foundation models, making it particularly useful in industries where accuracy and customer satisfaction are crucial.
Google’s new generative AI advancements are poised to revolutionize the development landscape, offering developers and data scientists an increasingly sophisticated toolset for leveraging AI in the cloud. With these new foundation models and tools, the possibilities for innovation and responsible AI development are virtually limitless.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
