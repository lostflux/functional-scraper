Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business A Stanford Proposal Over AI's 'Foundations' Ignites Debate Illustration: Sam Whitney; Getty Images Save this story Save Save this story Save End User Research Sector Research Technology Natural language processing Neural Network Last month, Stanford researchers declared that a new era of artificial intelligence had arrived, one built atop colossal neural networks and oceans of data. They said a new research center at Stanford would build—and study—these “foundation models” of AI.
Critics of the idea surfaced quickly—including at the workshop organized to mark the launch of the new center. Some object to the limited capabilities and sometimes freakish behavior of these models; others warn of focusing too heavily on one way of making machines smarter.
“I think the term ‘foundation’ is horribly wrong,” Jitendra Malik , a professor at UC Berkeley who studies AI, told workshop attendees in a video discussion.
Malik acknowledged that one type of model identified by the Stanford researchers—large language models that can answer questions or generate text from a prompt—has great practical use. But he said evolutionary biology suggests that language builds on other aspects of intelligence like interaction with the physical world.
“These models are really castles in the air; they have no foundation whatsoever,” Malik said. “The language we have in these models is not grounded, there is this fakeness, there is no real understanding.” He declined an interview request.
A research paper coauthored by dozens of Stanford researchers describes “an emerging paradigm for building artificial intelligence systems” that it labeled “foundation models.” Ever-larger AI models have produced some impressive advances in AI in recent years, in areas such as perception and robotics as well as language.
“These models are really castles in the air, they have no foundation whatsoever.” Jitendra Malik, professor of computer science, UC Berkeley Large language models are also foundational to big tech companies like Google and Facebook , which use them in areas like search, advertising, and content moderation. Building and training large language models can require millions of dollars worth of cloud computing power; so far, that’s limited their development and use to a handful of well-heeled tech companies.
But big models are problematic, too. Language models inherit bias and offensive text from the data they are trained on, and they have zero grasp of common sense or what is true or false. Given a prompt, a large language model may spit out unpleasant language or misinformation.
 There is also no guarantee that these large models will continue to produce advances in machine intelligence.
The Stanford proposal has divided the research community. “Calling them ‘foundation models’ completely messes up the discourse,” says Subbarao Kambhampati , a professor at Arizona State University. There is no clear path from these models to more general forms of AI, Kambhampati says.
Thomas Dietterich , a professor at Oregon State University and former president of the Association for the Advancement of Artificial Intelligence , says he has “huge respect” for the researchers behind the new Stanford center, and he believes they are genuinely concerned about the problems these models raise.
But Dietterich wonders if the idea of foundation models isn’t partly about getting funding for the resources needed to build and work on them. “I was surprised that they gave these models a fancy name and created a center,” he says. “That does smack of flag planting, which could have several benefits on the fundraising side.” Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX’s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X’s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Stanford has also proposed the creation of a National AI Cloud to make industry-scale computing resources available to academics working on AI research projects.
Emily M. Bender , a professor in the linguistics department at the University of Washington, says she worries that the idea of foundation models reflects a bias toward investing in the data-centric approach to AI favored by industry.
Bender says it is especially important to study the risks posed by big AI models. She coauthored a paper , published in March, that drew attention to problems with large language models and contributed to the departure of two Google researchers.
 But she says scrutiny should come from multiple disciplines.
“There are all of these other adjacent, really important fields that are just starved for funding,” she says. “Before we throw money into the cloud, I would like to see money going into other disciplines.” Percy Liang , director of the new Stanford research center, says he has heard the criticism but believes some people may misunderstand the goal of the project.
Liang says the large machine learning models dubbed “foundational” appear unique and important because of their ability to handle the complexity of the real world, as demonstrated by the capabilities of large language models. He says the feedback is part of a healthy academic debate. “All of these critiques are welcome,” he says.
Liang adds the Stanford researchers are fully aware of the limits of these models and describe some in their research paper. Nor do they believe that these models are all that’s needed to make further leaps forward in AI, he says.
“It's just a kind of unbridled raw potential,” Liang says, “that we need to figure out a way to harness and contain.” Updated 9-17-2021, 11:12 am EDT: A previous version of this article used the term “foundational models” in places when the correct term is “foundation models.” 📩 The latest on tech, science, and more: Get our newsletters ! Can robots evolve into machines of loving grace? 3D printing helps ultracold quantum experiments go small How community pharmacies stepped up during Covid The Artful Escape is psychedelic perfection How to send messages that automatically disappear 👁️ Explore AI like never before with our new database 🎮 WIRED Games: Get the latest tips, reviews, and more 📱 Torn between the latest phones? Never fear—check out our iPhone buying guide and favorite Android phones Senior Writer X Topics artificial intelligence deep learning machine learning neural networks Steven Levy Will Knight Khari Johnson Khari Johnson Niamh Rowe Steven Levy Will Knight Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
