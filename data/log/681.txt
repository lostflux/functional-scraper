Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Matt Simon Science How a Real Dog Taught a Robot Dog to Walk Photography: Kiyoshi Ota/Getty Images Save this story Save Save this story Save What you see when Boston Dynamics‚Äô humanoid robot does a backflip or its Spot dog robot fights off a human and opens a door is incredible hardware engineering, to be sure. But what you don‚Äôt see is the wildly complex underlying code that makes it possible. What comes so easily to you‚ÄîOK maybe not backflips, just walking‚Äîrequires extreme coordination, which roboticists have to replicate, a kind of dance of motors working in concert.
Pity the engineers who have to write out all that code. Over at Google, researchers have a secret weapon to teach robots to move that‚Äôs both less taxing and more adorable: dogs. They gather motion-capture videos from a public dataset, then feed that data into a simulator to create a digital version of the pooch. The researchers then translate the digital version of the real dog into a digital version of their four-legged robot‚ÄîLaikago, which has a rectangular body and skinny legs. Then they port those algorithms into the physical version of Laikago. (The robot is named, by the way, after Laika , the Soviet space dog who was the first animal to orbit Earth.) A robot works quite differently than a biological dog; it has motors instead of muscles, and in general it‚Äôs a lot stiffer. But thanks to this translation work, Laikago has learned to move like a real-life canine. Not only that, its learned gait is faster than the fastest gait provided by the manufacturer of the robot‚Äîthough in fairness it‚Äôs not yet as stable. The new system could be the first steps (sorry) toward robots that learn to move not thanks to exhaustive coding, but by watching videos of animals running and jumping.
‚ÄúThe drawback with the kind of manual approach is that it's not really scalable for every skill that we want a robot to perform,‚Äù says AI researcher Jason Peng, lead author on a new paper describing the system. ‚ÄúWe need long engineering hours in order to come up with the different strategies.‚Äù With this new approach, reinforcement learning algorithms do much of that work. Even though they‚Äôre both quadrupeds, the robot‚Äôs body is quite different from the dog‚Äôs body, so in the computer simulations the digital version of the robot has to figure out how to imitate the motion of the digital version of the dog without directly copying its mechanics. ‚ÄúSo what the reinforcement learning algorithm does is it tries to find a way that allows the robot to be as close to the original reference motion as possible,‚Äù Peng says.
By Matt Simon The algorithm tries random movements, and gets a digital ‚Äúreward‚Äù if it gets closer to the dog‚Äôs reference motion‚Äîbasically a thumbs-up message that says that was good, do that kind of thing again.
 If it tries something that‚Äôs not so hot, it gets a digital ‚Äúdemerit‚Äù‚Äî don‚Äôt do that kind of thing again.
 With this reward system, over many iterations the simulated robot teaches itself to move like the dog.
The next challenge is known as sim-to-real; that is, taking what the system has learned in simulation and getting it to work in a physical robot. This is tricky because a simulation is an imperfect and highly-simplified version of the real world. Mass and friction are represented as accurately as possible, but not perfectly. The actions of the simulated robot in the digital world don‚Äôt map precisely to movements of the real robot in the lab.
Courtesy of Google So Peng and his colleagues built not one definitive robot simulation, but a range of possibilities for what the robot‚Äôs behavior could be. They randomized friction in the simulation, for instance, and tweaked the latency between when you send the robot a command and when it actually executes the order. ‚ÄúThe idea is that if we train the simulation with enough diversity, it might learn a good enough set of strategies, such that one of those strategies will work in the real world,‚Äù Peng says.
All of these strategies are reasonable for the robot to pull off, by the way‚Äîthey don‚Äôt want it to move so rapidly or violently that it will injure itself or humans. The system has already made its most catastrophic mistakes in the computer simulation‚Äîremember those demerits‚Äîso the robot doesn‚Äôt have to make them in the real world. But some of those behaviors result in a better gait than others. They ended up being remarkably dog-like behaviors, despite the robot‚Äôs lack of a dog anatomy; the researchers even got it to chase its nonexistent tail, spinning around in circles. It also learned a few that weren‚Äôt dog-like at all, like little dances from animations created by an artist.
Courtesy of Google To be clear, this isn‚Äôt the first time that roboticists have looked to animal motion for inspiration. Boston Dynamics‚Äô Spot robot is obviously modeled after the fluid motions of quadrupeds, and its Atlas humanoid is modeled after those of people.
 By taking such inspiration, Spot can clamber over the most difficult of terrains , thanks to meticulously-coded control algorithms.
This new system? Not so much. ‚ÄúThis thing is walking around on flat floors,‚Äù says Chris Atkeson, a roboticist at Carnegie Mellon University, who wasn‚Äôt involved in the research. ‚ÄúThe state of the art is way beyond that in terms of rough terrain, particularly the Boston Dynamics stuff.‚Äù But there‚Äôs a bigger picture: If we want robots to be useful in an environment like the home, they‚Äôll have to learn like we learn. Think about the last time you struggled to open a jar. You didn‚Äôt eventually get into it by smashing the top off. You went to the utensil drawer, got out a spoon, and pried the edge of the lid, releasing the seal, because you once saw another human do the same.
Courtesy of Google ‚ÄúLet's say that that's how we do everything,‚Äù says Atkeson. ‚ÄúSo what does that mean? Well, that means you‚Äôve got to have this massive library of stuff you've seen other humans do. If you're presented with a situation that isn't in the library, you have to look among the elements of the library, find a couple cases that seem close, and maybe interpolate or pick the closest one, and use the techniques of this paper to make it work for the problem you really care about.‚Äù It‚Äôs going to take a whole lot of work to build such a library of movements that would be useful to legged robots. But doggonit, it‚Äôs better than hand-coding everything.
Update, 4/3/20, 2 pm ET: The story originally noted that the researchers gathered their own motion-capture video, when in fact they used a public data set.
Special issue: How we will all solve the climate crisis Why life during a pandemic feels so surreal OK, Zoomer! How to become a videoconferencing power user The Postal Service's surprising role in surviving doomsday Amazon workers face high risks and few options üëÅ Why can't AI grasp cause and effect ? Plus: Get the latest AI news üèÉüèΩ‚Äç‚ôÄÔ∏è Want the best tools to get healthy? Check out our Gear team‚Äôs picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Staff Writer X Topics robotics Ramin Skibba Matt Simon Amit Katwala Rob Reddick Matt Simon Ramin Skibba Rhett Allain Ramin Skibba Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
