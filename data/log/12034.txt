Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Intel makes it easier to bring Movidius AI accelerator chip into production Share on Facebook Share on X Share on LinkedIn An illustration shows the size of the AI Core board (left) and the Movidius Neural Compute Stick (right) Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Intel and Aaeon made it easier for hardware companies to build a machine learning accelerator into their products with today’s launch of a new circuit board called the AI Core. That board contains a Movidius Myriad 2 Vision Processing Unit that speeds up execution of AI algorithms while only drawing around a watt of power.
That’s the same sort of capability hardware makers can get from the Movidius Neural Compute Stick , which looks like a somewhat bulky USB flash drive but offers AI acceleration. Ever since Intel released that hardware last year, it has picked up a following among hardware startups, makers, and developers interested in experimenting with AI.
The stick is optimized for speeding up the execution of different types of machine learning algorithms, including convolutional neural networks, which are the backbone of many image recognition systems. Companies are increasingly building and deploying AI hardware because it can mitigate the computation and power requirements of the intelligent software.
Having a bulky USB stick that serves as an integral part of a robot and that could be knocked or pulled out isn’t exactly practical, which is why the AI Core now exists. When companies want to bring their AI hardware into production, they can move from using the Neural Compute Stick to the AI Core without changing their code.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Customers who want to take advantage of the other features in the Myriad 2, like video encoding accelerators, will still have to source the chips from Intel directly, rather than using the AI Core.
All of this is part of Intel’s overall strategy of building more AI-specific hardware following its acquisition of several key companies in the space, including Movidius, Altera, Mobileye, and Nervana. That entire arena is a battleground for established chipmakers and new startups, since machine learning algorithms can require a great deal of compute power that can be helped significantly by specialized silicon.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
