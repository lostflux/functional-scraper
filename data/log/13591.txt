Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages For Wells Fargo, solving for AI at scale is an iterative process Share on Facebook Share on X Share on LinkedIn This article is part of a VB special issue. Read the full series here: The quest for Nirvana: Applying AI at scale.
Wells Fargo, the 170-year-old multinational financial services giant, knows what it needs to do to scale AI across the organization. But that, according to Chintan Mehta, EVP and group CIO, is really just the beginning of the journey.
Implementing AI at scale is about artificial intelligence becoming a core component of any go-to-market product, he explained.
“It means there is no notion of a bolt-on AI,” he said, “which by definition is not a behavior of AI at scale because in that context AI is not fundamental to the proposition you are building.” Wells Fargo is not quite there yet, he emphasized. But Mehta believes that the company is at a point where it knows what it needs to do.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “We know how to go about it,” he explained. “But it’s a function of time capital, working through it and getting it to the point where it’s embedded, transparent and available.” The three key elements to solving for AI at scale These days, AI is no longer just about developing AI models. Instead, in order to scale AI across the enterprise, companies have to solve for three independent elements that have to converge.
“There are these three chunks, then you can iterate independently on each of them so that you can get better overall,” Mehta said.
The first is enterprise data strategy. That is, the signals that the company needs to use, whether for visualization or for model development.
“Data needs to be thought of as a product by itself,” he said, “[as] data products that data science teams can consume.” Next are the AI capabilities themselves, whether it’s large language models , neural networks , or statistical models.
The third is the independent verification and mitigation structure that operates organizationally, operationally and technically. This element allows organizations to create guardrails around how AI goes to market and how it is used for or on behalf of customers.
Wells Fargo has put all three elements into place, said Mehta. Now it’s about powering them at scale.
“We’re trying to expand them and make them faster. The faster it becomes, the more effective it is in bringing things to market,” he said.
Two examples of scaling AI at Wells Fargo It’s no surprise that processing documents is an important internal use case at Wells Fargo. So analyzing documents and streamlining processes was a prime candidate for implementing AI at scale.
“You have to understand what the artifact uploaded is, whether it is the right artifact, what it represents, what is the data underneath it, and so on,” said Mehta.
Wells Fargo built a capability for document processing which creates a semantic understanding of a document and provides a summary.
“It’s not 100% automated, but we can augment human beings quite a bit,” said Mehta.
A key customer-facing use case for scaling AI is Wells Fargo’s soon-to-launch virtual assistant, Fargo.
“We started with the experiential requirements and then said, ‘What will be the best solution for the natural language ask?’” said Mehta. “Should it be a chat? Voice? Should we use a recurrent neural network? How do we manage privacy? Tokenization?” Mehta’s teams built the scaffolding for Fargo up front, testing it with a small neural network. Then, to get a deeper language understanding, they used a Google large language model.
“This is going to be an ongoing thing where you keep iterating,” Mehta explained. “It’s not a one-directional flow; sometimes you find you are a few steps back because an approach doesn’t work. But that’s the journey.” There’s no magic to scaling AI There may be hype around scaling AI, but there’s no magic, Mehta emphasized.
“Everybody thinks that if they just put AI in there, it will do something magical,” he said. “But everybody learns there is no box which says ‘insert magic here.’ You have to work through what you’re actually trying to do and define the problem, and then think of AI in the context of solving that problem.” Wells Fargo, he added, doesn’t have the luxury of simply building models even if they don’t solve problems. Two or three years ago it took a median of 65 weeks to develop an AI model and take it to market, and even now it still takes roughly 21 weeks.
“We don’t have unlimited resources to deploy, so you’re trying to constantly fight the efficiency barrier — there’s a lot of interest, a lot of appetite, but at the same time you want to keep AI efforts safe and efficient.” That means, he said, you “have to pick the right problems to deal with in terms of where you deploy AI.” Wells Fargo’s 2023 priorities for AI at scale Mehta said there are three things he is focused on when it comes to implementing AI at scale in 2023.
“These are the ones I’m focused on in an immediate, practical way, because I think those will be force amplifiers for what we can do at scale later on,” he said.
The first is creating a foundational model library. “Some of these models are going to become impractical for any single group or a single entity to build out, because they become very, very large and very complex very quickly,” he said. “So our first tactical goal for this year is to build a foundational library of these kinds of models which can form the baseline for the next specialized set of models people want to build.” Next, Mehta said, Wells Fargo is trying to automate the entire AI pipeline, so “more citizen data scientists can also build on top of the models, instead of somebody who has a Ph.D. and has a Python library on their machine and knows Python.” Finally, it’s important to embed explainability into every AI step. “If you can explain along the way instead of at the end, it speeds up a lot of the other conversations later,” he said.
The future of AI at scale In a few years, we may not even be talking about AI “at scale,” because it will be everywhere, Mehta predicted.
“We will be hard-pressed to say, ‘Is there anything we use today which doesn’t have aspects of AI built into it?’” he said. “It’s going to be less about scale, and more about whether you know something is happening with AI at that exact moment and if it’s done safely.” Wells Fargo, he added, will continue iterating on that journey.
“We know the standards, we know the goals, we are very clear on how to do it,” he said. “Now it’s a function of making sure we work through all of it.” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
