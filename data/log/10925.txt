Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Matt Burgess Security ChatGPT Has a Big Privacy Problem Photograph: badahos/Getty Images Save this story Save Save this story Save When OpenAI released GPT-3 in July 2020 , it offered a glimpse of the data used to train the large language model. Millions of pages scraped from the web, Reddit posts, books, and more are used to create the generative text system, according to a technical paper.
 Scooped up in this data is some of the personal information you share about yourself online. This data is now getting OpenAI into trouble.
On March 31, Italyâ€™s data regulator issued a temporary emergency decision demanding OpenAI stop using the personal information of millions of Italians thatâ€™s included in its training data. According to the regulator, Garante per la Protezione dei Dati Personali, OpenAI doesnâ€™t have the legal right to use peopleâ€™s personal information in ChatGPT. In response, OpenAI has stopped people in Italy from accessing its chatbot while it provides responses to the officials, who are investigating further.
The action is the first taken against ChatGPT by a Western regulator and highlights privacy tensions around the creation of giant generative AI models, which are often trained on vast swathes of internet data. Just as artists and media companies have complained that generative AI developers have used their work without permission, the data regulator is now saying the same for peopleâ€™s personal information.
Similar decisions could follow all across Europe. In the days since Italy announced its probe, data regulators in France, Germany, and Ireland have contacted the Garante to ask for more information on its findings. â€œIf the business model has just been to scrape the internet for whatever you could find, then there might be a really significant issue here,â€ says Tobias Judin, the head of international at Norwayâ€™s data protection authority, which is monitoring developments. Judin adds that if a model is built on data that may be unlawfully collected, it raises questions about whether anyone can use the tools legally.
Italyâ€™s blow to OpenAI also comes as scrutiny of large AI models is steadily increasing. On March 29, tech leaders called for a pause on the development of systems like ChatGPT , fearing its future implications. Judin says the Italian decision highlights more immediate concerns. â€œEssentially, weâ€™re seeing that AI development to date could potentially have a massive shortcoming,â€ Judin says.
Europeâ€™s GDPR rules , which cover the way organizations collect, store, and use peopleâ€™s personal data , protect the data of more than 400 million people across the continent. This personal data can be anything from a personâ€™s name to their IP addressâ€”if it can be used to identify someone, it can count as their personal information. Unlike the patchwork of state-level privacy rules in the United States, GDPRâ€™s protections apply if peopleâ€™s information is freely available online. In short: Just because someoneâ€™s information is public doesnâ€™t mean you can vaccuum it up and do anything you want with it.
Italyâ€™s Garante believes ChatGPT has four problems under GDPR: OpenAI doesnâ€™t have age controls to stop people under the age of 13 from using the text generation system; it can provide information about people that isnâ€™t accurate; and people havenâ€™t been told their data was collected. Perhaps most importantly, its fourth argument claims there is â€œno legal basisâ€ for collecting peopleâ€™s personal information in the massive swells of data used to train ChatGPT.
â€œThe Italians have called their bluff,â€ says Lilian Edwards, a professor of law, innovation, and society at Newcastle University in the UK. â€œIt did seem pretty evident in the EU that this was a breach of data protection law.â€ Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Broadly speaking, for a company to collect and use peopleâ€™s information under GDPR, they must rely on one of six legal justifications , ranging from someone giving their permission to the information being required as part of a contract. Edwards says that in this instance, there are essentially two options: getting peopleâ€™s consentâ€”which OpenAI didnâ€™t doâ€”or arguing it has â€œlegitimate interestsâ€ to use peopleâ€™s data, which is â€œvery hardâ€ to do, Edwards says. The Garante tells WIRED it believes this defense is â€œinadequate.â€ OpenAIâ€™s privacy policy doesnâ€™t directly mention its legal reasons for using peopleâ€™s personal information in training data but says it relies upon â€œlegitimate interestsâ€ when it â€œdevelopsâ€ its services. The company did not respond to WIREDâ€™s request for comment. Unlike with GPT-3, OpenAI has not publicized any details of the training data that went into ChatGPT, and GPT-4 is thought to be several times larger.
However, GPT-4â€™s technical paper includes a section on privacy, which says its training data may include â€œpublicly available personal information,â€ which comes from a number of sources. The paper says OpenAI takes steps to protect peopleâ€™s privacy, including â€œfine-tuningâ€ models to stop people asking for personal information and removing peopleâ€™s information from training data â€œwhere feasible.â€ â€œHow to collect data lawfully for training data sets for use in everything from just regular algorithms to some really sophisticated AI is a critical issue that needs to be solved now, as weâ€™re kind of on the tipping point for this sort of technology taking over,â€ says Jessica Lee, a partner at law firm Loeb and Loeb.
The action from the Italian regulatorâ€”which is also taking on the Replika chatbot â€”has the potential to be the first of many cases examining OpenAIâ€™s data practices. GDPR allows companies with a base in Europe to nominate one country that will deal with all of its complaintsâ€”Ireland deals with Google, Twitter, and Meta, for instance. However, OpenAI doesnâ€™t have a base in Europe, meaning that under GDPR, every individual country can open complaints against it.
OpenAI isnâ€™t alone. Many of the issues raised by the Italian regulator are likely to cut to the core of all development of machine learning and generative AI systems, experts say. The EU is developing AI regulations , but so far there has been comparatively little action taken against the development of machine learning systems when it comes to privacy.
â€œThere is this rot at the very foundations of the building blocks of this technologyâ€”and I think thatâ€™s going to be very hard to cure,â€ says Elizabeth Renieris, senior research associate at Oxfordâ€™s Institute for Ethics in AI and author on data practices.
 She points out that many data sets used for training machine learning systems have existed for years, and it is likely there were few privacy considerations when they were being put together.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight â€œThereâ€™s this layering and this complex supply chain of how that data ultimately makes its way into something like GPT-4,â€ Renieris says. â€œThereâ€™s never really been any type of data protection by design or default.â€ In 2022, the creators of one widely used image database, which has helped trained AI models for a decade, suggested images of peopleâ€™s faces should be blurred in the data set.
In Europe and California, privacy rules give people the ability to request that information be deleted or corrected if it is inaccurate.
 But deleting something from an AI system that is inaccurate or that someone doesnâ€™t want there may not be straightforwardâ€”especially if the origins of the data are unclear. Both Renieris and Edwards question whether GDPR will be able to do anything about this in the long term, including upholding peopleâ€™s rights. â€œThere is no clue as to how you do that with these very large language models,â€ says Edwards from Newcastle University. â€œThey donâ€™t have provision for it.â€ So far, there has been at least one relevant instance, when the company formerly known as Weight Watchers was ordered by the US Federal Trade Commission to delete algorithms created from data it didnâ€™t have permission to use. But with increased scrutiny, such orders could become more common. â€œDepending, obviously, on the technical infrastructure, it may be difficult to fully clear your model of all of the personal data that was used to train it,â€ says Judin, from Norwayâ€™s data regulator. â€œIf the model was then trained by unlawfully collected personal data, it would mean that you would essentially perhaps not be able to use your model.â€ You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Senior writer X Topics artificial intelligence Regulation ChatGPT privacy Andy Greenberg Andy Greenberg Lily Hay Newman Lily Hay Newman Andy Greenberg Reece Rogers Andy Greenberg Garrett M. Graff Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
