Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Skyflow launches ‘privacy vault’ for building LLMs Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Palo Alto, California-based Skyflow , a company that makes it easier for developers to embed data privacy into their applications, today announced the launch of a “privacy vault” for large language models.
The solution, as the name suggests, provides enterprises with a layer of data privacy and security throughout the entire lifecycle of their LLMs, beginning with data collection and continuing through model training and deployment.
It comes as enterprises across sectors continue to race to embed LLMs, like the GPT series of models, into their workflows to simplify processes and boost productivity.
Why a privacy vault for GPT models? LLMs are all the rage today, helping with things like text generation, image generation and summarization. However, most of the models that are out there have been trained on publicly available data. This makes them suitable for broader public use, but not so much for the enterprise side of things.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! To make LLMs work in specific enterprise settings, companies need to train them on their internal knowledge. A few have already done it or are in the process of doing it , but the task is not easy, as you have to ensure that the internal, business-critical data used for training the model is protected at all stages of the process.
This is exactly where Skyflow’s GPT privacy vault comes in.
Delivered via API , the solution establishes a secure environment, allowing users to define their sensitive data dictionary and have that information protected at all stages of the model lifecycle: data collection, preparation, model training, interaction and deployment. Once fully integrated, the vault uses the dictionary and automatically redacts or tokenizes the chosen information as it flows through GPT — without lessening the value of the output in any way.
“Skyflow’s proprietary polymorphic encryption technique enables the model to seamlessly handle protected data as if it were plaintext,” Anshu Sharma, Skyflow cofounder and CEO, told VentureBeat. “It will protect all sensitive data flowing into GPT models and only reveal sensitive information to authorized parties once it has been processed by the model and returned.” For example, Sharma explained, plaintext sensitive data elements like email addresses and social security numbers are swapped with Skyflow-managed tokens before inputs are provided to GPTs. This information is protected by multiple layers of encryption and fine-grained access control throughout model training, and ultimately de-tokenized after the GPT model returns its output. As a result, authorized end users get a seamless output experience, with plaintext-sensitive data bypassing the GPT model.
“This works because GPT LLMs already break down inputs to analyze patterns and relationships between them and then make predictions about what comes next in the sequence. So, tokenizing or redacting sensitive data with Skyflow before inputs are provided to the LLM doesn’t impact the quality of GPT LLM output — the patterns and relationships remain the same as before plaintext sensitive data is tokenized by Skyflow,” Sharma added.
The offering can be integrated into an enterprise’s existing data infrastructure. It also supports multi-party training, where two or more entities could share anonymized datasets and train models to unlock insights.
Multiple use cases While the Skyflow CEO didn’t share how many companies are using the GPT privacy vault, he did note that the offering, which is an extension of the company’s existing privacy-focused solutions, is helping protect sensitive clinical trial data in the drug development cycle as well as customer data used by travel platforms for improving customer experiences.
IBM too is a customer of Skyflow and has been using the company’s products to de-identify sensitive information in large datasets before analyzing it via AI/ML.
Notably, there are also alternative approaches to the problem of privacy, such as creating a private cloud environment for running individual models or a private instance of ChatGPT. But those could prove to be far more expensive than Skyflow’s solution.
Currently, in the data privacy and encryption space, the company competes with players like Immuta , Securiti , Vaultree , Privitar and Basis Theory.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
