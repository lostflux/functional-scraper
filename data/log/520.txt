Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Bedingfield Culture The Bruce Willis Deepfake Is Everyoneâ€™s Problem Photograph: yipengge/Getty Images Save this story Save Save this story Save Application Deepfakes Regulation End User Big company Small company Sector Entertainment Video Source Data Biometric Speech Video Technology Machine learning Machine vision Jean-Luc Godard once claimed, regarding cinema, â€œ When I die, it will be the end.
â€ Godard passed away last month; film perseveres. Yet artificial intelligence has raised a kindred specter: that humans may go obsolete long before their artistic mediums do.
Novels scribed by GPT-3 ; art conjured by DALLÂ·E â€”machines could be making art long after people are gone. Actors are not exempt. As deepfakes evolve, fears are mounting that future films, TV shows, and commercials may not need them at all.
Not even Bruce Willis. Last month the actor had the strange experience of â€œappearingâ€ in an ad where he was tied to a bomb on the back of a yacht, growling "Mississippi" in a Russian accent.
The Telegraph reported the deepfake was possible because he sold his performance rights. That wasn't quite trueâ€”a representative for Willis later told reporters the actor had done no such thing.
 And as my colleague Steven Levy wrote a few days ago , the company who made the adâ€”the cheekily named Deepcakeâ€”never claimed to hold Willis' future rights, but had struck a deal that allowed the company to map a digital version of his appearance onto another actor in a commercial for the Russian cell network Megafon.
Yet the question of â€œwho owns Bruce Willis,â€ as Levy put it, isnâ€™t only a concern for the Hollywood star and his representatives. It concerns actors unions across the world, fighting against contracts that exploit their members' naivety about AI. And, for some experts, it's a question that implicates everyone, portending a wilder, dystopian futureâ€”one in which identities are bought, sold, and seized.
In America, explains Jennifer Rothman, author of The Right of Publicity: Privacy Reimagined for a Public World , people have a right under various state laws to limit unauthorized appropriation of their identities, particularly their names and likenesses. The scope of protection varies state by state.
 Some have statutes protecting the â€œright of publicityâ€ (a law barring unauthorized use of a personâ€™s name, likeness, voice, or other indicia of identity without permission, usually for a commercial purpose), while others offer these safeguards through common, or judge-made, laws. A few have both statutory and common law protections.
The devil is in the details, though. "A private individual or company that simply creates a deepfake of a person, without more, does not obviously run afoul of the right of publicity," explains David A. Simon, a research fellow at Petrie-Flom Center at Harvard Law School. In other words, if a Willis deepfake appears in an American ad for potato chips, then a claim becomes viable; if someone deepfakes Willisâ€™ yippie-ki-yay swagger into a home movie and throws it on YouTube, the actor may not have much of a case. Under certain circumstances, deepfake makers are protected by the First Amendment. As one Northwestern University paper put it last year, â€œthe government cannot prohibit speech merely because the speech is false; there must be some additional problem,â€ like defamation.
â€œThe right of publicity requires the commercial appropriation of identity while tort law does not always require a commercial element,â€ explains Simon. â€œIf an actor's deepfake is manipulated to portray someone in a defamatory manner, or used to defame someone else, the actor may have the ability to sue in tort." Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Actors unions have been fretting over deepfakes for decades. The Screen Actors Guildâ€”American Federation of Television and Radio Artists (SAG-AFTRA)â€™s interest began with sports video games, which started generating their own image rights controversies back in 2013. Even just looking at the rudimentary and blocky depictions of athletes in video games it was clear that the tech would develop in a way that would make it possible to drop actors into movies as easily as developers could drop quarterbacks into Madden.
In a landscape of desperate actors, confusing contracts, and multivarious laws, it doesn't take an agile mind to grasp that SAG-AFTRA has its work cut out. The wrong consent given to the wrong company can lead to pretty much any nightmare the mind can weave. Remember that episode of Friends where Joey ended up in an STD advert after a spot of seemingly innocuous modeling? Itâ€™s like that, except, in some cases, Joey wouldn't have to model at all. In his (fictional) story, everything was fine at the end of the half-hour, but a different (real) actor could find it hard to get work after being deepfaked into an unflattering or controversial role. And itâ€™s no longer just a problem of visual depiction: Deepfakes allow an actor to be â€œused,â€ in Simonâ€™s words, with words quite literally put into their mouths. (TikTok had to settle a legal case recently around this very issue.
) â€œThis is relevant not just to AI contracts [for synthetic performances], but any contract involving rights to oneâ€™s likeness and voice,â€ says Danielle S. Van Lier, assistant general counsel, intellectual property and contracts at SAG-AFTRA. â€œWe have been seeing contracts that now include â€˜simulation rightsâ€™ to performersâ€™ images, voices, and performances. These contract terms are buried deep in the boilerplate of performance agreements in traditional media.â€ Yet, and hereâ€™s the rub, actors also see the rise of deepfakes as a chance to cash in. â€œWhile many never become â€˜famous,â€™ their names, voices, images or likenesses still attain commercial value,â€ explains Van Lier. The commercial opportunities of synthetic performancesâ€“an actorâ€™s voice used in an automated audiobook or appearance as a digital avatar, abound, hence why SAG-AFTRA is pushing away from the term deepfakesâ€“and its association with pornâ€“to terms like â€œdigital doubleâ€ or â€œAI-generated.â€ Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg This is where the importance of â€œtransferabilityâ€ of publicity rights comes in: A law passed in New York in 2020, for instance, allows postmortem rights to be transferred. â€œThe ability to license and convey this property interest provides an important source of revenue to these professionals and their families,â€ says Van Lier. â€œLicensing allows creative professionals to work with entities and individuals with technological, financial and legal expertise, and to maximize the value of the asset.â€ Itâ€™s crucial to understand here that transferability isnâ€™t about authorizing uses of your identity for money; itâ€™s about ownership, your identity conceived of as a transferable property right, like patents or copyrights, able to be bought and sold. â€œIt affects whether the right over a person's identity is transferred (and taken away) from them and owned by a third party,â€ says Rothman.
For some experts, this transferability could lead to people losing control of their â€œpersonalityâ€ as firms take full ownership of their identity rather than just a licensed use for a particular purpose. In fact, the original calls for these kinds of transferability were made in the 1950s by studio lawyers who wanted to control the movies that actors appeared in and the products they endorsed. â€œOne might (potentially) garner more money for such a total transfer, but the cost seems inconceivably great to the person and society,â€ Rothman says.
Student athletes , for instance, risk agents, managers, companies, or even the NCAA hoovering up their identities in the hope of extracting any future profit if they find big-league success. Actors, athletes, and average citizens, Rothman argues , are in danger of losing control of their "own names, likenesses, and voices to creditors, ex-spouses, record producers, managers, and even Facebook." Many actors wonâ€™t be affected, simply because their identities wonâ€™t be valuable. But it is also true that celebrities like Kim Kardashian and Tom Cruise have bargaining power that others donâ€™t: They can bullishly negotiate that the use of their image not extend beyond any particular show or film. Smaller actors, meanwhile, face the possibility of contracts that extract rights wholesale. "There is a real risk that new actors (i.e., just starting out and desperate for breakthrough work) would be especially vulnerable to signing away their publicity rights as a condition of their first contracts," says Johanna Gibson, a professor of intellectual property law at Queen Mary, University of London. "This power imbalance could be exploited by studios keen both to commercialize image and character and indeed to avoid libel (depending upon the nature of that commercialization), as the performer would no longer have rights to control how their image is used." Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg This could leave actors in a position of either missing out on work, or signing a contract that would later allow them to be deepfaked into content they find demeaning without legal recourse. In the film franchise model, Gibson argues, the risk is even greater.
SAG-AFTRA disagrees, explaining that reasonable minds will always differ, even when working toward the same stated goal. â€œWhile some prominent commentators have expressed fear that a transferable right of publicity could lead to involuntary transfers or forced commercialization, there is little basis to believe this fear would come to fruition,â€ says Van Lier. â€There are no instances, to our knowledge, of the right being involuntarily transferred during anyoneâ€™s lifetime or anyone being forced to exploit it. The most notable attempt involved OJ Simpson and the court expressly refused to transfer it to his victimâ€™s family.â€ Eventually, AIs trained on Bruce Willisâ€™ likeness won't need Bruce Willis at all. â€œIf a company can train its AI algorithms to replicate the specific mannerisms, timing, tonality, etc. of a particular actor, it makes the AI-generated content more and more life-like,â€ says Van Lier. â€œThis can have long-term implications.â€ In other words, actorsâ€”and everyone elseâ€”must learn how to protect their digital rights, or they could find themselves performing a role they did not expect.
You Might Also Like â€¦ ğŸ“§ Find the best bargains on quality gear with our Deals newsletter â€œ Someone is using photos of me to talk to menâ€ First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the â€œbestâ€ T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? ğŸŒ See if you take a shine to our picks for the best sunglasses and sun protection Staff writer X Topics hollywood ethics Deepfakes Kate Knibbs Reece Rogers Megan Farokhmanesh Geek's Guide to the Galaxy Simon Hill Elana Levin Jason Parham Megan Farokhmanesh Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
