Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business Ex-Googler Timnit Gebru Starts Her Own AI Research Center Illustration: WIRED Staff; Getty Images Save this story Save Save this story Save Application Ethics Company Alphabet Google End User Research Sector IT Technology Natural language processing One year ago Google artificial intelligence researcher Timnit Gebru tweeted, ‚ÄúI was fired‚Äù and ignited a controversy over the freedom of employees to question the impact of their company‚Äôs technology.
 Thursday, she launched a new research institute to ask questions about responsible use of artificial intelligence that Gebru says Google and other tech companies won‚Äôt.
‚ÄúInstead of fighting from the inside, I want to show a model for an independent institution with a different set of incentive structures,‚Äù says Gebru, who is founder and executive director of Distributed Artificial Intelligence Research (DAIR). The first part of the name is a reference to her aim to be more inclusive than most AI labs‚Äîwhich skew white, Western, and male ‚Äîand to recruit people from parts of the world rarely represented in the tech industry.
Gebru was ejected from Google after clashing with bosses over a research paper urging caution with new text-processing technology enthusiastically adopted by Google and other tech companies.
 Google has said she resigned and was not fired, but acknowledged that it later fired Margaret Mitchell , another researcher who with Gebru co-led a team researching ethical AI. The company placed new checks on the topics its researchers can explore. Google spokesperson Jason Freidenfelds declined to comment but directed WIRED to a recent report on the company's work on AI governance, which said Google has published more than 500 papers on "responsible innovation" since 2018.
The fallout at Google highlighted the inherent conflicts in tech companies sponsoring or employing researchers to study the implications of technology they seek to profit from. Earlier this year, organizers of a leading conference on technology and society canceled Google‚Äôs sponsorship of the event. Gebru says DAIR will be freer to question the potential downsides of AI and will be unencumbered by the academic politics and pressure to publish that she says can complicate university research.
‚ÄúInstead of fighting from the inside, I want to show a model for an independent institution with a different set of incentive structures.‚Äù Timnit Gebru DAIR will also work on demonstrating uses for AI unlikely to be developed elsewhere, Gebru says, aiming to inspire others to take the technology in new directions. One such project is creating a public data set of aerial imagery of South Africa to examine how the legacy of apartheid is still etched into land use. A preliminary analysis of the images found that in a densely populated region once restricted to non-white people where many poor people still live, most vacant land developed between 2011 and 2017 was converted into wealthy residential neighborhoods.
A paper on that project will mark DAIR‚Äôs formal debut in academic AI research later this month at NeurIPS, the world‚Äôs most prominent AI conference. DAIR‚Äôs first research fellow, Raesetje Sefala, who is based in South Africa, is lead author of the paper, which includes outside researchers.
Safiya Noble , a professor at UCLA who researches how tech platforms shape society, serves on DAIR‚Äôs advisory board. She says Gebru‚Äôs project is an example of the kind of new and more inclusive institutions needed to make progress on understanding and responding to technology‚Äôs effects on society.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight ‚ÄúBlack women have been major contributors to helping us understand the harms of big tech and different kinds of technologies that are harmful to society, but we know the limits in corporate America and academia that Black women face,‚Äù says Noble. ‚ÄúTimnit recognized harms at Google and tried to intervene but was massively unsupported‚Äîat a company that desperately needs that kind of insight.‚Äù Noble recently launched a nonprofit of her own, Equity Engine , to support the ambitions of Black women. She is joined on DAIR‚Äôs advisory board by Ciira wa Maina, a lecturer at Dedan Kimathi University of Technology in Nyeri, Kenya.
DAIR is currently a project of nonprofit Code for Science and Society but will later incorporate as a nonprofit in its own right, Gebru says. Her project has received grants totaling more than $3 million from the Ford, MacArthur, Rockefeller, and Open Society foundations, as well as the Kapor Center. Over time, she hopes to diversify DAIR‚Äôs financial support by taking on consulting work related to its research.
DAIR joins a recent flourishing of work and organizations taking a broader and critical view of AI technology. New nonprofits and university centers have sprung up to study and critique AI‚Äôs effects in and on the world, such as NYU‚Äôs AI Now Institute , the Algorithmic Justice League , and Data for Black Lives.
 Some researchers in AI labs also study the impacts and proper use of algorithms, and scholars from other fields such as law and sociology have turned their own critical eyes on AI.
The White House Office of Science and Technology Policy this year hired two prominent academics who work on algorithmic fairness research and is working on a ‚Äúbill of rights‚Äù to guard against AI harms.
 The Federal Trade Commission last month hired three people from AI Now to serve as advisers on AI technology.
Despite those shifts, Baobao Zhang, an assistant professor at Syracuse University, says the US public still seems to broadly trust tech companies to guide development of AI.
Zhang recently surveyed AI researchers and the US public on who they trusted to shape development of the technology in the public interest. The results were starkly different: The public were most trusting of university researchers and the US military. Tech companies as a group came slightly behind, ranking similarly to international or nonprofit research institutions such as CERN, but ahead of the US government. AI researchers reported less trust than the general public in the US military and some tech companies, notably Facebook and Amazon, but more in the UN and non-governmental scientific organizations.
üì© The latest on tech, science, and more: Get our newsletters ! Amazon's dark secret : It has failed to protect your data Inside the lucrative world of console resellers How to run your own portable PC from a USB stick Locked out of ‚ÄúGod mode,‚Äù runners hack their treadmills The Turing test is bad for business üëÅÔ∏è Explore AI like never before with our new database ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Senior Editor X Topics artificial intelligence machine learning Google ethics Will Knight Khari Johnson Amit Katwala Kari McMahon David Gilbert Andy Greenberg David Gilbert Andy Greenberg Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
