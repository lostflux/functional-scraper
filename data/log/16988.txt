Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google Lens in Pixel’s Assistant can now recognize famous people Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google Lens in Pixel smartphones is now able to recognize photos and depictions of well-known people like actresses, celebrities, and politicians.
It’s not clear when the ability to recognize celebrities was added to Lens in Google Assistant. The feature was identified during Lens tests conducted by VentureBeat this week. Google did not respond to further questions about the sorts of people Lens is able to recognize.
The computer vision-powered service first became available last November as a premiere feature for Pixel smartphones. Lens in Assistant on a Pixel smartphone still appears to provide the most advanced version of Google’s visual search tool, even as the company expands its availability beyond its flagship smartphone to all Android smartphones.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Two weeks ago, Google announced plans to bring Lens to Google Photos for Android and iOS as well as Assistant for Android.
 On Tuesday, Lens was added to Google Photos for Android devices , but has yet to show up in Google Photos for iOS or Assistant in Android phones (Pixel aside, of course). In the Photos app, Lens brings the ability to scrape text from business cards to create new contacts on Android phones, plus recognize works of art, landmarks, text on billboards, plants, and animals.
Bringing Lens to more Android smartphones leads us to ask whether the visual search tool will work the same on all devices. Lens in the Photos app and Lens in Assistant already offer different experiences.
For example, if you snap a photo of a celebrity, like comedian Dave Chappelle, and scan that photo with Lens in the Google Photos app, a prompt will appear that says “Lens doesn’t recognize people.” Do the same with Lens in Google Assistant with a Pixel 2 and you will be shown suggested search results related to Chappelle’s movie career and former TV show, and even his net worth.
The experience of using Lens in the Photos app versus Lens in Pixel’s Assistant is innately different — Photos scans images of pictures you already took, while Lens in Assistant operates with the camera lens open so it only requires a tap on your screen. Lens in Assistant can also be tasked with remembering visual searches and translating text.
Lens in Pixel’s Assistant started out with similar features as those now available in Photos, but can now recognize when it sees currency denominations and objects like street signs or window curtains. Lens in Assistant is also able to recognize items of clothing and make some shopping recommendations.
Recognition of things like money and produce is in line with improvements forecast last fall by Assistant engineer Behshad Behzadi at Google Developer Days Europe.
A Google spokesperson did not answer questions about Assistant’s ability to recognize people or Lens capabilities beyond primary use cases introduced last fall for Pixel smartphones and earlier this week for the Photos app.
After scanning the face of a celebrity, suggested replies appear below their name and vary depending on the individual in question, though virtually all celebrities’ search results included a net worth suggestion. A Google spokesperson did not answer questions about how Google Assistant determines suggested replies for each celebrity.
Though Lens often gets things right, some false results can be amusing. An attempt to identify a cat from a distance brought back results like caterpillar, hamster, and chinchilla.
Google is extending the power of its computer vision-powered Lens at a time when other major mobile providers are also increasing their computer vision chops.
Samsung’s Galaxy S9 and Galaxy S9+ and LG V30S ThinQ made their debuts last month at Mobile World Congress, and both focused on changes that make their device’s camera capable of deploying computer vision. Samsung began to use visual search from companies like Amazon and Pinterest in the Galaxy S8 last year.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
