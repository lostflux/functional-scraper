Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons WIRED Staff Business The Lie Behind Lie Detectors Save this story Save Save this story Save If we can put a man on the moon, why can't we detect when someone is lying? Just as the space program seemed to be just the thing for combating communism during the Cold War, lie detection looks like just what we need in the fight against terrorism. The popular press, including Wired magazine, has been pretty optimistic that a high-tech replacement for the archaic and mistrusted polygraph machine is coming soon.
Last weekend, Stanford Law School hosted a workshop called "Reading Minds: Lie Detection, Neuroscience, Law and Society," where attendees took a closer look at the technology -- a look that suggests we're still light years away.
As a criminal defense attorney, I found the polygraph test useful, and I submitted my clients to testing on several occasions. There's little evidence that the polygraph is accurate, and most courts won't admit test results as evidence. But many people in law enforcement, including the FBI, believe in lie detectors, so strapping a defendant to a polygraph can be a useful tool in convincing prosecutors to drop borderline charges.
One time, I got to sit in the room as the examiner, paid by our firm, strapped and clipped the sensors to our high-strung, jittery female client. The machine looked like something out of the 1950s, with wires and electrodes connected to needles that marked variations on a roll of paper. The test measures the subject's changes in respiration, heartbeat and perspiration -- anxiety reactions allegedly correlated with lying.
In a protocol called the "control-question test," the polygraph operator asks irrelevant questions to obtain a base-line reaction, and asks "probable-lie" questions to get a sample of a deceptive reading. My client was anxious during all of these, whether the harmless, "Are you sitting down?" or the loaded, "Have you ever stolen anything?" that is designed to embarrass the subject into lying.
When my client almost jumped out of the chair when asked if she'd stolen the particular watch in question, the examiner declared that she passed with flying colors.
That was a good result for her, but an example of how far from hard science the polygraph falls. Proper protocol would have required that she not move during the test. For that matter, I wasn't supposed to be allowed in the room -- it should just be the suspect alone with the intimidating examiner. She was also supposed to believe that the examiner was neutral, rather than paid by her attorneys.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX’s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X’s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight The problems with the polygraph are more fundamental than in-the-field variables such as partisan experts and improper testing procedures. In 2003, the National Academy of Sciences reviewed scientific evidence on the polygraph. The study found that there is a lack of scientific evidence that the physiological reactions the polygraph measures are uniquely related to deception, as opposed to some other psychological process, like anxiety or fear.
In the lab, with a trained examiner and a cooperative subject who is not trying to game the device by pressing his feet against the floor or squeezing his fists during the control questions, a polygraph can distinguish lies from truth better than random chance. Beyond that, it's science fiction.
And that's why there's a significant push underway to develop more-reliable lie-detection devices.
Functional magnetic resonance imaging, or fMRI, and electroencephalography, or EEG, are the most promising modern techniques vying to replace the polygraph. One reason researchers think these methods might be superior is that instead of using sweat and heartbeat to tell us what's going on in the mind, these technologies map the brain itself. Another reason is that both methods are better suited than the polygraph to identifying whether the subject has guilty knowledge, and this is more useful in security screening than the highly targeted interrogation required by the control-question test.
But these modern methods are less miraculous than they might seem. The fMRI test measures oxygen in the brain, and oxygen is related to blood flow. The scientific hypothesis is that greater blood flow (oxygen) is tightly coupled with greater neural activity. If scientists can figure out which part of the brain we use to lie, the theory goes, then fMRI can tell when we are lying.
The hard part, what Georgetown Medical School associate professor of neurology Tom Zeffiro calls the "black art," is generating accurate models of the relationship between neurological activity and blood flow. The fMRI results have to account for up to 30 or 40 factors other than deception -- including heart rate, respiration, motion -- that might all cause variance in the signal. Also, the area of the brain related to deception differs a bit from individual to individual. Culture, language, personality, handedness, gender, medications and health can all affect the results.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX’s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X’s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Most importantly, fMRI is susceptible to simple countermeasures. Since fMRI measures oxygen in the brain, a subject can defeat the test by breathing deeply or by holding her breath.
EEG has some of the same problems as fMRI, and some unique challenges. An EEG measures electrical activity on the surface of the scalp, on the tip of the nose and around the eyes. The device then infers through skin, skull and hair what's happening with electrical waves in the brain.
Researchers have identified one wave shape, P300, as associated with deception. Research assistant professor Jennifer Vendemia from the University of South Carolina studies P300, and at the Stanford workshop she said that it's possible to see a lie by looking at this wave shape, which occurs milliseconds after a question is posed. But it's difficult to measure deception separately from other neurological phenomena like switching tasks, recalling something autobiographical or recalling something learned.
As with fMRI, the existence of wave variations can be generalized over a pool of people, but differs from person to person. Moreover, the science suffers from Zeno's paradox : As EEG measurement becomes more refined, smaller errors in the readings have larger consequences for the results. Vendemia showed the audience slides of an EEG test, and it looked to me like a child's drawing of a fleet of purposeful worms.
Under laboratory conditions, fMRI technology might be 90 percent accurate in determining whether individuals in a test group of Americans are lying about taking a watch or a ring. But it's useless for employee screening, convicting the guilty, identifying terrorists at the airport or separating innocents from enemy combatants at Guantanamo Bay -- at least at the moment.
At some point soon, these high-tech lie detectors will be cheap, accurate, portable and unobtrusive enough to replace the polygraph in incident investigations. But we are a long way from reading minds.
Lie detection raises a host of complicated ethical problems about autonomy and the privacy of one's own thoughts. But before we get there, we have to know whether the thing works, and what exactly it does. Being a smart consumer of security technology means asking about accuracy rates, validity, reproducibility, specificity and sensitivity.
Once these tools are on the market, there will be immense pressure to use, or rather misuse, them in Guantanamo Bay, on the battlefield, in the courtroom and at your workplace. We'll hear the usual argument about the need to trade some privacy for increased security. But that bargain is only equitable when you actually get some security in the exchange. With even the best technology, science says lie detection is still only a little better than a shot in the dark.
Lying Makes Brain Work Harder Can't Hide Your Lying ... Face? Polygraphs Don't Give True Story Liar, Liar, Eyes on Fire? Thought Police Peek Into Brains Topics laws politics Will Knight Steven Levy Khari Johnson Paresh Dave Will Knight Gregory Barber Will Bedingfield Steven Levy Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
