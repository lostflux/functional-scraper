Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Nvidia sets 6 MLPerf benchmark records for AI performance Share on Facebook Share on X Share on LinkedIn Nvidia headquarters in Santa Clara, Calif.
Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Nvidia has set six new records for how fast an AI model can be trained using a predetermined group of datasets.
MLPerf is a benchmark suite of tests created by prominent companies in the space to standardize and provide guidelines for how to measure AI training and inference speed. MLPerf is often used to share the speed of commercially available cloud computing services, mobile devices, or hardware in server hardware stacks.
Companies who contributed to the creation of MLPerf include Google, Nvidia, Baidu, and supercomputer maker Cray.
Above: MLPerf supporter organizations Nvidia set records for image classification with ResNet-50 version 1.5 on the ImageNet dataset, object instance segmentation, object detection, non-recurrent translation, recurrent translation, and recommendation systems.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “For all of these benchmarks we outperformed the competition by up to 4.7x faster,” Nvidia VP and general manager of accelerated computing Ian Buck said in a conference call with reporters. “There are certainly faster DGX-2 ResNet-50 renditions out there, but none under MLPerf benchmark guidelines.” The feat was achieved using Nvidia DGX systems , using NVSwitch interconnectors to work with up to 16 fully connected V100 Tensor Core GPUs , which was first unveiled in spring 2017. Nvidia submitted and was judged in the single node category with 16 GPUs, as well as distributed training with 16 GPUs to 80 nodes with 640 GPUs.
With a single node, Nvidia was able to train with ResNet-50 in 70 minutes. With distributed training, Nvidia was able to train with ResNet-50 in 6.3 minutes. By comparison, it would have taken 25 days for a single CUDA GPU to train with ResNet-50 in 2015.
The rapid rise in compute power has played a major role in the emergence of AI as an influential force in technology, business, and society in recent years.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
