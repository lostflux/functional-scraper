Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Paris Martineau Business Facebook's Plan for 2020 Is Too Little, Too Late, Critics Say â€œThe bottom line here is that elections have changed significantly since 2016, and Facebook has changed too,â€ CEO Mark Zuckerberg said Monday.
Photograph: Carlos Jasso/Reuters Save this story Save Save this story Save Mark Zuckerberg didnâ€™t mince words on a call with reporters Monday: â€œThe bottom line here is that elections have changed significantly since 2016, and Facebook has changed too.â€ Itâ€™s true, the days of Zuckerberg arguing that filter bubbles are worse in the real world than on Facebook, and dismissing the notion that social media could influence the way people vote as a â€œpretty crazy ideaâ€ are long gone. Facebook, he said, has gone from being â€œon our back footâ€ to proactively seeking out threats and fighting coordinated influence operations ahead of the 2020 US presidential election.
As proof, he pointed to the slew of new efforts the company announced Monday to combat combat election interference and the spread of disinformation, describing the initiatives as one of his â€œtop priorities.â€ But critics say heâ€™s missing the point.
Disinformation and media manipulation researchers say Facebookâ€™s announcements Monday left them frustrated and concerned about 2020. Though the policy updates show that Facebook understands that misinformation is a serious problem that can no longer be ignored, that message was undercut by the companyâ€™s reluctance to fully apply its own rules, particularly to politicians. Whatâ€™s more, they say the new election integrity measures are riddled with loopholes and still fail to get at many of the most pressing issues they had hoped Facebook would address by this time.
â€œAll of the tactics that were in play in 2016 are pretty much still out there,â€ says Joan Donovan, head of the Technology and Social Change Research Project at Harvard Kennedyâ€™s Shorenstein Center.
Among the features announced Monday were new interstitialsâ€”notices that appear in front of a postâ€”that warn users when content in their Instagram or Facebook feeds has been flagged as false by outside fact-checkers. Donovan says it makes sense to use a digital speed bump of sorts to restrict access to inaccurate content, but the notices may have the opposite effect.
â€œThe first accounts that they choose to enforce that policy on are going to get a lot of attention,â€ from both the media and curious users, she explained. â€œWe have to understand there's going to be a bit of a boomerang effect.â€ She says â€œmedia manipulatorsâ€ will test the system to see how Facebook responds, â€œand then they will innovate around them.â€ Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Facebook did not respond to inquiries about when or where the feature would be rolled out, or whether it would apply to all content that had been rated partly or completely false by third-party fact-checkers.
Donovan says sheâ€™s not sure if the featureâ€™s potential benefits are worth the risks of amplification, particularly since Facebook may not be able to identify and flag misleading content before it reaches people. â€œTaking it down two days later isn't helpful,â€ nor is hiding it behind a notice, she says, â€œespecially when it's misinformation that's traveling on the back of a viral news story, where we know that the first eight hours of that news story are the most consequential for people making assessments and bothering to read what the story is even about.â€ Also Monday, Facebook said it would attach new labels to pages or ads run by media outlets that it deems to be â€œstate-controlled,â€ like Russia Today. It said it will require that some pages with a lot of US-based users to be more transparent about whoâ€™s running themâ€”this will at first apply only to verified business pages, and later include pages that run ads on social issues, elections or politics in the US. In addition, ads that discourage people from voting would no longer be permitted.
But researchers say that these measures are too little too late. â€œEvery announcement like this, and all the recent publicity blitz has an undercurrent of inevitability,â€ says David Carroll, an associate professor at Parsons School of Design known for his quest to reclaim his Cambridge Analytica data.
 â€œIt shows that they still need to show that they're doing things. One advantage to these cosmetic things is that they look like they're significant moves, but they're really just like pretty small user interface tweaks.â€ But thatâ€™s not enough at this stage, he says.
The key question, researchers say, is enforcement, what Donovan calls â€œthe Achilles heel of all of these platform companies.â€ She says Facebook issues many policies related to hate speech, misinformation, and election integrity. â€œBut if theyâ€™re not willing to enforce those rulesâ€”especially on politicians, PACs, and super PACsâ€”then they havenâ€™t really done anything.â€ In September, Facebook said politicians would be exempt from the companyâ€™s usual policies prohibiting posting misinformation and other forms of problematic content in the name of newsworthiness. Earlier this month, that exemption was extended to advertisements, giving users free rein to lie in Facebook ads so long as they are political candidates or officeholders.
Business What Sam Altmanâ€™s Firing Means for the Future of OpenAI Steven Levy Business Sam Altmanâ€™s Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanityâ€™s Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg This is the â€œbig gaping holeâ€ Facebookâ€™s announcement Monday failed to address, says disinformation researcher (and WIRED Ideas contributor) Renee DiResta. Facebookâ€™s policies contradict themselves, she says, as they try to simultaneously argue that misinformation is a problem when disseminated by foreign actors, but free expression when posted by anyone that falls under the vague category of â€œpolitician.â€ Both DiResta and Donovan expressed concerns as to whether Facebookâ€™s new transparency measures and election integrity policies would be applied to political candidates at all. On the press call, Zuckerberg emphasized that he didnâ€™t think it was right for a private company like Facebook to â€œcensorâ€ the speech of politiciansâ€”a point he argued at length last week in a speech at Georgetown Universityâ€”but noted that there were exceptions, when the person calls for violence or urges voter suppression, for example.
Facebook was short on details as to how exactly it would determine a politician was doing so, and how it determines a user is a politician or political candidate. Katie Harbath, Facebookâ€™s public policy director for global elections, said Facebook would look at registration paperwork to determine whether campaigns are legitimate; though she offered no details as to who specifically would undertake the research, how the information would be communicated to moderators, and how frequently the information would be updated.
DiResta says the exemptions effectively communicate to bad actors that misinformation is allowed on Facebook, so long as you can find a way to get yourself labeled a politician or political candidate. â€œAnybody whoâ€™s a good troll should go and file papers to run for office at this point,â€ she joked. â€œRun for something thatâ€™s free to file forâ€”youâ€™re never going to get elected, but you can certainly troll the hell out of everybody else while youâ€™re doing it.â€ The death of cars was greatly exaggerated The first smartphone war 7 cybersecurity threats that can sneak up on you â€œForever chemicalsâ€ are in your popcornâ€” and your blood The spellbinding allure of Seoul's fake urban mountains ğŸ‘ Prepare for the deepfake era of video ; plus, check out the latest news on AI âœ¨ Optimize your home life with our Gear teamâ€™s best picks, from robot vacuums to affordable mattresses to smart speakers.
Staff Writer X Topics Facebook elections Social Media disinformation Paresh Dave Reece Rogers Reece Rogers Deidre Olsen David Gilbert David Gilbert Steven Levy Morgan Meaker Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
