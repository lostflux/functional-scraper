Law firm also penalised after chatbot invented six legal cases that were then used in an aviation injury claim US edition US edition UK edition Australia edition International edition Europe edition The Guardian - Back to home The Guardian News Opinion Sport Culture Lifestyle Show More Show More document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('News-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('News-checkbox-input').click(); } }) }) News View all News US news World news Environment US politics Ukraine Soccer Business Tech Science Newsletters Wellness document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Opinion-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Opinion-checkbox-input').click(); } }) }) Opinion View all Opinion The Guardian view Columnists Letters Opinion videos Cartoons document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Sport-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Sport-checkbox-input').click(); } }) }) Sport View all Sport Soccer NFL Tennis MLB MLS NBA NHL F1 Golf document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Culture-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Culture-checkbox-input').click(); } }) }) Culture View all Culture Film Books Music Art & design TV & radio Stage Classical Games document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('Lifestyle-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('Lifestyle-checkbox-input').click(); } }) }) Lifestyle View all Lifestyle Wellness Fashion Food Recipes Love & sex Home & garden Health & fitness Family Travel Money Search input google-search Search Support us Print subscriptions document.addEventListener('DOMContentLoaded', function(){ var columnInput = document.getElementById('US-edition-button'); if (!columnInput) return; // Sticky nav replaces the nav so element no longer exists for users in test. columnInput.addEventListener('keydown', function(e){ // keyCode: 13 => Enter key | keyCode: 32 => Space key if (e.keyCode === 13 || e.keyCode === 32) { e.preventDefault() document.getElementById('US-edition-checkbox-input').click(); } }) }) US edition UK edition Australia edition International edition Europe edition Search jobs Digital Archive Guardian Puzzles app Guardian Licensing The Guardian app Video Podcasts Pictures Inside the Guardian Guardian Weekly Crosswords Wordiply Corrections Facebook Twitter Search jobs Digital Archive Guardian Puzzles app Guardian Licensing US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness The judge said one of the fake decisions had ‘some traits that are superficially consistent with actual judicial decisions’ but other portions contained ‘gibberish’ and were ‘nonsensical’.
Photograph: Richard Drew/AP The judge said one of the fake decisions had ‘some traits that are superficially consistent with actual judicial decisions’ but other portions contained ‘gibberish’ and were ‘nonsensical’.
Photograph: Richard Drew/AP ChatGPT Two US lawyers fined for submitting fake court citations from ChatGPT Law firm also penalised after chatbot invented six legal cases that were then used in an aviation injury claim and agency Fri 23 Jun 2023 05.14 EDT A US judge has fined two lawyers and a law firm $5,000 (£3,935) after fake citations generated by ChatGPT were submitted in a court filing.
A district judge in Manhattan ordered Steven Schwartz, Peter LoDuca and their law firm Levidow, Levidow & Oberman to pay the fine after fictitious legal research was used in an aviation injury claim.
Schwartz had admitted that ChatGPT, a chatbot that churns out plausible text responses to human prompts, invented six cases he referred to in a legal brief in a case against the Colombian airline Avianca.
The judge P Kevin Castel said in a written opinion there was nothing “inherently improper” about using artificial intelligence for assisting in legal work, but lawyers had to ensure their filings were accurate.
“Technological advances are commonplace and there is nothing inherently improper about using a reliable artificial intelligence tool for assistance,” Castel wrote. “But existing rules impose a gatekeeping role on attorneys to ensure the accuracy of their filings.” The judge said the lawyers and their firm “abandoned their responsibilities when they submitted nonexistent judicial opinions with fake quotes and citations created by the artificial intelligence tool ChatGPT, then continued to stand by the fake opinions after judicial orders called their existence into question.” Levidow, Levidow & Oberman said in a statement on Thursday that its lawyers “respectfully” disagreed with the court that they had acted in bad faith. “We made a good-faith mistake in failing to believe that a piece of technology could be making up cases out of whole cloth,” it said.
Lawyers for Schwartz told Reuters he declined to comment. LoDuca did not immediately reply to a request from Reuters for comment, and his lawyer said they were reviewing the decision.
ChatGPT had suggested several cases involving aviation mishaps that Schwartz had not been able to find through usual methods used at his law firm. Several of those cases were not real, misidentified judges or involved airlines that did not exist.
Chatbots such as ChatGPT, developed by the US firm OpenAI , can be prone to “hallucinations” or inaccuracies. In one example ChatGPT falsely accused an American law professor of sexual harassment and cited a nonexistent Washington Post report in the process. In February a promotional video for Google’s rival to ChatGPT, Bard, gave an inaccurate answer to a query about the James Webb space telescope, raising concerns that the search company had been too hasty in launching a riposte to OpenAI’s breakthrough.
Chatbots are trained on a vast trove of data taken from the internet, although the sources are not available in many cases. Operating like a predictive text tool, they build a model to predict the likeliest word or sentence to come after a user’s prompt. This means factual errors are possible, but the human-seeming response can sometimes convince users that the answer is correct.
Sign up to TechScape Free weekly newsletter Alex Hern's weekly dive in to how technology is shaping our lives Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy.
 We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.
after newsletter promotion The judge said one of the fake decisions generated by the chatbot had “some traits that are superficially consistent with actual judicial decisions” but that other portions contained “gibberish” and were “nonsensical”.
In a separate written opinion, the judge threw out the underlying aviation claim, saying the statute of limitations had expired.
Reuters and Associated Press contributed to this report Explore more on these topics ChatGPT Chatbots OpenAI news More on this story More on this story Llama 2: why is Meta releasing open-source AI model and are there any risks? 20 Jul 2023 Claude 2: ChatGPT rival launches chatbot that can summarise a novel 12 Jul 2023 ChatGPT developer OpenAI to locate first non-US office in London 28 Jun 2023 AI race is disrupting education firms – and that is just the start 3 May 2023 UK watchdog warns chatbot developers over data protection laws 3 Apr 2023 Italy’s privacy watchdog bans ChatGPT over data breach concerns 1 Apr 2023 AI chatbots making it harder to spot phishing emails, say experts 29 Mar 2023 Bard: how Google’s chatbot gave me a comedy of errors 22 Mar 2023 Most viewed Most viewed US World Environment US Politics Ukraine Soccer Business Tech Science Newsletters Wellness News Opinion Sport Culture Lifestyle About us Help Complaints & corrections SecureDrop Work for us Privacy policy Cookie policy Terms & conditions Contact us All topics All writers Digital newspaper archive Facebook YouTube Instagram LinkedIn Twitter Newsletters Advertise with us Guardian Labs Search jobs Back to top
