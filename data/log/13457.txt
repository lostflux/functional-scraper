Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business Axon‚Äôs Taser-Drone Plans Prompt AI Ethics Board Resignations Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save Application Ethics Surveillance Sector Education Public safety Technology Machine vision A majority of Axon‚Äôs AI Ethics Board resigned in protest yesterday, following an announcement last week that the company planned to equip drones with Tasers and cameras as a way to end mass shootings in schools.
The company backed down on its proposal Sunday, but the damage had been done. Axon had first asked the advisory board to consider a pilot program to outfit a select number of police departments with Taser drones last year, and again last month. A majority of the AI Ethics Board, which comprises AI ethics experts, law professors, and police reform and civil liberties advocates, opposed it both times. Advisory board chairman Barry Friedman told WIRED that Axon never asked the group to review any scenario involving schools, and that launching the pilot program without addressing previously stated concerns is dismissive of the board and its established process.
In a joint letter of resignation made public today, nine members of the AI Ethics Board said the company appeared to be ‚Äútrading on the tragedy of recent mass shootings‚Äù in Buffalo and Uvalde, Texas. Despite mentioning both mass shootings in a press release announcing the pilot project, Axon CEO Rick Smith denied allegations that the company‚Äôs proposal was opportunistic in a Reddit AMA.
 Smith said a Taser drone could still be years off, but that he envisions 50 to 100 Taser drones in a school, run by trained staff. Ahead of Axon pausing the pilot project, Freidman called it a ‚Äúpoorly thought out idea,‚Äù and said that if the idea is unlikely to come to fruition, then Axon‚Äôs pitch ‚Äúdistracts the world from real solutions to a serious problem.‚Äù Another signatory to the resignation letter, University of Washington law professor Ryan Calo, calls Axon‚Äôs idea to test Taser drones in schools ‚Äúa very, very bad idea.‚Äù Meaningful change to curb gun violence in the United States requires confronting issues like alienation, racism, and widespread access to guns. The deaths of children in Uvalde, Texas, did not happen, Calo says, because the school lacked Tasers.
‚ÄúIf we're going to address the prospect of violence in schools, we all know that there are much better ways to do that,‚Äù he says.
The board had earlier expressed concern that weaponized drones could lead to increased use of force by police, especially in communities of color. A report detailing the advisory board‚Äôs evaluation of a pilot program was due out this fall.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight The real disappointment, Calo says, isn‚Äôt that the company didn‚Äôt do exactly what the board advised. It‚Äôs that Axon announced its Taser-drone plans before the board could fully detail its opposition. ‚ÄúAll of a sudden, out of nowhere, the company decided to just abandon that process,‚Äù he says. ‚ÄúThat‚Äôs why it‚Äôs so disheartening.‚Äù He finds it tough to imagine that police or trained staff in a school will possess the situational awareness to use a Taser drone judiciously. Even if a drone operator successfully saved the lives of suspects or people in marginalized or vulnerable communities, the technology wouldn‚Äôt stay there.
‚ÄúI think there will be mission creep, and that they will begin to use it in more and more contexts, and I think that the announcement by Axon to use it in a completely different context is proof of that,‚Äù Calo says. ‚ÄúA situation where there are ubiquitous cameras and remotely deployed Tasers is not a world that I want to live in. Period.‚Äù Axon‚Äôs is the latest external AI ethics board to come in conflict with its associated tech company. Google famously convened and disbanded an AI ethics advisory group in roughly a week in 2019. These panels often operate without clear structure beyond asking members to sign a nondisclosure agreement, and companies can use them for ‚Äúvirtue signaling‚Äù rather than substantive input, says Cortnie Abercrombie, founder of the nonprofit AI Truth. Her organization is currently researching best practices for corporate AI ethics.
In Axon‚Äôs case, multiple AI Ethics Board members who spoke with WIRED said that the company did have a record of listening to their suggestions, including in a 2019 decision not to deploy facial recognition on body cameras. That made the sudden Taser-drone announcement all the more jarring.
There‚Äôs usually conflict in companies between people who understand a technology‚Äôs risks and limitations and those who want to make products and profits, says Wael AbdAlmageed, a computer scientist at the University of Southern California who resigned from the Axon AI Ethics Board. If companies like Axon want to take AI ethics seriously, he says, the role of these boards cannot be advisory anymore.
‚ÄúIf the AI Ethics Board says this technology is problematic and the company should not develop products, then they shouldn‚Äôt. I know it‚Äôs a difficult proposition, but I really think this is how it has to be done,‚Äù he says. ‚ÄúWe‚Äôve seen problems at Google and other companies for people they hired to talk about AI ethics.‚Äù The AI Ethics Board tried to persuade Axon that it should be responsive to the communities affected by its products, Friedman says, rather than the police who buy them. The company did create a community advisory committee, but Friedman says that until AI ethics boards figure out how to bring local communities into the procurement process, ‚Äúthe vendors of policing technology are going to keep playing to the police.‚Äù Four members of the AI Ethics Board didn‚Äôt sign the resignation letter. They include former Seattle police chief Carmen Best, former Los Angeles police chief Charlie Beck, and former California Highway Patrol commissioner Warren Stanley.
You Might Also Like ‚Ä¶ üì® Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cash‚Äôs Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you üîå Charge right into summer with the best travel adapters , power banks , and USB hubs Senior Writer X Topics artificial intelligence drones Tasers weapons Khari Johnson Will Knight Khari Johnson Will Knight Steven Levy Will Knight Khari Johnson Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
