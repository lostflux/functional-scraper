Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Amazon launches Bedrock for generative AI, escalating AI cloud wars Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Yesterday Amazon launched Bedrock for generative AI, a landscape-shaking move that also escalated the cloud AI wars that have been heating up over the past year.
Bedrock, a new AWS cloud service, allows developers to build and scale generative AI chatbots and other applications in the cloud, using internal organizational data to fine-tune on a variety of leading pretrained large language models (LLMs) from Anthropic , AI21 and Stability AI , as well as two new LLMs in Amazon’s Titan model family.
Amazon CEO Andy Jassy spoke directly about the AWS focus on enterprise AI with Bedrock when speaking to CNBC’s Squawk Box yesterday.
“Most companies want to use these large language models, but the really good ones take billions of dollars to train and many years, and most companies don’t want to go through that,” he said. “So what they want to do is they want to work off of a foundational model that’s big and great already and then have the ability to customize it for their own purposes. And that’s what Bedrock is.” VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! According to Gartner analyst Sid Nag, with the buzz and excitement around generative AI news from Google and Microsoft, Amazon was overdue to follow suit.
“Amazon had to do something ,” he told VentureBeat in an interview. “The cloud providers are obviously best suited to handle data-heavy generative AI, because they are the ones that have these hyperscale cloud computing storage offerings.” Bedrock, he explained, provides a meta layer of usability for foundation models on AWS. Amazon is also notably calling out its ability to provide a secure environment for organizations to use this type of AI, he added. “Organizations want to create their own walled garden in a generative AI model, so I think you’ll see more and more of that,” he said.
In addition, Amazon’s Code Whisperer announcement, which is a AI-driven coding companion that uses an LLM under the hood and supports Python, Java, JavaScript and other languages, is also a key effort to make sure AWS competes in cloud AI, Nag said.
Bedrock’s multiple models makes Amazon’s AWS attractive Emad Mostaque, CEO of Stability AI, pointed out that Bedrock’s offering of multiple models including Stable Diffusion plays to Amazon’s history of focusing on choice. “In his original plan to $100 billion of revenue, Jeff Bezos envisioned that half that revenue would be Amazon products and half third party through their marketplace,” he told VentureBeat in a message.
While it may have been surprising that Cohere was not on the list of Bedrock models — it is available on SageMaker and AWS — Cohere CEO Aidan Gomez said the company decided not to participate in the Bedrock product at this time. “We may change our opinion and join the ‘model zoo’ in the future, but we decided not to be a part of this initial release,” he told VentureBeat by email.
But Yoav Shoham, cofounder and co-CEO of AI21 Labs, focused on the fact that AWS has curated a set of best-in-class models. “There is a class of text-based applications particularly well served by Jurassic-2’s multilingual, multisized models,” he told VentureBeat by email. “We look forward to enabling, jointly with AWS, the creation of many such applications.” Low-code platform Pega was noted in AWS VP Swami Sivasubramanian’s blog post yesterday as one of Bedrock’s early adoptors. Peter van der Putten, director of the AI lab at Pega, said the company intends to use Bedrock for a range of use cases in their platform, which they will make available to its customers.
“For example, just based on a simple sentence such as ‘create a dental insurance claim application,’ we can generate a runnable prototype low-code app including workflow, data models and other artifacts, which will jumpstart, democratize and accelerate development of low-code business applications,” he said. “There are also other areas in our low-code platform where we leverage it, such as allowing users to ask for reports just using natural language.” The desire for multicloud will keep the cloud AI competition going What makes Amazon very attractive for Pega and its customers, he added, is Bedrock’s access to a wide range of models, commercial as well as open source, in “a safe, enterprise-scale manner,” he said. But he also called out the importance of multicloud options: “In addition to this, our clients will also be able to access OpenAI models through Azure, and we are in discussion with other major cloud players as well, plus keeping a close eye on open source, for the most sensitive applications.” That, says Gartner’s Nag, is the irony of the cloud AI wars.
“The fundamental premise of building a generative AI model is democratization of data — the more information you have, the higher the fidelity of the response,” he said. “But the whole philosophy and approach that cloud providers have historically taken is ‘I should own everything, everything should run in my estate.’ So on the one hand, they want to be very predatory, but on the other hand, are they willing to share data across multiple estates?” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
