Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business Spooked by ChatGPT, US Lawmakers Want to Create an AI Regulator (L-R): Christina Montgomery, chief privacy and trust officer at IBM, Gary Marcus, professor emeritus at New York University, and Sam Altman, chief executive officer and co-founder of OpenAI, swear in during a Senate Judiciary Subcommittee hearing in Washington, DC on May 16, 2023.
Photograph: Eric Lee/Bloomberg/Getty Images Save this story Save Save this story Save Since the tech industry began its love affair with machine learning about a decade ago , US lawmakers have chattered about the potential need for regulation to rein in the technology. No proposal to regulate corporate AI projects has got close to becoming law‚Äîbut OpenAI‚Äôs release of ChatGPT last November has convinced some senators that there is now an urgent need to do something to protect people‚Äôs rights against the potential harms of AI technology.
At a hearing held by a Senate Judiciary subcommittee yesterday, attendees heard a terrifying laundry list of ways artificial intelligence can harm people and democracy. Senators from both parties spoke in support of creating a new arm of the US government dedicated to regulating AI. The idea even got the backing of Sam Altman, CEO of OpenAI.
‚ÄúMy worst fear is that we‚Äîthe field, the technology, the industry‚Äîcause significant harm to the world,‚Äù Altman said. He also endorsed the idea of AI companies submitting their AI models to testing by outsiders and said a US AI regulator should have the power to grant or revoke licenses for creating AI above a certain threshold of capability.
A number of US federal agencies, including the Federal Trade Commission and the Food and Drug Administration , already regulate how companies use AI. But Senator Peter Welch, a Democrat from Vermont, said his time in Congress has convinced him that it can‚Äôt keep up with the pace of technological change.
‚ÄúUnless we have an agency that is going to address these questions from social media and AI, we really don‚Äôt have much of a defense against the bad stuff, and the bad stuff will come,‚Äù he says. ‚ÄúWe absolutely have to have an agency.‚Äù Senator Richard Blumenthal from Connecticut, a fellow Democrat who chaired the hearing, said that a new AI regulator may be necessary because Congress has shown it often fails to keep pace with new technology. US lawmakers‚Äô spotty track record on digital privacy and social media were mentioned frequently during the hearing.
But Blumenthal also expressed concern that a new federal AI agency could struggle to match the tech industry‚Äôs speed and power. ‚ÄúWithout proper funding you‚Äôll run circles around those regulators,‚Äù he told Altman and fellow industry witness Christina Montgomery, IBM‚Äôs chief privacy and trust officer. Altman and Montgomery were joined by psychology professor turned AI commentator Gary Marcus , who advocated for the creation of an international body to monitor AI progress and encourage safe development of the technology.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Blumenthal opened the hearing with an AI voice clone of himself reciting text written by ChatGPT to highlight how AI can produce convincing results.
The senators did not suggest a name for the prospective agency or map out its possible functions in detail. They also discussed less radical regulatory responses to recent progress in AI‚Äîsuch as the requiring of public documentation of AI systems‚Äô limitations or the datasets used to create them, akin to an AI nutrition label‚Äîideas that had been introduced years ago by researchers like former Google ethical AI team lead Timnit Gebru , who was ousted from the company after a dispute about a prescient research paper which warned about the limitations and dangers of large language models.
Another change urged by lawmakers and industry witnesses alike was requiring disclosure to inform people when they‚Äôre conversing with a language model and not a human, or when AI technology makes important decisions with life-changing consequences. One example could be a disclosure requirement to reveal when a facial recognition match is the basis of an arrest or criminal accusation.
The Senate hearing follows growing interest from US and European governments, and even some tech insiders, in putting new guardrails on AI to prevent it from harming people. In March, a group letter signed by major names in tech and AI called for a six-month pause on AI development , and this month, the White House called in executives from OpenAI, Microsoft, and other companies and announced it is backing a public hacking contest to probe generative AI systems.
 The European Union is also finalizing a sweeping law called the AI Act.
IBM‚Äôs Montgomery urged Congress yesterday to take inspiration from the AI Act, which categorizes AI systems by the risks they pose to people or society and sets rules for‚Äîor even bans‚Äîthem accordingly. She also endorsed the idea of encouraging self-regulation, highlighting her position on IBM‚Äôs AI ethics board, although at Google and Axon those structures have become mired in controversy.
The Center for Data Innovation, a tech think tank, said in a letter released after yesterday‚Äôs hearing that the US doesn‚Äôt need a new regulator for AI. ‚ÄúJust as it would be ill-advised to have one government agency regulate all human decision-making, it would be equally ill-advised to have one agency regulate all AI,‚Äù the letter said.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg ‚ÄúI don‚Äôt think it‚Äôs pragmatic, and it‚Äôs not what they should be thinking about right now,‚Äù says Hodan Omaar, a senior analyst at the center.
Omaar says the idea of booting up a whole new agency for AI is improbable given that Congress has yet to follow through on other necessary tech reforms, like the need for overarching data privacy protections. She believes it is better to update existing laws and allow federal agencies to add AI oversight to their existing regulatory work.
The Equal Employment Opportunity Commission and Department of Justice issued guidance last summer on how businesses that use algorithms in hiring‚Äîalgorithms that may expect people to look or behave a certain way‚Äîcan stay in compliance with the Americans with Disabilities Act. Such guidance shows how AI policy can overlap with existing law and involve many different communities and use cases.
Alex Engler, a fellow at the Brookings Institution, says he‚Äôs concerned that the US could repeat problems that sank federal privacy regulation last fall.
 The historic bill was scuppered by California lawmakers who withheld their votes because the law would override the state‚Äôs own privacy legislation. ‚ÄúThat‚Äôs a good enough concern,‚Äù Engler says. ‚ÄúNow is that a good enough concern that you‚Äôre gonna say we‚Äôre just not going to have civil society protections for AI? I don't know about that.‚Äù Though the hearing touched on potential harms of AI‚Äîfrom election disinformation to conceptual dangers that don‚Äôt exist yet, like self-aware AI ‚Äîgenerative AI systems like ChatGPT that inspired the hearing got the most attention. Multiple senators argued they could increase inequality and monopolization. The only way to guard against that, said Senator Cory Booker, a Democrat from New Jersey who has cosponsored AI regulation in the past and supported a federal ban on face recognition, is if Congress creates rules of the road.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics artificial intelligence Regulation government ethics congress Policy ChatGPT Steven Levy Will Knight Will Knight Steven Levy Will Knight Khari Johnson Khari Johnson Amanda Hoover Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
