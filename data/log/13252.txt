Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google is bringing custom tensor processing units to its public cloud Share on Facebook Share on X Share on LinkedIn A Google server rack with TPUs.
Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google has begun to build its own custom application-specific integrated circuit (ASIC) chip called tensor processing units (TPUs), Google chief executive Sundar Pichai said today at the Google I/O developer conference in Mountain View, California. The name is inspired by Google’s TensorFlow open source deep learning framework. But the technology is one of a kind — something that makes sense only at Google scale.
These TPUs were used in the AlphaGo artificial intelligence (AI) powered Go player that beat top-ranked Go player Lee Sedol , Pichai said. It also works inside Google search and Google Street View. Now it sounds like they will become available for other companies to use, too.
“When you use the Google Cloud Platform, you can take advantage of TPUs as well,” Pichai said.
Above: How TPUs compare with other chips.
Specialty hardware — sort of taking a cue from the holographic processing unit (HPU) inside Microsoft’s HoloLens augmented reality headset — will not be the only thing that will make the Google public cloud stand out from market leader Amazon Web Services (AWS).
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Also, over time Google will expose more and more machine learning APIs, Pichai said. Google has already launched the Cloud Machine Learning Platform service and the Vision API.
“Our goal is to lead the industry on machine learning and make that innovation available to our customers,” Google distinguished hardware engineer Norm Jouppi wrote in a blog post.
 “Building TPUs into our infrastructure stack will allow us to bring the power of Google to developers across software like TensorFlow and Cloud Machine Learning with advanced acceleration capabilities. Machine Learning is transforming how developers build intelligent applications that benefit customers and consumers, and we’re excited to see the possibilities come to life.” Presumably the TPU chips will be useful for AI. But GPUs are being used to power databases like Nvidia-backed MapD.
 Time will tell just how much the TPUs will cost and how easy it will be to develop for them.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
