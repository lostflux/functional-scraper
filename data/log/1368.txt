Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Matt Burgess Security Criminals Have Created Their Own ChatGPT Clones Photograph: tiero/Getty Images Save this story Save Save this story Save It didn't take long. Just months after OpenAI‚Äôs ChatGPT chatbot upended the startup economy , cybercriminals and hackers are claiming to have created their own versions of the text-generating technology. The systems could, theoretically at least, supercharge criminals‚Äô ability to write malware or phishing emails that trick people into handing over their login information.
Since the start of July, criminals posting on dark-web forums and marketplaces have been touting two large language models (LLMs) they say they‚Äôve produced. The systems, which are said to mimic the functionalities of ChatGPT and Google‚Äôs Bard , generate text to answer the questions or prompts users enter. But unlike the LLMs made by legitimate companies, these chatbots are marketed for illegal activities.
There are outstanding questions about the authenticity of the chatbots. Cybercriminals are not exactly trustworthy characters, and there remains the possibility that they‚Äôre trying to make a quick buck by scamming each other. Despite this, the developments come at a time when scammers are exploiting the hype of generative AI for their own advantage.
In recent weeks, two chatbots have been advertised on dark-web forums‚ÄîWormGPT and FraudGPT‚Äîaccording to security researchers monitoring the activity. The LLMs developed by large tech companies, such as Google, Microsoft, and OpenAI, have a number of guardrails and safety measures in place to stop them from being misused. If you ask them to generate malware or write hate speech, they‚Äôll generally refuse.
The shady LLMs claim to strip away any kind of safety protections or ethical barriers. WormGPT was first spotted by independent cybersecurity researcher Daniel Kelley, who worked with security firm SlashNext to detail the findings.
 WormGPT‚Äôs developers claim the tool offers an unlimited character count and code formatting. ‚ÄúThe AI models are notably useful for phishing, particularly as they lower the entry barriers for many novice cybercriminals,‚Äù Kelley says in an email. ‚ÄúMany people argue that most cybercriminals can compose an email in English, but this isn‚Äôt necessarily true for many scammers.‚Äù In a test of the system, Kelley writes, it was asked to produce an email that could be used as part of a business email compromise scam, with a purported CEO writing to an account manager to say an urgent payment was needed. ‚ÄúThe results were unsettling,‚Äù Kelley wrote in the research. The system produced ‚Äúan email that was not only remarkably persuasive but also strategically cunning.‚Äù Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg In forum posts, the WormGPT developer claimed the system was built on the GPTJ language model, an open source language model that was developed by AI research group EleutherAI in 2021. They refused to disclose the data sets they used to train the system, according to Kelley‚Äôs research.
Meanwhile, the creator of FraudGPT has claimed loftier potential for their system, suggesting it could ‚Äúcreate undetectable malware‚Äù and find leaks and vulnerabilities, as well as crafting text that could be used in online scams. Rakesh Krishnan, the senior threat analyst at security firm Netenrich who found FraudGPT , says the person selling it has advertised the product on multiple dark-web forums and also on Telegram channels.
Krishnan says the creator of the system published a video appearing to show the chatbot operating and generating a scammy email. They were also trying to sell access to the system for $200 per month, or a yearly cost of $1,700. Krishnan says that in conversations with the developer behind FraudGPT, they claimed to have a few hundred subscribers and pushed for a sale, while the WormGPT creator appeared to have received payments into a cryptocurrency wallet address they shared. ‚ÄúAll these projects are in their infancy,‚Äù Krishnan says. He adds, ‚Äúwe haven‚Äôt got much feedback‚Äù into whether people are purchasing or using the systems.
While those touting the chatbots claim they exist, it is hard to verify the makeup and legitimacy of the systems. Cybercriminal scammers are known to scam other scammers, with previous research showing that they frequently try to rip each other off , don‚Äôt provide what they claim they are selling, and offer bad customer service. Sergey Shykevich, a threat intelligence group manager at security firm Check Point, says there are some hints that people are using WormGTP. ‚ÄúIt seems there is a real tool,‚Äù Shykevich says. The seller behind the tool is ‚Äúrelatively reliable‚Äù and has a history on cybercrime forums, he says.
There are more than 100 responses to one post about the WormGPT, Shykevich says, although some of these say the seller isn‚Äôt very responsive to their inquiries and others ‚Äúweren‚Äôt very excited‚Äù about the system. Shykevich is less convinced about FraudGPT‚Äôs authenticity‚Äîthe seller has also claimed to have systems called DarkBard and DarkBert.
 Shykevich says some of the posts from the seller were removed from the forums. Either way, the Check Point researcher says there‚Äôs no sign that any of the systems are more capable than ChatGPT, Bard, or other commercial LLMs.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Kelley says he believes claims about the malicious LLMs created so far are ‚Äúslightly overexaggerated.‚Äù But he adds, ‚Äúthis is not necessarily different from what legitimate businesses do in the real world.‚Äù Despite questions about the systems, it isn‚Äôt a surprise that cybercriminals want to get in on the LLM boom. The FBI has warned that cybercriminals are looking at using generative AI in their work, and European law enforcement agency Europol has issued a similar warning.
 The law enforcement agencies say LLMs could help cybercriminals with fraud, impersonation, and other social engineering faster than before and also improve their written English.
Whenever any new product, service, or event gains public attention‚Äîfrom the Barbie movie to the Covid-19 pandemic ‚Äîscammers rush to include it in their hacking artillery. So far, scammers have tricked people into downloading password-stealing malware through fake ads for ChatGPT, Bard, Midjourney, and other generative AI systems on Facebook.
Researchers at security firm Sophos have spotted the operators of pig butchering and romance scams accidentally including generated text in their messages ‚Äî‚ÄúAs a language model of ‚Äòme‚Äô I don‚Äôt have feelings or emotions like humans do,‚Äù one message said. And hackers have also been stealing tokens to provide them with access to OpenAI‚Äôs API and access to the chatbot at scale.
In his WormGPT report, Kelley notes that cybercriminals are often sharing jailbreaks that allow people to bypass the safety restrictions put in place by the makers of popular LLMs. But even unconstrained versions of these models may, thankfully, not be that useful for cybercriminals in their current form.
Shykevich, the Check Point researcher, says that even when he has seen cybercriminals try to use public models, they haven‚Äôt been effective. They can ‚Äúcreate ransomware strains, info stealers, but no better than even an average developer,‚Äù he says. However, those on the cybercrime forums are still talking about making their own clones, Shykevich says, and they‚Äôre only going to get better at using the systems. So be careful what you click.
Update: 4:15 pm ET, August 7, 2023: A previous version of this article misspelled Daniel Kelley's surname. We regret the error.
You Might Also Like ‚Ä¶ üì® Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cash‚Äôs Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you üîå Charge right into summer with the best travel adapters , power banks , and USB hubs Senior writer X Topics Crime artificial intelligence hacking ChatGPT malware phishing Matt Burgess Andy Greenberg Lily Hay Newman Lily Hay Newman Lily Hay Newman Andy Greenberg Andrew Couts Matt Burgess Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
