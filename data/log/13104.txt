Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages AWS adopts Nvidia’s Tesla T4 chip for AI inference Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Amazon’s AWS today announced new EC2 instances with Tesla T4 GPUs, which it says will be available via G4 instances to customers in the coming weeks. T4 will also be available through the Amazon Elastic Container service for Kubernetes.
“It will be featuring Nvidia T4 processors and really designed for machine learning and to help our customers shrink the time that it takes to do inference at the edge — where that response time really matters — but also reduce the cost,” AWS VP of compute Matt Garman said onstage today during the keynote address at San Jose State University.
The new instance will be able to harness up to eight T4 GPUs simultaneously in the cloud.
Nvidia debuted the T4 for datacenters last September.
 The Tesla T4 uses Turing architecture and is packed with 2,560 CUDA cores and 320 Tensor cores with the power to process queries nearly 40 times faster than a CPU.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Since Nvidia debuted the GPU, it has been incorporated into datacenters run by companies like Cisco, Dell EMC, and Hewlett Packard Enterprise.
Above: Nvidia T4 Nvidia also announced general availability of the Constellation platform for autonomous driving , the Safety Force Field for autonomous vehicles, Jetson Nano computer for embedded devices , and the reorganization of more than 40 Nvidia deep learning acceleration libraries under the new umbrella name CUDA-X AI.
CUDA-X AI libraries work with popular frameworks like MXNET, PyTorch, and TensorFlow.
Also today: Nvidia researchers introduced GauGAN , an AI system trained on 1 million Flickr photos that can create lifelike landscape images.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
