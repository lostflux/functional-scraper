Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Eric Lander Alondra Nelson Ideas Americans Need a Bill of Rights for an AI-Powered World Photo-Illustration: Sam Whitney; Getty Images Save this story Save Save this story Save Application Ethics Face recognition Regulation Prediction Source Data Biometric In the past decade, data-driven technologies have transformed the world around us. We‚Äôve seen what‚Äôs possible by gathering large amounts of data and training artificial intelligence to interpret it: computers that learn to translate languages , facial recognition systems that unlock our smartphones , algorithms that identify cancers in patients. The possibilities are endless.
Eric Lander is science adviser to the president and director of the White House Office of Science and Technology Policy.
Alondra Nelson is deputy director for science and society at the White House Office of Science and Technology Policy.
But these new tools have also led to serious problems. What machines learn depends on many things‚Äîincluding the data used to train them.
Data sets that fail to represent American society can result in virtual assistants that don‚Äôt understand Southern accents; facial recognition technology that leads to wrongful, discriminatory arrests; and health care algorithms that discount the severity of kidney disease in African Americans, preventing people from getting kidney transplants.
Training machines based on earlier examples can embed past prejudice and enable present-day discrimination. Hiring tools that learn the features of a company‚Äôs employees can reject applicants who are dissimilar from existing staff despite being well qualified‚Äîfor example, women computer programmers.
Mortgage approval algorithms to determine credit worthiness can readily infer that certain home zip codes are correlated with race and poverty, extending decades of housing discrimination into the digital age. AI can recommend medical support for groups that access hospital services most often, rather than those who need them most. Training AI indiscriminately on internet conversations can result in ‚Äú sentiment analysis‚Äù that views the words ‚ÄúBlack,‚Äù ‚ÄúJew,‚Äù and ‚Äúgay‚Äù as negative.
These technologies also raise questions about privacy and transparency. When we ask our smart speaker to play a song, is it recording what our kids say ? When a student takes an exam online, should their webcam be monitoring and tracking their every move? Are we entitled to know why we were denied a home loan or a job interview? Additionally, there‚Äôs the problem of AI being deliberately abused.
Some autocracies use it as a tool of state-sponsored oppression, division, and discrimination.
In the United States, some of the failings of AI may be unintentional, but they are serious and they disproportionately affect already marginalized individuals and communities. They often result from AI developers not using appropriate data sets and not auditing systems comprehensively, as well as not having diverse perspectives around the table to anticipate and fix problems before products are used (or to kill products that can‚Äôt be fixed).
In a competitive marketplace, it may seem easier to cut corners. But it‚Äôs unacceptable to create AI systems that will harm many people, just as it‚Äôs unacceptable to create pharmaceuticals and other products‚Äîwhether cars, children‚Äôs toys, or medical devices‚Äîthat will harm many people.
Americans have a right to expect better. Powerful technologies should be required to respect our democratic values and abide by the central tenet that everyone should be treated fairly. Codifying these ideas can help ensure that.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Soon after ratifying our Constitution, Americans adopted a Bill of Rights to guard against the powerful government we had just created‚Äîenumerating guarantees such as freedom of expression and assembly, rights to due process and fair trials, and protection against unreasonable search and seizure. Throughout our history we have had to reinterpret, reaffirm, and periodically expand these rights. In the 21st century, we need a ‚Äúbill of rights‚Äù to guard against the powerful technologies we have created.
Our country should clarify the rights and freedoms we expect data-driven technologies to respect. What exactly those are will require discussion, but here are some possibilities: your right to know when and how AI is influencing a decision that affects your civil rights and civil liberties; your freedom from being subjected to AI that hasn‚Äôt been carefully audited to ensure that it‚Äôs accurate, unbiased, and has been trained on sufficiently representative data sets; your freedom from pervasive or discriminatory surveillance and monitoring in your home, community, and workplace; and your right to meaningful recourse if the use of an algorithm harms you.
Of course, enumerating the rights is just a first step. What might we do to protect them? Possibilities include the federal government refusing to buy software or technology products that fail to respect these rights, requiring federal contractors to use technologies that adhere to this ‚Äúbill of rights,‚Äù or adopting new laws and regulations to fill gaps. States might choose to adopt similar practices.
In the coming months, the White House Office of Science and Technology Policy (which we lead) will be developing such a bill of rights, working with partners and experts across the federal government, in academia, civil society, the private sector, and communities all over the country.
Technology can only work for everyone if everyone is included, so we want to hear from and engage with everyone. You can email us directly at ai-equity@ostp.eop.gov.
We‚Äôre starting today with a public request for information about technologies used to identify people and infer attributes, often called biometrics‚Äîincluding facial recognition , but also systems that can recognize and analyze your voice , physical movements and gestures, heart rate, and more. We‚Äôre starting here because of how widely they‚Äôre being adopted, and how rapidly they‚Äôre evolving, not just for identification and surveillance, but also to infer our emotional states and intentions.
 We want to hear from experts on biometric data collection and use, but also many others: travelers who‚Äôve been asked to scan their faces before boarding a plane, workers whose employers gave them fitness trackers to monitor for fatigue , and teachers whose virtual lecture software purports to show which students aren‚Äôt paying attention in class.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg We want to hear from HR professionals whose hiring software might be using voice and behavioral analysis, from IT professionals and consumers who are buying and setting up these technologies, from data scientists and software engineers who are designing and building them‚Äîand anyone else who‚Äôs encountered these technologies in their daily life. Whatever your perspective, we‚Äôre eager to listen.
Developing a bill of rights for an AI-powered world won‚Äôt be easy, but it‚Äôs critical.
From its founding, America has been a work in progress‚Äîaspiring to values, recognizing shortcomings, and working to fix them. We should hold AI to this standard as well. It‚Äôs on all of us to ensure that data-driven technologies reflect, and respect, our democratic values.
WIRED Opinion publishes articles by outside contributors representing a wide range of viewpoints. Read more opinions here , and see our submission guidelines here.
 Submit an op-ed at opinion@wired.com.
üì© The latest on tech, science, and more: Get our newsletters ! Is Becky Chambers the ultimate hope for science fiction? An excerpt from The Every, Dave Eggers' new novel Why James Bond doesn't use an iPhone The time to buy your holiday presents now Religious exemptions for vaccine mandates shouldn't exist üëÅÔ∏è Explore AI like never before with our new database üéÆ WIRED Games: Get the latest tips, reviews, and more ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Topics Wired Opinion artificial intelligence ethics Tech Policy and Law government Meghan O'Gieblyn Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
