Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Google releases Model Card Toolkit to promote AI model transparency Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Google today released the Model Card Toolkit , a toolset designed to facilitate AI model transparency reporting for developers, regulators, and downstream users. It’s based on Google’s Model Cards framework for reporting on model provenance, usage, and “ethics-informed” evaluation, which aims to provide an overview of a model’s suggested uses and limitations.
Over the past year, Google publicly launched Model Cards, which sprang from a Google AI whitepaper published in October 2018. Model Cards specify model architectures and provide insight into factors that help ensure optimal performance for given use cases. To date, Google has released Model Cards for open source models built on its MediaPipe platform , as well as its commercial Cloud Vision API Face Detection and Object Detection services.
The Model Card Toolkit aims to make it easier for third parties to create Model Cards by compiling the necessary information and aiding in the creation of interfaces for different audiences. A JSON schema specifies the fields to include in a Model Card. Using the model provenance data stored with ML Metadata (MLMD), the Model Card Toolkit automatically fills the JSON with information, including data class distributions and performance statistics. It also provides a ModelCard data API to represent an instance of the JSON schema and visualize it as a Model Card.
Above: An example of a Model Card.
Model Card creators can choose which metrics and graphs to display in the final Model Card, including stats that highlight areas where the model’s performance could deviate from its overall performance. Once the Model Card Toolkit has populated the Model Card with key metrics and graphs, developers can supplement this with information regarding the model’s limitations, intended usage, trade-offs, and ethical considerations otherwise unknown to model users. If a model underperforms for certain slices of data, the Model Cards’ limitations section offers a place to acknowledge that, along with mitigation strategies to help address the issues.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “This type of information is critical in helping developers decide whether or not a model is suitable for their use case, and helps Model Card creators provide context so that their models are used appropriately,” wrote Google Research software engineers Huanming Fang and Hui Miao in a blog post. “Right now, we’re providing one UI template to visualize the Model Card, but you can create different templates in HTML should you want to visualize the information in other formats.” The idea of Model Cards emerged following Microsoft’s work on “ datasheets for data sets ,” or datasheets intended to foster trust and accountability through documenting data sets’ creation, composition, intended uses, maintenance, and other properties. Two years ago, IBM proposed its own form of model documentation in voluntary factsheets called “Supplier’s Declaration of Conformity” (DoC) to be completed and published by companies developing and providing AI. Other attempts at an industry standard for documentation include Responsible AI Licenses (RAIL) , a set of end-user and source code license agreements with clauses restricting the use, reproduction, and distribution of potentially harmful AI technology, and a framework called SECure that attempts to quantify the environmental and social impact of AI.
“Fairness, safety, reliability, explainability, robustness, accountability — we all agree that they are critical,” Aleksandra Mojsilovic, head of AI foundations at IBM Research and codirector of the AI Science for Social Good program, wrote in a 2018 blog post. “Yet, to achieve trust in AI, making progress on these issues will not be enough; it must be accompanied with the ability to measure and communicate the performance levels of a system on each of these dimensions.” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
