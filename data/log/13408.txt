Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business A Zelensky Deepfake Was Quickly Defeated. The Next One Might Not Be Photograph: Emin Sansar/Getty Images Save this story Save Save this story Save Application Deepfakes Safety Sector Public safety Social media Source Data Video On March 2, the Ukraine government‚Äôs Center for Strategic Communication warned that its enemies might be preparing a ‚Äú deepfake ‚Äù video that appeared to show president Volodymyr Zelensky announcing his surrender to Russia‚Äôs invasion. On Wednesday, that warning appeared prescient.
A fake video emerged on Facebook and YouTube in which a strangely motionless version of Zelensky asked Ukrainian troops to lay down their weapons in a voice different from his usual tone. The clip was also posted to Telegram and Russian social network VKontakte, according to the US think tank the Atlantic Council.
 TV Channel Ukraine 24 said hackers defaced its website with a still from the video and inserted a summary of the fake news into a broadcast‚Äôs scrolling chyron.
Minutes after the TV station posted about the hack, Zelensky himself posted a Facebook video denying that he had asked Ukrainians to lay down their arms and calling the fake a childish provocation. Nathaniel Gleicher, head of security policy at Facebook‚Äôs owner Meta, tweeted that the company had removed the original deepfake clip for violating its policy against misleading manipulated media. A statement provided by Twitter spokesperson Trenton Kennedy said the company was tracking the video and removing it in cases where it breached rules banning deceptive synthetic media. YouTube spokesperson Ivy Choi said it also had removed uploads of the video.
That short-lived saga could be the first weaponized use of deepfakes during an armed conflict, although it is unclear who created and distributed the video and with what motive. The way the fakery unraveled so quickly shows how malicious deepfakes can be defeated‚Äîat least when conditions are right.
X content This content can also be viewed on the site it originates from.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight The real Zelensky benefited Wednesday from being part of a government that had prepared for deepfake attacks. His quick response with a video debunking it, and the nimble reaction from Ukraine 24 and social platforms, helped limit the time the clip could spread uncontested.
Those are textbook strategies for defending against a threat as new as political deepfakes. Preparation and rapid response were at the heart of a playbook for defeating deepfakes that the Carnegie Endowment for International Peace released for political campaigns ahead of the 2020 US presidential election.
Zelensky also benefited from his position as one of the highest-profile people in the world and the deepfake‚Äôs poor quality. The deepfake presidential double looked unnatural, with a face that didn‚Äôt match its body, and its voice sounded different from that of its target.
Other conflicts and political leaders may be less fortunate, and could be more vulnerable to disruption by deepfakes, says Sam Gregory, who works on deepfakes policy at the nonprofit Witness.
Zelensky‚Äôs high profile helped Ukraine‚Äôs deepfake warning two weeks ago win international news coverage, and it also helped his quick response on Wednesday to spread rapidly. His prominence may also have prompted a quick response to the video from social networking companies. Meta spokesperson Aaron Simpson declined to say how it detected the video; so did YouTube‚Äôs Choi. The statement provided by Twitter‚Äôs Kennedy credited unspecified ‚Äúexternal investigative reporting.‚Äù Not all people targeted by deepfakes will be able to react as nimbly as Zelensky‚Äîor find their repudiation so widely trusted. ‚ÄúUkraine was well positioned to do this,‚Äù Gregory says. ‚ÄúThis is very different from other cases, where even a poorly made deepfake can create uncertainty about authenticity.‚Äù Gregory points to a video that appeared in Myanmar last year, which appeared to show a former government minister held in detention saying he provided cash and gold to the country‚Äôs former leader Aung San Suu Kyi.
The military government that displaced Aung San Suu Kyi in a coup used that footage to accuse her of corruption. But in the video the former minister‚Äôs face and voice were distorted, causing many journalists and citizens to suggest the clip was faked.
Fuel Up Gregory Barber Public Enemy Tom Simonite and Gian M. Volpicelli Public Health Max G. Levy Technical analysis has not resolved the mystery, in part because the video is of low quality, and because the former minister and others familiar with the truth don‚Äôt speak as freely or to as large an audience as Zelensky could on Wednesday. While automatic deepfake detectors could someday help combat bad actors, they‚Äôre still a work in progress.
Deepfakes are still generally used more for titillation or harassment than grand deception, especially as they become easier to create.
 A deepfake of Russian president Vladimir Putin circulated on Twitter this week as well, although it was identified as inauthentic from the start. The Zelensky deepfake and accompanying hacks, though, could represent a troubling new frontier. The quick and successful response to the clip highlights how, with a few tweaks and better timing, a deepfake attack could be an effective political weapon.
‚ÄúIf this was a more professional video and had been released early on in a more successful Russian advance on Kyiv, it could have created a lot of confusion,‚Äù says Samuel Bendett, who tracks Russian defense technology at the nonprofit CNA. As deepfake technology continues to get easier to access and more convincing , Zelensky is unlikely to be the last political leader targeted by fake video.
üì© The latest on tech, science, and more: Get our newsletters ! Driving while baked? Inside the high-tech quest to find out Horizon Forbidden West is a worthy sequel North Korea hacked him. He took down its internet How to set up your desk ergonomically Web3 threatens to segregate our online lives üëÅÔ∏è Explore AI like never before with our new database ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Senior Editor X Topics Russia disinformation content moderation Ukraine Deepfakes Matt Burgess Will Knight Will Knight Aarian Marshall Morgan Meaker Vittoria Elliott Reece Rogers Reece Rogers Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
