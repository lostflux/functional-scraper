Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Carnegie Mellon researchers create the most convincing deepfakes yet Share on Facebook Share on X Share on LinkedIn Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
Ever heard of “deepfakes”? Videos generated with artificial intelligence (AI) that learn to superimpose the face of one person onto the body of another have been used to swap Harrison Ford for Nicolas Cage in countless movie clips , and for far more nefarious purposes, like fake celebrity porn and propaganda. Now, for better or worse, researchers at Carnegie Mellon University have developed a new AI system that’s more powerful — and versatile — than previous attempts.
It’s called “Recycle-GAN,” and the team described it as an “unsupervised, data-driven approach” for transferring the content of one video or photo to another. “Such a content translation and style preservation task has numerous applications, including human motion and face translation from one person to other, teaching robots from human demonstration,” the researchers wrote, “or converting black-and-white videos to color.” So far, most state-of-the-art transfer techniques have targeted human faces, which the researchers said “lack generalization to other domains” and “fail when applied to occluded faces.” Others rely on paired image-to-image translation, which requires labor-intensive manual data labeling and alignment.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Recycle-GAN, in contrast, leveraged conditional generative adversarial networks (GANs) and “spatiotemporal cues” to learn “better association” between two pictures or videos. (GANs are two-part models consisting of a generator that attempts to “fool” a discriminator by producing increasingly realistic outputs from input data.) When trained on footage of human subjects, it was able to generate videos that captured subtle expressions, like dimples that formed when smiling and the movement of facial mouth lines.
“Without any manual supervision and domain-specific knowledge, our approach learns this retargeting from one domain to the other, using publicly available video data on the web from both domains,” the team wrote.
Recycle-GAN is capable of much more than capturing facial tics. The researchers used it to modify the weather conditions in a video, converting a breezeless day to a windy day. They aligned blooming and dying flowers, and they synthesized a convincing sunrise from videos on the web.
The results were good enough to fool 15 test subjects 28.3 percent of the time, but the team believes future versions of the system could be made more accurate if they learned the speed of “generated output,” like the different rates at which people speak.
“A true notion of style should be able to generate even this variation in time required for delivering speech/content,” the team wrote. “We believe that better spatiotemporal neural network architecture could attempt this problem in the near future.” Deepfakes remain a hot-button issue, unsurprisingly. Publicly available tools make them relatively easy to create, and there’s no legal recourse for the victims of malicious AI-generated videos.
Reddit, Pornhub, Twitter, and other platforms have taken a stance against them, and researchers (most recently at the U.S. Defense Department ) continue to look for ways of detecting deepfakes. But as Eric Goldman, a professor at Santa Clara University School of Law and director of the school’s High Tech Law Institute, cautioned recently, it’s probably best to “prepare for a world where we are routinely exposed to a mix of truthful and fake photos and videos.” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
