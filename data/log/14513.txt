Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Databricks debuts ChatGPT-like Dolly, a clone any enterprise can own Share on Facebook Share on X Share on LinkedIn Image by Canva Pro Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Was data lakehouse platform Databricks becoming an OpenAI rival on anyone’s 2023 bingo card? Well, hello, Dolly.
Today, in an effort the company says is meant to build on its longtime mission to democratize AI for the enterprise, Databricks released the code for an open-source large language model (LLM) called Dolly — named after Dolly the sheep , the first cloned mammal — that it said companies can use to create instruction-following chatbots similar to ChatGPT.
The model can be trained, the company explained in a blog post , on very little data and in very little time. “With 30 bucks, one server and three hours, we’re able to teach [Dolly] to start doing human-level interactivity,” said Databricks CEO Ali Ghodsi.
There are many reasons a company would prefer to build its own LLM model rather than sending data to a centralized LLM provider that serves a proprietary model behind an API , the blog post explained. Handing sensitive data over to a third party may not be an option, and organizations may have specific needs for model quality, cost and desired behavior.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “We believe that most ML users are best served long term by directly owning their models,” said the blog post.
Databricks found ChatGPT-like qualities don’t require latest or largest LLM According to the announcement, Dolly is meant to show that anyone “can take a dated off-the-shelf open-source large language model and give it magical ChatGPT-like instruction.” Surprisingly, it said, instruction-following does not seem to require the latest or largest models — Dolly is only 6 billion parameters, compared to 175 billion for GPT-3.
“We’ve been calling ourselves a data and AI company since 2013, and we have close to 1,000 customers that have been using some kind of large language model on Databricks,” said Ghodsi, who told VentureBeat he was “blown away” when ChatGPT was launched at the end of November 2022, but realized only a few companies on the planet have the massive language models necessary for ChatGPT-level ability.
“Most people were thinking, do we have to all leverage these proprietary models that these very few companies have? And if so, do we have to give them our data?” he said.
The answer to both of those questions is no: In February, Meta released the weights for a set of high-quality (but not instruction-following) language models called LLaMA , trained for over 80,000 GPU-hours each, to academic researchers. Then, in March, Stanford built the Alpaca model, which was based on LLaMA, but tuned on a small dataset of 50,000 human-like questions and answers that, surprisingly, made it exhibit ChatGPT-like interactivity.
Inspired by those two options, Databricks was able to take an existing open-source 6-billion-parameter model from EleutherAI and slightly modify it to elicit instruction-following capabilities such as brainstorming and text generation not present in the original model, using data from Alpaca.
Surprisingly, the modified model worked very well. According to the blog post, this suggests that “much of the qualitative gains in state-of-the-art models like ChatGPT may owe to focused corpuses of instruction-following training data, rather than larger or better-tuned base models.” LLM models will not be in the hands of only a few companies Ghodsi said that going forward there will many more LLM models that will become cheaper and cheaper — and won’t be in the hands of only a few companies.
“Every organization on the planet will probably utilize these,” he said. “Our belief is that in every industry, the winning, leading companies will be data and AI companies that will be leveraging this kind of technology and will have these kinds of models.” VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
