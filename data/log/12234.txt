Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages AI Weekly: Microsoft, machine learning framework interoperability, and ONNX Share on Facebook Share on X Share on LinkedIn Scott Guthrie, executive vice president for Microsoft's Cloud and AI group, speaks at Microsoft's Build conference in San Francisco.
Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
This week, Facebook’s AI team introduced PyTorch 1.1 and Ax for model experiment management.
 Microsoft also made a splash with the launch of a blockchain service , Unreal Engine support for HoloLens 2 for developers , and new Azure Machine Learning and Azure Cognitive Service announcements.
Amid all that news, a few important stories may have gone unnoticed : Microsoft made generally available FPGA chips for machine model training and inferencing, and the Open Neural Network Exchange ( ONNX ) now supports Nvidia’s TensorRT and Intel’s nGraph for high-speed inference on Nvidia and Intel hardware.
This comes after Microsoft joined the MLflow Project and open-sourced the high-performance inference engine ONNX Runtime.
Facebook and Microsoft created the ONNX open source project in 2017 , which now includes virtually every major global company in AI including AWS, AMD, Baidu, Intel, IBM, Nvidia, and Qualcomm.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Ahead of the news Thursday, Microsoft Azure’s cloud and AI group head Scott Guthrie spoke to reporters in San Francisco on a range of topics, including Microsoft’s approach to open source projects and AI strategy. More news is anticipated Monday as Microsoft kicks off its annual Build developer conference in Seattle.
“Ultimately, I think what’s compelling about hardware isn’t the hardware work we’re doing itself, it’s what lights up on top,” he said.
Guthrie said he loves ONNX because it gives machine learning practitioners the flexibility to use the best machine learning framework and chip hardware for certain tasks. FPGA chips have been used for years now to run 100% of data encryption and compression acceleration tasks for Azure.
“Even today with the ONNX workloads for AI, the compelling part is you can now build custom models or use our models, again using TensorFlow, PyTorch, Keras, whatever framework you want, and then know that you can hardware-accelerate it whether it’s on the latest Nvidia GPU, whether it’s on the new AMD GPUs, whether it’s on Intel FPGA, whether it’s on someone else’s FPGA or new silicon we might release in the future. That to me is more compelling than ‘do we have a better instruction set at the hardware level’ and generally what I find resonates best with customers.” Guthrie spoke at length about open source contributions and said overall Microsoft gives back more than Amazon or Google, as part of an evolution at the company in the past 10 years to make tools for DevOps, database, Kubernetes, and AI.
In the 2018 Octoverse Report released last fall , GitHub, which was acquired by Microsoft last year, found that Microsoft, Google, Redhat, and University of California, Berkeley employ the largest number of contributors to open source projects.
“We’ve gone from not being a fan of open source to being a big supporter,” he said. “I think you’re seeing a Microsoft that’s both deeply embracing openness, both as consumers, but also as contributors, and I think that’s unique. If you look at, say, AWS’ contributions to open source, there’s not a lot. There’s a lot of consumption, but there’s not a lot of contribution back, and I think even if you were to look at Google relative to the amount of contributions we’ve made on Azure, I think people are often pleasantly surprised when they add it up.” PyTorch and TensorFlow are some of the most popular frameworks around today, but “It” frameworks come and go, Guthrie said. The interoperability ONNX brings to the collections of different frameworks, runtimes, compilers, and other tools enables a machine learning ecosystem.
Much of the modern machine learning industry is built on advances in compute power as well as open source projects. It’s that architecture that will enable leaps forward in machine intelligence, and if the employees of tech giants compete to give more back, it’s likely for the greater benefit.
For AI coverage, send news tips to Khari Johnson and Kyle Wiggers — and be sure to subscribe to the AI Weekly newsletter and bookmark our AI Channel.
Thanks for reading, Khari Johnson AI Staff Writer The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
