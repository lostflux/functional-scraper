Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business Most Deepfakes Are Porn, and They're Multiplying Fast Play/Pause Button Pause Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save Application Deepfakes Ethics Identifying Fabrications Regulation Sector Social media Video Public safety Source Data Video Technology Machine learning Machine vision In November 2017, a Reddit account called deepfakes posted pornographic clips made with software that pasted the faces of Hollywood actresses over those of the real performers. Nearly two years later, deepfake is a generic noun for video manipulated or fabricated with artificial intelligence software. The technique has drawn laughs on YouTube, along with concern from lawmakers fearful of political disinformation. Yet a new report that tracked the deepfakes circulating online finds they mostly remain true to their salacious roots.
Startup Deeptrace took a kind of deepfake census during June and July to inform its work on detection tools it hopes to sell to news organizations and online platforms. It found almost 15,000 videos openly presented as deepfakes‚Äînearly twice as many as seven months earlier. Some 96 percent of the deepfakes circulating in the wild were pornographic, Deeptrace says.
The count is unlikely to be exhaustive, but the findings are a reminder that despite speculation about deepfakes destabilizing elections , the technology is mostly being used very differently, including as a tool for harassment.
 One worrying trend: Deeptrace says the tools needed to create deepfakes are becoming more sophisticated and more widely available.
The startup's report describes a niche but thriving ecosystem of websites and forums where people share, discuss, and collaborate on pornographic deepfakes. Some are commercial ventures that run advertising around deepfake videos made by taking a pornographic clip and editing in a person's face without that individual's consent.
All the people edited into the pornographic clips Deeptrace found were women. Clips of the most popular figures‚ÄîWestern actresses and South Korean pop celebrities‚Äîhad millions of views. Nonprofits have already reported that women journalists and political activists are being attacked or smeared with deepfakes. Henry Ajder, a researcher at Deeptrace who worked on the firm's report, says there are deepfake forums where users discuss or request pornographic deepfakes of women they know, such as ex-girlfriends, wanting to see them edited into a pornographic clip.
Danielle Citron, a law professor at Boston University, describes pornographic deepfakes made without a person‚Äôs consent as an ‚Äúinvasion of sexual privacy.‚Äù She spoke at a June hearing by the US House Intelligence Committee about artificial intelligence media manipulation tools.
The porn industry has helped pioneer new media technologies , from VHS and pop-up ads to streaming video. Citron says that the preponderance of pornographic deepfakes is a reminder of another consistent lesson from the history of technology: ‚ÄúAt each stage we‚Äôve seen that people use what‚Äôs ready and at hand to torment women. Deepfakes are an illustration of that.‚Äù Citron helped spur the recent spread of state legislation on revenge porn, which is now subject to laws in at least 46 states and the District of Columbia. California is among them; last week week its governor, Gavin Newsom, signed into law a bill that allows a person edited into sexually explicit material without consent to seek civil damages against the person who created or disclosed it.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg The law professor also says she is currently talking with House and Senate lawmakers from both parties about new federal laws to penalize distribution of malicious forgeries and impersonations, including deepfakes. ‚ÄúWe‚Äôve been encouraged that the uptake has been swift,‚Äù she adds.
Last week, senators Marco Rubio, the Republican of Florida, and Mark Warner, the Democrat from Virginia, both of whom are members of the Senate Intelligence Committee, wrote to Facebook and 10 other social media sites seeking more details of how they plan to detect and respond to malicious deepfakes. The legislators cautioned that fake clips could have a ‚Äúcorrosive impact on our democracy.‚Äù Ajder of Deeptrace plays down fears that a fake clip could significantly affect the 2020 election. But the startup‚Äôs report notes that growing awareness of the technology can fuel political deception.
In June, a Malaysian political aide was arrested after a video surfaced purportedly showing him having sex with the country‚Äôs minister of economic affairs. (Gay sex is illegal in Malaysia.) The country‚Äôs prime minister said the video was a deepfake, but independent experts have been unable to determine if the video was manipulated. ‚ÄúDeepfakes can provide plausible deniability,‚Äù Ajder says.
To conduct its analysis, Deeptrace used a mixture of manual searching and web scraping tools and data analysis to record known deepfakes from major porn sites, mainstream video services such as YouTube, and deepfake-specific sites and forums.
That methodology is imperfect. It couldn‚Äôt account for deepfakes that successfully passed off as real clips or probe every hidden online corner. Jack Clark, policy director at independent AI lab OpenAI, says the Deeptrace report is nonetheless a welcome attempt to gather empirical evidence on deepfakes, which has been lacking.
Clark predicts that fake videos won‚Äôt be the first example of unsavory consequences from the spread of artificial intelligence tools through commercialization and open source.
 ‚ÄúIndividuals will mess around with the technology and some of the ways they mess around will be harmful and offensive,‚Äù he notes.
Even a small nuclear war could trigger a global apocalypse Teaching pilots a new trick: landing quietly The former Soviet Union's surprisingly gorgeous subways Why are rich people so mean ? A brutal murder, a wearable witness, and an unlikely suspect üëÅ If computers are so smart, how come they can‚Äôt read ? Plus, check out the latest news on artificial intelligence ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers.
Senior Editor X Topics artificial intelligence machine learning pornography Video Deepfakes Amy Martyn David Gilbert Matt Laslo Steven Levy Niamh Rowe Will Bedingfield Morgan Meaker Peter Guest Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
