Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts I Was There When: AI helped create a vaccine I Was There When is an oral history project that’s part of the In Machines We Trust podcast. It features stories of how breakthroughs and watershed moments in artificial intelligence and computing happened, as told by the people who witnessed them. In this episode we meet Dave Johnson, the chief data and artificial intelligence officer at Moderna.
Credits: This project was produced by Jennifer Strong, Anthony Green and Emma Cillekens. It’s edited by Michael Reilly and mixed by Garret Lang with original music by Jacob Gorski. The art is from Eric Mongeon and Stephanie Arnett.
Full transcript: [PREROLL] [TR ID] Jennifer Strong: The genetic sequence of the COVID-19 virus was first published in January 2020.
It kicked off an international sprint to develop a vaccine... and represented an unprecedented collaboration between the pharmaceutical industry and governments around the world.
And it worked.
Months later, the U.S Government approved emergency authorizations for multiple vaccines.
I’m Jennifer Strong, and this is I Was There When— an oral history project featuring the stories of breakthroughs and watershed moments in AI and computing… as told by those who witnessed them.
This episode, we meet Dave Johnson, the chief data and artificial intelligence officer at Moderna.
[PREROLL] [TR ID] Dave Johnson: Moderna is a biotech company that was founded on the promise of mRNA technology.
My name is Dave Johnson. I'm chief data and AI officer at Moderna. mRNA is essentially an information molecule. It's encoded, a sequence of amino acids, which when they enter the cell in your body, it produces a protein and that protein can perform a variety of different functions in your body from curing a rare disease, potentially attacking cancer, or even a vaccine to battle of virus like we've seen with Covid.
What's so fundamentally different about this approach from the typical pharmaceutical development is it's much more of a design approach. We're saying we know what we want to do. And then we're trying to design the right information molecule, the right protein, that will then have that effect in the body.
And if you know anything about pharmaceutical development, it tends to be a very serial process. You know, you start with some kind of initial concept, some initial idea and you test it in Petri dishes or in, you know, small experiments. And then you move on to preclinical testing. And if all of that looks good, then you're finally moving off to, to human testing and you go through several different phases of clinical trials where phase three is the, the largest one where you're proving the efficacy of this drug.
And that whole process from end to end can be immensely expensive, cost billions of dollars and take, you know, up to a decade to do that. And in many cases, it still fails. You know, there's countless diseases out there right now that have no vaccine for them, that have no treatment for them. And it's not like people haven't tried, it's just, they're, they're challenging.
And so we built the company thinking about: how can we reduce those timelines? How can we target many, many more things? And so that's how I kind of entered into the company. You know, my background is in software engineering and data science. I actually have a PhD in what's called information physics—which is very closely related to data science.
And I started when the company was really young, maybe a hundred, 200 people at the time. And we were building that early preclinical engine of a company, which is, how can we target a bunch of different ideas at once, run some experiments, learn really fast and do it again. Let's run a hundred experiments at once and let's learn quickly and then take that learning into the next stage.
So if you wanna run a lot of experiments, you have to have a lot of mRNA. So we built out this massively parallel robotic processing of mRNA, and we needed to integrate all of that. We needed systems to kind of drive all of those, uh, robotics together. And, you know, as things evolved as you capture data in these systems, that's where AI starts to show up. You know, instead of just capturing, you know, here's what happened in an experiment, now you're saying let's use that data to make some predictions.
Let's take out decision making away from, you know, scientists who don't wanna just stare and look at data over and over and over again. But let's use their insights. Let's build models and algorithms to automate their analyses and, you know, do a much better job and much faster job of predicting outcomes and improving the quality of our, our data.
So when Covid showed up, it was really, uh, a powerful moment for us to take everything we had built and everything we had learned, and the research we had done and really apply it in this really important scenario. Um, and so when this sequence was first released by Chinese authorities, it was only 42 days for us to go from taking that sequence, identifying, you know, these are the mutations we wanna do. This is the protein we want to target.
Forty-two days from that point to actually building up clinical-grade, human safe manufacturing, batch, and shipping it off to the clinic—which is totally unprecedented. I think a lot of people were surprised by how fast it moved, but it's really… We spent 10 years getting to this point. We spent 10 years building this engine that lets us move research as quickly as possible. But it didn't stop there.
We thought, how can we use data science and AI to really inform the, the best way to get the best outcome of our clinical studies. And so one of the first big challenges we had was we have to do this large phase three trial to prove in a large number, you know, it was 30,000 subjects in this study to prove that this works, right? That's a huge study. Covid had been flaring, um, infecting countless people. And we had to figure out: where do we run our studies? We're gonna pick a hundred locations in the US to run this study and we needed to balance finding places where we have kind of the right racial diversity that's the right makeup for the country.
We needed to balance… kind of practical concerns. If we need a, you know, the right size facility and clinical trial sites that can deliver quality data. And we need to find places where Covid has not already hit. So at the time New York, for example, was already heavily hit. And so it wouldn't be an ideal place to run a clinical study because we have to accrue cases of it.
So we had to find places that weren't quite yet hit, but places that we expected to actually, you know, surge, you know, maybe six weeks after the study started after people had been inoculated. So that's a really challenging problem we had to solve. And I wanna say, you know, we, we didn't do this all entirely internally.
We worked with countless external partners. And I can't tell you the number of different epidemiology models that we saw. It seemed like everybody was an epidemiologist all of a sudden. But we incorporated all that learning all that information into our internal decision making and used that to try to find: these are the optimal places that we should run this study.
And then even while we were running this study, we were saying, how can we continue to optimize and do better? You know, we built real time analytics into our studies enrollment. So as patients or subjects enrolled into the study, were treated with our vaccine, we are monitoring the diversity of this: the age, the gender, and racial diversity to ensure that the final makeup of this study, when all said and done was representative of the US.
We got, I wanna say, maybe 80% of the way through the study. And we realized, look, we are not gonna meet our, our objectives because the level of volunteers aren't quite what we wanted. And so we made the, the really difficult decision to say, look, we need a throttle, some areas of the country and focus on outreach in different areas to get the right makeup so that the study was representative.
All told, it was about a year from when we, you know, started this journey on Covid to when we got the emergency use authorization for the vaccine—which again is really unprecedented for something that usually takes many years. And I'll say for myself personally, it was just such an amazing kind of emotional moment of, you know, I joined the company almost eight years earlier, not thinking necessarily I would ever use one of our own medicines because we weren't even doing vaccines at the time. But to have that injected in my arm and for my family to get it for my friends and everyone else to, to see that benefit and for so many other people in the world, was just an amazing moment for us.
Jennifer Strong: I Was There When...
features stories from people who witnessed or created breakthroughs in artificial intelligence and computing.
Do you have a story to tell? Know someone who does? Drop us an email at podcasts at technology review dot com.
[MIDROLL] Jennifer Strong: This project was produced by me with Anthony Green and Emma Cillekens. We’re edited by Michael Reilly and our mix engineer is Garret Lang.
Thanks for listening, I’m Jennifer Strong.
[TR ID] hide Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä Everything you need to know about artificial wombs Cassandra Willyard How to fix the internet Katie Notopoulos New approaches to the tech talent shortage MIT Technology Review Insights Deep Dive Artificial intelligence This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Driving companywide efficiencies with AI Advanced AI and ML capabilities revolutionize how administrative and operations tasks are done.
By MIT Technology Review Insights archive page Rogue superintelligence and merging with machines: Inside the mind of OpenAI’s chief scientist An exclusive conversation with Ilya Sutskever on his fears for the future of AI and why they’ve made him change the focus of his life’s work.
By Will Douglas Heaven archive page Generative AI deployment: Strategies for smooth scaling Our global poll examines key decision points for putting AI to use in the enterprise.
By MIT Technology Review Insights archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
