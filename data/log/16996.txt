Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Alexa Presentation Language is now generally available Share on Facebook Share on X Share on LinkedIn Are you looking to showcase your brand in front of the brightest minds of the gaming industry? Consider getting a custom GamesBeat sponsorship.
Learn more.
Following a press event at its Seattle headquarters this morning, Amazon announced general availability of Alexa Presentation Language (APL), the toolset designed to make it easier for developers to create “visually rich” skills for Alexa devices with screens — such as Amazon’s Echo Show, Fire TV, Fire Tablet, and Echo Spot. Its rollout comes after the launch of APL 1.1 in beta in July and coincides with the preview of two new developer tools — skill personalization and the Alexa Web API for Games.
“We believe that the emergence of voice user interfaces isn’t an incremental improvement to existing technology; it marks a significant shift in human-computer interaction,” wrote Alex Skills Kit senior product manager Arunjeet Singh. “That’s why APL is designed from the ground up for creating voice-first, multimodal Alexa skills.” Amazon Presentation Language As a refresher, APL — a JSON-based HTML5 language — consists of five core elements: Images, text, and lists Layouts, styles, and conditional expressions Speech synchronization Slideshows Built-in intents by ordinal App designers can specify text color, size, and weight; make text and image responsive; or use both vertical and horizontal scrollbars to show continuous lists of choices. APL ships with preconfigured headers, footers, and dialog boxes, and app layouts, voice responses, and other visuals can be tailored to the device shapes and types. Also in tow are commands that change the audio or visual presentation of on-screen content, built-in intents that enable selection by ordinal (for example, a user can say “Select the second one” when a list is on-screen), and slideshows of images and other content.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Here’s how it works: Developers create JSON files — “documents,” in APL parlance — that get invoked by Alexa skills and downloaded to target devices. Those devices import images and other data from the document and render the experience.
Skills using APL include a CNBC stock organizer, Big Sky’s weather forecast app, public transit schedule tracker NextThere, travel app Kayak, and Food Network’s recipe sorter.
Notably, Facebook’s Portal and Portal+ devices incorporate elements of APL for hands-free visual content; their weather forecasts, shopping lists, and calendar events screens were designed with Amazon’s toolkit. And LG and Sony smart TVs and Lenovo tablets support APL through the Alexa Smart Screen and TV Device SDK.
Amazon says that in the coming months it will improve APL with support for shadow effects, noise filters, and play and pause buttons on TV devices.
Personalized Alexa skill experiences Alongside the latest version of the Alexa Presentation Language, Amazon took the wraps off skill personalization in the Alexa Skills Kit , which enables developers to create personalized skill experiences using voice profiles captured by the Alexa app. Voice apps leveraging skill personalization can address preferences, remember settings, differentiate between household members, and more.
A developer could personalize a game based on who’s playing, for example, or offer a customized exercise routine tailored to individual fitness goals. Moreover, voice-personalized Alexa skills can be combined with app-to-app account linking to help users discover skills, link accounts, and deliver flows unique to their voice.
Skill personalization is available in preview for existing and new skills. Interested developers are required to fill out and submit a brief survey , after which they’ll be notified if they’re selected.
Alexa Web API for Games Today also marks the debut of the Alexa Web API for Games , which Amazon describes as a collection of tech and tools for creating visually rich and interactive voice-controlled game experiences. Using the new API, developers can build voice apps using HTML, Canvas 2D, WebAudio, WebG, JavaScript, and CSS, starting with Echo Show devices and Fire TVs.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
