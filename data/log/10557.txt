Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Steven Levy Backchannel Inside Metaâ€™s Oversight Board: 2 Years of Pushing Limits Illustration: Deena Soâ€™Oteh Save this story Save Save this story Save On the morning of Thursday, June 30, 2022, two large luxury buses pulled up to a grand hotel in Menlo Park, California. Milling on the driveway were the members, staffers, and trustees of the Oversight Board. Set up two years ago by Facebook, now Meta , this august gaggle exists to second-guess the companyâ€™s most controversial actions. The board members, whoâ€™d already logged countless hours on video calls and email, were spending their first week together in person. The buses rumbled off, whisking the 23 Zoom buddies to Metaâ€™s headquarters 4 miles away.
The group made its way across the mammoth Gehryâ€“designed complex to a verdant outdoor amphitheater known as the Bowl. Sheryl Sandberg, Metaâ€™s outgoing chief operating officer, greeted the crowd in the midday heat. Next up was Nick Clegg, the companyâ€™s president for global affairs. Clegg was almost startling in his effusive praise of the board. He was taking questions from the members when, suddenly, the large screens in the Bowl lit up with a familiar face.
This article appears in the December 2022/January 2023 issue.
Subscribe to WIRED.
Illustration: Boldtron Mark Zuckerberg â€™s expressionless visage peered down at the sweaty visitors. Though Zuckerberg had personally willed into being this body of overseersâ€”overseeing him â€”he had never met with all its current members. Metaâ€™s founder and CEO didnâ€™t share his location, but a fair guess would have been that he was at his Hawaiian island retreat, where he had spent much of the previous year. Staring into his webcam, Zuckerberg congratulated the board on its work so far. Free expression, he said, has always been part of his companyâ€™s missionâ€”but sometimes people use their voices to put others in danger. Meta shouldnâ€™t be making so many decisions on speech by itself. Zuckerberg finished his talk with a wholehearted endorsement. â€œThis has been important to me from the beginning,â€ he said, â€œand Iâ€™m committed to the board for the long term.â€ Indeed, a few weeks later, Meta announced it would give the board $150 millionâ€”more than double its original commitmentâ€”to keep the project going through 2025. So far, the board has received nearly 2 million appeals on content and ruled on 28 of them. It has made 119 recommendations to Meta. Its judgments have involved wampum belts, blackface, and the removal of a former US president from Facebook.
Some critics see the Oversight Board as an exercise in corporate ass-covering by a bunch of Metaâ€™s puppets. If the company doesnâ€™t want to make a controversial call, it can push the board to take a position on the issue and, conveniently, take the heat. Emi Palmor, a board member who once served as the director general of Israelâ€™s Justice Ministry, says sheâ€™s frequently approached in the supermarket by people seeking tech support for Meta apps. â€œI want to murder the person who chose the name Oversight Board,â€ she says. â€œIt is an unexplainable term.â€ But since it started hearing cases in the fall of 2020, the board has won grudging respect from the human rights organizations and content moderation wonks who pay attention to its work. â€œPeople thought it would be a total fiasco,â€ says Evelyn Douek , a Stanford law professor who follows the board closely. â€œBut in some real ways, it has brought some accountability to Facebook.â€ Meta, meanwhile, is declaring victory. â€œIâ€™m absolutely delightedâ€”thrilled, thrilled, thrilled with the progress,â€ Clegg says. The boardâ€™s approach to cases â€œis exactly what you should expect between a social media platform and an independent oversight entity.â€ Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy The truth is more complicated, and Cleggâ€™s ebullient praise and Zuckerbergâ€™s encouraging mahalo make board members nervous. If one of the worldâ€™s most transgressive companies thinks that the oversight is going fantastically, how great can the board be? Suzanne Nossel, a member who is also the CEO of the literature and human rights nonprofit PEN America, thinks itâ€™s too early to make a call. â€œWeâ€™ve only just begun to figure out how to do this work,â€ she says.
The board has figured out one big thing: It has an opportunity, with caveats, to alter how the internetâ€™s Goliaths treat the speech of billions of people.
Even after more than two decades of social media, the way platforms patrol their corridors can seem arbitrary and self-serving.
 Imperfect algorithms and armies of undertrained, overworked moderators make life-altering decisions. People scramble to contest them, filing millions of appeals every month. They dig through help pages, argue with bots, and most often give up in frustration. The policies that supposedly balance free expression and safety were drawn up by companies whose priorities are growth and profit. â€œThe platform was not designed with integrity in mind,â€ says Jamal Greene, a Columbia law professor who is one of the boardâ€™s cochairs. â€œIt was designed with reach in mind.â€ No one wants the government to step in and bash out rulings on edgy posts. But online speech is still speech, and people expect some rights around it. The Oversight Board is a first stab at securing those liberties and, in its most ambitious form, a chance to stem some chaos. But the deeper the boardâ€™s members get into the issues, the more they find themselves bumping up against the edges of what Meta will let them do.
Illustration: Deena Soâ€™Oteh Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy â€‹â€‹The great experiment of the Oversight Board started on a bike ride. In January 2018, Noah Feldman, a professor at Harvard Law School, was visiting the Bay Area and crashing at his friend Sheryl Sandbergâ€™s house. One day, he was pedaling around the local foothills when his mind turned to Facebook. The problem with his hostâ€™s social media employer, he thought, was that no matter what it decided on a given piece of content, someone would be mad at the company. Perhaps it could benefit from a separation of powers. By the end of his ride he had a suggestion for Sandberg: Facebook should create its own version of the Supreme Court , an independent body that would examine the biggest complaints about the companyâ€™s decisions.
Sandberg brought the idea to Zuckerberg, who had been pummeled for months about speech on his platform and was now thinking about â€œgovernanceâ€ as a way to signal that he wasnâ€™t the dictator of the worldâ€™s expression. He embraced the concept. In June of that year, I met Zuckerberg at Facebookâ€™s headquarters for a walk through its 9-acre rooftop gardens. As we strolled, he shared a vision of an independent body that would make binding decisions on content. â€œWe need to figure out the mechanism for appointmentâ€”but they donâ€™t report to me,â€ he said. â€œTheyâ€™re not likely going to be Facebook employees.â€ He understood then that he would need to fend off the impression that the overseers were his flunkies.
Zuckerbergâ€™s MO for new initiatives is to rely on loyal long-time lieutenants to make them happen. In this case, Facebook used an internal team of governance nerds. It was headed by Brent Harris, an attorney with experience in climate and environmental work, and Heather Moore, who had worked in the US Attorneyâ€™s Office in Newark, New Jersey. Both said they saw it as a chance to help people on the platform. (Harris now heads a governance group at Meta that includes the boardâ€™s support team.) For a company that once boasted of moving fast, Facebook set up its board with the cautious deliberation of a 19th-century government railway bureaucracy. Buy-in was not universal. â€œI was skeptical we would get much benefit,â€ says Monika Bickert, who heads global content policy. (It would be her rules that the board would question.) But the team plodded forward, set up a series of workshops, and solicited suggestions from outsiders on how the board should operate. Some participants would wind up filling its seats.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy By 2020, Facebook had set up the board as an independent trust with a $130 million grant. The company would pay up to 40 board members six-figure salaries for what was estimated to be 15 hours of work each week. A full-time staff would support the effort, like clerks for Supreme Court justices. A lengthy charter set the ground rules. The meat of the boardâ€™s activities would be handling disagreements over individual posts. Perhaps Facebook or Instagram had removed someoneâ€™s post for violating its terms, and the user wanted to contest that decision. The board could rule on posts, but not ads, algorithms, or groups. (That stuff might come later.) A case selection committee, made up of board members, would extract from the sea of appeals the cases the board would take on, then assign them to five-person panels. Those groups would evaluate their case and reach a decision. Facebook was bound to honor the boardâ€™s rulings on individual posts.
But there was more. The board could include in its case rulings sweeping recommendations, which the company could take or leave. If it rejected the suggestions, it would have to explain itself, but that would be it. The board could get a crack at the companyâ€™s knottiest conundrums through a â€œpolicy advisory opinionâ€â€”a request directly from Meta for the board to review an especially controversial decision. Meta could again accept or reject whatever the board advised.
To this day, Facebook and Instagram users are not guaranteed that when some robot blocks their speech, a human being will ever see their complaints.
In May 2020, the company announced it had recruited a distinguished collection of lawyers, journalists, and human rights activists to become the boardâ€™s first 20 members , including four cochairs. There was a former prime minister of Denmark, a Pulitzer Prizeâ€“winning former newspaper editor, and a Nobel Peace Prize laureate. All the members had one thing in commonâ€”a resolve that they be seen as independent of the company funding their paychecks.
Still, Facebookâ€™s critics were ready to call out the Oversight Board as a sham.
 Jessica Gonzalez is the co-CEO of Free Press, a group opposed to corporate control of media, and one of a motley collection of company detractorsâ€”including full-time Meta apostate Roger McNamee and Nobel laureate Maria Ressa â€”who created a shadow organization called the Real Facebook Oversight Board; it is dedicated to issuing body blows to everything its namesake does. The really real board â€œis a PR stunt,â€ Gonzalez says, â€œthat gives Facebook cover for not adequately investing in the integrity of its systems and not doing enough to keep people safe.â€ In January 2021, the board ruled on its first casesâ€”and set a pot of tension on simmer. The previous October, a Brazilian Instagram user touting a breast cancer awareness campaign had posted an image with several examples of post-surgery breasts. An algorithm trained to seek and destroy nipple content took down the post. Once the board accepted the case, the company decided to manually review the post. Nudity for the sake of medical awareness was within Instagramâ€™s rules, so the policy standards team restored the post. With the issue now moot, the company told the board to drop the case.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy The members declined. Their insistence was a message: While their decisions were nominally about individual pieces of content, the real work was in interrogating company policies. They were out to change Meta.
In the write-up of their decisionâ€”reaffirming that the post should stay upâ€”the board members exposed how this seemingly trivial, fixable mistake was a window into a deeper failure. The company overly relied on algorithms, which in this case didnâ€™t pick up the Portuguese for â€œbreast cancer.â€ Removing the post, the board argued, raised â€œhuman rights concerns.â€ Citing the International Covenant on Civil and Political Rights, a foundational United Nations treaty, the board wrote, â€œAny restriction on freedom of expression must be for a legitimate aim.â€ It recommended that anytime a user appeals an algorithmic decision of this sort, that person should automatically be granted a human content moderator. â€œWe basically asserted our authority even though Facebook had decided to reinstate the content,â€ says board member Ronaldo Lemos, a law professor from Brazil. â€œAt the same moment we said, â€˜We want to talk about algorithms.â€™â€ A pretty reasonable requestâ€”except the company did not follow up on the boardâ€™s recommendation. To this day, Facebook and Instagram users are not guaranteed that when some robot blocks their speech, a human being will ever see their complaints. The board was imagining a world in which social media platforms would have to at least treat their users like human beings. The members would keep pressing to make that happen, because, well, human rights are their thing.
Illustration: Deena Soâ€™Oteh Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy The board had issued only a handful of rulings when a bombshell of a case dropped: the suspension of President Donald Trump.
In the heated hours of the insurrection on January 6, 2021, Trump blessed the violent protests in posts on Facebook and Instagram. The company swiftly removed the posts and suspended him from both platforms indefinitely. The MAGA crowd cried censorship. Anti-Trumpers were outraged that the ban wasnâ€™t permanent. On January 21â€”perhaps not coincidentally, after a new US president had been inauguratedâ€”Facebook told the board members to figure it out.
 â€œIt was a very, very simple decision,â€ Clegg says of requesting a public advisory opinion. â€œJust imagine if we hadnâ€™t deferred that decision to them. People wouldâ€™ve quite rightly said, â€˜Youâ€™ve created an oversight board, and you wonâ€™t even share with them this dilemma of what to do with the former elected president of the most powerful democracy on the planet.â€™â€ For the board, though, the moment was perilous. Both pro- and anti-Trump observers were ready to pounce on any misstep; a clumsy move could have sunk the whole experiment. After months of deliberation, the board backed the companyâ€™s decision to remove the former presidentâ€™s incendiary words on Facebook and Instagram and to boot him from the platforms. But the board once again demanded that the company make its policies more explicit. In its ruling that spring , the board excoriated Facebook for basically making decisions on the flyâ€”and for refusing to provide a time frame for the ex-presidentâ€™s restoration. By not having clear standards for suspensions, the company was failing the public. â€œFacebook shunned its responsibility,â€ said board cochair Helle Thorning-Schmidt, a former prime minister of Denmark.
The boardâ€™s commentary on that high-profile case pointed to one of its obsessions: Facebookâ€™s lack of transparency about its own rules. The board returned to it frequently and became adept at choosing complaints with the most potential for broad impact. â€œCase selection is the whole game,â€ says Nicolas Suzor, a board member and law professor from Australia. Suzor is at times on the selection committee that decides which issues the board wants to address and has staffers sifting through thousands of appeals to find cases that fit.
In April 2021, the committee plucked out a case that came to be known as Ocalanâ€™s Isolation. Abdullah Ocalan is a founding member of the Kurdistan Workersâ€™ Party (PKK), a group that Facebook had designated a â€œdangerous entity.â€ He is currently incarcerated on a Turkish prison island in perpetual solitary confinement. A few months earlier, an Instagram user in the US had posted a picture of Ocalan with the words â€œyâ€™all ready for this conversation?â€ and urged people to discuss the conditions of the prisonerâ€™s confinement. Facebook removed it. Company policy bans posts in support of people involved in dangerous entities. This post wasnâ€™t that.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy The board was eager to tackle the issue. â€œYou have an organization that you canâ€™t talk about,â€ says board member Julie Owono, who is executive director of the digital rights organization Internet Sans FrontiÃ¨res. â€œYet you have a leader whose situation has been internationally recognized as a violation of the personâ€™s human rights.â€ Researchers within the company started digging up background information on the case, much of it from Facebookâ€™s private databases. While going through files, they stumbled on an embarrassing detail: The issue of Ocalanâ€™s imprisonment had come up before. The company had even created a special policy that allowed posts from users who advocated for humane treatment but werenâ€™t themselves PKK supporters. But that instruction, written in 2017, was never made public. It was evidently forgotten inside the company too, as it routinely took down posts regarding the conditions of Ocalanâ€™s confinement. Facebook was violating its own rules. â€œWhen I found out about that disconnection, I thought, thatâ€™s precisely why I came here,â€ Owono says.
In its first year, the board steadily pushed the company to fix its imperious attitude toward complaints. Users were seldom informed why posts were taken down or why seemingly obvious violations were allowed to remain. The board views this Kafkaesque behavior as one of the companyâ€™s ongoing insults to human rights. â€œIt was something I wouldnâ€™t have thought was even a problem before I joined the board,â€ says Greene, one of the cochairs. â€œBut we realized itâ€™s a huge problem.â€ In 2021 alone, six of their 20 rulings recommended that when the company removes a personâ€™s content, it should inform the user what rule they broke.
The battle proved to the board that its mission was not to rule on the fate of one post or another, but to make Meta own up to the monster it has created.
When I bring this up with Clegg, he acts as if the boardâ€™s continued pounding on this topic is the greatest thing since targeted ads. â€œA thousand percent!â€ he says. â€œThe main early, consistent drumbeat of criticism weâ€™ve had from the boardâ€”and I think itâ€™s totally understandableâ€”is that youâ€™re not explaining to users where you stand, and users feel you are applying arbitrary decisions.â€ Citing the boardâ€™s criticisms, Meta revealed this summer that it was creating a customer service group to provide explanations of its takedowns and suspensions.
It took multiple decisions, but the board had made its point.
 Now, â€œMeta is more transparent with its users about what theyâ€™ve done wrong,â€ Greene says.
The battle proved to the board that its mission is not to decide the fate of one post or another, but to make Meta own up to the monster it has created. On the page of the boardâ€™s website where users lodge their complaints, the text does not read, â€œGet your post restoredâ€ or â€œFix this bad decision.â€ The call to action says, in giant letters, â€œAppeal to shape the future of Facebook and Instagram.â€ Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy While the board racked up points with that win, it still has limited leverage. When the board makes recommendations, a Meta working group determines whether the company will implement them. â€œWe treat the board the way we do a regulator,â€ says Harris, the lawyer who helped set up the board and remains its closest contact within Meta. There is, of course, a difference. While there are consequences for ignoring a regulator, Meta is free to do as it wishes. Of the boardâ€™s 87 recommendations through the end of 2021, Meta claims to have fully implemented only 19, though it reports progress on another 21. The company brushed off another 13 recommendations by saying, without elaboration, it is â€œwork Meta already does.â€ Other recommendations are outright refused.
â€œWe donâ€™t have a police force,â€ Owono says. â€œBut I donâ€™t think it prevents us from holding the company accountable, at least to its users.â€ A board committee is studying how to make their recommendations harder to dodge.
By early 2022, two themes were emerging in the relationship between Meta and its Oversight Board. In some company quarters, the boardâ€™s decisions were having a positive effect. Even Metaâ€™s content policy head, Bickertâ€”whom one board insider cited to me as a powerful internal detractor of the effortâ€”says that she now often asks herself, â€œWhat would the board think?â€ Some board members, however, were feeling increasingly frustrated with the boundaries they were forced to work within and the obstacles they felt that Meta was intentionally placing in their path.
One point of friction is how the board grows. In an early conversation I had with Metaâ€™s Harris and Moore, the idea was that the company would help choose the first tranche of members, then step aside. But in the boardâ€™s charter, the company gave itself a say in selecting the full complement of 40 members. Meta employees remain deeply involved in hiring and are a factor in why the board is still far short of the total number set out in its charter. â€œWhile itâ€™s hard to find the right kind of people, I donâ€™t know thatâ€™s an excuse for operating at 50 percent capacity,â€ says Douek, the Stanford law professor who keeps an eye on the boardâ€™s activities.
Metaâ€™s influence became hard to miss when the board invited RenÃ©e DiResta to interview. DiResta, the technical research manager of the Stanford Internet Observatory, was interested in becoming a member, she says, because it â€œwould be an opportunity to shape the direction of something that I think has real potential.â€ DiResta has degrees in political science and computer science. Beginning in April 2021, she underwent multiple interviews. On paper, her inclusion made a lot of sense. The Oversight Board lacks experts on algorithms, so her presence would fill a void. But there was a problem: She has been a consistent critic of Metaâ€™s failure to deal with the harmful disinformation on its platforms.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy In March 2022, DiResta got an email rejecting her application. â€œThey said they were going in a different direction,â€ she says. That direction, it turned out, was the same as before. The board proceeded to add three more members who, like the first 20, are lawyers or journalists with no technical background. One person familiar with the process says it was Metaâ€™s reservations that put the kibosh on the nomination. Harris, of Meta, says that â€œthe company has expressed concern in some instances about who may or may not be more effective in certain lights as a board member.â€ Meta further explains it is not unusual for multiple people to withhold their endorsement, and that the exceptions are the candidates who earn consensus and get hired. (Thatâ€™s a big reason why the board has trouble filling its vacancies.) If the board were truly independent, of course, it would never solicit, let alone entertain, Metaâ€™s concerns.
Around the time of DiRestaâ€™s rejection, board members were also fuming over another dispute with Meta. They wanted access to a basic company-owned tool that would help them choose and contextualize their cases. Called CrowdTangle, the software is essential for analyzing the impact of Facebook and Instagram posts. It is used internally and by selected outside researchers and media organizations. Getting access seemed like a no-brainer; investigating a case without it is like assessing damage to a coal mine without a flashlight. The board spent months asking for access, yet Meta still didnâ€™t grant the request. It seemed clear that someone at Meta didnâ€™t want the board to have it.
Ultimately, the issue came up in a March 2022 meeting with Clegg, who seemed taken aback by the board membersâ€™ frustration. He promised to break the logjam, and a few weeks later the board finally got the tool it should have had from the start. â€œWe had to fight them to get it, which was baffling,â€ says Michael McConnell, a Stanford law professor who is one of the boardâ€™s cochairs. â€œBut we did it.â€ No sooner had that skirmish been resolved than another incident roiled the waters. When Russian troops invaded Ukraine last February, Facebook and Instagram were quickly overwhelmed with questionable, even dangerous content. Posts promoting violence, such as â€œdeath to the Russian invaders,â€ were in clear violation of Metaâ€™s policies, but banning them might suggest the company was rooting for those invaders. In March, Meta announced that in this narrow instance, it would temporarily allow such violent speech. It turned to the board for backup and asked for a policy advisory opinion. The board accepted the request, eager to ponder the human rights conundrum involved. It prepared a statement and set up appointments to brief reporters on the upcoming case.
â€œThere are plenty of people in the company for whom weâ€™re more of an irritation,â€ says board member Michael McConnell. â€œNobody really likes people looking over their shoulders and criticizing.â€ But just before the board announced its new case, Meta abruptly withdrew the request. The stated reason was that an investigation might put some Meta employees at risk. The board formally accepted the explanation but blasted it in private meetings with the company. â€œWe made it very clear to Meta that it was a mistake,â€ says Stephen Neal, the chair of the Oversight Board Trust, who noted that if safety were indeed the reason, that would have been apparent before Meta requested the policy advisory opinion.
When I asked whether Neal suspected that the boardâ€™s foes wanted to prevent its meddling in a hot-button issue, he didnâ€™t deny it. In what seemed like an implicit return blow, the board took on a case that addressed the very issues raised by Metaâ€™s withdrawn advisory opinion. It involved a Russian-language post from a Latvian user that showed a body, presumably dead, lying on the ground and quoted a famous Soviet poem that reads, â€œKill the fascist so he will lie on the groundâ€™s backbone â€¦ Kill him! Kill him!â€ Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy Other members also noticed the mixed feelings inside Meta. â€œThere are plenty of people in the company for whom weâ€™re more of an irritation,â€ McConnell says. â€œNobody really likes people looking over their shoulders and criticizing.â€ Since the board members are accomplished people who were probably chosen in part because they arenâ€™t bomb throwers, theyâ€™re not the type to declare outright war on Meta. â€œI donâ€™t approach this job thinking that Meta is evil,â€ says Alan Rusbridger, a board member and former editor of The Guardian.
 â€œThe problem that theyâ€™re trying to crack is one that nobody on earth has ever tried to do before. On the other hand, I think there has been a pattern of dragging them screaming and kicking to give us the information weâ€™re seeking.â€ There are worse things than no information. In one case, Meta gave the board the wrong informationâ€”which may soon lead to its most scathing decision yet.
During the Trump case, Meta researchers had mentioned to the board a program called Cross Check. It essentially gave special treatment to certain accounts belonging to politicians, celebrities, and the like. The company characterized it to the board as a limited program involving only â€œa small number of decisions.â€ Some board members saw it as inherently unfair, and in their recommendations in the Trump case, they asked Meta to compare the error rates in its Cross Check decisions with those on ordinary posts and accounts. Basically, the members wanted to make sure this odd program wasnâ€™t a get-out-of-jail-free card for the powerful.
Meta refused, saying the task wasnâ€™t feasible. (This excuse seems to be a go-to when the company wants to bounce the boardâ€™s suggestions.) Meta also pointed the board to one of its previous statements: â€œWe remove content from Facebook no matter who posts it, when it violates our standards.â€ In September 2021, The Wall Street Journal began publishing leaked documents showing that Cross Check actually involved millions of accounts. The program wound up shielding so much improper content that even its own employees had condemned it as allowing the powerful to circumvent the companyâ€™s rules. (One example: Trumpâ€™s infamous Black Lives Matterâ€“related post that said, â€œWhen the looting starts, the shooting starts.â€ Another was a soccer starâ€™s nude photos of a woman who accused him of rape.) In a May 2019 internal memo, dismayed Facebook researchers had written, â€œWe are knowingly exposing users to misinformation that we have the processes and resources to mitigate.â€ Another internal paper put it bluntly: â€œWe are not actually doing what we say we do publicly.â€ Meta was busted. Its claims to the board about the Cross Check system were at best a gross understatement. â€œI thought it was extremely disrespectful that Facebook so openly lied to the Oversight Board,â€ says former employee Frances Haugen , who leaked the papers and has met with the board privately to discuss the program.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy The board demanded that Meta explain itself, and the company admitted, according to the boardâ€™s transparency report, that it â€œshould have not said that Cross Check only applied to â€˜a small number of decisions.â€™â€ The board stated that if it couldnâ€™t trust Meta to provide accurate information, the entire exercise would crumble. Suzanne Nossel, the PEN CEO, says she worried that the companyâ€™s deceptions might hobble their project. â€œI was chagrined and concerned about the credibility of the board, our ability to carry out our work,â€ she says.
Metaâ€™s next move was reminiscent of its buck-passing in the Trump decisionâ€”it asked the board for its views on the program. Over the next few months, the board set up a committee to study Cross Check. Most of the meetings were virtual. But in April, the committee managed to meet for several days in New York City. The six members of the board and their prodigious staff took over several meeting rooms at a law firm in Midtown. After much pleading on my part, I sat in on one of their deliberationsâ€”the first time a journalist was allowed in an official Oversight Board session. (I had to agree not to attribute quotes to members by name.) It should not be the last; the mere glimpse I got showed just how frank and determined these semi-outsiders were to change the company that had brought them together.
Can Meta claim the right to favor certain customers? Of course not, because it is so entwined with the way people express themselves around the globe. At one point, a board member cried out in frustration: â€œIs being on Facebook a basic human right?â€ Fifteen people gathered around a set of tables arranged in a rectangle and set up with all the formality of a United Nations summit. A team of translators was on hand so every member could speak their native language, and each participant got an iPod Touch through which to listen to the translations. Once the conversation got underway, it quickly became heated. Some members abandoned their home tongues and spoke in less-polished English so the others could hear their urgency straight from their mouths.
I wound up monitoring perhaps an hour of a much longer session. From what I could perceive, the board was evaluating the program from a human rights perspective. The members seemed to have already concluded that Cross Check embodied inequality, the exact opposite of Metaâ€™s claim that â€œwe remove content from Facebook no matter who posts it, when it violates our standards.â€ One member referred to those in the program as the Privileged Post Club.
The board members seemed to understand Metaâ€™s argument that giving special treatment to well-known accounts could be expeditious. Employees could more quickly assess whether an improper post was excusable for its â€œnewsworthiness.â€ But the members zeroed in on the programâ€™s utter lack of transparency. â€œItâ€™s up to them to say why it should be private,â€ the cochair who was moderating the session remarked.
The members discussed whether Meta should make public all the details of the program. One suggestion was that the Privileged Posters be labeled. After listening to all this back-and-forth, one member finally burst out an objection to the entire concept of the program. â€œThe policies should be for all people!â€ she exclaimed.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy It was becoming clear that the problems with the Cross Check program were the same seemingly intractable problems of content moderation at scale. Meta is a private serviceâ€”can it claim the right to favor certain customers? Of course not, because Meta is so entwined with the way people express themselves around the globe. At one point, a member cried out in frustration: â€œIs being on Facebook a basic human right?â€ Meta, meanwhile, was still not sharing critical facts about the program. Was Cross Check singling out people solely to clear questionable content, or was it giving some people extra scrutiny? The board hadnâ€™t gotten an answer. After that meeting, members and staffers met with Meta officials and unloaded on them. â€œWe were pretty blunt and tenacious in trying to get the information we wanted,â€ Rusbridger told me later. â€œThey were a bit bruised; they thought we had behaved discourteously.â€ He says that the board got some of the details it soughtâ€”but not all of them.
Despite the frustrations so far, or perhaps because of them, the members are hoping to maneuver the board into a more visible, consequential spot. In October 2022, it announced that in recent months, Meta had been accepting more of its recommendations. Going forward, it might try to take on a wider range of cases, including ones on ads and groups. â€œI think we could double or triple the number of cases we handle without dramatically changing the nature of our operations,â€ says Neal, the chair of the trust. â€œBut letâ€™s assume we were doing 100 cases a yearâ€”is that alone enough to have a real impact on where platform content moderation is going? If you want to think about bigger impacts, you need to think about a much bigger organization.â€ The board could start by filling all its open slots.
It could also start critiquing Metaâ€™s algorithms. Even though they fall outside the boardâ€™s scope of influence, some of the groupâ€™s recommendations have implicated the companyâ€™s code. â€œWe have our own freedom of speech,â€ says Palmor, the lawyer from Israel. â€œEven if we donâ€™t talk directly about the algorithm, we do take into consideration the way content spreads.â€ The next step would be to get more expertise on how algorithms actually operate, and to make more direct rulings. (Hiring RenÃ©e DiResta would have helped with that.) Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed Xâ€™s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight Business Who Is Mira Murati, OpenAIâ€™s New Interim CEO? Steven Levy Then there are the policy advisory opinions, the big-issue examinations that, to date, have all originated within Meta. Members wish they could also add to the list. If Tawakkol Karman, a board member and Nobel Peace Prizeâ€“winning journalist, had her way, she would demand action on Metaâ€™s notoriously high volume of bogus accounts, which she calls â€œa disaster.â€ â€œThey breed misinformation, hatred, and conflict, and at the same time, fake accounts are recruited to attack the real accounts,â€ she says. â€œItâ€™s become a tool of oppressors.â€ So does the board have plans to address the issue? â€œWe are working on this,â€ she says.
The board is now exploring how it might exercise its power beyond Meta. Neal says the organization is considering a role in the execution of the European Unionâ€™s Digital Services Act, which will introduce a breathtaking suite of rules on digital platforms, including social media. The act includes a provision for mandatory appeals systems. Joining the effort might stretch the board thin but could also bring it closer to becoming, as some members dream, a more global force in content policy, with influence over other companies.
Never mind that Twitter, Snap, YouTube, and TikTok arenâ€™t exactly beating down the doors to get a piece of the Oversight Board. (Twitterâ€™s new CEO had, uh, tweeted to say heâ€™s setting up an advisory committee. Almost instantly, the Oversight Board responded with an offer to help, but so far he hasnâ€™t accepted.) The boardâ€™s decisions donâ€™t even cover Meta-owned WhatsApp. â€œI think we are making a difference,â€ Palmor says. â€œDo I think that the board has enough impact? My answer is no. I wish we had made more of a difference.â€ Yet both within Meta and on the board, people seem intoxicated by the idea of extended purview. For Meta, it would be a triumph if its competitors also had to play by its rules.
â€œWeâ€™re not seeking to be the board for the industry,â€ says Thomas Hughes, who handles the boardâ€™s operation. â€œBut we are seeking to understand how we might interrelate with other companiesâ€ to share what theyâ€™ve learned and â€œhow we might interact with companies setting up different types of councils or bodies to talk about standards.â€ Itâ€™s ironic that a board convened to oversee Meta, a company whose sins spring from a mania for growth, now has its own visions of getting big fast.
This article appears in the December 2022/January 2023 issue.
Subscribe now.
Let us know what you think about this article. Submit a letter to the editor at mail@wired.com.
You Might Also Like â€¦ ğŸ“¨ Make the most of chatbots with our AI Unlocked newsletter Taylor Swift, Star Wars, Stranger Things , and Deadpool have one man in common Generative AI is playing a surprising role in Israel-Hamas disinformation The new era of social media looks as bad for privacy as the last one Johnny Cashâ€™s Taylor Swift cover predicts the boring future of AI music Your internet browser does not belong to you ğŸ”Œ Charge right into summer with the best travel adapters , power banks , and USB hubs Editor at Large X Topics longreads magazine-30.12/31.01 Facebook Mark Zuckerberg content moderation Meta Social Media Steven Levy Steven Levy WIRED Staff Lauren Smiley Brandi Collins-Dexter Steven Levy Andy Greenberg Angela Watercutter Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
