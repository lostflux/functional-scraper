Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business New Algorithms Could Reduce Racial Disparities in Health Care Photograph: BSIP/Getty Images Save this story Save Save this story Save Application Ethics Personal services End User Research Sector Health care Source Data Images Technology Machine learning Machine vision Researchers trying to improve health care with artificial intelligence usually subject their algorithms to a form of machine med school. Software learns from doctors by digesting thousands or millions of x-rays or other data labeled by expert humans until it can accurately flag suspect moles or lungs showing signs of Covid-19 by itself.
A study published this month took a different approach‚Äîtraining algorithms to read knee x-rays for arthritis by using patients as the AI arbiters of truth instead of doctors. The results revealed that radiologists may have literal blind spots when it comes to reading Black patients‚Äô x-rays.
The algorithms trained on patients‚Äô reports did a better job than doctors at accounting for the pain experienced by Black patients, apparently by discovering patterns of disease in the images that humans usually overlook.
‚ÄúThis sends a signal to radiologists and other doctors that we may need to reevaluate our current strategies,‚Äù says Said Ibrahim, a professor at Weill Cornell Medicine, in New York City, who researches health inequalities, and who was not involved in the study.
Algorithms designed to reveal what doctors don‚Äôt see, instead of mimicking their knowledge, could make health care more equitable. In a commentary on the new study, Ibrahim suggested it could help reduce disparities in who gets surgery for arthritis. African American patients are about 40 percent less likely than others to receive a knee replacement, he says, even though they are at least as likely to suffer osteoarthritis. Differences in income and insurance likely play a part, but so could differences in diagnosis.
‚ÄúThe algorithm was seeing things over and above what the radiologists were seeing.‚Äù Ziad Obermeyer, professor, UC Berkeley School of Public Health Ziad Obermeyer, an author of the study and a professor at the University of California Berkeley‚Äôs School of Public Health, was inspired to use AI to probe what radiologists weren‚Äôt seeing by a medical puzzle. Data from a long-running National Institutes of Health study on knee osteoarthritis showed that Black patients and people with lower incomes reported more pain than other patients with x-rays radiologists scored as similar. The differences might stem from physical factors unknown to keepers of knee knowledge, or psychological and social differences‚Äîbut how to tease those apart? Obermeyer and researchers from Stanford, Harvard, and the University of Chicago created computer vision software using the NIH data to investigate what human doctors might be missing. They programmed algorithms to predict a patient‚Äôs pain level from an x-ray. Over tens of thousands of images, the software discovered patterns of pixels that correlate with pain.
When given an x-ray it hasn‚Äôt seen before, the software uses those patterns to predict the pain a patient would report experiencing. Those predictions correlated more closely with patients‚Äô pain than the scores radiologists assigned to knee x-rays, particularly for Black patients. That suggests the algorithms had learned to detect evidence of disease that radiologists didn‚Äôt. ‚ÄúThe algorithm was seeing things over and above what the radiologists were seeing‚Äîthings that are more commonly causes of pain in Black patients,‚Äù Obermeyer says.
By Tom Simonite History may explain why radiologists aren‚Äôt as proficient in assessing knee pain in Black patients. The standard grading used today originated in a small 1957 study in a northern England mill town with a less diverse population than the modern US. Doctors used what they saw to devise a way to grade the severity of osteoarthritis based on observations such as narrowed cartilage. X-ray equipment, lifestyles, and many other factors have changed a lot since. ‚ÄúIt‚Äôs not surprising that that fails to capture what doctors see in the clinic today,‚Äù Obermeyer says.
The study is notable not just for showing what happens when AI is trained by patient feedback instead of expert opinions, but because medical algorithms have more often been seen as a cause of bias, not a cure. In 2019, Obermeyer and collaborators showed that an algorithm guiding care for millions of US patients gave white people priority over Black people for assistance with complex conditions such as diabetes.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Obermeyer‚Äôs new study showing how algorithms can uncover bias comes with a catch: Neither he nor the algorithms can explain what the algorithms see in x-rays that doctors miss. The researchers used artificial neural networks , a technology that has made many AI applications more practical, but is so tricky to reverse engineer that experts call them ‚Äúblack boxes.‚Äù Judy Gichoya, a radiologist and assistant professor at Emory University, aims to uncover what the knee algorithms know. It will depend on human labor and ingenuity.
She‚Äôs assembling a larger, more diverse collection of x-rays and other data to test the algorithms‚Äô performance. By asking radiologists to make detailed notes on x-rays, and comparing what they see with the pain-predicting algorithms‚Äô output, Gichoya hopes to uncover clues about what it‚Äôs picking up on. She‚Äôs hopeful it won‚Äôt be anything too alien to human doctors. ‚ÄúIt may be that it‚Äôs something we do see, but in the wrong way,‚Äù she says.
üì© Want the latest on tech, science, and more? Sign up for our newsletters ! The unsettling truth about the ‚ÄúMostly Harmless‚Äù hiker How many microcovids would you spend on a burrito ? Apps to help you trim down subscriptions‚Äîand save money The Parler bans and a new front in the ‚Äúfree speech‚Äù wars Listening to Black women: The innovation tech can't crack üéÆ WIRED Games: Get the latest tips, reviews, and more üíª Upgrade your work game with our Gear team‚Äôs favorite laptops , keyboards , typing alternatives , and noise-canceling headphones Senior Editor X Topics algorithms health machine learning artificial intelligence medicine neural networks Will Knight Khari Johnson Will Bedingfield Steven Levy Will Knight Caitlin Harrington Peter Guest Khari Johnson Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
