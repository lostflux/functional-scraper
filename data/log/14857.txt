Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Intel unveils new generation of infrastructure processing units Share on Facebook Share on X Share on LinkedIn Intel's infrastructure processing unit roadmap.
Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Intel unveiled its latest infrastructure processing unit (IPU) with plans to take on its rivals through the year 2026.
With this roadmap, Intel said it plans to create end-to-end programmable networks, deploying its full portfolio of based on field programmable gate arrays (FPGA) and application specific integrated circuits (ASIC) IPU platforms.
The company will also have open-software frameworks designed to better serve customer needs with improved data center efficiency and manageability. Intel made the announcement at its Intel Vision conference in Dallas, Texas, today.
About the IPU An IPU is a programmable networking device designed to enable cloud and communication service providers, as well as enterprises, to improve security, reduce overhead and free up performance for central processing units (CPUs).
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! With an IPU, customers better utilize resources with a secure, stable, programmable solution that provides greater security and isolation to both service provider and tenant, Intel said.
About the IPDK Intel said an open ecosystem is the best way to extract the value of the IPU. Intel’s IPUs are enabled by a foundation powered by open-source software, including the infrastructure programmer development kit (IPDK), which builds upon the company’s history of open engagements with SPDK, DPDK and P4.
Intel remarked that it has worked with the community to simplify developer access to the technology and help customers build cloud orchestration software and services. The IPDK allows customers to focus on their applications not on the underlying API, or on the hardware.
Intel’s IPU roadmap Intel said that its second-generation 200GB IPU, dubbed Mount Evans, is its first ASIC IPU. And it said Oak Springs Canyon is Intel’s second-generation FPGA IPU shipping to Google and other service providers. Those are coming this year.
Intel also said that for 2023 and 2024, it will have its third-generation 400GB IPUs, code-named Mount Morgan and Hot Springs Canyon, expected to ship to customers and partners.
And in 2025 and 2026, Intel said it will ship its 800GB IPUs for customers and partners. The Mount Evans IPU was architected and developed with Google Cloud. It integrates lessons from multiple generations of FPGA SmartNICs and the first-generation Intel FGPA based IPU.
Hyperscale-ready, it offers high-performance network and storage virtualization offload while maintaining a high degree of control. The Mount Evans IPU will ship in 2022 to Google and other service providers; broad deployment is expected in 2023.
Habana Labs’ Gaudi2 deep learning training processor Meanwhile, Intel’s Habana Labs division launched the Gaudi2 processor, a second-generation Gaudi processor for training. And for inference deployments, it introduced the Greco processor, the successor to the Goya processor.
The processors are purpose-built for AI deep learning applications. Implemented in seven-nanometer production, the processors use Habana’s high-efficiency architecture to provide customers with higher-performance model training and inferencing for computer vision and natural language applications in the datacenter.
The Greco is a second-generation inference processor for deep learning. It is built in seven-nanometer production and will debut in the second half of 2022.
At the conference, Habana demonstrated Gaudi2 training throughput performance on computer vision – ResNet-50 (v1.1) – and natural language processor – BERT Phase-1 and Phase-2 (version) – workloads, nearly twice that of the rival Nvidia A100 80GB processor, Intel said.
For data center customers, the task of training deep learning models is increasingly time-consuming and costly due to the growing size and complexity of datasets and AI workloads, Intel said. Gaudi2 was designed to bring improved deep learning performance and efficiency – and choice – to cloud and on-premises systems.
To increase model accuracy and recency, customers require more frequent training. According to IDC, 74% of machine learning (ML) practitioners surveyed in 2020 run five to 10 training iterations of their models, more than 50% rebuild models weekly or more often and 26% rebuild models daily or even hourly.
And 56% of those surveyed cited cost-to-train as the number one obstacle to their organizations taking advantage of the insights, innovations and enhanced end-customer experiences that AI can provide. The Gaudi platform solutions, first-gen Gaudi and Gaudi2, were created to address this growing need.
To date, one thousand HLS-Gaudi2s have been deployed in the Habana Gaudi2 data centers in Israel to support research and development for Gaudi2 software optimization and to inform further advancements in the forthcoming Gaudi3 processor.
Habana is partnering with Supermicro to bring the Supermicro Gaudi2 Training Server to market in 2022’s second half. It is also working with DDN to deliver a turnkey server featuring the Supermicro server with augmented AI storage with the pairing of the DDN AI400X2 storage solution.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
