Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Researchers develop ‘Woodpecker’: A groundbreaking solution to AI’s hallucination problem Share on Facebook Share on X Share on LinkedIn Credit: VentureBeat made with Midjourney Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
A group of artificial intelligence researchers from the University of Science and Technology of China (USTC) and Tencent YouTu Lab have developed an innovative framework, coined as “ Woodpecker “, designed to correct hallucinations in multimodal large language models ( MLLMs ).
The research paper outlining this groundbreaking approach was published on the pre-print server arXiv, under the title “Woodpecker: Hallucination Correction for Multimodal Large Language Models.” “Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content,” the researchers note in their paper. Existing solutions mainly resort to an instruction-tuning manner that requires retraining the models with specific data, which can be data—and computation—intensive.
The five stages of the ‘Woodpecker’ framework Woodpecker offers a fresh perspective by introducing a training-free method that corrects hallucinations from the generated text. The framework performs correction after a thorough diagnosis, incorporating a total of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! “Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text,” the researchers stated, explaining the inspiration behind the framework’s name. Each step in the pipeline is clear and transparent, providing valuable interpretability.
The stages of Woodpecker work in harmony to validate and correct any inconsistencies between image content and generated text. First, it identifies the main objects mentioned in the text. Then, it asks questions around the extracted objects, such as their number and attributes. The framework answers these questions using expert models in a process called visual knowledge validation. Following this, it converts the question-answer pairs into a visual knowledge base consisting of object-level and attribute-level claims about the image. Finally, Woodpecker modifies the hallucinations and adds the corresponding evidence under the guidance of the visual knowledge base.
The researchers have released the source code for Woodpecker, encouraging further exploration and application of the framework by the wider AI community. For those interested in experiencing the capabilities of Woodpecker firsthand, the researchers have provided an interactive demo of the system.
 This platform provides an opportunity to understand the workings of Woodpecker in real-time and observe its hallucination correction capabilities.
How effective is ‘Woodpecker’? A comprehensive analysis The team conducted comprehensive quantitative and qualitative experiments to evaluate Woodpecker’s effectiveness, using various datasets, including POPE, MME, and LLaVA-QA90. “On the POPE benchmark, our method largely boosts the accuracy of the baseline MiniGPT-4/mPLUG-Owl from 54.67%/62% to 85.33%/86.33%,” they reported.
This breakthrough comes at a time when AI is increasingly integrated into various industries. MLLMs have a wide range of applications, from content generation and moderation to automated customer service and data analysis. However, hallucinations—where the AI generates information not present in the input data—have been a significant roadblock in their practical application.
The development of Woodpecker signifies a crucial step forward in addressing this issue, paving the way for more reliable and accurate AI systems. As MLLMs continue to evolve and improve, the importance of such frameworks in ensuring their accuracy and reliability cannot be overstated.
The Woodpecker framework, with its ability to correct hallucinations without retraining and high interpretability, promises to be a game-changer in the world of MLLMs. It holds immense potential to significantly improve the accuracy and reliability of AI systems in various applications, making this a notable development in the field of artificial intelligence.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
