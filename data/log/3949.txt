Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages AI Weekly: AI prosecutors and pong-playing neurons closed out 2021 Share on Facebook Share on X Share on LinkedIn Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
In the week that drew 2021 to a close, the tech news cycle died down, as it typically does. Even an industry as fast-paced as AI needs a reprieve, sometimes — especially as a new COVID-19 variant upends plans and major conferences.
But that isn’t to say late December wasn’t eventful.
One of the most talked-about stories came from the South China Morning Post (SCMP), which described an “AI prosecutor” developed by Chinese researchers that can reportedly identify crimes and press charges “with 97% accuracy.” The system — which was trained on 1,000 “traits” sourced from 17,000 real-life cases of crimes from 2015 to 2020, like gambling, reckless driving, theft, and fraud — recommends sentences given a brief text description. It’s already been piloted in the Shanghai Pudong People’s Procuratorate, China’s largest district prosecution office., according to SCMP.
It isn’t surprising that a country like China — which, like parts of the U.S., has embraced predictive crime technologies — is pursuing a black-box stand-in for human judges. But the implications are nonetheless worrisome for those who might be subjected to the AI prosecutor’s judgment, given how inequitable algorithms in the justice system have historically been shown to be.
VB Event The AI Impact Tour Connect with the enterprise AI community at VentureBeat’s AI Impact Tour coming to a city near you! Published last December, a study from researchers at Harvard and the University of Massachusetts found that the Public Safety Assessment (PSA), a risk-gauging tool that judges can opt to use when deciding whether a defendant should be released before a trial, tends to recommend sentencing that’s too severe. Moreover, the PSA is likely to impose a cash bond on male arrestees versus female arrestees, according to the researchers — a potential sign of gender bias.
The U.S. justice system has a history of adopting AI tools that are later found to exhibit bias against defendants belonging to certain demographic groups. Perhaps the most infamous of these is Northpointe’s Correctional Offender Management Profiling for Alternative Sanctions (COMPAS), which is designed to predict a person’s likelihood of becoming a recidivist. A ProPublica report found that COMPAS was far more likely to incorrectly judge black defendants to be at higher risk of recidivism than white defendants, while at the same time flagging white defendants as low risk more often than black defendants.
With new research showing that even training predictive policing tools in a way meant to lessen bias has little effect, it’s become clear — if it wasn’t before — that deploying these systems responsibly today is infeasible. That’s perhaps why some early adopters of predictive policing tools, like the police departments of Pittsburgh and Los Angeles, have announced they will no longer use them.
But with less scrupulous law enforcement , courtrooms , and municipalities plowing ahead, regulation-driven by public pressure is perhaps the best bet for reigning in and setting standards for the technology. Cities including Santa Cruz and Oakland have outright banned predictive policing tools, as has New Orleans. And the nonprofit group Fair Trials is calling on the European Union to include a prohibition on predictive crime tools in its proposed AI regulatory framework.
“We do not condone the use [of tools like the PSA],” Ben Winters, the creator of a report from the Electronic Privacy Information Center that called pretrial risk assessment tools a strike against individual liberties, said in a recent statement. “But we would absolutely say that where they are being used, they should be regulated pretty heavily.” A new approach to AI It’s unclear whether even the most sophisticated AI systems understand the world the way that humans do. That’s another argument in favor of regulating predictive policing, but one company, Cycorp — which was profiled by Business Insider this week — is seeking to codify general human knowledge so that AI might make use of it.
Cycorp’s prototype software, which has been in development for nearly 30 years, isn’t programmed in the traditional sense. Cycorp can make inferences that an author might expect a human reader to make. Or it can pretend to be a confused sixth-grader, tasking users with helping it to learn sixth-grade math.
Is there a path to AI with human-level intelligence? That’s the million-dollar question. Experts like the vice president and chief AI scientist for Facebook, Yann LeCun, and renowned professor of computer science, and artificial neural networks expert, Yoshua Bengio, don’t believe it’s within reach, but others beg to differ.
 One promising direction is neuro-symbolic reasoning, which merges learning and logic to make algorithms “smarter.” The thought is that neuro-symbolic reasoning could help incorporate common sense reasoning and domain knowledge into algorithms to, for example, identify objects in a picture.
New paradigms could be on the horizon, like “synthetic brains” made from living cells. Earlier this month, researchers at Cortical Labs created a network of neurons in a dish that learned to play Pong faster than an AI system. The neurons weren’t as skilled at Pong as the system, but they took only five minutes to master the mechanics versus the AI’s 90 minutes.
Pong hardly mirrors the complexity of the real world. But in tandem with forward-looking hardware like neuromorphic chips and photonics , as well as novel scaling techniques and architectures, the future looks bright for more capable, potentially human-like AI. Regulation will catch up, with any luck. We’ve seen a preview of the consequences — including wrongful arrests , sexist job recruitment , and erroneous grades — if it doesn’t.
For AI coverage, send news tips to Kyle Wiggers — and be sure to subscribe to the AI Weekly newsletter and bookmark our AI channel, The Machine.
Thanks for reading, Kyle Wiggers AI Staff Writer VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
