Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons John Pavlus Science Computers Are Learning to Readâ€”But They're Still Not So Smart The BERT neural network has led to a revolution in how machines understand human language.
Illustration: Jon Fox/Quanta Magazine Save this story Save Save this story Save In the fall of 2017, Sam Bowman, a computational linguist at New York University, figured that computers still werenâ€™t very good at understanding the written word.
 Sure, they had become decent at simulating that understanding in certain narrow domains, like automatic translation or sentiment analysis (for example, determining if a sentence sounds â€œmean or nice,â€ he said). But Bowman wanted measurable evidence of the genuine article: bona fide, human-style reading comprehension in English. So he came up with a test.
Original story reprinted with permission from Quanta Magazine , an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developÂ­ments and trends in matheÂ­matics and the physical and life sciences.
In an April 2018 paper coauthored with collaborators from the University of Washington and DeepMind, the Google-owned artificial intelligence company, Bowman introduced a battery of nine reading-comprehension tasks for computers called GLUE (General Language Understanding Evaluation). The test was designed as â€œa fairly representative sample of what the research community thought were interesting challenges,â€ said Bowman, but also â€œpretty straightforward for humans.â€ For example, one task asks whether a sentence is true based on information offered in a preceding sentence. If you can tell that â€œPresident Trump landed in Iraq for the start of a seven-day visitâ€ implies that â€œPresident Trump is on an overseas visit,â€ youâ€™ve just passed.
The machines bombed. Even state-of-the-art neural networks scored no higher than 69 out of 100 across all nine tasks: a D-plus, in letter grade terms. Bowman and his coauthors werenâ€™t surprised. Neural networks â€” layers of computational connections built in a crude approximation of how neurons communicate within mammalian brains â€” had shown promise in the field of â€œnatural language processingâ€ (NLP), but the researchers werenâ€™t convinced that these systems were learning anything substantial about language itself. And GLUE seemed to prove it. â€œThese early results indicate that solving GLUE is beyond the capabilities of current models and methods,â€ Bowman and his coauthors wrote.
Their appraisal would be short-lived. In October of 2018, Google introduced a new method nicknamed BERT (Bidirectional Encoder Representations from Transformers). It produced a GLUE score of 80.5. On this brand-new benchmark designed to measure machinesâ€™ real understanding of natural language â€” or to expose their lack thereof â€” the machines had jumped from a D-plus to a B-minus in just six months.
â€œThat was definitely the â€˜oh, crapâ€™ moment,â€ Bowman recalled, using a more colorful interjection. â€œThe general reaction in the field was incredulity. BERT was getting numbers on many of the tasks that were close to what we thought would be the limit of how well you could do.â€ Indeed, GLUE didnâ€™t even bother to include human baseline scores before BERT; by the time Bowman and one of his Ph.D. students added them to GLUE in February 2019, they lasted just a few months before a BERT-based system from Microsoft beat them.
As of this writing, nearly every position on the GLUE leaderboard is occupied by a system that incorporates, extends or optimizes BERT. Five of these systems outrank human performance.
But is AI actually starting to understand our language â€” or is it just getting better at gaming our systems ? As BERT-based neural networks have taken benchmarks like GLUE by storm, new evaluation methods have emerged that seem to paint these powerful NLP systems as computational versions of Clever Hans, the early 20th-century horse who seemed smart enough to do arithmetic, but who was actually just following unconscious cues from his trainer.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall â€œWe know weâ€™re somewhere in the gray area between solving language in a very boring, narrow sense, and solving AI,â€ Bowman said. â€œThe general reaction of the field was: Why did this happen? What does this mean? What do we do now?â€ In the famous Chinese Room thought experiment, a non-Chinese-speaking person sits in a room furnished with many rulebooks. Taken together, these rulebooks perfectly specify how to take any incoming sequence of Chinese symbols and craft an appropriate response. A person outside slips questions written in Chinese under the door. The person inside consults the rulebooks, then sends back perfectly coherent answers in Chinese.
The thought experiment has been used to argue that, no matter how it might appear from the outside, the person inside the room canâ€™t be said to have any true understanding of Chinese. Still, even a simulacrum of understanding has been a good enough goal for natural language processing.
The only problem is that perfect rulebooks donâ€™t exist, because natural language is far too complex and haphazard to be reduced to a rigid set of specifications. Take syntax, for example: the rules (and rules of thumb) that define how words group into meaningful sentences. The phrase â€œ colorless green ideas sleep furiously â€ has perfect syntax, but any natural speaker knows itâ€™s nonsense. What prewritten rulebook could capture this â€œunwrittenâ€ fact about natural language â€” or innumerable others? NLP researchers have tried to square this circle by having neural networks write their own makeshift rulebooks, in a process called pretraining.
Before 2018, one of NLPâ€™s main pretraining tools was something like a dictionary. Known as word embeddings, this dictionary encoded associations between words as numbers in a way that deep neural networks could accept as input â€” akin to giving the person inside a Chinese room a crude vocabulary book to work with. But a neural network pretrained with word embeddings is still blind to the meaning of words at the sentence level. â€œIt would think that â€˜a man bit the dogâ€™ and â€˜a dog bit the manâ€™ are exactly the same thing,â€ said Tal Linzen , a computational linguist at Johns Hopkins University.
Tal Linzen, a computational linguist at Johns Hopkins University, wonders â€œto what extent these models are really understanding language,â€ and not just â€œpicking up weird tricks that happen to work.â€ Photograph: Will Kirk/Johns Hopkins University A better method would use pretraining to equip the network with richer rulebooks â€” not just for vocabulary, but for syntax and context as well â€” before training it to perform a specific NLP task. In early 2018, researchers at OpenAI, the University of San Francisco, the Allen Institute for Artificial Intelligence and the University of Washington simultaneously discovered a clever way to approximate this feat. Instead of pretraining just the first layer of a network with word embeddings, the researchers began training entire neural networks on a broader basic task called language modeling.
â€œThe simplest kind of language model is: Iâ€™m going to read a bunch of words and then try to predict the next word,â€ explained Myle Ott , a research scientist at Facebook. â€œIf I say, â€˜George Bush was born in,â€™ the model now has to predict the next word in that sentence.â€ Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall These deep pretrained language models could be produced relatively efficiently. Researchers simply fed their neural networks massive amounts of written text copied from freely available sources like Wikipedia â€” billions of words, preformatted into grammatically correct sentences â€” and let the networks derive next-word predictions on their own. In essence, it was like asking the person inside a Chinese room to write all his own rules, using only the incoming Chinese messages for reference.
â€œThe great thing about this approach is it turns out that the model learns a ton of stuff about syntax,â€ Ott said. Whatâ€™s more, these pretrained neural networks could then apply their richer representations of language to the job of learning an unrelated, more specific NLP task, a process called fine-tuning.
â€œYou can take the model from the pretraining stage and kind of adapt it for whatever actual task you care about,â€ Ott explained. â€œAnd when you do that, you get much better results than if you had just started with your end task in the first place.â€ Indeed, in June of 2018, when OpenAI unveiled a neural network called GPT , which included a language model pretrained on nearly a billion words (sourced from 11,038 digital books) for an entire month, its GLUE score of 72.8 immediately took the top spot on the leaderboard. Still, Sam Bowman assumed that the field had a long way to go before any system could even begin to approach human-level performance.
Then BERT appeared.
So what exactly is BERT? First, itâ€™s not a fully trained neural network capable of besting human performance right out of the box. Instead, said Bowman, BERT is â€œa very precise recipe for pretraining a neural network.â€ Just as a baker can follow a recipe to reliably produce a delicious prebaked pie crust â€” which can then be used to make many different kinds of pie, from blueberry to spinach quiche â€” Google researchers developed BERTâ€™s recipe to serve as an ideal foundation for â€œbakingâ€ neural networks (that is, fine-tuning them) to do well on many different natural language processing tasks. Google also open-sourced BERTâ€™s code, which means that other researchers donâ€™t have to repeat the recipe from scratch â€” they can just download BERT as-is, like buying a prebaked pie crust from the supermarket.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall If BERT is essentially a recipe, whatâ€™s the ingredient list? â€œItâ€™s the result of three things coming together to really make things click,â€ said Omer Levy , a research scientist at Facebook who has analyzed BERTâ€™s inner workings.
Omer Levy, a research scientist at Facebook, has studied why BERT is so successful.
Photograph: Courtesy of Omer Levy The first is a pretrained language model, those reference books in our Chinese room. The second is the ability to figure out which features of a sentence are most important.
In 2017, an engineer at Google Brain named Jakob Uszkoreit was working on ways to accelerate Googleâ€™s language-understanding efforts. He noticed that state-of-the-art neural networks also suffered from a built-in constraint: They all looked through the sequence of words one by one. This â€œsequentialityâ€ seemed to match intuitions of how humans actually read written sentences. But Uszkoreit wondered if â€œit might be the case that understanding language in a linear, sequential fashion is suboptimal,â€ he said.
Uszkoreit and his collaborators devised a new architecture for neural networks focused on â€œattention,â€ a mechanism that lets each layer of the network assign more weight to some specific features of the input than to others. This new attention-focused architecture, called a transformer, could take a sentence like â€œa dog bites the manâ€ as input and encode each word in many different ways in parallel. For example, a transformer might connect â€œbitesâ€ and â€œmanâ€ together as verb and object, while ignoring â€œaâ€; at the same time, it could connect â€œbitesâ€ and â€œdogâ€ together as verb and subject, while mostly ignoring â€œthe.â€ The nonsequential nature of the transformer represented sentences in a more expressive form, which Uszkoreit calls treelike. Each layer of the neural network makes multiple, parallel connections between certain words while ignoring others â€” akin to a student diagramming a sentence in elementary school. These connections are often drawn between words that may not actually sit next to each other in the sentence. â€œThose structures effectively look like a number of trees that are overlaid,â€ Uszkoreit explained.
This treelike representation of sentences gave transformers a powerful way to model contextual meaning, and also to efficiently learn associations between words that might be far away from each other in complex sentences. â€œItâ€™s a bit counterintuitive,â€ Uszkoreit said, â€œbut it is rooted in results from linguistics, which has for a long time looked at treelike models of language.â€ Jakob Uszkoreit, who leads the Google AI Brain team in Berlin, helped develop a new architecture for neural networks that focuses on attention.
Photograph: Google Finally, the third ingredient in BERTâ€™s recipe takes nonlinear reading one step further.
Unlike other pretrained language models, many of which are created by having neural networks read terabytes of text from left to right, BERTâ€™s model reads left to right and right to left at the same time, and learns to predict words in the middle that have been randomly masked from view. For example, BERT might accept as input a sentence like â€œGeorge Bush was [â€¦â€¦..] in Connecticut in 1946â€ and predict the masked word in the middle of the sentence (in this case, â€œbornâ€) by parsing the text from both directions. â€œThis bidirectionality is conditioning a neural network to try to get as much information as it can out of any subset of words,â€ Uszkoreit said.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall The Mad-Libs-esque pretraining task that BERT uses â€” called masked-language modeling â€” isnâ€™t new. In fact, itâ€™s been used as a tool for assessing language comprehension in humans for decades. For Google, it also offered a practical way of enabling bidirectionality in neural networks, as opposed to the unidirectional pretraining methods that had previously dominated the field. â€œBefore BERT, unidirectional language modeling was the standard, even though it is an unnecessarily restrictive constraint,â€ said Kenton Lee , a research scientist at Google.
Each of these three ingredients â€” a deep pretrained language model, attention and bidirectionality â€” existed independently before BERT. But until Google released its recipe in late 2018, no one had combined them in such a powerful way.
Like any good recipe, BERT was soon adapted by cooks to their own tastes. In the spring of 2019, there was a period â€œwhen Microsoft and Alibaba were leapfrogging each other week by week, continuing to tune their models and trade places at the number one spot on the leaderboard,â€ Bowman recalled. When an improved version of BERT called RoBERTa first came on the scene in August, the DeepMind researcher Sebastian Ruder dryly noted the occasion in his widely read NLP newsletter : â€œAnother month, another state-of-the-art pretrained language model.â€ BERTâ€™s â€œpie crustâ€ incorporates a number of structural design decisions that affect how well it works. These include the size of the neural network being baked, the amount of pretraining data, how that pretraining data is masked and how long the neural network gets to train on it. Subsequent recipes like RoBERTa result from researchers tweaking these design decisions, much like chefs refining a dish.
In RoBERTaâ€™s case, researchers at Facebook and the University of Washington increased some ingredients (more pretraining data, longer input sequences, more training time), took one away (a â€œnext sentence predictionâ€ task, originally included in BERT, that actually degraded performance) and modified another (they made the masked-language pretraining task harder). The result? First place on GLUE â€” briefly. Six weeks later, researchers from Microsoft and the University of Maryland added their own tweaks to RoBERTa and eked out a new win. As of this writing, yet another model called ALBERT, short for â€œA Lite BERT,â€ has taken GLUEâ€™s top spot by further adjusting BERTâ€™s basic design.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall â€œWeâ€™re still figuring out what recipes work and which ones donâ€™t,â€ said Facebookâ€™s Ott, who worked on RoBERTa.
Still, just as perfecting your pie-baking technique isnâ€™t likely to teach you the principles of chemistry, incrementally optimizing BERT doesnâ€™t necessarily impart much theoretical knowledge about advancing NLP. â€œIâ€™ll be perfectly honest with you: I donâ€™t follow these papers, because they are extremely boring to me,â€ said Linzen, the computational linguist from Johns Hopkins. â€œThere is a scientific puzzle there,â€ he grants, but it doesnâ€™t lie in figuring out how to make BERT and all its spawn smarter, or even in figuring out how they got smart in the first place. Instead, â€œwe are trying to understand to what extent these models are really understanding language,â€ he said, and not â€œpicking up weird tricks that happen to work on the data sets that we commonly evaluate our models on.â€ In other words: BERT is doing something right. But what if itâ€™s for the wrong reasons? In July 2019, two researchers from Taiwanâ€™s National Cheng Kung University used BERT to achieve an impressive result on a relatively obscure natural language understanding benchmark called the argument reasoning comprehension task. Performing the task requires selecting the appropriate implicit premise (called a warrant) that will back up a reason for arguing some claim. For example, to argue that â€œsmoking causes cancerâ€ (the claim) because â€œscientific studies have shown a link between smoking and cancerâ€ (the reason), you need to presume that â€œscientific studies are credibleâ€ (the warrant), as opposed to â€œscientific studies are expensiveâ€ (which may be true, but makes no sense in the context of the argument). Got all that? If not, donâ€™t worry. Even human beings donâ€™t do particularly well on this task without practice: The average baseline score for an untrained person is 80 out of 100. BERT got 77 â€” â€œsurprising,â€ in the authorsâ€™ understated opinion.
But instead of concluding that BERT could apparently imbue neural networks with near-Aristotelian reasoning skills, they suspected a simpler explanation: that BERT was picking up on superficial patterns in the way the warrants were phrased. Indeed, after re-analyzing their training data, the authors found ample evidence of these so-called spurious cues. For example, simply choosing a warrant with the word â€œnotâ€ in it led to correct answers 61% of the time. After these patterns were scrubbed from the data, BERTâ€™s score dropped from 77 to 53 â€” equivalent to random guessing. An article in The Gradient , a machine-learning magazine published out of the Stanford Artificial Intelligence Laboratory, compared BERT to Clever Hans , the horse with the phony powers of arithmetic.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall In another paper called â€œ Right for the Wrong Reasons ,â€ Linzen and his coauthors published evidence that BERTâ€™s high performance on certain GLUE tasks might also be attributed to spurious cues in the training data for those tasks. (The paper included an alternative data set designed to specifically expose the kind of shortcut that Linzen suspected BERT was using on GLUE. The data setâ€™s name: Heuristic Analysis for Natural-Language-Inference Systems, or HANS.) So is BERT, and all of its benchmark-busting siblings, essentially a sham? Bowman agrees with Linzen that some of GLUEâ€™s training data is messy â€” shot through with subtle biases introduced by the humans who created it, all of which are potentially exploitable by a powerful BERT-based neural network. â€œThereâ€™s no single â€˜cheap trickâ€™ that will let it solve everything [in GLUE], but there are lots of shortcuts it can take that will really help,â€ Bowman said, â€œand the model can pick up on those shortcuts.â€ But he doesnâ€™t think BERTâ€™s foundation is built on sand, either. â€œIt seems like we have a model that has really learned something substantial about language,â€ he said. â€œBut itâ€™s definitely not understanding English in a comprehensive and robust way.â€ According to Yejin Choi , a computer scientist at the University of Washington and the Allen Institute, one way to encourage progress toward robust understanding is to focus not just on building a better BERT, but also on designing better benchmarks and training data that lower the possibility of Clever Hansâ€“style cheating. Her work explores an approach called adversarial filtering, which uses algorithms to scan NLP training data sets and remove examples that are overly repetitive or that otherwise introduce spurious cues for a neural network to pick up on. After this adversarial filtering, â€œBERTâ€™s performance can reduce significantly,â€ she said, while â€œhuman performance does not drop so much.â€ Still, some NLP researchers believe that even with better training, neural language models may still face a fundamental obstacle to real understanding. Even with its powerful pretraining, BERT is not designed to perfectly model language in general. Instead, after fine-tuning, it models â€œa specific NLP task, or even a specific data set for that task,â€ said Anna Rogers , a computational linguist at the Text Machine Lab at the University of Massachusetts, Lowell. And itâ€™s likely that no training data set, no matter how comprehensively designed or carefully filtered, can capture all the edge cases and unforeseen inputs that humans effortlessly cope with when we use natural language.
Science SpaceXâ€™s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall Bowman points out that itâ€™s hard to know how we would ever be fully convinced that a neural network achieves anything like real understanding. Standardized tests, after all, are supposed to reveal something intrinsic and generalizable about the test-takerâ€™s knowledge. But as anyone who has taken an SAT prep course knows, tests can be gamed. â€œWe have a hard time making tests that are hard enough and trick-proof enough that solving [them] really convinces us that weâ€™ve fully solved some aspect of AI or language technology,â€ he said.
Indeed, Bowman and his collaborators recently introduced a test called SuperGLUE thatâ€™s specifically designed to be hard for BERT-based systems. So far, no neural network can beat human performance on it. But even if (or when) it happens, does it mean that machines can really understand language any better than before? Or does just it mean that science has gotten better at teaching machines to the test? â€œThatâ€™s a good analogy,â€ Bowman said. â€œWe figured out how to solve the LSAT and the MCAT, and we might not actually be qualified to be doctors and lawyers.â€ Still, he added, this seems to be the way that artificial intelligence research moves forward. â€œChess felt like a serious test of intelligence until we figured out how to write a chess program,â€ he said. â€œWeâ€™re definitely in an era where the goal is to keep coming up with harder problems that represent language understanding, and keep figuring out how to solve those problems.â€ Original story reprinted with permission from Quanta Magazine , an editorially independent publication of the Simons Foundation whose mission is to enhance public understanding of science by covering research developments and trends in mathematics and the physical and life sciences.
WIRED25: Stories of people who are racing to save us Massive, AI-powered robots are 3D-printing entire rockets Ripper â€”the inside story of the egregiously bad videogame USB-C has finally come into its own Planting tiny spy chips in hardware can cost as little as $200 ğŸ‘ Prepare for the deepfake era of video ; plus, check out the latest news on AI ğŸƒğŸ½â€â™€ï¸ Want the best tools to get healthy? Check out our Gear teamâ€™s picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones.
Topics Quanta Magazine Ramin Skibba Jim Robbins Tristan Kennedy Robin Andrews Grace Browne Maryn McKenna Emily Mullin Rebecca Boyle Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help CondÃ© Nast Store Do Not Sell My Personal Info Â© 2023 CondÃ© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of CondÃ© Nast.
Ad Choices Select international site United States LargeChevron UK Italia JapÃ³n Czech Republic & Slovakia
