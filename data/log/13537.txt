Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Khari Johnson Business Algorithms Allegedly Penalized Black Renters. The US Government Is Watching Illustration: Jacqui VanLiew; Getty Images Save this story Save Save this story Save Two years ago, Mary Louis submitted an application to rent an apartment at Granada Highlands in Malden, Massachusetts. She liked that the unit had two full bathrooms and that there was a pool on the premises. But the landlord denied her the apartment, allegedly due to a score assigned to her by a tenant-screening algorithm made by SafeRent.
Louis responded with references to prove 16 years of punctual rent payments, to no avail. Instead she took a different apartment that cost $200 more a month in an area with a higher crime rate. But a class-action filed by Louis and others last May argues that SafeRent scores based in part on information in a credit report amounted to discrimination against Black and Hispanic renters in violation of the Fair Housing Act.
 The groundbreaking legislation prohibits discrimination on the basis of race, disability, religion, or national origin and was passed in 1968 by Congress a week after the assassination of Martin Luther King Jr.
That case is still pending, but the US Department of Justice last week used a brief filed with the court to send a warning to landlords and the makers of tenant-screening algorithms. SafeRent had argued that algorithms used to screen tenants aren‚Äôt subject to the Fair Housing Act, because its scores only advise landlords and don‚Äôt make decisions. The DOJ‚Äôs brief, filed jointly with the Department of Housing and Urban Development, dismisses that claim, saying the act and associated case law leave no ambiguity.
‚ÄúHousing providers and tenant screening companies that use algorithms and data to screen tenants are not absolved from liability when their practices disproportionately deny people of color access to fair housing opportunities,‚Äù Department of Justice civil rights division leader Kristen Clarke said in a statement.
Like in many areas of business and government, algorithms that assign scores to people have become more common in the housing industry. But although claimed to improve efficiency or identify ‚Äúbetter tenants,‚Äù as SafeRent marketing material suggests, tenant-screening algorithms could be contributing to historically persistent housing discrimination, despite decades of civil rights law. A 2021 study by the US National Bureau of Economic Research that used bots using names associated with different groups to apply to more than 8,000 landlords found significant discrimination against renters of color, and particularly African Americans.
‚ÄúIt‚Äôs a relief that this is being taken seriously‚Äîthere's an understanding that algorithms aren't inherently neutral or objective and deserve the same level of scrutiny as human decisionmakers,‚Äù says Michele Gilman, a law professor at the University of Baltimore and former civil rights lawyer at the Department of Justice. ‚ÄúJust the fact that the DOJ is in on this I think is a big move.‚Äù Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X‚Äôs Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight A 2020 investigation by The Markup and Propublica found that tenant-screening algorithms often encounter obstacles like mistaken identity, especially for people of color with common last names. A Propublica assessment of algorithms made by the Texas-based company RealPage last year suggested it can drive up rents.
A second case against SafeRent under the Fair Housing Act concluded in federal court in Connecticut in November and awaits a judge‚Äôs decision. It was brought by Carmen Arroyo and others, who say the company‚Äôs CrimSAFE algorithm deemed a shoplifting charge that was later dropped ‚Äúdisqualifying,‚Äù leading to a request for her disabled son, who is unable to speak or walk, to be denied. The case alleges the system discriminated on the basis of disability, national origin, and race.
In response to the brief filed by the DOJ and HUD, Andrew Soukup, an attorney for SafeRent, said the company aims to supply property managers and landlords with predictions to help them make good decisions but does not itself make housing decisions. ‚ÄúSafeRent does not decide whether to approve anyone's application for housing. Those decisions are made by property managers and landlords,‚Äù he said in a statement.
The Department of Justice‚Äôs intervention in the SafeRent case is one part of recent efforts by the US government to enforce civil rights law on algorithms that make important decisions about people‚Äôs lives. On the same day, the department announced terms of a settlement agreement with Meta for selling ads that allegedly violate the Fair Housing Act. The company has developed a system to reduce discrimination in Facebook ads and will remain under federal government supervision until 2026.
‚ÄúFederal monitoring of Meta should send a strong signal to other tech companies that they too will be held accountable for failing to address algorithmic discrimination that runs afoul of our civil rights laws,‚Äù said Clarke, the Department of Justice civil rights division leader in a statement. Last year she worked with the Equal Employment Opportunity Commission to issue guidance to businesses using hiring algorithms on how to avoid violation of the Americans With Disabilities Act.
Together, those interventions suggest the DOJ is determined to enforce federal antidiscrimination law to protect people‚Äôs rights in the era of algorithms. ‚ÄúObviously, advertising is different than tenant screening, but it puts these different industries on notice that they can't hide behind a lack of transparency anymore and that there is going to be greater accountability,‚Äù said Gilman, the University of Baltimore law professor. She has represented low-income clients for 25 years, and in the past few years has encountered more cases in which she suspects an algorithm working in the background denied a client housing. But whether existing antidiscrimination law will prove adequate or whether new law is necessary to protect against harmful algorithms is an unresolved issue.
The signal sent to the housing sector this week by the Department of Justice seems in line with other proclamations by the Biden administration on addressing the role AI can play in human rights abuses. Last year, the White House proposed an AI Bill of Rights , a set of principles intended to protect citizens from algorithms in critical areas of their lives like housing, health care, finance, and government benefits. The Trump administration had attempted to make it more difficult to prosecute landlords who use tenant-screening algorithms under the Fair Housing Act.
You Might Also Like ‚Ä¶ üìß Find the best bargains on quality gear with our Deals newsletter ‚Äú Someone is using photos of me to talk to men‚Äù First-gen social media users have nowhere to go The truth behind the biggest (and dumbest) battery myths We asked a Savile Row tailor to test all the ‚Äúbest‚Äù T-shirts you see in social media ads My kid wants to be an influencer.
 Is that bad? üåû See if you take a shine to our picks for the best sunglasses and sun protection Senior Writer X Topics artificial intelligence algorithms government machine learning Khari Johnson Khari Johnson Vittoria Elliott Caitlin Harrington Peter Guest Morgan Meaker Paresh Dave Caitlin Harrington Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
