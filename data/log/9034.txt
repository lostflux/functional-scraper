Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Louise Matsakis Business Facebook‚Äôs Ad System Might Be Hard-Coded for Discrimination Play/Pause Button Pause Alyssa Foote Save this story Save Save this story Save Civil rights groups, lawmakers, and journalists have long warned Facebook about discrimination on its advertising platform. But their concerns, as well as Facebook‚Äôs responses, have focused primarily on ad targeting , the way businesses choose what kind of people they want to see their ads. A new study from researchers at Northeastern University, the University of Southern California, and the nonprofit Upturn finds ad delivery ‚Äîthe Facebook algorithms that decide exactly which users see those ads‚Äîmay be just as important.
Even when companies choose to show their ads to inclusive audiences, the researchers wrote, Facebook sometimes delivers them ‚Äúprimarily to a skewed subgroup of the advertiser‚Äôs selected audience, an outcome that the advertiser may not have intended or be aware of.‚Äù For example, job ads targeted to both men and women might still be seen by significantly more men.
The study, which has not yet been peer-reviewed, indicates that Facebook‚Äôs automated advertising system‚Äîwhich earns the company tens of billions of dollars in revenue each year‚Äîmay be breaking civil rights laws that protect against advertising discrimination for things like jobs and housing. The issue is with Facebook itself, not with the way businesses use its platform. Facebook did not return a request for comment, but the company has not disputed the researchers‚Äô findings in statements to other publications.
Discrimination in ad targeting has been an issue at Facebook for years. In 2016, ProPublica found businesses could exclude people from seeing housing ads based on characteristics like race, an apparent violation of the 1968 Fair Housing Act. Last month, the social network settled five lawsuits from civil rights organizations that alleged companies could hide ads for jobs, housing, and credit from groups like women and older people. As part of the settlement, Facebook said it will no longer allow advertisers to target these ads based on age, gender, or zip code. But those fixes don‚Äôt address the issues the researchers of this new study found.
‚ÄúThis is a stark illustration of how machine learning incorporates and perpetuates existing biases in society, and has profound implications,‚Äù says Galen Sherwin, a senior staff attorney at the ACLU Women‚Äôs Rights Project, one of the organizations that sued Facebook. ‚ÄúThese results clearly indicate that platforms need to take strong and proactive measures in order to counter such trends.‚Äù In one experiment, the researchers ran ads for 11 different generic jobs in North Carolina, like nurse, restaurant cashier, and taxi driver, to the same audience. Facebook delivered five ads for janitors to an audience that was 65 percent female and 75 percent black. Five ads for jobs in the lumber industry were shown to users that were 90 percent male and 70 percent white. And in the most extreme cases, advertisements for supermarket clerks were shown to audiences that were 85 percent women and taxi driving opportunities to audiences that were 75 percent black.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall The researchers ran a similar series of housing ads and found that, despite having the same targeting and budget, some were shown to audiences that were over 85 percent white, while others were shown to ones that were 65 percent black.
Facebook doesn‚Äôt tell businesses the race of people who see their ads, but it does provide the general area where they are located. In order to create a proxy for race, the researchers used hundreds of thousands of public voting records from North Carolina, which include the voter‚Äôs address, phone number, and their stated race. Using the records, they targeted ads to black voters in one part of the state and white voters in another; when looking at Facebook‚Äôs reporting tools, they could then assume the users‚Äô race based on where they lived.
Examples of advertisements with stereotypical female and male images. The third ad image is nearly transparent and can't be detected by the human eye.
University of Southern California; Northeastern University; Upturn In another portion of the study, the researchers tried to determine whether Facebook automatically scans the images associated with ads to help decide who should see them. They ran a series of ads with stereotypical male and female stock imagery, like a football and a picture of a perfume bottle, using identical wording. They then ran corresponding ads with the same images, except the photos were made invisible to the human eye. Machine learning systems could still detect the data in the photos, but to Facebook users they looked like white squares.
The researchers found that the ‚Äúmale‚Äù and ‚Äúfemale‚Äù ads were shown to gendered audiences, even when their images were blank. In one test, both the visible and invisible male images reached an audience that was 60 percent male, while the audience of the visible and invisible female ones was 65 percent female. The results indicate that Facebook is preemptively analyzing advertisements to determine who should see them, and is making those decisions using gender stereotypes.
There‚Äôs no way to know exactly how Facebook‚Äôs image analyzation process works, because the company's advertising algorithms are secret. (Facebook has said in the past, however, that it has the capability to analyze over a billion photos every day.) ‚ÄúUltimately we don‚Äôt know what Facebook is doing,‚Äù says Alan Mislove, a computer science professor at Northeastern University and an author of the research.
The study also found that ad pricing may cause gender discrimination, because women are typically more expensive to reach since they tend to engage more with advertisements. The researchers tested spending between $1 and $50 on their ad campaigns, and found that ‚Äúthe higher the daily budget, the smaller the fraction of men in the audience.‚Äù Previous research has similarly shown that advertising algorithms show fewer ads promoting opportunities in STEM fields to women because they cost more to target.
Science SpaceX‚Äôs Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Gear The Best Home Depot Black Friday Deals Matt Jancer Gear 16 Early Black Friday Deals From Walmart Matt Jancer Business Why Teslas Totaled in the US Are Mysteriously Reincarnated in Ukraine Aarian Marshall The study‚Äôs authors were careful to note that their findings can‚Äôt be generalized to every advertisement on Facebook. ‚ÄúFor example, we observe that all of our ads for lumberjacks deliver to an audience of primarily white and male users, but that may not hold true of all ads for lumberjacks,‚Äù they wrote.
But the research indicates Facebook‚Äôs highly-personalized advertising system does at least sometimes mirror inequalities already present in the world, an issue lawmakers have yet to address. The study could have implications for a housing discrimination lawsuit the Department of Housing and Urban Development filed against Facebook late last month. In the suit , HUD‚Äôs lawyers allege Facebook‚Äôs ‚Äúad delivery system prevents advertisers who want to reach a broad audience of users from doing so,‚Äù because it discriminates based on whether it thinks users are likely to engage with a particular ad, or find it ‚Äú relevant.
‚Äù Regulators may also need to examine protections granted to Facebook under Section 230 of the Communications Decency Act, which shields internet platforms from liability for what their users post. Facebook has argued that advertisers are completely responsible for ‚Äúdeciding where, how, and when to publish their ads.‚Äù The study shows that isn't always true, advertisers can‚Äôt control exactly who sees their ads. Facebook is not a neutral platform.
It‚Äôs not clear how Facebook might reform its advertising system to address the issues raised in the study. The company might need to exchange some efficiency in favor of fairness, says Miranda Bogen, a senior policy analyst at Upturn and another author of the research. Alex Stamos, Facebook‚Äôs former chief security officer, similarly said on Twitter that the problem may only be solved ‚Äúby having no algorithmic optimization of certain ad classes.‚Äù But that optimization is a large part of what makes Facebook valuable to advertisers. If lawmakers decide to regulate its algorithms, that could have damning implications for the company‚Äôs business.
How AI and data-crunching can reduce preterm births DJs of the future don't spin records‚Äî they write code India goes electric with battery-swapping rickshaws The beautiful benefits of contemplating doom HTTPS isn't always as secure as it seems üëÄ Looking for the latest gadgets? Check out our latest buying guides and best deals all year round üì© Hungry for even more deep dives on your next favorite topic? Sign up for the Backchannel newsletter Contributor X Topics Facebook Vittoria Elliott Reece Rogers Morgan Meaker Morgan Meaker Reece Rogers Paresh Dave Vittoria Elliott Steven Levy Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
