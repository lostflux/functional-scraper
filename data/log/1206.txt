Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Tom Simonite Business The Tricky Ethics of Google's Cloud Ambitions Getty Images Save this story Save Save this story Save Application Cloud computing Ethics Company Alphabet Google Google‚Äôs attempt to wrest more cloud computing dollars from market leaders Amazon and Microsoft got a new boss late last year. Next week, Thomas Kurian is expected to lay out his vision for the business at the company‚Äôs cloud computing conference, building on his predecessor‚Äôs strategy of emphasizing Google‚Äôs strength in artificial intelligence.
That strategy is complicated by controversies over how Google and its clients use the powerful technology. After employee protests over a Pentagon contract in which Google trained algorithms to interpret drone imagery, the cloud unit now subjects its‚Äîand its customers‚Äô‚ÄîAI projects to ethical reviews.
 They have caused Google to turn away some business. ‚ÄúThere have been things that we have said no to,‚Äù says Tracy Frey, director of AI strategy for Google Cloud, although she declines to say what.
But this week, the company fueled criticism that those mechanisms can‚Äôt be trusted when it fumbled an attempt to introduce outside oversight over its AI development.
Google‚Äôs ethics reviews tap a range of experts. Frey says product managers, engineers, lawyers, and ethicists assess proposed new services against Google‚Äôs AI principles. Some new products announced next week will come with features or limitations added as a result.
Last year, that process led Google not to launch a facial recognition service, something rivals Microsoft and Amazon have done. This week, more than 70 AI researchers‚Äîincluding nine who work at Google‚Äî signed an open letter calling on Amazon to stop selling the technology to law enforcement.
Frey says that tricky decisions over how‚Äîor whether‚Äîto release AI technology will become more common as the technology advances.
In February, San Francisco research institute OpenAI said it would not release new software it created that is capable of generating surprisingly fluent text because it might be used maliciously. The episode was dismissed by some researchers as a stunt, but Frey says it provides a powerful example of the kind of restraint needed as AI technology gets more powerful. ‚ÄúWe hope to be able to have that same courageous stance,‚Äù she says. Google said last year that it modified research on lip-reading software to minimize the risk of misuse. The technology could help the hard of hearing‚Äîor be used to infringe on privacy.
Not everyone is convinced that Google itself can be trusted to make ethical decisions about its own technology and business.
Google‚Äôs AI principles have been criticized as too vague and permissive. Weapons projects are banned, but military work is still allowed. The principles say Google will not pursue ‚Äútechnologies whose purpose contravenes widely accepted principles of international law and human rights,‚Äù but the company has been testing a search engine for China that, if launched, would have to perform political censorship.
Business What Sam Altman‚Äôs Firing Means for the Future of OpenAI Steven Levy Business Sam Altman‚Äôs Sudden Exit Sends Shockwaves Through OpenAI and Beyond Will Knight Gear Humanity‚Äôs Most Obnoxious Vehicle Gets an Electric (and Nearly Silent) Makeover Boone Ashworth Security The Startup That Transformed the Hack-for-Hire Industry Andy Greenberg Since Google revealed its AI principles, the company has been dogged by questions about how they would be enforced without external oversight. Last week Google announced a panel of eight outsiders it said would help implement the principles. Late Thursday it said that new Advanced Technology External Advisory Council was being shut down and that the company was ‚Äúgoing back to the drawing board.‚Äù The U-turn came after thousands of Google employees signed a petition protesting the inclusion of Kay Coles James, president of conservative think tank the Heritage Foundation. She worked on President Trump‚Äôs transition team and has spoken against policies aimed at helping trans and LGBTQ people. As the controversy grew, one council member resigned and another, Oxford University philosopher Luciano Floridi, said Google had made a ‚Äú grave error ‚Äù in appointing James.
Os Keyes, a researcher at the University of Washington who joined hundreds of outsiders in signing the Googlers‚Äô petition protesting James‚Äô inclusion, says the episode suggests Google cares more about currying political favor with conservatives than the impact of AI technology. ‚ÄúThe idea of ‚Äòresponsible AI‚Äô as practiced by Google is not actually responsible,‚Äù Keyes says. ‚ÄúThey mean ‚Äònot harmful, unless harm makes money.‚Äô‚Äù Anything that adds friction to new products or deals could heighten Kurian‚Äôs challenge. He took over at Google Cloud last year after the departure of Diane Greene , a storied engineer and executive who led a broad expansion of the unit after joining in 2016.
 Although Google‚Äôs cloud business made progress during Greene‚Äôs tenure, Amazon‚Äôs and Microsoft‚Äôs did too. Oppenheimer estimates that Google has 10 percent of the cloud market, well behind Amazon‚Äôs 45 percent and Microsoft‚Äôs 17 percent.
Google is not the only big company talking more about AI ethics lately. Microsoft has its own internal ethical review process for AI deals and also says it has turned down some AI projects.
 Frey says such reviews don‚Äôt have to slow down a business and that Google‚Äôs ethical AI checkups can generate new business because of growing awareness of the risks that come with AI‚Äôs power. Google Cloud needs to encourage trust in AI to succeed in the long term, she says. ‚ÄúIf that trust is broken at any point we run the risk of not being able to realize the important and valuable effects of AI being infused in enterprises around the world,‚Äù Frey says.
Want to start fermenting your food? Get this gear Free throws should be easy. Why do NBA players miss ? Russia's bid to exploit gas under the Arctic tundra Tracking eye movements can help computers learn Al Gore did not invent the Green New Deal, but he likes it üëÄ Looking for the latest gadgets? Check out our latest buying guides and best deals all year round üì© Want more? Sign up for our daily newsletter and never miss our latest and greatest stories Senior Editor X Topics Google artificial intelligence cloud Amazon Microsoft ethics Steven Levy Will Knight Will Knight Khari Johnson Will Knight Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n Czech Republic & Slovakia
