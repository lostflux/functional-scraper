Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Will Knight Business Job Screening Service Halts Facial Analysis of Applicants Illustration: Elena Lacey; Getty Images Save this story Save Save this story Save Application Ethics Face recognition Human-computer interaction Personal services Recommendation algorithm Prediction End User Big company Small company Startup Sector Consumer services Source Data Video Speech Technology Machine learning Natural language processing Machine vision Job hunters may now need to impress not just prospective bosses but artificial intelligence algorithms too—as employers screen candidates by having them answer interview questions on a video that is then assessed by a machine.
HireVue , a leading provider of software for vetting job candidates based on an algorithmic assessment, said Tuesday it is killing off a controversial feature of its software: analyzing a person’s facial expressions in a video to discern certain characteristics.
Job seekers screened by HireVue sit in front of a webcam and answer questions. Their behavior, intonation, and speech is fed to an algorithm that assigns certain traits and qualities.
HireVue says that an “algorithmic audit” of its software conducted last year shows it does not harbor bias. But the nonprofit Electronic Privacy Information Center had filed a complaint against the company with the Federal Trade Commission in 2019.
HireVue CEO Kevin Parker acknowledges that public outcry over the use of software to analyze facial expressions in video was part of the calculation. “It was adding some value for customers, but it wasn’t worth the concern,” he says.
The algorithmic audit was performed by an outside firm, O’Neil Risk Consulting and Algorithmic Auditing.
 The company did not respond to requests for comment.
Alex Engler , a fellow at the Brookings Institution who has studied AI hiring, says the idea of using AI to determine someone’s ability, whether it is based on video, audio, or text, is far-fetched. He says it is also problematic that the public cannot vet such claims.
“There are parts that machine learning can probably help with, but fully automated interviews, where you’re making inferences about job performance—that’s terrible,” he says. “Modern artificial intelligence can’t make those inferences.” “Fully automated interviews, where you’re making inferences about job performance—that’s terrible.” Alex Engler, fellow, Brookings Institution HireVue says that about 700 companies, including GE, Unilever, Delta, and Hilton, use its technology. The software requires job applicants to respond to a series of questions in a recorded video. The company’s software then analyzes various characteristics including the language they use, their speech, and, until now, their facial expressions. It then provides an assessment of the applicant’s suitability for a job, as well as a measure of traits including “dependability,” “emotional intelligence,” and “cognitive ability.” Parker says the company helped screen more than 6 million videos last year, although sometimes this involved simply transcribing answers for an interviewer rather than performing an automated assessment of candidates. He adds that some clients let candidates opt out of automated screening. And he says HireVue has developed ways to avoid penalizing candidates with spotty internet connections, automatically referring those candidates to a human.
Culture The Future of Game Accessibility Is Surprisingly Simple Geoffrey Bunting Science SpaceX’s Starship Lost Shortly After Launch of Second Test Flight Ramin Skibba Business Elon Musk May Have Just Signed X’s Death Warrant Vittoria Elliott Business OpenAI Ousts CEO Sam Altman Will Knight AI experts warn that algorithms trained on data from previous job applicants may perpetuate existing biases in hiring. Lindsey Zuloaga, HireVue’s chief data scientist, says the company screens for bias on gender, race, and age by collecting that information in training data and looking for signs of bias.
But she acknowledges that it may be more difficult to know if the system is biased on factors such as income or education level, or if it could be affected by something like a stutter.
“I am surprised they are dropping this, as it was a keystone feature of the product they were marketing,” says John Davisson, senior counsel at EPIC. “That is the source of a lot of concerns around biometric data collection, as well as these bold claims about being able to measure psychological traits, emotional intelligence, social attitudes, and things like that.” By Tom Simonite The use of facial analysis to determine emotion or personality traits is controversial; some experts warn that the underlying science is flawed.
Lisa Feldman Barrett , a professor at Northeastern University who studies analysis of emotion, says a person’s face does not on its own reveal emotion or character. “Just by looking at someone smiling, you can’t really tell anything about them except maybe that they have nice teeth,” she says. “It is a bad idea to make psychological inferences, and therefore determine people's outcomes, based on facial data alone.” EPIC’s FTC complaint accused HireView of failing to guarantee fairness and of using algorithms that cannot be vetted. It also accused the company of misrepresenting its technology by claiming not to use facial recognition. Davisson says the agency has not yet acted on the complaint.
But Davisson says he worries that automated analysis of speech could still have problems, and he says it is important that companies release the results of algorithmic audits. He says HireVue’s technology still needs to be vetted thoroughly.
“I’m certainly concerned that the same potential issues around data collection and bias and opacity would just carry over to an audio-based screening system AI hiring has caught the attention of some regulators. A bill before the New York City Council proposes regulating the use of hiring software by requiring employers to inform candidates when they are being assessed by AI, and requiring them to audit their algorithms every year.
An Illinois law requires consent from candidates for analysis of video footage. Maryland has banned the use of facial analysis. In 2018, Amazon reportedly abandoned the use of its own technology for automating the assessment of candidate résumés due to biased results.
Updated, 1-13-21, 4:50pm ET: An earlier version of this story incorrectly said HireVue had about 100 customers.
📩 Want the latest on tech, science, and more? Sign up for our newsletters ! The secret history of the microprocessor, the F-14, and me What AlphaGo can teach us about how people learn Unlock your cycling fitness goals by fixing up your bike 6 privacy-focused alternatives to apps you use every day Vaccines are here. We have to talk about side effects 🎮 WIRED Games: Get the latest tips, reviews, and more 🏃🏽‍♀️ Want the best tools to get healthy? Check out our Gear team’s picks for the best fitness trackers , running gear (including shoes and socks ), and best headphones Senior Writer X Topics algorithms machine learning artificial intelligence face recognition Will Knight Khari Johnson Niamh Rowe Aarian Marshall Khari Johnson Peter Guest Matt Burgess Will Knight Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Black Friday Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Condé Nast Store Do Not Sell My Personal Info © 2023 Condé Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices Select international site United States LargeChevron UK Italia Japón Czech Republic & Slovakia
