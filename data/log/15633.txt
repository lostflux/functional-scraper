Artificial Intelligence View All AI, ML and Deep Learning Auto ML Data Labelling Synthetic Data Conversational AI NLP Text-to-Speech Security View All Data Security and Privacy Network Security and Privacy Software Security Computer Hardware Security Cloud and Data Storage Security Data Infrastructure View All Data Science Data Management Data Storage and Cloud Big Data and Analytics Data Networks Automation View All Industrial Automation Business Process Automation Development Automation Robotic Process Automation Test Automation Enterprise Analytics View All Business Intelligence Disaster Recovery Business Continuity Statistical Analysis Predictive Analysis More Data Decision Makers Virtual Communication Team Collaboration UCaaS Virtual Reality Collaboration Virtual Employee Experience Programming & Development Product Development Application Development Test Management Development Languages Microsoft exec apologizes for Tay chatbot’s racist tweets, says users ‘exploited a vulnerability’ Share on Facebook Share on X Share on LinkedIn Tay tweet.
Are you ready to bring more awareness to your brand? Consider becoming a sponsor for The AI Impact Tour. Learn more about the opportunities here.
Peter Lee, the corporate vice president of Microsoft Research, Microsoft’s research and development wing, today apologized for the behavior of Tay , the artificial intelligence-powered chatbot the company unveiled earlier this week and soon thereafter took offline.
“We are deeply sorry for the unintended offensive and hurtful tweets from Tay, which do not represent who we are or what we stand for, nor how we designed Tay,” Lee wrote in a blog post , adding that the bot will come back online only after the company is sure that it’s ready to deal with “malicious intent.” Indeed, Lee said that a small number of people “exploited a vulnerability” in Tay and thus were to blame for the tweets, which spoke positively of Hitler, among other things.
“Although we had prepared for many types of abuses of the system, we had made a critical oversight for this specific attack,” Lee wrote.
The incident is in contrast to the more well received Xiaoice chatbot that Microsoft deployed in China in 2014. Of course chatbots are not new — remember AOL’s SmarterChild? — but team communication tool Slack and other companies have been pushing bots as a way to automatically supply helpful information so people don’t need to.
Microsoft has been investing in AI research aplenty alongside Facebook, Google , and other companies. Microsoft has previously had imperfect demos of its AI-powered speech recognition. And in image recognition Microsoft had some troubles last year with the launch of the How Old Do You Look? app — it got many people’s ages wrong. But Tay’s remarks and Microsoft’s decision to stop it from working after it behaved badly provoked some concern about AI, and now a top figure at Microsoft has come to say sorry.
“We will remain steadfast in our efforts to learn from this and other experiences as we work toward contributing to an Internet that represents the best, not the worst, of humanity,” Lee wrote.
VentureBeat's mission is to be a digital town square for technical decision-makers to gain knowledge about transformative enterprise technology and transact.
Discover our Briefings.
The AI Impact Tour Join us for an evening full of networking and insights at VentureBeat's AI Impact Tour, coming to San Francisco, New York, and Los Angeles! VentureBeat Homepage Follow us on Facebook Follow us on X Follow us on LinkedIn Follow us on RSS Press Releases Contact Us Advertise Share a News Tip Contribute to DataDecisionMakers Careers Privacy Policy Terms of Service Do Not Sell My Personal Information © 2023 VentureBeat.
 All rights reserved.
