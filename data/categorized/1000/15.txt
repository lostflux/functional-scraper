old id = 4753
Exclusive Q&A: Neuralink’s Quest to Beat the Speed of Type - IEEE Spectrum
1000
https://spectrum.ieee.org/exclusive-neuralinks-goal-of-bestinworld-bmi

TopicsSectionsMoreFor IEEE MembersFor IEEE MembersIEEE SpectrumFollow IEEE SpectrumSupport IEEE SpectrumIEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Enjoy more free content and benefits by creating an accountSaving articles to read later requires an IEEE Spectrum accountThe Institute content is only available for membersDownloading full PDF issues is exclusive for IEEE MembersAccess toSpectrum's Digital Edition is exclusive for IEEE MembersFollowing topics is a feature exclusive for IEEE MembersAdding your response to an article requires an IEEE Spectrum accountCreate an account to access more content and features onIEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, considerJoining IEEE.
Join the world’s largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum’s articles, archives, PDF downloads, and other benefits.
Learn more →Access Thousands of Articles — Completely FreeCreate an account and get exclusive content and features:Save articles, download collections,andtalk to tech insiders— all free! For full access and benefits,join IEEEas a paying member.
Exclusive Q&A: Neuralink’s Quest to Beat the Speed of TypeAn inside engineering look at the brain implant company's near and far term goalsElon Musk's brain tech company,Neuralink, is subject to rampant speculation and misunderstanding. Just start a Google search with the phrase “can Neuralink..." and you'll see the questions that are commonly asked, which include “can Neuralink cure depression?" and “can Neuralink control you?" Musk hasn't helped ground the company's reputation in reality with his public statements, including hisclaimthat the Neuralink device will one day enable “AI symbiosis" in which human brains will merge with artificial intelligence.
It's all somewhat absurd, because the Neuralinkbrain implantis still an experimental device that hasn't yet gotten approval for even the most basic clinical safety trial.
But behind the showmanship and hyperbole, the fact remains that Neuralink is staffed by serious scientists and engineers doing interesting research. The fully implantable brain-machine interface (BMI) they've been developing is advancing the field with its super-thin neural “threads" that can snake through brain tissue to pick up signals and its custom chips and electronics that can process data from more than 1000 electrodes.
In August 2020 the companydemonstrated the technology in pigs, and this past April it dropped aYouTube videoandblog postshowing a monkey using the implanted device, called a Link, to control a cursor and play the computer game Pong. But the BMI team hasn't been public about its current research goals, and the steps it's taking to achieve them.
In this exclusive Q&A withIEEE Spectrum,Joseph O'Doherty, a neuroengineer at Neuralink and head of its brain signals team, lays out the mission.
Joseph O'Doherty on…Aiming for a World RecordIEEE Spectrum: Elon Musk often talks about the far-future possibilities of Neuralink; a future in which everyday people could get voluntary brain surgery and have Links implanted to augment their capabilities. But whom is the product for in the near term?Joseph O'Doherty:We're working on a communication prosthesis that would give back keyboard and mouse control to individuals with paralysis. We're pushing towards an able-bodied typing rate, which is obviously a tall order. But that's the goal. We have a very capable device and we're aware of the various algorithmic techniques that have been used by others. So we can apply best practices engineering to tighten up all the aspects. What it takes to make the BMI is a good recording device, but also real attention to detail in the decoder, because it's a closed-loop system. You need to have attention to that closed-loop aspect of it for it to be really high performance. We have an internal goal of trying to beat the world record in terms of information rate from the BMI. We're extremely close to exceeding what, as far as we know, isthe best performance. And then there's an open question: How much further beyond that can we go?My team and I are trying to meet that goal and beat the world record. We'll either nail down what we can, or, if we can't, figure out why not, and how to make the device better.
BACK TO TOP↑The HardwareSpectrum: The Neuralink system has been through some big design changes over the years. When I was talking to your team in 2019, the system wasn't fully implantable, and there was still a lot in flux about the design of the threads, how many electrodes per thread, and the implanted chip. What's the current design?O'Doherty:The threads are often referred to as the neural interface itself; that's the physical part that actually interfaces with the tissue. The broad approach has stayed the same throughout the years: It's our hypothesis that making these threads extremely small and flexible is good for the long-term life of the device. We hope it will be something that the immune system likes, or at least dislikes less. That approach obviously comes with challenges because we have very, very small things that need to be robust over many years. And a lot of the techniques that are used to make things robust have to do with adding thickness and adding layers and having barriers.
Spectrum: I imagine there are a lot of trade-offs between size and robustness.
O'Doherty:There are other flexible and very cool neural interfaces out in the world that we read about in academic publications. But those demonstrations often only have to work for the one hour or one day that the experiment is done. Whereas we need to have this working for many, many, many, many days. It's a totally different solution space.
NeuralinkSpectrum: When I was talking to your team in 2019, there were 128 electrodes per thread. Has that changed?O'Doherty:Right now we're doing 16 contacts per thread, spaced out by 200 microns. The earlier devices were denser, but it was overkill in terms of sampling neurons in various layers of the cortex. We could record the same neurons on multiple adjacent channels when the contacts were something like 20 microns apart. So we could do a very good job of characterizing the individual neurons we were recording from, but it required a lot of density, a lot of stuff packed in one spot, and that meant more power requirements. That might be great if you're doing neuroscience, perhaps with less good if you're trying to make a functional product. That's one reason why we changed our design to spread out our contacts in the cortex, and to distribute them on many threads across the cortical area. That way we don't have redundant information. The current design is 16 channels per thread, and we have 64 of these threads that we can place wherever we want within the cortical region, which adds up to 1,024 channels. Those threads go to a single tiny device that's smaller than a quarter, which has the algorithms, the spike detection, battery, telemetry, everything. In addition to 64x16, we're also testing 128x8 and 256x4 configurations to see if there are performance gains. We ultimately have the flexibility to do any configuration of 1024 electrodes we'd like.
Spectrum: Does each Link device have multiple chips?O'Doherty:Yes. The actual hardware is a 256-channel chip, and there are four of them, which adds up to 1,024 channels. The Link acts as one thing, but it is actually made up of four chips.
Spectrum: I imagine you're continually upgrading the software as you push toward your goal, but is the hardware fixed at this point?O'Doherty:Well, we're constantly working on the next thing. But it is the case that we have to prove the safety of a particular version of the device so that we can translate that to humans. We use what are called design controls, where we fix the device so we can describe what it is very well and describe how we are testing its safety. Then we can make changes, but we do it under an engineering control framework.
We describe what we're changing and then we can either say this change is immaterial to safety or we have to do these tests.
BACK TO TOP↑The SoftwareSpectrum: It sounds like a lot of the spike detection is being done on the chips. Is that something that's evolved over time? I think a few years back it was being done on an external device.
O'Doherty:That's right. We have a slightly different approach to spike detection. Let me first give a couple of big picture comments. For neuroscience, you often don't just want to detect spikes. You want to detect spikes and then sort spikes by which neurons generated them. If you detect a spike on a channel and then realize, Oh, I can actually record five different neurons here. Which neuron did it come from? How do I refer each spike to the neuron that generated it? That's a very difficult computational problem. That's something that's often done in post-processing—so after you record a bunch of data, then you do a bunch of math. There's another extreme where you simply put a threshold on your voltage, and you say that every time something crosses that threshold, it's a spike. And then you just count how many of those happen. That's all. That's all the information you can use.
Both extremes are not great for us. In the first one, you're doing a lot of computation that's perhaps infeasible to do in a small package. With the other extreme, you're very sensitive to noise and artifacts because many things can cause a threshold crossing that are not neurons firing. So we're using an approach in the middle, where we're looking for shapes that look like the signals that neurons generate. We transmit those events, along with a few extra bits of information about the spike, like how tall it is, how wide it is, and so on. That's something that we were previously doing on the external part of the device. At the time we validated that algorithm, we had much higher bandwidth, because it was a wired system. So we were able to stream a lot of data and develop this algorithm. Then the chip team took that algorithm and implemented it in hardware. So now that's all happening automatically on the chip. It's automatically tuning its parameters—it has to learn about the statistical distribution of the voltages in the brain. And then it just detects spikes and sends them out to the decoder.
Spectrum: How much data is coming off the device these days?O'Doherty:To address this in brain-machine interface terms, we are detecting spikes within a 25-millisecond window or “bin." So the vectors of information that we use in our algorithms for closed-loop control are factors of spike counts: 1,024 by 25 milliseconds. We count how many spikes occur per channel and that's what we send out. We only need about four bits per bin, so that's four bits times forty bins per second times 1,024 channels, or about 20 kilobytes each second. That degree of compression is made possible by the fact that we're spike detecting with our custom algorithm on the chip. The maximum bandwidth would be 1,024 channels times 20,000 samples per second, which is a pretty big number. That's if we could send everything. But the compressed version is just the number of spike events that occur—zero one, two, three, four, whatever—times 1,024 channels. For our application, which is controlling our communications prosthesis, this data compression is a good way to go—and we still have usable signals for closed-loop control.
Spectrum: When you say closed-loop control, what does that mean in this context?O'Doherty:Most machine learning is open-loop. Say you have an image and you analyze it with a model and then produce some results, like detecting the faces in a photograph. You have some inference you want to do, but how quickly you do it doesn't generally matter. But here the user is in the loop—the user is thinking about moving and the decoder is, in real time, decoding those movement intentions, and then taking some action. It has to act very quickly because if it's too slow, it doesn't matter. If you throw a ball to me and it takes my BMI five seconds to infer that I want to move my arm forward—that's too late. I'll miss the ball. So the user changes what they're doing based on visual feedback about what the decoder does: That's what I mean by closed loop. The user makes a motor intent; it's decoded by the Neuralink device; the intended motion is enacted in the world by physically doing something with a cursor or a robot arm; the user sees the result of that action; and that feedback influences what motor intent they produce next. I think the closest analogy outside of BMI is the use of a virtual reality headset—if there's abig lag between what you do and what you see on your headset, it's very disorienting, because it breaks that closed-loop system.
BACK TO TOP↑What He's Working on Right NowSpectrum: What has to happen to get from where you are right now to best-in-world?O'Doherty:Step one is to find the sources of latency and eliminate all of them. We want to have low latency throughout the system. That includes detecting spikes; that includes processing them on the implant; that includes the radio that has to transmit them—there's all kinds of packetization details with Bluetooth that can add latency. And that includes the receiving side, where you do some processing in your model inference step, and that even includes drawing pixels on the screen for the cursor that you're controlling. Any small amount of lag that you have there adds delay and that affects closed-loop control.
Spectrum: OK, so let's imagine all latency has been eliminated. What next?O'Doherty:Step two is the decoder itself, and the model that it uses. There's great flexibility in terms of the model—it could be very simple, very complex, very nonlinear, or very deep in terms of deep learning—how many layers your entire network has. But we have particular constraints. We need our decoder model to work fast, so we can't use a sophisticated decoder that's very accurate but takes too long to be useful. We're also potentially interested in running the decoder on the implant itself, and that requires both low memory usage, so we don't have to store a lot of parameters in a very constrained environment, and also compute efficiency so we don't use a lot of clock cycles. But within that space, there's some clever things we can do in terms of mapping neural spikes to movement. There are linear models that are very simple and nonlinear models that give us more flexibility in capturing the richness of neural dynamics. We want to find the right sweet spot there. Other factors include the speed at which you can calibrate the decoder to the user. If we have to spend a long time training the decoder, that's not a great user experience. We want something that can come online really quickly and give the subject a lot of time to practice with the device. We're also focusing on models that are robust. So from day one to day two to day three, we don't want to have to recalibrate or re-tune the decoder. We want one that works on day one and that works reliably for a long time. Eventually, we want decoders that calibrate themselves, even without the user thinking about it. So the user is just going about their day doing things that cause the model to stay calibrated.
Spectrum: Are there any decoder tricks or hacks you've figured out that you can tell me about?O'Doherty:One thing we find particularly helpful is decoding click intention. When a BMI user moves a cursor to a target, they typically need to dwell on that target for a certain amount of time, and that is considered a click. The user dwelled for 200 milliseconds, so they selected it. Which is fine, but it adds delay because the user has to wait that amount of time for the selection to happen. But if we decode click intention directly, that lets the user make selections that much faster.
And this is something that we're working on—we don't have a result yet. But we can potentially look into the future. Imagine you're making a movement with the brain-controlled cursor, and I know where you are now… but maybe I also know where you're going to want to go in a second. If I know that, I can do some tricks, I can just teleport you there and get you there faster. And honestly, practice is a component. These neuroprosthetic skills have to be learned by the user, just like learning to type or any other skill. We've seen this with non-human primates, and I've heard it's also true of human participants inBrainGatetrials. So we want a decoder that doesn't pose too much of a learning burden. Beyond that, I can speculate on cool stuff that could be done. For example, you type faster with two fingers than one finger, or text faster with two thumbs versus one pointer finger. So imagine decoding movement intention for two thumbs to control your brain-controlled keyboard and mouse. That could potentially be a way to boost performance.
Spectrum: What is the current world record for BMI rate?O'Doherty:Krishna Shenoyof Stanford has been keeping track of this in sometables of BCI performance, which includesthe paperthat recently came out from his group. That paper set the record with a maximum bit rate of 6.18 bits per second with human participants. For non-human primates, the record is 6.49 bits per second.
Spectrum: And can you prove best-in-world BMI with non-human primates, or do you need to get into humans for that?O'Doherty:That's a good question. Non-human primates can't talk or read English, so to some extent we have to make inferences. With a human participant you might say, here's a sentence we'd like you to copy, please type it as best you can. And then we can look at performance there. For the monkey, we can create a string of sequences and ask them to do it quickly and compute performance rates that way. Monkeys are motivated and they'll do those tasks. So I don't see any reason, in principle, why one is superior to the other for this. For linguistic and semantic tasks like decoding speech or decoding text directly from your brain we'll have to prototype in humans, of course.
But until we get to that point, and even after that, non-human primates and other animal models are really important for proving out the technology.
BACK TO TOP↑What the Limits Are, Where the Ceiling IsSpectrum: You said earlier that your team will either achieve a new world record or find out the reason why you can't. Are there reasons why you think it might not work?O'Doherty:The 2D cursor control is not a very high-dimension task. There are probably limits that have to do with intention and speed. Think about how long it takes to move a cursor around and hit targets: It's the time it takes the user to go from point A to point B, and the time it takes to select when they're at point B. Also if they make a mistake and click the wrong button, that's really bad. So they have to go faster between A and B, they have to click there more reliably, and they can't make mistakes.
At some point, we're going to hit a limit, because the brain can't keep up. If the cursor is going too fast, the user won't even see it moving. I think that's where the limits will come from—not the neural interfacing, but what it means to move a cursor around. So then we'll have to think about other interesting ways to interface with the brain to get beyond that. There are other ways of communicating that might be better—maybe it will involve ten-finger typing. I think it's an open question where that ceiling is.
Spectrum: Both the games that the monkey played were basically just cursor control: finding targets and using a cursor to move the paddle in Pong. Can you imagine any tests that would go beyond that for non-human primates?O'Doherty:Non-human primates can learn other more complicated tasks. The training can be lengthy, because we can't tell them what to do; we have to show them and take small steps toward more complicated things. To pick a game out of a hat: Now we know that monkeys can play Pong, but can they play Fruit Ninja? There's a training burden, but I think it's within their capability.
Spectrum: Is there anything else you want to emphasize about the technology, the work you're doing, or how you're doing it?O'Doherty:I first started working on BMI in an academic environment. The concerns that we have at Neuralink are different from the concerns involved with making a BMI for an academic demonstration. We're really interested in the product, the experience of the user, the robustness, and having this device be useful across a long period of time. And those priorities necessarily lead to slightly different optimizations than I think we would choose if we were doing this for a one-off demonstration. We really enjoyed the Pong demo, but we're not here to make Pong demos. That's just a teaser for what will be possible when we bring our product to market.
This article appears in the September 2021 print issue as "Elon Musk's Mind Games."BACK TO TOP↑Eliza Stricklandis a senior editor atIEEE Spectrum, where she covers AI, biomedical engineering, and other topics. She holds a master's degree in journalism from Columbia University.
Will there be any type of water resistance and if so how resistant will it beAcer Goes Big on Glasses-Free, 3D Monitors—Look Out, VRDARPA Wants a Better, Badder Caspian Sea MonsterIEEE Spectrum Wins Six Neal AwardsRelated StoriesEvaluating Mobile Health Tools Is Comparing Apples to OrangesMed-Tech Eureka: The Body Is the Best Secure Data ChannelShould Right-to-Repair Laws Extend to Bionic Body Parts?This CAD Program Can Design New OrganismsGenetic engineers have a powerful new tool to write and edit DNA codeFoundries such as the Edinburgh Genome Foundry assemble fragments of synthetic DNA and send them to labs for testing in cells.
In the next decade,medical science may finally advance cures for some of the most complex diseases that plague humanity. Many diseases are caused by mutations in the human genome, which can either be inherited from our parents (such as in cystic fibrosis), or acquired during life, such as most types of cancer. For some of these conditions, medical researchers have identified the exact mutations that lead to disease; but in many more, they're still seeking answers. And without understanding the cause of a problem, it's pretty tough to find a cure.
We believe that a key enabling technology in this quest is a computer-aided design (CAD) program for genome editing, which our organization is launching this week at theGenome Project-write (GP-write) conference.
With this CAD program, medical researchers will be able to quickly design hundreds of different genomes with any combination of mutations and send the genetic code to a company that manufactures strings of DNA. Those fragments of synthesized DNA can then be sent to a foundry for assembly, and finally to a lab where the designed genomes can be tested in cells. Based on how the cells grow, researchers can use the CAD program to iterate with a new batch of redesigned genomes, sharing data for collaborative efforts. Enabling fast redesign of thousands of variants can only be achieved through automation; at that scale, researchers just might identify the combinations of mutations that are causing genetic diseases. This is the first critical R&D step toward finding cures.
Applications for the CAD software extend far beyond medicine and throughout the burgeoning field ofsynthetic biology, which involves redesigning organisms to give them new abilities. For example, we envision users designing solutions for biomanufacturing; it's possible that society could reduce its reliance on petroleum thanks to microorganisms that produce valuable chemicals and materials. And to aid the fight against climate change, users could design microorganisms that ingest and lock up carbon, thus reducing atmospheric carbon dioxide (the main driver of global warming).
DNA, the molecule that encodes instructions for life, is composed of four types of nitrogen bases, which pair up to create what look like the rungs of a twisted ladder.
James ProvostOur consortium,GP-write, can be understood as a sequel to theHuman Genome Project, in which scientists first learned how to "read" the entire genetic sequence of human beings. GP-write aims to take the next step in genetic literacy by enabling the routine "writing" of entire genomes, each with tens of thousands of different variations. As genome writing and editing becomes more accessible, biosafety is a top priority. We're building safeguards into our system from the start to ensure that the platform isn't used to craft dangerous or pathogenic sequences.
Need a quick refresheron genetic engineering? It starts withDNA, the double-stranded molecule that encodes the instructions for all life on our planet. DNA is composed of four types of nitrogen bases—adenine (A), thymine (T), guanine (G), and cytosine (C)—and the sequence of those bases determines the biological instructions in the DNA. Those bases pair up to create what look like the rungs of a long and twisted ladder. The human genome (meaning the entire DNA sequence in each human cell) is composed of approximately 3 billion base-pairs. Within the genome are sections of DNA calledgenes,many of which code for the production of proteins; there are more than 20,000 genes in the human genome.
TheHuman Genome Project, which produced the first draft of a human genome in 2000, took more than a decade and cost about$2.7 billionin total. Today, an individual's genome can be sequenced in a day for$600, with some predicting that the $100 genome is not far behind. The ease of genome sequencing has transformed both basic biological research and nearly all areas of medicine. For example, doctors have been able to precisely identify genomic variants that are correlated with certain types of cancer, helping them to establish screening regimens for early detection. However, the process of identifying and understanding variants that cause disease and developing targeted therapeutics is still in its infancy and remains a defining challenge.
Until now, genetic editing has been a matter of changing one or two genes within a massive genome; sophisticated techniques likeCRISPRcan create targeted edits, but at a small scale. And although many software packages exist to help with gene editing and synthesis, the scope of those software algorithms is limited to single or few gene edits. Our CAD program will be the first to enable editing and design at genome-scale, allowing users to change thousands of genes, and it will operate with a degree of abstraction and automation that allows designers to think about the big picture. As users create new genome variants and study the results in cells, each variant's traits and characteristics (called its phenotype) can be noted and added to the platform's libraries. Such a shared database could vastly speed up research on complex diseases.
What's more, current genomic design software requires human experts to predict the effect of edits. In a future version, GP-write's software will include predictions of phenotype to help scientists understand if their edits will have the desired effect. All the experimental data generated by users can feed into a machine-learning program, improving its predictions in a virtuous cycle. As more researchers leverage the CAD platform and share data (the open-source platform will be freely available to academia), its predictive power will be enhanced and refined.
Our first version of the CAD software will feature a user-friendly graphical interface enabling researchers to upload a species' genome, make thousands of edits throughout the genome, and output a file that can go directly to a DNA synthesis company for manufacture. The platform will also enable design sharing, an important feature in the collaborative efforts required for large-scale genome-writing initiatives.
There are clear parallelsbetween CAD programs for electronic and genome design. To make a gadget with four transistors, you wouldn't need the help of a computer. But today's systems may have billions of transistors and other components, and designing them would be impossible without design-automation software. Likewise, designing just a snippet of DNA can be a manual process. But sophisticated genomic design—with thousands to tens of thousands of edits across a genome—is simply not feasible without something like the CAD program we're developing. Users must be able to input high-level directives that are executed across the genome in a matter of seconds.
Our CAD program will be the first to enable editing at genome-scale, with a degree of abstraction and automation that allows designers to think about the big picture.
A good CAD program for electronics includes certain design rules to prevent a user from spending a lot of time on a design, only to discover that it can't be built. For example, a good program won't let the user put down transistors in patterns that can't be manufactured or put in a logic that doesn't make sense. We want the same sort of design-for-manufacture rules for our genomic CAD program. Ultimately, our system will alert users if they're creating sequences that can't be manufactured by synthesis companies, which currently have limitations such as trouble with certain repetitive DNA sequences. It will also inform users if their biological logic is faulty; for example, if the gene sequence they added to code for the production of a protein won't work, because they've mistakenly included a "stop production" signal halfway through.
But other aspects of our enterprise seem unique. For one thing, our users may import huge files containing billions of base-pairs. The genome of thePolychaos dubium, a freshwater amoeboid, clocks in at 670 billion base-pairs—that's over 200 times larger than the human genome! As our CAD program will be hosted on the cloud and run on any Internet browser, we need to think about efficiency in the user experience. We don't want a user to click the "save" button and then wait ten minutes for results. We may employ the technique of lazy loading, in which the program only uploads the portion of the genome that the user is working on, or implement other tricks with caching.
Getting a DNA sequence into the CAD program is just the first step, because the sequence, on its own, doesn't tell you much. What's needed is another layer of annotation to indicate the structure and function of that sequence. For example, a gene that codes for the production of a protein is composed of three regions: the promoter that turns the gene on, the coding region that contains instructions for synthesizing RNA (the next step in protein production), and the termination sequence that indicates the end of the gene. Within the coding region, there are "exons," which are directly translated into the amino acids that make up proteins and "introns," intervening sequences of nucleotides that are removed during the process of gene expression. There are existing standards for this annotation that we want to improve on, so our standardized interface language will be readily interpretable by people all over the world.
The CAD program from GP-write will enable users to apply high-level directives to edit a genome, including inserting, deleting, modifying, and replacing certain parts of the sequence.
GP-writeOnce a user imports the genome, the editing engine will enable the user to make changes throughout the genome. Right now, we're exploring different ways to efficiently make these changes and keep track of them. One idea is an approach we call genome algebra, which is analogous to the algebra we all learned in school. In mathematics, if you want to get from the number 1 to the number 10, there are infinite ways to do it. You could add 1 million and then subtract almost all of it, or you could get there by repeatedly adding tiny amounts. In algebra, you have a set of operations, costs for each of those operations, and tools that help organize everything.
In genome algebra, we have four operations: we can insert, delete, invert, or edit sequences of nucleotides. The CAD program can execute these operations based on certain rules of genomics, without the user having to get into the details. Similar to the "PEMDAS rule" that defines the order of operations in arithmetic, the genome editing engine must order the user's operations correctly to get the desired outcome. The software could also compare sequences against each other, essentially checking their math to determine similarities and differences in the resulting genomes.
In a later version of the software, we'll also have algorithms that advise users on how best to create the genomes they have in mind. Some altered genomes can most efficiently be produced by creating the DNA sequence from scratch, while others are more suited to large-scale edits of an existing genome. Users will be able to input their design objectives and get recommendations on whether to use a synthesis or editing strategy—or a combination of the two.
Users can import any genome (here, the E. coli bacteria genome), and create many edited versions; the CAD program will automatically annotate each version to show the changes made.
GP-writeOur goal is to makethe CAD program a "one-stop shop" for users, with the help of the members of our Industry Advisory Board:Agilent Technologies, a global leader in life sciences, diagnostics and applied chemical markets; the DNA synthesis companiesAnsa Biotechnologies,DNA Script, andTwist Bioscience; and the gene editing automation companiesInscriptaandLattice Automation. (Lattice was founded by coauthor Douglas Densmore). We are also partnering with biofoudries such as theEdinburgh Genome Foundrythat can take synthetic DNA fragments, assemble them, and validate them before the genome is sent to a lab for testing in cells.
Users can most readily benefit from our connections to DNA synthesis companies; when possible, we'll use these companies' APIs to allow CAD users to place orders and send their sequences off to be synthesized. (In the case of DNA Script, when a user places an order it would be quickly printed on the company's DNA printers; some dedicated users might even buy their own printers for more rapid turnaround.) In the future, we'd like to make the ordering step even more user-friendly by suggesting the company best suited to the manufacture of a particular sequence, or perhaps by creating a marketplace where the user can see prices from multiple manufacturers, the way people do on airfare sites.
We've recently added two new members to our Industrial Advisory Board, each of which brings interesting new capabilities to our users.
Catalog Technologiesis the first commercially viable platform to use synthetic DNA for massive digital storage and computation, and could eventually help users store vast amounts of genomic data generated on GP-write software. The other new board member isSOSV'sIndieBio, the leader in biotech startup development. It will work with GP-write to select, fund, and launch companies advancing genome-writing science from IndieBio's New York office. Naturally, all those startups will have access to our CAD software.
We're motivated by a desireto make genome editing and synthesis more accessible than ever before. Imagine if high-school kids who don't have access to a wet lab could find their way to genetic research via a computer in their school library; this scenario could enable outreach to future genome design engineers and could lead to a more diverse workforce. Our CAD program could also entice people with engineering or computational backgrounds—but with no knowledge of biology—to contribute their skills to genetic research.
Because of this new level of accessibility, biosafety is a top priority. We're planning to build several different levels of safety checks into our system. There will be user authentication, so we'll know who's using our technology. We'll have biosecurity checks upon the import and export of any sequence, basing our "prohibited" list on the standards devised by theInternational Gene Synthesis Consortium(IGSC), and updated in accordance with their evolving database of pathogens and potentially dangerous sequences. In addition to hard checkpoints that prevent a user from moving forward with something dangerous, we may also develop a softer system of warnings.
Imagine if high-school kids who don't have access to a lab could find their way to genetic research via a computer in their school library.
We'll also keep a permanent record of redesigned genomes for tracing and tracking purposes. This record will serve as a unique identifier for each new genome and will enable proper attribution to further encourage sharing and collaboration. The goal is to create a broadly accessible resource for researchers, philanthropies, pharmaceutical companies, and funders to share their designs and lessons learned, helping all of them identify fruitful pathways for advancing R&D on genetic diseases and environmental health. We believe that the authentication of users and annotated tracking of their designs will serve two complementary goals: It will enhance biosecurity while also engendering a safer environment for collaborative exchange by creating a record for attribution.
One project that willput the CAD program to the test is a grand challenge adopted by GP-write, theUltra-Safe Cell Project. This effort, led by coauthor Farren Isaacs and Harvard professorGeorge Church, aims to create a human cell line that is resistant to viral infection. Such virus-resistant cells could be a huge boon to thebiomanufacturingand pharmaceutical industry by enabling the production of more robust and stable products, potentially driving down the cost of biomanufacturing and passing along the savings to patients.
The Ultra-Safe Cell Project relies on a technique called recoding. To build proteins, cells use combinations of three DNA bases, called codons, to code for each amino acid building block. For example, the triplet 'GGC' represents the amino acid glycine, TTA represents leucine, GTC represents valine, and so on. Because there are 64 possible codons but only 20 amino acids, many of the codons are redundant. For example, four different codons can code for glycine: GGT, GGC, GGA, and GGG. If you replaced a redundant codon in all genes (or 'recode' the genes), the human cell could still make all of its proteins. But viruses—whose genes would still include the redundant codons and which rely on the host cell to replicate—would not be able to translate their genes into proteins. Think of a key that no longer fits into the lock; viruses trying to replicate would be unable to do so in the cells' machinery, rendering the recoded cells virus-resistant.
This concept of recoding for viral resistance has already been demonstrated. Isaacs, Church, and their colleagues reported in a 2013 paper inSciencethat, by removing all 321 instances of a single codon from the genome of theE. colibacterium, they could impart resistance to viruses which use that codon. But the ultra-safe cell line requires edits on a much grander scale. We estimate that it would entail thousands to tens of thousands of edits across the human genome (for example, removing specific redundant codons from all 20,000 human genes). Such an ambitious undertaking can only be achieved with the help of the CAD program, which can automate much of the drudge work and let researchers focus on high-level design.
The famed physicistRichard Feynmanonce said, "What I cannot create, I do not understand." With our CAD program, we hope geneticists become creators who understand life on an entirely new level.
