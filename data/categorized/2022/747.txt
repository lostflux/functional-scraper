old id = 2050
NVIDIA Is Making Next-Gen GPUs 'Better Than Human' Thanks To AI & Machine Learning
2022
https://wccftech.com/nvidia-better-than-human-gpu-design-thanks-to-ai-machine-learning

NVIDIA Is Making Next-Gen GPUs ‘Better Than Human’ Thanks To AI & Machine LearningDuring the GTC conference, Bill Dally, NVIDIA's chief scientist and senior vice president of research,discussedhow the company's research and development teams are utilizingAIand machine learning to increase the design and efficiency of the company's next-gen GPUs. Dally further discussed the use of machine learning and artificial intelligence to advance their goals of a better and more powerful GPU.
NVIDIA discusses GPU design and the influence of AI and machine learning in tomorrow's hardwareDally gave an example of using AI and ML to increase inference to speed a standard GPU design task from three hours to three seconds. The two approaches have optimized up to four processes that ran slow and were highly intricate.
ASUS Says Crypto GPU Demand Has Dried Up But Gaming Demand Remains Strong & Will Take Time For Pricing To NormalizeDally drafted four substantial sections on GPU designing and how AI and machine learning can significantly impact during the GTC conference. Processes include controlling drops in power voltage, anticipating errors and more, establishing and delineating issues, and cell migration automation.
Mapping Voltage DropsThis mapping drops in voltage allows NVIDIA to see where the power flow travels on the next-gen GPU designs. Where once standard CAD tools would help in the process, the new AI tools used by NVIDIA can process these tasks in seconds, which is a significant fraction of the time. Implementing AI and machine learning will increase accuracy by 94% and exponentially increase speed.
Parasitic PredictionDally has a soft spot for predicting parasitics utilizing artificial intelligence. As a circuit designer, he would spend long periods with his colleagues anticipating parasitics in the development process. With the current testing completed at NVIDIA, they saw a drop in simulation error, less than ten percent. This improvement in development is excellent for circuit designers, as it frees those developers to open up more inventive and breakthrough concepts in design.
Place and Routing ChallengesZoning and routing challenges are significant to the design of advanced chips in that poor data flow can drop efficiency exponentially. Dally states that NVIDIA uses GNNs, or Graph Neural Networks, to investigate and locate any issues and quickly find solutions that would take crucial time out of the development process.
Standard Cell Migration AutomationThe migration of a chip would sometimes cause developers to spend countless months in development without AI. Now, Dally states that "92% of the cell library was able to be done by this tool with no design rule or electrical rule errors" and that "in many cases, we wind up with a better design."NVIDIA GeForce RTX 40 ‘Next-Gen Gaming’ Graphics Cards Featuring Ada Lovelace GPUs Rumored For Early Q3 LaunchNVIDIA plans to prioritize AI and machine learning in five of the company's laboratories. From the conference discussions by Dally, he hints that we should see the inclusion of automated standard cell migration in their newer 7nm and 5nm designs and that NVIDIA will include the Ada Lovelace line in these new projects.
Stay in the loopGET A DAILY DIGEST OF LATEST TECHNOLOGY NEWSStraight to your inboxSubscribe to our newsletterRelated StoriesNVIDIA Ada Lovelace ‘GeForce RTX 40’ Gaming GPU Detailed: Double The ROPs, Huge L2 Cache & 50% More FP32 Units Than Ampere, 4th Gen Tensor & 3rd Gen RT CoresNVIDIA GeForce RTX 4090 Gets 24 GB GDDR6X Memory at 21 Gbps & 600W TDP, RTX 4070 Gets 12 GB GDDR6 Memory at 18 Gbps & 300W TDPNVIDIA & AMD GPU Pricing Update For May 2022: GeForce Graphics Cards Now 14% Over MSRP, Radeon at Just 6% Over MSRPIntel representative teases the new Ponte Vecchio compute GPU for AI & HPC applications of the futureAMD Radeon RX 6950XT Equips The Navi 21 KXTX GPU With Samsung & Hynix 18 Gbps Memory Support, Up To 400W TBPTrending StoriesNVIDIA GeForce RTX 4080 Graphics Card Specs, Performance, Price & Availability – Everything We Know So FarGrand Theft Auto San Andreas Remade in Unreal Engine 5 Looks Amazing in New Concept TrailerThe Number of Ethereum Addresses Holding Over 100 Coins Just Hit a 6-Month High as the Much-anticipated “Merge” Event Is Now Scheduled for August 2022AirPods Ruptured Child’s Eardrums Due to Amber Alert, Apple Faces LawsuitStarlink Stuns & Crosses 300 Mbps In Download Speed Once Again!About•Advertise•Tip Us•Careers•ContactTerms of Use•Privacy Policy•Ethics StatementAppeal Moderation(function waitGEO() { var readyGEO; if (window['UnicI'] && window['UnicI'].geo && window['UnicI'].geo !== '-' ) { readyGEO = true; console.log(window['UnicI'].geo); if (window['UnicI'].geo === 'EU') { if(document.getElementById("unic-gdpr")) { document.getElementById("unic-gdpr").style.display = 'block'; } } if (window['UnicI'].geo === 'CA') { if(document.getElementById("unic-ccpa")) { document.getElementById("unic-ccpa").style.display = 'block'; } } } if (!readyGEO) { setTimeout(waitGEO, 200); } })();Change Ad ConsentDo not sell my dataTwitterFacebookYouTube© 2022 WCCF TECH INC. All rights reserved.
Some posts on Wccftech.com may contain affiliate links. We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to Amazon.comShare This
