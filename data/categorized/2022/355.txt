old id = 1377
NVIDIA Is Making Next-Gen GPUs 'Better Than Human' Thanks To AI & Machine Learning
2022
https://wccftech.com/nvidia-better-than-human-gpu-design-thanks-to-ai-machine-learning

Menu News Hardware Gaming Mobile Finance Software Deals Reviews Videos How To Hardware Report NVIDIA Is Making Next-Gen GPUs ‘Better Than Human’ Thanks To AI & Machine Learning • • During the GTC conference, Bill Dally, NVIDIA's chief scientist and senior vice president of research, discussed how the company's research and development teams are utilizing AI and machine learning to increase the design and efficiency of the company's next-gen GPUs. Dally further discussed the use of machine learning and artificial intelligence to advance their goals of a better and more powerful GPU.
NVIDIA discusses GPU design and the influence of AI and machine learning in tomorrow's hardware Dally gave an example of using AI and ML to increase inference to speed a standard GPU design task from three hours to three seconds. The two approaches have optimized up to four processes that ran slow and were highly intricate.
Related Story NVIDIA Next-Gen B100 “Blackwell” AI GPUs Enter Supply Chain Certification Stage With Foxconn & Wistron In Race Dally drafted four substantial sections on GPU designing and how AI and machine learning can significantly impact during the GTC conference. Processes include controlling drops in power voltage, anticipating errors and more, establishing and delineating issues, and cell migration automation.
2 of 9 Mapping Voltage Drops This mapping drops in voltage allows NVIDIA to see where the power flow travels on the next-gen GPU designs. Where once standard CAD tools would help in the process, the new AI tools used by NVIDIA can process these tasks in seconds, which is a significant fraction of the time. Implementing AI and machine learning will increase accuracy by 94% and exponentially increase speed.
Parasitic Prediction Dally has a soft spot for predicting parasitics utilizing artificial intelligence. As a circuit designer, he would spend long periods with his colleagues anticipating parasitics in the development process. With the current testing completed at NVIDIA, they saw a drop in simulation error, less than ten percent. This improvement in development is excellent for circuit designers, as it frees those developers to open up more inventive and breakthrough concepts in design.
Place and Routing Challenges Zoning and routing challenges are significant to the design of advanced chips in that poor data flow can drop efficiency exponentially. Dally states that NVIDIA uses GNNs, or Graph Neural Networks, to investigate and locate any issues and quickly find solutions that would take crucial time out of the development process.
Standard Cell Migration Automation The migration of a chip would sometimes cause developers to spend countless months in development without AI. Now, Dally states that "92% of the cell library was able to be done by this tool with no design rule or electrical rule errors" and that "in many cases, we wind up with a better design." NVIDIA plans to prioritize AI and machine learning in five of the company's laboratories. From the conference discussions by Dally, he hints that we should see the inclusion of automated standard cell migration in their newer 7nm and 5nm designs and that NVIDIA will include the Ada Lovelace line in these new projects.
Deal of the Day Further Reading AMD RDNA3 iGPUs For Ryzen 7000 APUs Set to Receive “Cycles Renderer” Support In Blender Moore Thread’s MTT S80, The World’s Only PCIe 5.0 GPU With 16 GB VRAM, Now Available For $164 US AMD Reportedly Receives Orders For Next-Gen Instinct MI300X AI Accelerators From Oracle NVIDIA CEO Reacts To US Policies, China Ban Will Have An Impact But Will Continue To Work With Chinese Customers Comments Trending Stories Former TSMC, IBM Exec Says Huawei Can Make Even More Advanced 5nm Chips 66 Active Readers Qualcomm’s Snapdragon X Elite 12-Core CPU Is Faster Than Intel 12700K & AMD 7845HX 12-Core Chips In Single-Core, Comparable In Multi-Core Tests At Just 28W 40 Active Readers Metal Gear Solid: Master Collection Gets Much-Needed HD Texture Packs 32 Active Readers Intel Steals NVIDIA’s AI Chip Orders From South Korea’s ‘Google’ – Report 24 Active Readers M3 Pro Has Fewer Performance Cores, Lower Memory Bandwidth Than Previous-Generation M2 Pro, Indicating A Notable Downgrade 22 Active Readers Popular Discussions Alan Wake 2 PC Performance Impressions: NVIDIA DLSS 3.5 With Path Tracing Delivers Photorealistic Graphics 2250 Comments Intel Arrow Lake-S Desktop CPUs Might Have ISA-Edge Over Arrow Lake-H Mobile 1466 Comments Intel 1st Gen Core Ultra Naming Gets Even More Confusing As More Meteor Lake CPUs Are Unveiled 1332 Comments First Intel Meteor Lake Laptops Listed With Prices Starting Around $1400 US For Core Ultra 5 & $1600 US For Core Ultra 7 1324 Comments NVIDIA GeForce RTX 4080 SUPER, RTX 4070 Ti SUPER & RTX 4070 SUPER GPUs Rumored Specs Revealed 1262 Comments Subscribe to get an everyday digest of the latest technology news in your inbox Follow us on Facebook Youtube Twitter Topics Hardware Gaming Mobile Finance Software Security Web Sections Deals Reviews Videos How To's Analysis Exclusives Interviews Company About Advertise with Us Contact Tip Us Careers Terms of Use Privacy & Cookie Policy Ethics Statement Appeal Moderation Some posts on wccftech.com may contain affiliate links. We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.com © 2023 WCCF TECH INC. 700 - 401 West Georgia Street, Vancouver, BC, Canada '+n.loadingCaption+"
