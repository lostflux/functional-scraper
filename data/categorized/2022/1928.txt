old id = 4409
Artificial Intelligence Won't Save Us From Coronavirus  | WIRED
2022
https://www.wired.com/story/artificial-intelligence-wont-save-us-from-coronavirus

To revist this article, visit My Profile, thenView saved stories.
To revist this article, visit My Profile, thenView saved stories.
Alex EnglerArtificial Intelligence Won't Save Us From CoronavirusTo revist this article, visit My Profile, thenView saved stories.
To revist this article, visit My Profile, thenView saved stories.
ApplicationPredictionEnd UserGovernmentResearchSectorHealth careSource DataSensorsImagesTechnologyMachine learningMachine visionArtificial intelligence ishere to save us from coronavirus. It spots new outbreaks, identifies people with fevers, diagnoses cases, prioritizes the patients most in need, reads the scientific literature, and is on its way to creating a cure.
If only.
Alex Engleris a David M. Rubenstein Fellow at the Brookings Institution and an adjunct professor and affiliated scholar at Georgetown University’s McCourt School of Public Policy.
As the world confronts the outbreak of coronavirus, many have lauded AI as our omniscient secret weapon. Although corporate press releases and some media coverage sing its praises, AI will play only a marginal role in our fight against Covid-19. While there are undoubtedly ways in which it will be helpful—and even more soin future pandemics—at the current moment, technologies like data reporting, telemedicine, and conventional diagnostic tools are far more impactful. So how can you avoid falling for the AI hype? In a recentBrookings Institution report, I identified the necessary heuristics for a healthy skepticism of AI claims around Covid-19.
Let’s start with the most important rule: always look to the subject matter experts. If they are applying AI, fantastic! If not, be wary of AI applications from software companies that don’t employ those experts. Data is always dependent on its context, which takes expertise to understand. Does data from China apply to the United States? How long might exponential growth continue? By how much will our interventions reduce transmission? All models, even AI models, make assumptions about questions like these. If the modelers don’t understand those assumptions, their models are more likely to be harmful than helpful.
Thankfully, in the case of Covid-19, epidemiologists know quite a bit about the context of the data. Even though the virus is new and there is much to be learned, there is tremendous depth of expertise aroundwhat questions to askand how they can be answered.
Modern statistical epidemiologydates to the early 1900s, which means the field is incorporating a century of scientific research into its analyses. In contrast, machine learning methods tend to assume that everything can be learned directly from a data set, without incorporating the broader scientific context.
Consider, for example, the claim that AI was the first to detect the coronavirus. Machine learning is very dependent on historical data to create meaningful insights. Since there is no database of prior Covid-19 outbreaks, AIalonecannot predict the spread of this new pandemic. What’s more, the claim implicitly overstates the ability of AI to inform us about huge and rare events, which is not the strength of AI at all. As it turns out, while software may have sounded the alarm, grasping the significance of the outbreakrequired human analysis.
AI’s real value lies in its ability to create many minute predictions. For instance, the AI epidemiology company BlueDot hassuccessfully helpedthe state of California monitor the spread of the coronavirus. The company augmented traditional epidemiological models with machine learning, using flight patterns to predict the spread at the zip code level. That’s the value of AI. Thosegranular estimatescan enable precise allocation of funding, supplies, and medical staff.
That said, you should not trust all individualized estimates from AI. Frequently, a company will report accuracy—the percent of predictions that are correct during development—to purport the effectiveness of an AI model. Unfortunately, this number is easy to juke and often offers an incomplete picture. For instance, Alibaba has claimed it can diagnose Covid-19 from CT scanswith 96 percent accuracy. But, if you check in with the subject matter experts, you’ll see that the American College of Radiologyhas saidthat CT scans should not be used as “first-line tests to diagnose Covid-19." Other experts echo that thismethod is not yet proven, and further caution that while the algorithm may be fast, it requires that CT scan rooms must be cleaned and their air recirculated between each patientAs for that impressively high rate of accuracy, it’s time to share a dirty secret of the machine learning world: any data scientist in the field would scoff at that level of accuracy. It’sunbelievablyhigh. Without any caveat, self-criticism, or external validation, it’s suspicious on its face. Even if it is true, we often need metrics aside from accuracy to know if a model is effective, such as the percent of sick individuals who are correctly diagnosed. While fatigued medical systems have turned toAI analysis of x-raysfor triaging patients based on the severity of their lung conditions, AI can’t currently diagnose Covid-19 on its own.
Even AI models that are thoroughly tested and validated in development need further skepticism, since real-world situations nearly always degrade AI performance. In arecent paperabout the diagnosis of malignant moles, researchers noticed that their AI models had learned that medical rulers were often present in images of moles known to be malignant. This has the dual effect of driving accuracy up in the lab but down in the real world.
This lesson gives us reason to be dubious of AI systems that attempt to detect fevers from thermal cameras. Surveillance technology company Athena Security claimed that, in the past month, they had adapted their existing software todo just that. Even before it was reported that Athena had allegedly faked thesoftware demonstration, the claim warranted skepticism. While the fever-detecting technology may work well in lab conditions, the software would require a clear and precise view of a person’s inner face, something that could be difficult for a camera to obtain for, say, a person quickly walking into a grocery store. That’s not to mention that the analysis is affectedby ambient temperature, humidity, and even the sexof the subject, which, of course, opens the door to bias.
Fever detection is a plausible use case of AI, but it will take far more time, effort, and money to build systems that are robust enough to trust. AI predictions are only valuable if they enable an intervention—is the fever detection reliable enough to prevent people from entering a supermarket or pharmacy? The CDC doesn’t think so andwould require a confirmatory testin addition to thermal cameras.
All this should give you pause when evaluating claims that tout AI as our Covid savior, and that’s before considering the high likelihood that, just as we’ve seen with other applications of machine learning, it will introduceunintended consequencesandsystemic bias. But while a dose of skepticism is healthy, the near-future impact of AI on some of these applications is bright. AI is a widely applicable technology with tremendous potential, but its advantages need to be hedged in a realistic understanding of its limitations.
WIRED Opinionpublishes articles by outside contributors representing a wide range of viewpoints. Read more opinionshere. Submit an op-ed at opinion@wired.com.
More From WIREDContact© 2022 Condé Nast. All rights reserved. Use of this site constitutes acceptance of ourUser AgreementandPrivacy Policy and Cookie StatementandYour California Privacy Rights.
Wiredmay earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices
