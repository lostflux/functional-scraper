old id = 2585
What's Behind the International Rush to Write an AI Rulebook?
2022
https://singularityhub.com/2019/06/11/whats-behind-the-international-rush-to-write-an-ai-rulebook

What’s Behind the International Rush to Write an AI Rulebook?There’s no better way of ensuring you win a race than by setting the rules yourself. That may be behind the recent rush by countries, international organizations, and companies to put forward their visions for how theAI raceshould be governed.
China became the latest to release a set of“ethical standards”for the development of AI last month, which might raise eyebrows given the country’s well-documentedAI-powered state surveillance programand suspect approaches to privacy and human rights.
But given the recent flurry of AI guidelines, it may well have been motivated by a desire not to be left out of the conversation. The previous week the OECD, backed by the US, released its own“guiding principles”for the industry, and in April the EU released“ethical guidelines.”The language of most of these documents is fairly abstract and noticeably similar, with broad appeals to ideals like accountability, responsibility, and transparency. The OECD’s guidelines are the lightest on detail, while the EU’s offer some more concrete suggestions such as ensuring humans always know if they’re interacting with AI and making algorithms auditable. China’s standards have an interesting focus on promoting openness and collaboration as well as expressly acknowledgingAIs potential to disrupt employment.
Overall, though, one might be surprised that there aren’t more disagreements between three blocs with very divergent attitudes to technology, regulation, and economics. Most likely these are just the opening salvos in what will prove to be a long-running debate, and the devil will ultimately be in the details.
The EU seems to havestolen a marchon the other two blocs, being first to publish its guidelines and having already implemented the world’s most comprehensive regulation of data—the bedrock of modern AI—with last year’s GDPR. But its lack of industry heavyweights is going to make it hard to hold onto that lead.
One organization that seems to be trying to take on the role of impartial adjudicator is the World Economic Forum, which recently hostedan eventdesigned to find common ground between various stakeholders from across the world. What will come of the effort remains to be seen, but China’s release of guidelines broadly similar to those of its Western counterparts is a promising sign.
Perhaps most telling, though, is the ubiquitous presence of industry leaders in both advisory and leadership positions. China’s guidelines are backed by “anAI industrial league” including Baidu, Alibaba, and Tencent, and the co-chairs of the WEF’s AI Council are Microsoft President Brad Smith and prominent Chinese AI investor Kai-Fu Lee.
Shortly after the EU released its proposals one of the authors, philosopher Thomas Metzinger, said theprocess had been compromisedby the influence of the tech industry, leading to the removal of “red lines” opposing the development of autonomous lethal weapons or social credit score systems like China’s.
For a long time big tech argued for self-regulation, but whether they’ve had an epiphany or have simply sensed the shifting winds, they are now coming out in favor of government intervention.
Both Amazon and Facebook have called forregulation of facial recognition, and in February Google went even further, calling for thegovernment to set down rules governing AI. Facebook chief Mark Zuckerberg has also since called for evenbroader regulation of the tech industry.
But considering the current concern around the anti-competitive clout of the largest technology companies, it’s worth remembering that tough rules are alwayseasier to deal withfor companies with well-developed compliance infrastructure and big legal teams. And these companies are also making sure the regulation is on their terms.
WireddetailsMicrosoft’s protracted effort to shape Washington state laws governing facial recognition technology and Google’s enormous lobbying effort.
“Industry has mobilized to shape the science, morality and laws of artificial intelligence,” Harvard law professor Yochai Benklerwrites inNature. He highlights how Amazon’s funding of a National Science Foundation (NSF) program for projects on fairness in artificial intelligence undermines the ability of academia to act as an impartial counterweight to industry.
Excluding industry from the process of setting the rules to govern AI in a fair and equitable way is clearly not practical, writes Benkler, because they are the ones with the expertise. But there also needs to be more concerted public investment in research and policymaking, and efforts to limit the influence of big companies when setting the rules that will governAI.
Image Credit:create jobs 51/Shutterstock.comFollow Edd:LatestThis Week’s Awesome Tech Stories From Around the Web (Through May 21)Volvo and DHL Are Partnering on Hub-to-Hub Autonomous TruckingHow a Volcanic Bombardment in Ancient Australia Led to the World’s Greatest Climate CatastropheRELATEDNanomagnetic Computing Could Drastically Cut AI’s Energy UseA Hybrid AI Just Beat Eight World Champions at Bridge—and Explained How It Did ItNVIDIA’s Tiny New AI Transforms Photos Into Full 3D Scenes in Mere SecondsHow the Extinction of Ice Age Mammals May Have Forced Us to Invent CivilizationGet the latest news from Singularity Hub!Singularity University, Singularity Hub, Singularity Summit, SU Labs, Singularity Labs, Exponential Medicine, Exponential Finance and all associated logos and design elements are trademarks and/or service marks of Singularity Education Group.
© 2022 Singularity Education Group. All Rights Reserved.
Singularity University is not a degree granting institution.
