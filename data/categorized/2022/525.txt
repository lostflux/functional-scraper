old id = 1601
Dima Damen, Professor of Computer Vision, University of Bristol
2022
http://people.cs.bris.ac.uk/~damen

Dima DamenFollow @dimadamenNewsMar 2022: Two papers accepted at CVPR 2022.
Feb 2022:Ego4D Dataset is now publicly availableJan 2022: 10th EPIC Workshop and 1st Ego4D workshop will be jointly held alongside CVPR 2022Dec 2021: NewArXiv Paper: UnweaveNet: Unweaving Activity StoriesNov 2021: Our BMVC 2021 paper "With a little help from my temporal context" is nowAvailable on ArXivOct 2021:Ego4D ProjectandArXiv papernow out.
Reveal session during EPIC@CCV2021Sep 2021: Our paperRescaling Egocentric Visionaccepted at IJCVAug 2021: WelcomingAlexandros StergiouandBin Zhuas postdocs to the groupJuly 2021:Technical report for 2021 EPIC-KITCHENS challengsis onlineJune 2021: Our paperSlow-Fast Auditory Streamswon outstanding paper at ICASSP 2021 (3 out of 1700 papers awarded)June 2021:EPSRC Program Grant Visual AI has a live website nowJune 2021: Pleased to be outstanding reviewer for CVPR 2021May 2021: During CVPR 2021, I'll be delivering keynotes during2nd comprehensive tutorial on Video understanding,8th workshop on FGVCand2nd HVU workshop, in addition to co-organising8th EPIC@CVPR2021Mar 2021: CVPR 2021 paper "On Semantic Similarity in Video Retrieval"now on ArXivMar 2021: CVPR 2021 paper "Temporal-Relational CrossTransformers for Few-Shot Action Recognition"now on ArXivFeb 2021: Will be delivering keynotes at two CVPR2021 workshops:Fine-grained visual categorisation (FGVC8)andHolistic Video Understanding (HVU)Jan 2021: Slides for my talk atHAU@ICPR 2021 workshopcan be foundhereNov 2020: Two papers presented at ACCV 2020:Play Fair: Frame Attributions in Video Models(Project)andMeta-Learning with Context-Agnostic Initialisations(Project)Nov 2020: Excited to start active work asProgram Chair for ICCV 2021in MontrealSep 2020: Glad to join theELLIS (European Laboratory for Learning and Intelligent Systems) Societyas a memberSep 2020: Will be giving a keynote at theDeep Video Understanding workshop alongside ICMI 2020Sep 2020: Will be giving a keynote at theHCMA workshop alongside ACM MMon 12 OctAug 2020: Final program for our EPIC@ECCV Workshop is nowavailable online1 July 2020: EPIC-KTICHESN-100 Dataset Now Released -Download,webinarJune 2020:ArXiv Manuscript "Rescaling Egocentric Vision"is now onlineJune 2020: Will be happy to deliver keynotes in August at ECCV workshops:Women in Computer VisionandCompositional and Multimodal Video Perception ChallengeJun 2020: Proud to be anOutstanding Reviewer for CVPR 2020.
Jun 2020: My talk on "Learning from Narrated Videos of Everyday Tasks" at the CVPR2020 workshop on Instructional Videos is now availableonlineJun 2020: Deadline for the 7thEPIC@ECCV2020 Workshopis 10th of July - published proceedings includedApr 2020:EPSRC Program Grant Visual AIapproved for funding.
Mar 2020: I join theeditorial board of IJCVas an associate editor.
Mar 2020: Our paper "Action Modifers: Learning from Adverbs in Instructional Videos", accepted at CVPR 2020 is now onArXiv-watch the video that explains the method hereMar 2020: Our paper "Multi-Modal Domain Adaptation for Fine-Grained Action Recognition", accepted for Oral at CVPR 2020 is now onArxiv- seeproject detailsFeb 2020: Two papers accepted in CVPR 2020 - available in Arxiv already (see publications)Dec 2019:Jade-2 HPC Clusterhas been accepted for fundingDec 2019: My talk at NCVPRIPG2019 in Hubli India is availablehereDec 2019: I start EPSRC Early Career FellowshipUMPIREthis Jan. 5-Years Funding to expand my research activities in object interaction understanding.
Nov 2019: I join the editorial board of IEEE TPAMI as associate editorNov 2019: Congrats to Davide Moltisanti and Michael Wray for passing their PhD vivasOct 2019: My talk from the Extreme Vision ICCV workshop is availablehereOct 2019: Videos of all talks in our BMVA symposium areon available on YouTubeOct 2019: Videos of my 4-hour tutorial at North African Summer School in Machine Learning are now on YouTube:Part1,Part2Sep 2019: Our paper "Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos" (ICCVW) is now on Arxiv -DetailsAug 2019: We releasepretrained modelsandtechnical reportfor action recognition on EPIC-KitchensJuly 2019: Our paper "Learning Visual Actions Using Multiple Verb-Only Labels" accepted for presentation at BMVC2019 isavailable on ArxivJuly 2019: Two papers accepted at ICCV 2019, "EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition" with Evangelos Kazakos (Bristol), Arsha Nagrani and Andrew Zisserman (Oxford), and "Fine-Grained Action Retrieval through Multiple Parts-of-Speech Embeddings" with Mike Wray (Bristol), Gabriela Csurka and Diane Larlus (Naver Labs)July 2019: I'll be giving keynotes at theICCV2019 workshop YouTube8M,ICCV2019 workshop ACVR, and at theBMVC2019 workshop EgoAppJuly 2019: CFPBMVA symposium on Video Understandingin London - 25 SepJune 2018: Slides from my tutorial atNorth African Summer School in Machine Learning (NASSMA)are nowonlineApr 2019:Camera ready version and details of our paper Dual-Domain LSTM for Cross-Dataset Action Recognition- CVPR 2019 now onlineApr 2019:Camera ready version and details of our paper The Pros and Cons: Rank-aware Temporal Attention for Skill Determination in Long Videos- CVPR 2019 now onlineApr 2019: Fifth EPIC workshop accepted -EPIC@ICCV2019will be held in Seoul this Oct/NovApr 2019: Will be giving a keynote at the7th Workshop on Assistive Computer Vision and Roboticsalongside ICCV in Seoul this October.
Apr 2019:Camera ready version and details of our paper Action Recognition from Single Timestamp Supervision in Untrimmed Videos- CVPR 2019 now online andon ArxivMar 2019: Looking forward to returning as a speaker for the2019 BMVA summer schoolin Lincoln this JuneMar 2019: Slides for my keynote at VISAPP nowonlineMar 2019: Invited as one of the speakers at the First North African summer school in Machine LearningNASSMAFeb 2019:Three papers accepted at CVPR 2019(coming soon on Arxiv)Feb 2019: Keynote atVISAPP 2019 in PragueDec 2018:EPIC@CVPR2019Workshop to take place in Long BeachOct 2018: Scheduled talk at MPI Tubingen -detailsSep 2018: EPIC-KITCHENS presented as Oral at ECCV 2018 - camera ready availableArxiv,WebpageSep 2018: Leaderboards for the EPIC-KITCHENS challenges on CodaLab are nowopenSep 2018: Two papers presented at BMVC 2018.
Action Completion(Dataset) andCaloriNetAug 2018: EPIC-SKILLS dataset, for our CVPR2018 paper is nowonlineAug 2018: Programme forEPIC@ECCV2018 workshopis now available. Join us in Munich on Sep 9thJuly 2018: Looking forward to giving a tutorial onegocentric visionas part of theBMVA Summer Schoolon July 5th, University of East Anglia.
Apr 2018: EPIC-KITCHENS 2018 goes live today: 11.5M Frames, full HD, 60fps, head-mounted, 32 kitchens from 4 cities (in North America and Europe), 10 nationalities. FULLY annotated: 40K action segments, 454K object bounding boxes. Dataset:http://epic-kitchens.github.ioDetails at:ArxivApr 2018: Our paper "Human Routine Change Detection using Bayesian Modelling" accepted at ICPR2018, to be presented in Beijing this August.
DetailsFeb 2018: Our paper "Who's Better, Who's Best" accepted at CVPR2018, to be presented in Salt Lake city this June.
DetailsFeb 2018: Congrats toYangdi Xufor passing his PhD viva with minor correctionsJan 2018: Serving on the High Performance Computing exec board at UoBOct 2017: Selected as outstanding reviewer at ICCV 2017Oct 2017: Well-attendedSecond Int. Egocentric Perception Interaction and Computing (EPIC) workshop alongside ICCV in VeniceOct 2017: Our paper "Trespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video" was presented in ICCV -detailsOct 2017: Our paper "Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks" was presented at ACVR -pdfSep 2017:Unit details for thenewApplied Deep Learning M level unit-Uni CatalogueSep 2017: Serving asassociate editor for Pattern RecognitionAug 2017: Happy to be working as a consultant with Bristol's Cookpad on developing their Computer Vision and Machine Learning agendaApr 2017:6 July - Lincoln, BMVA summer school, will be giving a tutorial on Egocentric VisionApr 2017:15 May - Bristol, will be giving a public talk on 'What can a wearable camera know about me?'Mar 2017:Slides from my talk on Challenges and Opportunities for Action and Activity Recognition using RGBD Data, BMVA Symposium are now availableFeb 2017:Videos from BMVA symposium on Transfer Learning now availableDec 2016:Final programme for BMVA Symposium on Transfer Learning now availableOct 2016:Code Releasedfor 3DV paper on acquisition and registration of point clouds using two facing KinectsSep 2016: 3D Data Acquisition and Registration Using Two Opposing Kinects - Paper accepted at 3DVAug 2016: Action Completion paper accepted at BMVC and dataset released -Project WebpageAug 2016: Nokia Technologies donation of â‚¬50KPress releaseAug 2016: Action Completion paper accepted at BMVC, York, Sep 2016.
projectJuly 2016: PhD students Michael Wray and Davide Moltisanti awarded second poster prize at BMVA summer schoolnewsJuly 2016: CFP: Transfer Learning in Computer Vision - BMVA Symposium[details, dates and submission]Jun 2016: PhD opening in Computer Vision and Machine Learning (Home/EU students) -Open Until,ad on jobs.ac.ukJun 2016:CVPR 2016 Demo for GlaciARMay 2016:EPIC@ECCV2016 Workshop (Egocentric Perception, Interaction and Computing) Accepted.
Apr 2016:EPSRC Project LOCATEto be funded starting July 2016Mar 2016:You-Do, I-Learn: Egocentric Unsupervised Discovery of Objects and their Modes of Interaction Towards Video-Based Guidanceaccepted at CVIUNov 2015:EPSRC Project GLANCEto be funded starting March 2016Sep 2015: Paper "Unsupervised Daily Routine Modelling from a Depth Sensor using Bottom-Up and Top-Down Hierarchies" accepted at ACPRSep 2015: Paper "Estimating Visual Attention from a Head Mounted IMU" presented at ISWC in Okasa, JapanSep 2015: Paper "Real-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling" Presented at BMVCAug 2015: PhD Student Vahid Soleiman publishes paper on Remote Pulmonary Function Testing using a Depth Sensor at BIOCAS 2015.
Demo VideoJune 2015: PLOSONE articleavailable onlineJune 2015: SI on cognitive robotics systems: concepts and applications at the Journal of Intelligent & Robotic Systems isonlineMar 2015: Interdisciplinary research internshipawarded for CS student Hazel Doughty.
Sep 2014: Paper"You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video"presented at BMVCSep 2014: Paper"Online quality assessment of human movement from skeleton data"presented at BMVCSep 2014: Paper"Multi-user egocentric Online System for Unsupervised Assistance on Object Usage"presented at ECCVW (ACVR 2014)Aug 2014: C++ code (improved performance v 1.2) and Android apkfor real-time object detectoravailable.
July 2014: TheBristol Egocentric Object Interactions Datasethas now been releasedJuly 2014:Book review published in IAPR newsletterJuly 2014: Video lectures from BMVC 2013are now available online.
July 2014: Sphere project's websiteirc-sphere.ac.ukhas now been released (2013-2018).
May 2014:Project Ideas for 3G403 and 2G400 students available.
Feb 2014:PhD Opening in Ego-centric Vision- apply as soon as possible...
Nov 2013: Project GlaciAR is starting funded bySamsung's GRO 2013 AwardsNov 2013:Cognitive Robotics Systems (CRS 2013)(IROS 2013workshop), successfully concludes at Tokyo, Japan.
Sep 2013:BMVC 2013successfully concluded at BristolAug 2013: Outstanding Reviewer award atIEEE AVSS 2013.
June 2013: Outstanding Reviewer award atIEEE CVPR 2013.
May 2013: New bug-fixed version (v1.1) of our Multi-Object Detector (MOD) code is now availableonlineResearch ProjectsUnweaveNet: Unweaving Activity StoriesUnweaveNet: Unweaving Activity Stories. W Price, C Vondrick, D Damen. CVPR (2022).
ArXiv Paper|Project Webpage|AnnotationsEgo4D: Around the World in 3,000 Hours of Egocentric VideoAround the World in 3,000 Hours of Egocentric Video. K Grauman (+83 Authors) et al. CVPR (2022).
ArXivTemporal Context in Egocentric VideoWith a Little Help from my Temporal Context: Multimodal Egocentric Action Recognition. E Kazakos, J Huh, A Nagrani, A Zisserman, D Damen. BMVC (2021).
ArXiv Paper|Project Webpage|Code, features and modelsRescaling Egocentric VisionTrailer|Video Demonstration|Webinar|DownloadRescaling Egocentric Vision. D Damen, H Doughty, G Farinella, A Furnari, E Kazakos, J Ma, D Moltisanti, J Munro, T Perrett, W Price, M Wray. IJCV.
IJCV paper,ArXiv,WebpageThe EPIC-KITCHENS Dataset: Collection, Challenges and Baselines. D Damen, H Doughty, GM Farinella, S Fidler, A Furnari, E Kazakos, D Moltisanti, J Munro, T Perrett, W Price, M Wray. IEEE Transactions on Pattern Analysis and Machine Intelligence 43(11) pp 4125-4141 (2021).
IEEE,Arxiv PreprintDomain Adaptation in Video RetrievalDomain Adaptation in Multi-View Embedding for Cross-Modal Video Retrieval. J Munro, M Wray, D Larlus, G Csurka, D Damen. ArXiv (2021).
ArXiv PaperSemantic Similarity in Video RetrievalOn Semantic Similarity in Video Retrieval. M Wray, H Doughty, D Damen. CVPR (2021).
CVF PDF|ArXiv Preprint|Project Webpage|VideoTemporal-Relational CrossTransformersTemporal-Relational CrossTransformers for Few-Shot Action Recognition. T Perrett, A Masullo, T Burghardt, M Mirmehdi, D Damen. CVPR (2021).
CVF PDF|ArXiv Preprint|Code and Model|Project WebpageSlow-Fast Auditory StreamsSlow-Fast Auditory Streams For Audio Recognition. E Kazakos, A Nagrani, A Zisserman, D Damen. ICASSP (2021).
ArXiv Preprint|IEEE PDF|Code and Models|Project Webpage[Outstanding Paper]Frame Attributions in Video ModelsInteractive Dashboard|Teaser Video|CodePlay Fair: Frame Attributions in Video Models. W Price, D Damen. ACCV (2020).
ArXiv Preprint|Project Details|CVF|CVF PDFMetaLearning with Context-Agnostic InitialisationTalk VideoMetaLearning with Context-Agnostic Initialisation. T Perrett, A Masullo, T Burghard, M Mirmehdi, D Damen. ACCV (2020).
ArXiv Preprint|CVF|CVF PDF|Project DetailsAction Modifiers: Learning from Adverbs in Instructional VideosVideo,Talk VideoAction Modifiers: Learning from Adverbs in Instructional Videos. H Doughty, I Laptev, W Mayol-Cuevas, D Damen. CVPR (2020).
ArXiv Preprint,CVF PDF,Project DetailsMulti-Modal Domain Adaptation for Fine-Grained Action RecognitionVideo,Oral Presentation VideoMulti-modal Domain Adaptation for Fine-grained Action Recognition. J Munro, Dima Damen. CVPR (2020).
ArXiv Preprint,CVF PDF,Project Details,CodeRetro-ActionsVideoRetro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos. W Price, Dima Damen. ICCV (2019).
ArXiv Preprint,Project DetailsFine-Grained Action RetrievalVideoFine-Grained Action Retrieval through Multiple Parts-of-Speech Embeddings. Michael Wray, Diane Larlus, Gabriela Csurka, Dima Damen. ICCV (2019).
CVF PDF,ArXiv Preprint,Project DetailsAudio-Visual Temporal Binding for Egocentric Action RecognitionTalk Video,VideoEPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition. Evangelos Kazakos, Arsha Nagrani, Andrew Zisserman, Dima Damen. ICCV (2019).
Project Details,CVF PDF,Arxiv PreprintLearning Visual Actions Using Multiple Verb-Only LabelsVideoLearning Visual Actions Using Multiple Verb-Only Labels. M Wray, D Damen. BMVC (2019).
ArXiv Preprint,Project DetailsDDLSTM: Dual-Domain LSTMVideoDDLSTM: Dual-Domain LSTM for Cross-Dataset Action Recognition. T Perrett and D Damen. CVPR (2019).
pdf preprint,ArxivProject DetailsThe Pros and Cons: Rank-Aware Attention ModulesTeaser VideoResults VideoThe Pros and Cons: Rank-aware Temporal Attention for Skill Determination in Long Videos. H Doughty, W Mayol-Cuevas, D Damen. CVPR (2019).
pdf preprint,Arxiv,Project DetailsAction Recognition from Single TimestampsResults VideoAction Recognition from Single Timestamp Supervision in Untrimmed Videos. D Moltisant, S Fidler and D Damen. CVPR (2019).
pdf preprint,Project DetailsTent Assembly Egocentric DatasetVideo(2021) B Sullivan, C Ludwig,D Damen, W Mayol-Cuevas, I Gilchrist. Look-Ahead Fixations During Visuomotor Behavior: Evidence from Assembling a Camping Tent. Journal of Vision 21(3):13.
PDFEPIC-Tent: An Egocentric Video Dataset for Camping Tent Assembly. Y Jang, B Sullivan, C Ludwig, I.D. Gilchrist, D Damen and W Mayol-Cuevas. ICCV Workshops (2019).
pdf,Project Details,Dataset,AnnotationsScaling Egocentric Vision: EPIC-KITCHENS 2018VideoScaling Egocentric Vision: The EPIC-KITCHENS Dataset. D Damen, H Doughty, G Farinella, S Fidler, A Furnari, E Kazakos, D Moltisanti, J Munro, T Perrett, W Price, M Wray. ECCV (2018).
Webpage|Dataset|arxivAn Evaluation of Action Recognition Models on EPIC-Kitchens. W Price, D Damen. Arxiv (2019)Arxiv|Github|PDFThe EPIC-KITCHENS Dataset: Collection, Challenges and Baselines. D Damen, H Doughty, GM Farinella, S Fidler, A Furnari, E Kazakos, D Moltisanti, J Munro, T Perrett, W Price, M Wray. IEEE Transactions on Pattern Analysis and Machine Intelligence (2020).
Arxiv PreprintSkill Determination in VideoVideoWho's Better? Who's Best? Pairwise Deep Ranking for Skill Determination. H Doughty, D Damen, W Mayol-Cuevas. CVPR (2018).
PDF|arxiv|DatasetAction Completion: A Temporal Model for Moment DetectionWeakly-Supervised Completion Moment Detection using Temporal Attention. F Heidarivincheh, M Mirmehdi, D Damen. ICCV Workshop on Human Behaviour Understanding.
Arxiv|CVF PDF, Oct 2019.
Video2018,Video2016Action Completion: A Temporal Model for Moment Detection. F Heidarivincheh, M Mirmehdi, D Damen. British Machine Vision Conference (BMVC), Sep 2018.
Arxiv PDF|DatasetBeyond Action Recognition: Action Completion in RGB-D Data. F Heidarivincheh, M Mirmehdi, D Damen. British Machine Vision Conference (BMVC), Sep 2016.
pdf|abstract|DatasetHuman Routine Modelling and Change DetectionHuman Routine Change Detection using Bayesian Modelling. Y Xu, D Damen. ICPR (2018).
PDFUnsupervised Long-Term Routine Modelling using Dynamic Bayesian Networks. Y Xu, D Bull, D Damen. DICTA (2017).
PDFTrespassing the Boundaries of Object InteractionsVideoTrespassing the Boundaries: Labeling Temporal Bounds for Object Interactions in Egocentric Video. D Moltisanti, M Wray, W Mayol-Cuevas, D Damen. International Conference on Computer Vision (ICCV), 2017.
pdf(camera ready) |arxivSemantic Embedding for Egocentric ActionsVideoSEMBED: Semantic Embedding of Egocentric Action Videos. M Wray, D Moltisanti, W Mayol-Cuevas, D Damen. Egocentric Interaction, Perception and Computing (EPIC), European Conference on Computer Vision Workshops (ECCVW), Oct 2016.
pdf|DatasetYou-Do, I-LearnVideo1 (2014),Video2 (2017)Automated capture and delivery of assistive task guidance with an eyewear computer: The GlaciAR system. T Leelasawassuk, D Damen, W Mayol-Cuevas. Augmented Human, Mar 2017pdfYou-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video. D Damen, T Leelasawassuk, O Haines, A Calway, W Mayol-Cuevas. British Machine Vision Conference (BMVC), Sep 2014.
PDF|Abstract|DatasetMulti-user egocentric Online System for Unsupervised Assistance on Object Usage. D Damen, O Haines, T Leelasawassuk, A Calway, W Mayol-Cuevas. ECCV Workshop on Assistive Computer Vision and Robotics (ACVR), Sep 2014.
PDF PreprintEstimating Visual Attention from a Head Mounted IMU. T Leelasawassuk, D Damen, W Mayol-Cuevas. International Symposium on Wearable Computers (ISWC), Sep 2015.
PDFDS-KCF: Depth-Based Real-Time Single Object TrackerVideo 1|Video 2|CodeReal-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling. M Camplani, S Hannuna, M Mirmehdi, D Damen, L Tao, T Burghardt and A Paiment. British Machine Vision Conference (BMVC), Sep 2015.
PDF.
Real-time Learning and Detection of 3D Texture-minimal ObjectsVideo|CodeReal-time Learning and Detection of 3D Texture-minimal Objects: A Scalable approach. D Damen, P Bunnun, A Calway, W Mayol-Cuevas. British Machine Vision Conference (BMVC), Sep 2012.
PDF|Abstract|Code|Video|Dataset.
Efficient Texture-less Object Detection for Augmented Reality Guidance. T Hodan, D Damen, W Mayol-Cuevas, J Matas. IEEE Int. Symposium on Mixed and Augmented Reality (ISMAR) Workshop on Visual Recognition and Retrieval for Mixed and Augmented Reality, Sep 2015.
Egocentric Real-time Industrial WorkflowVideo 1|Video 2Cognitive Learning, Monitoring and Assistance of Industrial Workflows Using Egocentric Sensor Networks. G Bleser, D Damen, A Behera, et al. PLOSONE, June 2015PDF.
Egocentric Real-time Workspace Monitoring using an RGB-D Camera. D Damen, A Gee, W Mayol-Cuevas, A Calway. Intelligent Robotics and Systems (IROS), Oct 2012.
PDF|Video.
Online Quality Assessment for Human MotionCodeOnline quality assessment of human movement from skeleton data. A Paiment, L Tao, S Hannuna, M Camplani, D Damen and M Mirmehdi. British Machine Vision Conference (BMVC), Sep 2014.
PDF|Dataset.
The Bicycle ProblemExplaining Activities as Consistent Groups of Events - A Bayesian Framework using Attribute Multiset Grammars. D Damen and D Hogg International Journal of Computer Vision (IJCV), 2012.
PDF.
Recognizing Linked Events: Searching the Space of Feasible Explanations. D Damen and D Hogg. Computer Vision and Pattern Recognition (CVPR), Miami, Florida, June 2009.
PDF|PosterDetecting Carried Objects from Walking PedestriansVideo|CodeDetecting Carried Objects from Sequences of Walking Pedestrians. D Damen and D Hogg. Pattern Analysis and Machine Intelligence (PAMI), 2012.
PDF.
Detecting Carried Objects in Short Video Sequences. D Damen and D Hogg. European Conference on Computer Vision (ECCV), Marseille, France, Oct 2008PDF|PosterResearch Group MembersPrevious Students, and Postdocs
