old id = 648
A leading AI ethics researcher says she’s been fired from Google | MIT Technology Review
2022
https://www.technologyreview.com/2020/12/03/1013065/google-ai-ethics-lead-timnit-gebru-fired

A leading AI ethics researcher says she’s been fired from GoogleOn December 2, the AI research community was shocked to learn that Timnit Gebru had been fired from her post at Google. Gebru, one of the leading voices in responsible AI research, is known among other things for coauthoring groundbreaking work that revealed thediscriminatory nature of facial recognition, cofounding the Black in AI affinity group, andrelentlessly advocating for diversity in the tech industry.
But on Wednesday evening, she announcedon Twitterthat she had been terminated from her position as Google’s ethical AI co-lead. “Apparently my manager’s manager sent an email [to] my direct reports saying she accepted my resignation. I hadn’t resigned,” she said.
Inan interview with Bloombergon Thursday, Gebru said that the firing happened after a protracted fight with her superiors over the publication of an AI ethics research paper.
One of Gebru’s tweetsand a laterinternal emailfrom Jeff Dean, head of Google AI, suggest that the paper was critical ofthe environmental costsand embedded biases of large language models.
Thanks@red_abebe.
@JeffDeanI realize how much large language models are worth to you now. I wouldnâ€™t want to see what happens to the next person who attempts this.
https://t.co/rIBXYPvQ3dGebru, who had written the paper with four Google colleagues and two external collaborators, had submitted it to a research conference being held next year. After an internal review, she was asked to retract the paper or remove the names of the Google employees. She responded that she would do so if her superiors met a series of conditions. If they could not, she would “work on a last date,” she said.
I said here are the conditions. If you can meet them great Iâ€™ll take my name off this paper, if not then I can work on a last date. Then she sent an email to my direct reports saying she has accepted my resignation. So that is google for you folks. You saw it happen right here.
She also sent afrustrated emailto an internal listserv, Google Brain Women and Allies, detailing the repeated hardships she’d experienced as a Black female researcher. “We just had a Black research all hands with such an emotional show of exasperation,” she wrote. “Do you know what happened since? Silencing in the most fundamental way possible.”Gebru then went on a vacation and received a termination email from Megan Kacholia, the VP of engineering at Google Research, before her return. “Thanks for making your conditions clear,”the email stated, as tweeted by Gebru. “We cannot agree to #1 and #2 as you are requesting. We respect your decision to leave Google as a result, and we are accepting your resignation.” Her email to the listserv was “inconsistent with the expectations of a Google manager,” it continued. “As a result, we are accepting your resignation immediately, effective today.”On Thursday morning, after an outpouring of support for Gebru on social media, Dean sent aninternal emailto Google’s AI group with his account of the situation. He said that Gebru’s paper “didn’t meet our bar for publication” because “it ignored too much relevant research.” He also said that Gebru’s conditions included “revealing the identities of every person who Megan and I had spoken to and consulted as part of the review of the paper and the exact feedback.”“Given Timnit's role as a respected researcher and a manager in our Ethical AI team, I feel badly that Timnit has gotten to a place where she feels this way about the work we’re doing,” he wrote. “I know we all genuinely share Timnit’s passion to make AI more equitable and inclusive.”Neither Gebru, Dean, nor Google communications responded to requests for comment, and many details surrounding the exact progression of events, or cause of termination, remain unclear. As they continue to emerge, many have brought renewed attention toa November 30 tweetthat Gebru pinned to the top of her profile. “Is there anyone working on regulation protecting Ethical AI researchers, similar to whistleblower protection?” it reads. “Because with the amount of censorship & intimidation that goes on towards people in specific groups, how does anyone trust any real research in this area can take place?”byKaren HaoSharePopularDeep DiveTech policySouth Africa’s private surveillance machine is fueling a digital apartheidAs firms have dumped their AI technologies into the country, it’s created a blueprint for how to surveil citizens and serves as a warning to the world.
A quick guide to the most important AI law you’ve never heard ofThe European Union is planning new legislation aimed at curbing the worst harms associated with artificial intelligence.
Inside the fierce, messy fight over “healthy” sugar techYi-Heng “Percival” Zhang was a leader in rare sugar research. Then things got sticky.
The secret police: Inside the app Minnesota police used to collect data on journalists at protestsIntrepid Response is a little-known but powerful app that lets police quickly upload and share information across agencies. But what happens to the information it collects?Stay connectedGet the latest updates fromMIT Technology ReviewDiscover special offers, top stories, upcoming events, and more.
Thank you for submitting your email!It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us atcustomer-service@technologyreview.comwith a list of newsletters you’d like to receive.
MIT Technology ReviewOur in-depth reporting reveals what’s going on now to prepare you for what’s coming next.
Subscribeto support our journalism.
AboutHelp© 2022 MIT Technology Review
