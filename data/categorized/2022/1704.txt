old id = 3689
Computing Power Can Keep Growing as Moore's Law Winds Down. Here's How
2022
https://singularityhub.com/2020/06/08/computing-power-can-keep-growing-as-moores-law-winds-down-heres-how

Computing Power Can Keep Growing as Moore’s Law Winds Down. Here’s HowMoore’s Law is faltering, but that doesn’t mean the end of progress in processing power. Rather than relying on semiconductor physics and silicon-fabrication technology, though, we need to turn to innovations in software, algorithms, and hardware, says a group of leading experts.
Despite powering exponential growth in computing power for nearly half a century, the miniaturization of transistors is about to hit fundamental buffers. Not only do the physics behind these performance gains start to change as we approach atomic levels, but the costs quickly become prohibitive.
A hostofalternatives to silicon are waiting in the wings, such as photonics,carbon nanotube transistors, and superconducting circuits, but none are close to being able to replace the technology we’ve become so reliant on. But according to the authors of a newpaper inScience,all is not lost, because there is huge scope for performance gains in software, algorithms, and chip architectures.
While Moore’s Law was doubling chip performance every year or two it was easy to get lazy, the authors say. Because regular boosts in speed were guaranteed, software development focused on cutting the time it took to develop an application rather than the time it takes to run that application. Similarly, there was little incentivetodevelop a chip specialized to a particular task when you knewthatin a couple of years a general-purpose chip would outperform it.
Nowthatthose easy gains have gone, though, the authors say it’s going to be increasingly important to refocus computer scientists’ efforts on optimizing all elements of the computing stack for performance.
It will be hard,and thegains will be unevenandsporadic.
But they also highlight the kindofheadroom there is for improvement. In a simple example of a piece of code for matrix multiplication, they show thatjustswitching from the coding language Python to C can generate a 50x speedup, and thenoptimizingthe code to take advantage of chip hardware features provides a 60,000x boost.
For software, many of the gains will come from better tailoring code to take advantage of hardware features; for instance, exploiting the multiple cores on modern chips by running many operations inparallelrather than sequentially. Most modern software also features huge amounts of bloat due to lazilyre-purposingcode for things it wasn’t built for.
Unfortunately, the authors note that high-performance code tends to be much more complicated to write than slow code, so there needs to be better training for programmers and more productivity tools to assist them.
At the level of algorithms, the path to improvements is less clear, because breakthroughstend to rely on human ingenuity and tend to be specific to a particular problem. But despite their unpredictability, the potential for enormous gains in efficiency means that averaged over time they can rival those we’ve come to expect from Moore’s Law.
There are some simple wins—for example, updating the model underlying much of today’s algorithmic development, which assumes a processor can only do one operation at a time and that it costs the same to access any part ofitsmemory, which is not true of today’s hardware.
When it comes to chip architecture, the authors say, designers will need to turn their approach on its head.
Moore’s Law was powered by squeezing more transistors onto a chip, but future gains will come from streamlining by using fewer transistorsand less chip space to carry out hardware functions.
That extra space will make it possible to squeeze more cores onto chips and further boost thenumber of operations running in parallel. This trend has already been behind much of the performance gain since processor clock speeds stopped rising around 2004, but there’s still lots of scope for further improvements.
Simplifying processors and specializing them to specific applications also holds promise for removing much of the overhead involved in building jack-of-all-trades general-purpose chips. The GPUs that power both computer graphics and machine learning are an excellent example of the power of specialization.
They excel in matrix multiplications and can run the snippet of code mentioned above 360,000x faster than the original implementation.
One of the biggest challengesis that many of these avenues for performance gains are intertwined. For instance, more cores on a processor only gives you a boost if code is designed to be more parallel.
That means the easiest place to make these gains is with what the authors call “big components”—complex and self-contained bits of computing machinery such as operating systems, microprocessors, or compilers—particularly when they’re owned by a single entity who has the freedom and motivation to make significant changes.
Whether the owners of these big components heed the authors’ call remains to be seen. But at least nowwe havea roadmap to get us over the hump until one of the post-Moore’s Law computing technologies takes us beyond the limitations of silicon.
Image Credit:Miguel Á. PadriñánfromPixabayFollow Edd:LatestThis Week’s Awesome Tech Stories From Around the Web (Through May 21)Volvo and DHL Are Partnering on Hub-to-Hub Autonomous TruckingHow a Volcanic Bombardment in Ancient Australia Led to the World’s Greatest Climate CatastropheRELATEDThis Portable Wind Turbine Is the Size of a Water Bottle and Charges Devices in Under an HourNanomagnetic Computing Could Drastically Cut AI’s Energy UseThe Ideal Qubit? Future Quantum Computers Could Crunch Data With Single Electrons on Neon IceHow the Extinction of Ice Age Mammals May Have Forced Us to Invent CivilizationGet the latest news from Singularity Hub!Singularity University, Singularity Hub, Singularity Summit, SU Labs, Singularity Labs, Exponential Medicine, Exponential Finance and all associated logos and design elements are trademarks and/or service marks of Singularity Education Group.
© 2022 Singularity Education Group. All Rights Reserved.
Singularity University is not a degree granting institution.
