old id = 1220
Our Work - Partnership on AI
2022
https://www.partnershiponai.org/why-were-creating-a-dedicated-research-fellowship-to-advance-diversity-and-inclusion-in-ai/work

Our WorkOrganized under Programs, our work contributes to the rigorous development of resources, recommendations, and best practices for AI.
Inclusive Research & DesignAt PAI, equity and inclusion are core values which we seek to promote among our Partner organizations, in our own work, and throughout the greater AI field, including inmachine learning and other automated decision-making systems. This Program explores the many barriers to inclusion in the AI space — as experienced by those who work in technology and those who are consistently excluded from key decision-making processes.
The Inclusive Research and Design Program is currently creating resources to help AI practitioners and impacted communities more effectively engage one another to develop AI responsibly. Ultimately, this work seeks to achieve a more holistic reimagining of how AI is developed and deployed around the world, leading to an AI industry that recognizes end users and impacted communities as essential expert groups.
AI and Media IntegrityWhile AI has ushered in an unprecedented era of knowledge-sharing online, it has also enabled novel forms of misinformation, manipulation, and harassment, creating new categories of harmful digital content and extending their potential reach. PAI’s AI and Media Integrity Program directly addresses these critical challenges to the quality of public discourse, researching timely subjects such as manipulated media detection, misinformation interventions, and content-ranking principles.
Through this Program, PAI works to ensure that AI systems bolster the quality of public discourse and online content around the world, which includes considering how we define quality in the first place. By convening a fit-for-purpose, multidisciplinary field of actors—including representatives from media, industry, academia, civil society, and users themselves—the AI and Media Integrity Program is developing best practices for AI to have a positive impact on the global information ecosystem.
AI, Labor, and the EconomyPAI believes that AI has tremendous potential to solve major societal problems and make peoples’ lives better. At the same time, individuals and organizations must grapple with new forms of automation, wealth distribution, and economic decision-making. Whether AI promotes equality or increases injustice, whether it makes all of us richer or the poor poorer is a choice we, as a world, must consciously make.
To advance a beneficial economic future from AI, the AI, Labor, and the Economy Program gathers Partner organizations, economists, and worker representative organizations. Together, these actors work to form shared answers and recommendations for actionable steps that need to be taken to ensure AI supports an inclusive economic future.
Fairness, Transparency, and Accountability & ABOUT MLAs AI systems are deployed across an ever-growing number of domains, the fairness, transparency, and accountability of these systems has become a critical societal concern. This Program examines the intersections between AI and some of humanity’s most fundamental values, addressing urgent questions about algorithmic equity, explainability, responsibility, and inclusion.
Through original research and multistakeholder input, our Fairness, Transparency, and Accountability work asks how AI can build a world that is more (and not less) just than the one that came before it. And by offering actionable resources for implementing transparency at scale, ABOUT ML seeks to operationalize these insights with full-cycle documentation of machine learning systems.
Safety-Critical AIHow can we ensure that AI and machine learning technologies are safe? This is an urgent short-term question, with applications in computer security, medicine, transportation, and other domains. It is also a pressing longer-term question, particularly with regard to environments that are uncertain, unanticipated, and potentially adversarial.
As our lives become increasingly saturated with artificial intelligence systems, the safety of these systems becomes a vital consideration. The Safety-Critical AI Program seeks to establish social and technical foundations that will support the safe development and deployment of AI.
© 2022 Partnership on AI | All Rights Reserved
