old id = 4279
A Study on the Deployment of a Service Robot in an Elderly Care Center | SpringerLink
2019
https://doi.org/10.1007/s12369-018-0492-5

AdvertisementA Study on the Deployment of a Service Robot in an Elderly Care CenterInternational Journal of Social Roboticsvolume11,pages317–341 (2019)Cite this article2336Accesses43CitationsMetricsdetailsAbstractIn this article, we address the implementation and deployment of a service robot platform for interaction with the elderly in the context of a collaborative European initiative. Specifically, we overview the development of the robot system architecture and components, focusing on the graceful integration of a set of interoperable intelligent services towards advanced human–robot interaction. The service robot targets older people with light physical or psychological issues, delivering several different functionalities, and putting itself at their service. We describe the initial validation tests in a semi-controlled scenario, as well as the deployment of the robotic platform during a week-long pilot in an end user environment. The main challenges and the outcome of the experimental tests with the mobile robot platform are discussed, and results show generally positive reactions from the care center residents, which have provided their valuable feedback on the usability, appearance, interaction and satisfaction of the robot, yielding important lessons that were learned while performing the pilot.
IntroductionThis work addresses the development of a social robotic system to provide companionship, care and socialization services via Information and Communications Technology (ICT) to support the elderly, thus motivating them to remain active and independent and improve their well-being. Several demographic studies report that Europe’s population is aging, as the average life expectancy over the years increase [1]. As a consequence, in recent years, there has been a noticeable growth in the attention given to assistive technologies for helping older individuals to stay active and live independently for longer in their preferred environment, revealing a huge unexplored market potential. Robotic systems are among those initiatives offering functionality related to the support of independent living, monitoring and maintaining safety or enhancement of health and psychological well-being by providing companionship. The SocialRobot projectFootnote1aims to provide an answer to this demographic change challenge. Therefore, we have been developing an integrated social robotics system to address key issues for improved independent living and quality of life of the elderly people.
Despite the fast growth of the ICT and robotics market for aging well, it is still in a premature phase and does not yet fully ensure the availability of the necessary solutions. Existing solutions are either not quite ready for commercial service or represent a high cost. A common property of assistive service robots is that they are pre-programmed with specific services and knowledge at the manufacturing stage, and as a consequence they often fail to properly cope with the constantly changing needs of elderly people [2]. In this paper, we describe an innovative solution, which involves a practice-oriented home care mobile robot targeted to interact with people with light physical or cognitive disabilities, whom can find pleasure and relief in getting help or stimulation to carry out their daily routine. To situate this group in clinically definable metrics, we use the revised Rancho levels of cognitive functions [3], a widely-adopted assessment scale to describe the stages of cognitive functions in patients. In this work, we target people with level VII and above, i.e. starting in people with automatic-appropriate behavior that can go through their daily routine with minimal confusion, and requiring minimal assistance for daily living tasks. Our aim is to empower and stimulate these older adults through the provision of ICT care services to continue living independently for as long as possible in their preferred environment. Being a service robot, the platform provides assistance to users, aiming to tackle the area of preventive care at an early stage of the aging process. Following a user-driven approach, we consider the elderly as active collaborative agents able to make personal choices and the care model is adapted to their lifestyle, personalized needs and changes in capabilities over the aging process. This elderly support paradigm allows to maintain their self-esteem when managing the daily routine at home. Thus, our solution integrates state of the art, standardized and interoperable robotic technologies and ICT-based care and wellness services, and benefits from a virtual social care community network.
The rest of the article is structured as follows: Firstly, we overview seminal work on social robotics and assisted living, with special focus on domestic and service robots for elderly care. We then clearly state the contributions of the article. Afterwards, we provide a brief overview of the mobile robotic platform in Sects.
4and5the developed services and functionalities are presented. In Sect.
6we outline a representative use-case scenario to showcase the robot operating in an indoor environment and discuss the preliminary results, and in Sect.
7we describe a real world testbed to demonstrate and disseminate the project achievements in a human populated environment, i.e. an elderly care center. Section8summarizes the results and the performance achieved by the system based on users’ feedback. Finally, Sect.
9provides conclusions and considerations for the future.
Related WorkThe key scientific assumptions underlying the Social Robot project research are: (i) current technologies enable the acceptance and confidence in robots by humans and; (ii) robots can provide day-to-day support to the elderly to stay active and independent in their preferred environment. These ideas are supported by extensive existing work on robotic technologies, which enable sophisticated perception and autonomous navigation; and ICT-based care and wellness services. SocialRobot addresses the link between these areas to provide affective and advanced user–robotic interaction.
Designing robots for social purposes has been a trendy topic for the last decades. The literature in this area is vast and has yielded several interesting designs [4,5], as seen in Fig.
1. Domestic robots with distinct features and configurations have been proposed to assist the elderly in the past. For instance, one of the pioneer robots in this area was Flo [6] developed at Carnegie Mellon University. It used natural language to provide information related to activities of daily living obtained from the web, and it also enabled remote caregivers to establish telepresence in people’s home. A totally different approach is behind the seal robot Paro [7], which can be found in several care institutions around the world. This is a therapeutic interactive robot that resembles a baby harp seal, which has been found to reduce stress, stimulate interaction with caregivers, and improve relaxation, motivation and socialization of its user. The robot responds to sounds and petting by moving its tail and opening/closing its eyes. It can also simulate emotions such as surprise, happiness and anger.
Recently, innovation in robot and sensor technology, as well as in human–robot interaction (HRI) [8], people detection [9], and autonomous navigation [10] have allowed the emergence of new and more advanced social robots, particularly in Europe. In [11], a robot was developed to improve the well-being of the elderly by providing connectivity, reminders, fall detection, encouraging activities, gaming and interface with home devices. Other notable service robots include Care-O-Bot [12], CAESAR [13], and PR2 [14].
The CompanionAble EU FP7 initiative provides the synergy of robotics and ambient intelligence technologies, and their semantic integration for assistive home care. The project supports the cognitive stimulation and therapy management of the care-recipient, mediated by a robotic companion working collaboratively with a smart home environment. CompanionAble addresses the issues of social inclusion and home care of persons suffering from chronic cognitive disabilities prevalent among the older European population [15].
Robotic platforms developed in the CompanionAble, GiraffPlus, Accompany, Robot-Era, Mobiserv and Hobbit projects (from left to right)The GiraffPlus EU FP7 projectFootnote2provides a telepresence robot, which allows relatives or caregivers to virtually visit an elderly person at home. The project places special emphasis in empathetic user interaction to address the needs and capabilities of the users. GiraffPlus benefits from a network of sensors to monitor the activities in the home environment, placed in and around the home, as well as on the body of the elderly to extract high level activities from sensor data [16].
In the Accompany EU FP7 project, a robotic companion is proposed as part of an intelligent environment, providing services to elderly users in a motivating and socially acceptable manner to facilitate independent living at home. The Accompany system provides physical, cognitive and social assistance in everyday home tasks, and contributes to the re-ablement of the user, i.e. assist the user in being able to carry out certain tasks on his/her own [17].
Similarly, the Robot-Era EU FP7 projectFootnote3focuses on implementing and integrating advanced robotic systems and intelligent environments in real scenarios for the ageing population. Besides demonstrating the general feasibility and effectiveness of the system, the consortium addresses social/legal plausibility and acceptability by end users. To that end, the system is employed in real conditions to cooperate with real people so as to favor independent living, improve the quality of life and the efficiency of care for elderly people [18].
In the Mobiserv EU FP7 initiative, a robot was developed to support the daily living of seniors focusing on health, nutrition, well-being and safety, including the capability to monitor vital signs or detecting falls. The Mobiserv system consists of an interplay between a social companion robot, wearable smart clothes and a smart home environment [19].
Finally, in the Hobbit EU FP7 project,Footnote4a socially assistive robot was developed to help seniors and old people at home by picking up objects from the floor, bring objects and provide entertainment functions. The main goal was to make older people feel safe at home via a mutual care concept, reducing the risk of falling and aiming at increased acceptability. The robot was designed to detect emergency situations and trigger an appropriate alarm. Furthermore, it provided tools to keep seniors socially connected, active and motivated to exercise [20].
As seen above, the European Union (EU) has encouraged the development of social robots by funding several projects that involve robots in human populated environments for elderly support in their 7th Framework Programme (FP7) for research. Recently additional projects have been approved in the context of Horizon 2020 (H2020) such as: ENRICHME,Footnote5GrowMeUp,Footnote6SOCRATES,Footnote7RADIO,Footnote8and STRANDS.
Footnote9Nevertheless, there are still several issues to be taken into account concerning the use of robots for elderly home care. For instance, it has been shown that robots are more likely to be accepted by humans when they are modeled to show an infant-like behavior [21]. Furthermore, different care studies [22] have identified that the combination of emotional, behavior and environmental factors play a key role in the older person’s care experience. Additionally, technological solutions that address all of these factors lower social and economic barriers towards a more universal usability [23]. Acceptability depends not only on what robots can offer to people (e.g. entertainment, status gain, practical benefits), but also on people’s intrinsic features (age, needs, gender, experience with technology, cognitive ability, education, culture, role, expectation and attitude towards robots), as well as robot intrinsic features (safety, usability, intelligence, appearance, humanness, facial expressions, size, gender, personality and adaptability) [24,25,26].
Alongside the robotics domain, there are various ways to improve monitoring in ICT. Assistive technological services have been target of keen research [27,28], having also strong support by the European Commission. In fact, the EU funded different specific research programmes, such as the Ambient Assisted Living – Joint Programme (AAL-JP). Examples include Miraculous-Life (FP7),Footnote10which aims to design, develop and evaluate an innovative user-centered Avatar based solution, attending to the older person’s daily needs and behavior changes, while they go about their normal life; CogniWin (AAL),Footnote11which targets older people in working environments by providing an innovative personalized system to support and overcome eventual aging related cognitive degradation and gradual decreasing of memory and cognitive capabilities; or DOREMI (FP7),Footnote12which targets the three main causes of premature mortality: malnutrition, sedentariness and cognitive decline, by developing a systemic solution for the elderly, able to prolong the functional and cognitive capacity by unobtrusively monitoring their daily activities, thus empowering and stimulating them so as to promote active lifestyle management and social inclusion.
Statement of ContributionsExisting service robots, such as the solutions referred in the previous section, either address less social bonding mechanisms and/or only offer pure functionality, i.e. they take on the role of a device; or the services employed by those systems utilize simple, straightforward context interpretation without taking into consideration factors like the emotional state of the older person and their behavior changes over time, which are very important in achieving high usability and acceptability of a robotic system. In addition, service robots addressing the care and support of older adults face different challenges, such as the lack of appropriate paradigms for designing home service robots that combine affective human–robot communication and adaptable service functionality, leading to low user acceptance and making it more difficult for new solutions to enter the personal support and care domain. Also, they face several concerns associated to the high costs for acquiring and maintaining these platforms. For instance, the PR2 from Willow Garage is sold for approximately 280k$, and the Care-o-Bot from Fraunhofer IPA used in the Accompany project costs around 250k$. Other less complex robots, like the Scitos models from MetraLabs, used in STRANDS, Companionable and Robot-Era projects, costs in between 20–29 k$, and the Hobbit robot is tagged at 17–20 k$. In a lower range of prices, there is the Kompaï robot from RoboSoft (Mobiserv project), costing in between 12–19 k$, and finally the SocialRobot solution, developed at IDMind, has a price tag in between 10–15 k$. A comparable platform referred is the GiraffPlus, which is sold at 12 k$. However, this is just a simple telepresence robot, with limited autonomous capabilities.
In this article, we present the development of an appealing mobile robot able to navigate in indoor environments and provide affective and advanced user–robot interaction, taking into account the capabilities and acceptance by elderly users, and the issues of size, shape, color and acoustics. We describe several multimodal services developed for the SocialRobot platform, focusing on the essentials of care provision and affordability. The system leverages a modular architecture, which enables seamless integration of new modules and capabilities. Therefore, the existing platform can be expanded with new functions, knowledge and services to continuously meet user needs. As a technological solution, this presents a clear economic benefit, able to exploit the rapid technological advances and also to cope with the changing needs of elderly people, thus avoiding becoming obsolete. The service robot proposed aims at addressing the human–robot bonding with affective human–robot communication to foster acceptance, while maintaining low complexity and cost. It is designed not to abruptly replace existing personal skills or functioning social networks of the older adult, instead it offers gradually increasing support at the time when life starts to become increasingly challenging.
Furthermore, unlike other solutions, the deployment of the platform proposed does not involve modifying the environment, or adding smart devices and monitoring sensors on the environment, or more intrusively on the senior, which may yield considerable privacy concerns. SocialRobot is especially designed to address social interaction with the elderly and personalized care to combat the typical loneliness that haunts this age group.
In sum, the key contributions, which represent the core focus of this work, consist of:A modular service robotic architecture allowing easily addition of new components, and grounded on a collaborative social community network to foster service adaptability over time.
The design of an innovative and affordable social robotic platform for advanced and useful human–robot interaction, benefiting from state-of-the art sensing and perception to address the elderly care and assisted living domain.
The development, implementation and integration of technically innovative services for interaction between seniors and the proposed social robot.
A one-week long user study on a human populated elderly care center, providing important lessons learned and opening good prospects for the development of additional and more advanced social robots in the future.
OverviewIn this work, a modular service robot architecture, following a user-driven philosophy, has been proposed. To that end, a social care community network (SoCoNet) has been developed [29] to encourage and support communication, assistance and self-management of senior citizens. SoCoNet promotes seamless connection and interaction to different people in their virtual care team (VCT) at any time, where the robotic platform acts as a form of an intermediate agent between the elderly and the social care community.
Footnote13In our user-driven paradigm, services are adaptable to dynamic parameters and benefit from the knowledge of the end users preferences and personal information. The system architecture is highly modular, combining different functions of the platform to provide different services. Therefore, we will show that this is an easily scalable solution and it has the ability to explore user preferences, abilities and habits to provide a high level service personalization.
The service robot platform developed:ahuman–robot interaction;bdocking stationOur service robot, illustrated in Fig.
2, is fully integrated in the ROS framework [30], and the software has been fully developed in the C++ programming language. ROS provides drivers for integrating commonly used sensors without needing hardware expertise, such as the Hokuyo URG-04LX-UG01 laser range finder or the Asus Xtion PRO Live RGBD camera, which reduced the overall time spent in development. Such drivers place virtually all complexity in libraries, only creating small executables, exposing library functionalities.
Complying with our user-driven philosophy, during the initial stages of the project, the technical team had several meetings with members from end user institutions, such as caregivers, workers, older adults, etc. including the care center, where the main pilot described in Sect.
7occurred. This allowed to clearly specify the user needs, develop use case scenarios, and defining the functional requirements and main design for the platform. In this way, all the ICT-based services presented in this article were decided with prior caregiver and user input, based on the initial requirement analysis stage of the project.
In the following subsections, we will overview the innovative architecture defined, the hardware and sensors included in the mobile robot platform, leaving the robot services that expose intelligent capabilities for human–robot interaction for Sect.
5.
ArchitectureDevelopment on the SocialRobot project followed the principles of a Service-Oriented Architecture (SOA), whose modularity design maximizes the benefits of multidisciplinary contributions from researchers of different areas. It is virtually impossible to identify all the older adults’ needs in advance, since their sensitive condition leads to constantly changing needs. The proposed methodology fosters services adaptability. It allows for them to continuously fit elderly specific needs efficiently and improve the quality of a service without requiring to entirely redeveloping it. Hence, the proposed strategy intends to provide a scalable framework through seamless plug and play integration. Having this in mind, we propose a hierarchical approach where complex servicing tasks are recursively broken down into simpler operations. The proposed SOA-based model is presented in Fig.
3.
Architecture overviewSoCoNet was implemented so as to provide a secure web-based virtual collaborative social community network that enables the effective administration and coordination of the user profiles and VCTs around the elderly person. SoCoNet has been designed and maintained regardless of the robotic platform used. Therefore, robot services are supported by SoCoNet towards an active and personalized assistive care. This way, it ensures a unique personalized profile of disabilities and abilities, special needs and preferences, stored in a secure database (cf. Fig.
3), thus promoting personalized care provision. Furthermore, SoCoNet supports intelligent management techniques, which dynamically adapt the content included in the database throughout the elderly aging process, enabling the update of preferences, priorities, routines and so on. SoCoNet is designed to allow easy integration of new staff and caregiver members in the future by the care center administration. In its turn, caregivers can also add new seniors under their responsibility using a web client. Through the web management interface, caregivers manage the user profiles under their responsibility, and edit the personalization features (e.g., agenda, medicine, favorite activities, emergency contact, etc.), which can be easily achieved using a PC, smartphone or tablet. Moreover, caregivers coordinate amongst themselves by assigning a main caregiver for each user, exchanging messages through the interface and adding notes.
Moving on to the remaining modules of the architecture, the hardware layer includes physical components that provide input/output resulting from the interaction of the mobile robot with the real world. The operational layer encompasses low-level methods, mainly to retrieve, parse and process data from the physical components and the intelligently managed SoCoNet database. The functional layer includes intelligent algorithms for decision-making and cognitive reasoning capabilities. The workflow engine is responsible for the interpretation of a service that the robot provides to the older person, and orchestrating a sequence of required functionalities to fulfill the service provision to the user. Finally, on top of the hierarchy is the definition of all services that the robot is expected to deliver.
To promote scalability and layer abstraction, inter-layer communication is minimized, such that it is limited to adjacent layers. This approach mitigates functional dependencies. In addition, interaction between adjacent layers makes use of a standardized set of inputs and outputs. ROS is the supporting framework located in the robotic platform. The SoCoNet uses a Microsoft SQL server and a set of Java web methods that are exposed via web services. Communication between both frameworks is ensured by SOAP-based messages and standard web communication protocols. This architecture aims to establish a clear separation between service design and low-level development.
The modular architecture described is the key to add and adapt distinct decoupled services on the robot. Its design, even allows the replication and testing of services on other robots, as it is robot- and hardware-agnostic, as long as inputs and outputs can be forwarded to alternative sensors and/or actuators. On one hand, to provide an additional service or adapt an existing one, the developer needs to program the functionality using a predefined structure, specifying its inputs/outpus (top layer of the architecture), to enable appropriate replies and actions, when they are requested by the workflow engine (second layer), as a result of a user-triggered event. On the other hand, caregivers, and more generally the virtual care team of the older adult, may change the preferences, options and/or characteristics related to the older adult using the SoCoNet web-based interface, thus manipulating a particular database, which is the source of personalized information for the robot. For instance, the caregivers may change the emergency contact of an older adult in the SocoNet, and the robot will take this information into account when needed for the next time.
Hardware and SensorsServices are actively provided by an appealing and affordable mobile robot platform [31]. Illustrated in Figs.
4,5, the platform is a two-wheel robotic base, with a structured body and robotic head with several integrated sensors. The robot’s height is 125 cm in order to be socially acceptable and dynamically stable. This enables to fulfill the goal of promoting the interaction between the elderly, family, friends, and caregivers supported by the robotic platform and the SoCoNet.
SocialRobot platform: internal viewPlatform hardware, sensors and devicesBesides basic physical safety of the people interacting with the robot, safety concerns are directly related to ethics issues and they are of paramount importance in social environments. Safety measures are embedded at both hardware and software levels. Unexpected collisions can be detected at hardware level, triggered by the robot’s bumpers, and bypass all decisions levels to stop the robot. Another important issue is the cost of the platform. The project offers a solution that can fulfill the initially set project requirements and at the same time minimize the price of the final technological platform to ease the process of commercial exploitation.
In terms of sensors and devices, the robot is endowed with a Full HDMicrosoft LifeCam StudioCamera; a RGBDAsus Xtion PRO Livecamera, which also includes an infrared sensor and two microphones; a programmable array of LEDs forming the SocialRobot’s face; audio amplifier and stereo sound speakers (in the robot’s ears); a\(10''\)touch screen for user interaction; temperature and humidity sensors inside the robot body; capacitive sensors to detect if a person is touching the robot (in the back); anMPU6050inertial measurement unit (IMU) inside the robot provides the estimation of orientation as well as accelerometer, gyroscope and compass data; 12Maxbotix EZ4ultrasonic sensors around the robot to detect proximity of obstacles; anHokuyo URG-04LX-UG01Laser Range Finder for navigation and mapping; omnidirectional bumpers; and two differential drive wheels (together with two omnidirectional wheels on the back).
The robot is also equipped with amini-ITXcomputer board with an i7 quad-core processor, RAM, SSD and several peripherals (USB ports, Ethernet ports, audio ports, etc). In addition, several electronic boards were installed for sensor management and motor control. Finally, the robot is powered by three 12 V, 14 Ah LiFePO4 batteries, providing autonomy of up to 5 h in continuous operation.
A specific deliverable of the SocialRobot project [32] analyzes the elderly user needs regarding the main quotidian issues that they face, which compromise their independent living. Focus groups, structured interviews and questionnaires have been applied making use of different methods, ranging from evaluation of the conditions and well-being of the elderly, interviews and questionnaires with the elderly, their family and friends, public health workers and care professional personnel with regards to socialization needs, technology and independence. These needs and requirements were then translated into technical specifications that were considered during the design and development of the SocialRobot system. The early stages of the design process were paper-based, using for example paper mock-ups, and the later stages were based on increasingly working prototypes that were presented to the users and care staff [33], following a compilation of fundamental principles for designing user interfaces, especially for elderly users, and guidelines for documentation of common interface standards. As such, end users were involved in the platform design stage, and their suggestions related to the size, shape and the color of the robot were taken into account, thus leading to the appealing robot proposed. The rationale behind the technical solutions chosen for the platform considered other important aspects such as safety, cost, suitability for HRI, autonomy for long deployments, wireless communication and processing abilities, and adequate sensing and perception modalities. In the inclusion of sensors and hardware listed above, relevant aspects such as their features, market availability, ROS-ready drivers, code reuse, and technical maturity were also considered.
Service Provision and Robot CapabilitiesIn this section, we describe the developed services that are embedded in the robotic platform for elderly care and socialization via multimodal interaction [34]. Given that the whole system is the result of an integration of several different modules, when the robot is under operation, it checks which components are plugged in and run their respective driver, which then become responsible for publishing sensor data. The services described below not only consider sensor data, but also exploit user information and environment knowledge to trigger different robot behaviors and functionalities.
Robot Navigation and PerceptionThe robot is capable of navigating autonomously by following the approach presented in [10]. We are using a 2D occupancy grid map, derived from the output of a Rao-Blackwellized Particle Filter (RBPF) Simultaneous Localization and Mapping (SLAM) algorithm [35]. This map is used both for motion planning and localization. This way, given any physically reachable goal, the robot should be able to autonomously navigate to that goal, avoiding collisions with obstacles on the way by following a series of steps, considering data from sensors and localization information.
Robot navigating in an indoor scenario. Green cones correspond to sonar readings, red dots to laser range readings, black points to 3D voxels, and the depth image of the Asus RGBD sensor can also be seen in front of the robot. The projected obstacles (in purple/blue/yellow) correspond to the local obstacle costmap around the robot. (Color figure online)Detection of a generic person’s face, and extraction of the coordinates of the person’s head in 3D space. This is crucial for the robot to navigate and safely approach a personBeing commonly initialized with a grid map of the environment, the robot is aware of any unexpected obstacle by perceiving them with its range sensors, namely: a 12-sonar array, a forward-facing laser range finder and the Asus RGBD camera. The depth information acquired with the Asus Xtion PRO Live sensor, enables us to also consider obstacles in 3D, in the form of voxels, as illustrated in Fig.
6. Therefore, the robot is not limited to the scanning plane of the laser and the low-resolution ranging of sonars. These complementary sensors allow for robust navigation of the mobile robot platform in an indoor environment.
The navigation algorithm includes several interesting features. For instance, Random Sample Consensus (RANSAC) is applied to filter out Light Detection And Ranging (LIDAR) readings that are invalid due to hardware limitations, such as false positives generated by veiling effects. Also, the voxel costmap, which is initialized with the static map (if available), is used to represent obstacle data at different heights and the most recent sensor data, in order to maintain an updated view of the robot’s local and global environment. Inflation is performed in 2D to propagate costs from obstacles out to a specified radius in order to conservatively avoid collisions.
The global planner uses an A* algorithm that plans in configuration space computed during obstacle inflation in the costmap, not taking into account the dynamics or the kinematics of the robot, which are considered instead by the local planner, which generates velocity commands for the robot, safely moving it towards a goal. The planner cost function combines distance to obstacles, distance to the path produced by the global planner, and the speed at which the robot travels. While moving, as more information about the world is acquired, the robot may re-plan in order to avoid collisions with obstacles.
Regarding the local motion planner, the robot uses the Dynamic Window approach [36], as tests shown its superior performance considering the platform kinematics, steering system and configuration over the Trajectory Rollout approach [37]. The planner includes a few recovery behaviors that can be performed, e.g. due to entrapment. The robot will perform increasingly aggressive behaviors to clear out space around it and check if the goal is feasible, eventually giving up in case the goal is not feasible without colliding with obstacles. For localization, we make use of the Adaptive Monte Carlo Localization (AMCL) implementation, which is a probabilistic localization system that uses a particle filter to track the pose of a robot against a known map [38].
These navigation capabilities enable the robot to perform autonomous monitoring within an indoor environment. This works similar to a patrolling behavior [39], where the robot is given a set of way points to follow consecutively, while doing other tasks in parallel, such as detecting and approaching people or detecting anomalous situations. In addition, the robot constantly checks its battery status and, when reaching a minimum threshold, the robot is able to drive towards its charging station. In this process, the robot moves towards a goal placed directly in front of the charging station, and carefully drives backwards to dock, controlling at the same time its backwards distance with the rear-facing sonar. When the robot docks (see Fig.
2), it automatically acknowledges that it is charging via its low-level driver. This autonomous behavior enables the robot to be in operation during long-term periods.
People Detection and Face RecognitionOne of the key features within a social robot is to detect and recognize people. Detection consists in identifying the presence of generic people in the robot’s field of vision, while recognition assumes higher intelligence, as the robot is supposed to acknowledge a specific person, thus being aware of this person’s profile during the interaction so as to provide a personalized service. In this subsection, we describe how the robot detects people and recognizes known faces.
For people detection, the robot actively looks for the eventual presence of people by visually detecting possible faces based on a cascade of Haar-like features [40] to obtain an initial set of detections. Afterwards, it prunes false positives using depth information from the RGBD camera. Namely, the depth information is used to predict the real-world size of the detected face, which is then preserved as a true face detection only if the size is realistic for a human face or if the detection contains sufficient depth information. This removes the majority of false positives given by the detector. The 3D position of the person’s head in the depth sensor frame of reference can be extracted from the depth information provided by the RGBD camera, as illustrated in Fig.
7. The detection of a generic person and extraction of its coordinates in 3D space enables the robot to safely navigate closer to the unknown person to approach him/her and start an interaction, opening the possibility to perform several different types of interaction, as seen in Sect.
5.3.
The process for face recognition has a few key differences from the one described for people detection. For identification of a specific person, we assume that a training dataset with the person’s face has been created previously to generate an eigenfaces database that is stored internally by the software. These eigenfaces correspond to a set of eigenvectors that are derived from the covariance matrix of the probability distribution over the vector space of face images used for face recognition. These are generated by performing a principal component analysis (PCA) on a large set of images depicting different human faces. This way, using a Haar cascade classifier, consisting of a machine learning based approach where a cascade function is trained from several images, a person’s face can be recognized in real-time due to its unique features (cf. Fig.
9c). The ability to identify a person enables the system to trigger a vast possibility of personalized services, such as those addressed in Sect.
5.4.
InteractionAfter approaching the person, the robot is expected to start an interaction. This is done via audio. The robot greets and inquires the identified person using the embedded stereo speakers, and then extracts emotion from the verbal reply via the microphones on the Asus Xtion PRO Live sensor. Real-time emotion and affect recognition is possible using the open source emotion and affect recognition (openEAR) framework [41]. This is an efficient, multi-threaded, real-time framework providing an extensible, platform-independent feature extractor implemented in C++, with pre-trained models on six well-known emotion databases that are ready-to-use for online emotion and affect recognition, and supporting scripts for model building, evaluation, and visualization. Leveraging the efficient low-level audio feature extraction algorithms implemented in C++, it applies various statistical functionals and transformations to those features (e.g. extract signal energy, FFT-spectrum, Mel-Spectrum, pitch, voice quality, etc.) to classify emotions using Support-Vector Machines with polynomial kernel function of degree 1, resulting in emotions such as anger, fear, happiness, disgust, boredom, sadness and neutral.
Besides emotion recognition, the robot is able to detect a limited set of simple words through speech. Ideally, the robot should incorporate an array of several non-collinear microphones for superior robust speech recognition. However, it is limited to the two collinear microphones incorporated in the Asus Xtion PRO Live sensor. In order to recognize speech, we make use of PocketSphinx, a lightweight speaker-independent speech recognition engine. It is an open-source framework featuring feasibility of continuous speech and large vocabulary recognition. It makes use of hidden Markov acoustic models (HMMs) with trained data to learn the best parameters, and an n-gram statistical language model. Additionally, to formulate verbal replies the robot uses predefined text-to-speech recordings to interact with the user. The above features were integrated in the robot via appropriate ROS wrappers.
In the short-term future, we intend to incorporate intelligent dialogue management in our robotic system based on the work described in [42], and enhance the emotion recognition system by also extracting vision features such as facial points or optical flow measures to be fused with audio features.
Data Retrieval and PersonalizationOne of the key modules of our system is the SoCoNet. As mentioned before, this is an elderly centered web-based collaborative social community network that enables the effective administration, management and coordination of the user profile and VCTs around the elderly person. Additionally, it provides a knowledge repository containing organized personal information, including user preferences, events and medicine calendar. By connecting to the SoCoNet via web services, the robot is able to securely retrieve particular user information, and provide personalized care when it recognizes a specific person.
Examples of developed features include reminding the user to take his/her medicine during interaction or fulfilling household tasks; doing appropriate physical activity based on the individual’s actual physical and psychological status; suggesting the user to carry out a preferred activity or ingesting a specific meal; and reminding the person to take a given accessory before carrying out an activity. Furthermore, the robot provides a Skype interface (cf. Fig.
9e). Skype is a telecommunications application software, enabling the robot to call the user’s relatives, emergency contacts or caregivers. As seen in Sect.
2, telepresence is a highly required feature, since it alleviates the anxiety and worry that senior citizens often feel.
Since the elderly fragile condition leads to constantly changing needs, SoCoNet provides a front end for formal and informal caregivers to add, remove and modify the user information. This allows the robot to adapt to the most recent changes.
InterfacingThe platform developed incorporates five capacitive sensors, which allows for the robot to perceive if a person is touching its back or torso area. This type of feedback results in affective interaction between the person and the robot. Moreover, a touchscreen has been embedded in the chest area of the robot for user interface. A simple QT-based GUI has been developed to confirm the answers provided by users to the robot and yield error-free interaction. The advantages of a user touch interface include overcoming social isolation by facilitating the access to phone and video conversation, daily shopping, social life, public services, displaying information and easy access over the internet. In Fig.
8we illustrate the touch-based GUI developed for the pilot, which is described in detail in Sect.
7.
QT-based user touch interface running on the SocialRobotIt is noteworty that the encapsulation of the abovementioned services and robot capabilities in our innovative modular service robot architecture resulted in a significant integration effort. Moreover, while some of the components were adapted by us to fit the objectives of the project (e.g., navigation, face detection, speech recognition), we have also proposed novel contributions in this context, of which we highlight: the automatic docking behavior when running out of battery, correctly approaching a person while maintaining a socially acceptable distance, accessing and retrieving user information through the SoCoNet to foster personalized interactions, and the implementation of several carefully designed services (e.g., displaying the users’ agenda and other information, suggest activities, provide a Skype interface or allowing the user to take pictures) in a new user touch-based graphical interface.
The motivation for the services chosen to be integrated in the platform, followed several guidelines such as: prioritization of user needs, reliability, availability, open source nature, and proven track record in previous initiatives. All components were surveyed and compared against other solutions before being chosen for integration in the SocialRobot system.
Integration and Initial ValidationUnlike other service robot solutions, the SocialRobot architecture offers an intuitive XML-based service orchestration [43], minimizing the need for expert developer intervention. The top-layer service module is designed so as to allow non developers to define new services by themselves. This is done through XML format descriptions, which are comprised by a sequence of functional modules and parameters such as execution order.
This way, by applying the proposed integration architecture, a service robot can for example search actively for an elderly person to assess his/her status (feeling sad, bored, etc.) and perform specific actions in a personalized way, according to his/her preferences. In order to do so, the workflow engine (cf. Sect.
4.1) is responsible to interpret the XML description of the service called, assess its integrity (e.g.,guarantee the required models are running), and execute any necessary algorithm from the functional layer of the architecture to provide the requested service. A clear and simple example of an XML service definition is given below.
Being fully integrated in ROS with several available functionalities, the robot is capable of performing different tasks, such as indoor navigation and mapping [44], and provide affective and advanced user–robotic interaction, taking into account the needs of the elderly users. Technically speaking, the robot capabilities, as those referred in the previous section, are exposed to the workflow engine in the form of ROS Services.
Footnote14After integration and extensive testing of the different modules of the system, a preliminary validation stage of the integrated services has been conducted. End user involvement has been a priority ever since the beginning of the project, namely in the requirement specification stage, system design and prototype testing. During the development phase, we invited care center staff, caregivers and elderly users for a set of informal interactive sessions, where the robot displayed basic functionality, and we analyzed how the users reacted and interacted with the robot. Initial feedback showed positive end user acceptance to the support of the SocialRobot platform, which was found friendly and fun to interact with [43]. These findings were obtained by observing their engagement when interacting with the robot, via conversations and asking the honest opinion of the care center staff and the elderly. Therefore, a preliminary test scenario deemed as useful for the end users is discussed in this section.
Having in mind that the system should provide ICT-based personalized services such as reminders and assistance, recognition of abnormal behavior and alerting, suggestions and guidance for daily activities, the following scenario was defined:Robot enters a specific room (navigate_to).
Robot approaches a person (approach_person).
Robot recognizes person (face_recognition).
Robot inquires the person (speech_synthesis).
Robot extracts emotion from response (emotion recognition).
Robot suggests activity according to the emotional state and personal preferences (soconet_call: suggest activity), e.g. call a friend or a caregiver (social_connection).
After completion, the robot says goodbye (speech_synthesis), and visits other rooms (monitoring).
The presentation of this scenario aimed to attract both research and industrial stakeholders, and disseminate the project’s results at an European and International level. Therefore, a video of the experiments was prepared.
Footnote15Important steps of the scenario described above are presented in Fig.
9. In this scenario, the robot is interacting with project fellows in a company office.
Main steps of the experimental scenario defined.
aRobot entering in the room.
bRobot approaching an unidentified person.
cRecognition of a person’s face.
dRobot interacting with a known person.
eSocial connection with a friend via Skype.
fRobot leaving the roomPreliminary results have shown that the robot is able to properly navigate indoors, even in tight spaces using its range sensors (e.g. when it enters the room’s door as shown in Fig.
9a), and leveraging the environment’s knowledge, which was mapped by the robota priori. After entering the room, the robot actively looks for the eventual presence of people by visually detecting possible faces and using depth information from the RGBD camera to prune false positives. The 3D position of the person in the depth sensor frame of reference is extracted, and a goal is sent to the navigation software for the robot to move closer and face the unknown person (Fig.
9b). Results have shown the reliability of the person detection software, since even in low lightning condition the robot is able to approach a person thanks to the available depth information. In the next step, the face recognition process to identify the person searches the training dataset to identify the person’s face, which is recognized in real-time due to its unique features (Fig.
9c). After greeting and inquiring the identified person, the robot extracts emotion from his verbal reply (Fig.
9d). In the scenario presented, two different replies trigger different actions. In the first example, the robot recognizes that the user is feelingsadand suggests him to interact with a friend on Skype (Fig.
9e). This is based on the VCT members of the user and his/her contacts, which are retrieved from the SoCoNet. In the second example, the robot recognizes that the user is feelingboredand based on the user agenda and his preferences stored in the SoCoNet, the robot suggests him to play cards with a group of friends. Finally, after the interaction is complete the robot bids farewell and leaves the room (Fig.
9f) to resume its monitoring task.
The performance of the robot, especially regarding detection of human characteristics was compared against the human perception of a third-person bystander. We verified if the robot could correctly identify the actions of the user with two binary outcomes: right or wrong. The scenario presented is the result of the technical development carried out over approximately a 1-year period, where simple adjustments and adaptations were done to the software to increase its robustness and reliability. By running each scenario 20 times, we were able to obtain on average, less than 5% of misdetections.
The semi-controlled typical scenario presented takes around 80–100 s to finish, and consisted of limited sound sources, a structured layout and adequate lightning conditions. In the final testbed scenario presented in the next section, we intend to verify whether the obtained success can be transferred when operating in uncontrolled real world environments.
Real World Experiment in a Human Populated Care CenterA pilot demo for validation of the SocialRobot platform took place at the premises of the Zuyderland Hoogstaete care center in Sittard, the Netherlands, during one week (5 business days). In order to set up and deploy the platform in the pilot scenario, it was necessary to firstly map the building using a Simultaneous Localization and Mapping (SLAM) approach. A picture of the main hall of the Hoogstaete building, where the pilot took place is shown in Fig.
10, and the map of the building generated is displayed in Fig.
11.
Picture of the main hall at the Zuyderland Hoogstaete care center buildingMap of the Zuyderland Hoogstaete care center building. A few labels were added for visualization purposesSocial Robot, which was baptized as “Tom” by the Zuyderland care center staff team, was engaged in a continuous monitoring task in the large entrance hall of the care center environment. Along its navigation route, the robot visited specific places, and looked for people to greet and interact with. An overview of the sequence of steps that describe the robot’s behavior is illustrated in Fig.
12.
Overview of steps and actions undertook by the robot during the demo at the care centerDifferent output expressions for robotic emotional interactionAccording to recognized HRI studies, the most successful way for a robot to attract human interest is for the robot to demonstrate awareness of human presence [45]. By deliberately facing a person and saying “hello”, the elderly people were almost always surprised, as this is a typical way in which humans start a social interaction, and that was exactly what the robot would do. Thus, if a person was detected up to a given proximity range of 1.5 m, SocialRobot would turn to that person, display an open smile, stop and greet her/him (by saying “hello”). The robot would promote the interaction by presenting a blinking message in the touch screen (saying “touch me here”), so that the user understood that the robot was waiting for a touch.
If the user touched the robot’s touchscreen, then it would ask the person “what can I do for you today?”. The person could choose from within different options displayed in the robot’s touchscreen via the simple and intuitive user interface (cf. Fig.
8). One of the options included simply to ask the robot to go away. However, if the person decides to engage and interact with the robot, it would propose to start activities like doing a skype call, suggest a preferred activity, take a picture or display an agenda. The robot would confirm the option chosen by the person, by recognizing through speech a “Yes” or “No” answer. Furthermore, each option would result in a different robot expression (see Fig.
13).
When the robot was told to go away, it would say “Bye bye! see you soon!” and would continue to wander around the building. If the user did not touch the robot at all, it would also continue in wander mode and look for someone else to interact with. While wandering (or after a user interaction), the robot would eventually detect when it was running out of battery, and it would automatically dock into the charging station. The list of individual services tested in the final project’s demo is shown in Table1.
With the one-week long pilot that was hosted by the Zuyderland care center institution, we were able to go one step forward than in the lab scenario by deploying the robot in a real world environment with older adults that are not acquainted with robots, and validating the integration of the SocialRobot system within a more demanding environment.
During the setting up of the pilot, we were able to prepare the robot deployment by mapping the building, defining the docking station location, do some preliminary tests and calibrations regarding hardware and software functionalities, and in cooperation with the Zuyderland staff, we were able to discuss and introduce a few modifications in the demo scenario to fit users’ will. This included limiting the robot’s maximum speed so as to avoid taking the elderly by surprise, and the modification of dutch wording in the user interface, due to cultural differences and to provide a more pleasant interaction with the elderly. For instance, initially the robot would display in its touchscreen a “Touch Me” message while wondering. However, in general the visitors and users would approach the robot and touch it in any point of its physical body, instead of touching it directly in the touchscreen. By modifying the sentence to “Touch Me Here”, the issue was quickly solved.
System Performance and Users’ FeedbackThe pilot described in the previous section ran along 5 working days from 9:00 AM to 5:00 PM in the main hall of the Zuyderland care center. The care center consists of 94 apartments, some of which occupied by elderly couples, and there are hundreds of people visiting the care center every day, such as residents, other elderly people from the independent residential blocks nearby, visitors, as well as caregivers and other staff in the center. Being in a common area, near the main hall of the center and the cafeteria, the robot inevitably caught the attention of most people present in the building. Nevertheless, it is not possible to exactly quantify the number of people who may have seen the robot.
Researchers were close to the robot mostly in the beginning of the week to set the demo up, clarify the questions of the staff and elderly people, and overview the pilots. However, after this initial stage, the robot was left wandering alone in the main hall, and researchers only observed from a safe distance, 15–20 m away from the main hall, in a position where they could see the whole operation scenario, intervene timely if necessary, while being completely unnoticed to the participants, so as to minimize their influence on the interaction between humans and the robot, thus not affecting the results.
SocialRobot wondering in the care center environment. Video Available at:https://www.youtube.com/watch?v=Zb_VI7oz7owDuring the pilot, the researchers sporadically took notes, recorded videos, took pictures, received feedback from the participants after interacting with the robot, explained the project philosophy and interaction scenarios to distinguished guests, directors and staff from the care center, and kept an attentive eye on the technical functionality of the robot.
SocialRobot platform interacting with people in the care center Environment. Some seniors have been anonymized for privacy protection reasonsSocialRobot platform interacting with people in the care center environment. Some seniors have been anonymized for privacy protection reasonsWe estimate that, the robot was visited and appreciated at close sight by around 250–300 people, from which around 100 individuals, including seniors, caregivers and visitors, have actually interacted directly with it, possibly repeatedly, according to our logs. In Fig.
14, we illustrate the robot navigating within the facilities of the care center environment, and in Figs.
15and16, we show several pictures took during the pilot operation.
From the technical point of view, there were no major issues during the pilot. The robot was able to safely navigate without colliding with known and with unexpected obstacles, there were no major hardware failures, software crashes, etc., which demonstrated the reliability and robustness of the platform, and the careful preparation of the pilot before the deployment of the robot in the care center. People detection, user interface, speech synthesis, automatic docking, taking pictures, displaying agendas, suggestions and robot expressions revealed no issues at all. As for the Skype interface, there were minor issues in some areas of the environment where the robot had a poor network connection, which resulted in some failed calls. Unfortunately this issue was out of our control. Another minor issue was related to the speech recognition system that would not always return the correct “Yes” or “No” recognition (adjusted to “Ja” and “Nee” in Dutch). This was mitigated by asking the users via the GUI to confirm their reply. We logged all the answers in the robot, and results showed a 65.93% of speech recognition accuracy. This result can be explained by four main factors: (i) the robot was wondering in a noisy area, where several sound sources were present; (ii) people usually approached the robot in groups and would talk at the same time to the robot; (iii) we were limited to the two collinear microphones of the Asus Xtion RGBD sensor; (iv) PocketSphinx does not support dutch directly, and is no longer maintained, therefore it is not the best solution for speech recognition. We are currently integrating the Google Speech Recognition API in the robot to overcome the aforementioned issue.
The reaction from the care center residents, staff and visitors was generally positive. Most of them instantly smiled when seeing and interacting with the robot, and complemented the robot’s appearance and actions. It was also clear from their body language that the robot was extremely likable and they were having fun interacting with it, as evidenced later on (e.g. Q18 of the questionnaire, and the analysis of the pictures taken by the robot). Moreover, all the staff and caregivers, which we have talked to, considered the robot as a good influence on the residents, giving them an overall positive mood. While the vast majority of people were curious and wanted to interact with the robot, it must also be said that a minority of people were not comfortable with the presence of the robot and would avoid it, these included residents and visitors. From these very specific group, some elderly people would ignore it, and an elderly male resident actually expressed his discomfort with the presence of the robot, due to its beliefs and reluctance to adopt new technologies. Moreover, a visitor immediately rejected the robot and considered that it had no use for his parents, and did not see the point of the robot being there. Evidently, this group of people did not interact with the robot at all.
Over the course of the week, we observed some changes in the attitude towards the robot for people who repeatedly saw or interacted with the robot. The novelty effect slowly faded, and people also became more acquainted with the presence of the robot. We believe that this had an overall positive effect, as users started to interact with the robot by themselves and without asking for help from the staff, and in the second and third time, i.e. in the following days, people would try different options leading to different interaction scenarios, as described previously. The staff and some of the residents started to develop a relationship with the robot, even naming the robot and/or addressing the robot as if it were a baby.
During the demonstration, with the help of the care center’s staff, questionnaires were handed out in the Dutch language for users to fill after interacting with the robot, typically for in between 1 minute and 30 seconds to 5 minutes. There was no systematic way of choosing the participants, and people were asked to fill the questionnaires, independently of liking or not the robot (we were not aware of this, most of the time). The translated english version can be found in “Appendix A”: User Questionnaires (English Version). These questionnaires enabled us to receive valuable user feedback on the usability, appearance, interaction, satisfaction and their expectations about the robot. A total of 30 users filled out the questionnaires, from which 23 answered the optional qualitative questions (Q27–Q30).
A summary of the questionnaire results is presented in Table2. Therein, the quantitative questions are presented, with average scores from 1 to 10. In italic, we have highlighted the replies to questions with average score above 8.0, and in bold we highlight replies with average score below 6.0. Questionnaires clearly show that users found the robot useful (Q2), friendly (Q18), safe (Q20), fun (Q23) and non-invasive (Q24). The users believe that the robot could help them to become more active (Q11), i.e. participate in more activities, thus becoming more sociable. More importantly, an excellent indicator is that users assigned an average score of 8.07 to the performance of the robot during the demo (Q26).
Examples of pictures taken by the robot camera while interacting with different people. Note that most elderly were omitted to protect their privacyResults show that users have rated the majority of the robot’s parameters (60%) in between 7.0 and 8.0. Within this group of parameters, we would like to highlight that users found the robot easy (Q3) and simple (Q9) to use, it makes them feel happier (Q14) and less concerned (Q15), and they found the robot intelligent (Q19) as well as respectful of their wishes (Q25).
On the other hand, on average the users feel that the robot is more machine-like than human-like (Q16). Surprisingly enough and contrarily to what previous studies show, this did not seem to affect the likeability of the robot (Q18). Additionally, the animacy of the robot was rated below 6.0 (Q17). This means that users did not consider the robot particularly lively, finding it somewhat stagnant. This kind of feedback is particularly important to take into consideration in the future so as to perform specific modifications in the platform’s appearance and behavior in order to raise this parameter rate in a future validation action. Despite these two parameters being rated below 6.0, it is also interesting to verify that they obtained the higher standard deviation, meaning that the opinions provided are spread out over a wider range of values than in other questions.
Analyzing now the qualitative questions (Q27–Q30), in Table3we provide a summary of the answers concerning what the users most liked about the robot (Q27), and liked the least (Q28).
The outcome of the qualitative questions confirms the quantitative results provided before. In a sample of 23 users, who answered the qualitative questions, 11 considered the robot kind, friendly or accessible, 5 indicated that the robot provides clear answers, 14 of these people liked the robot’s looks, movement and interaction, and 20 found the robot to be useful. Seven users also referred that the robot should have arms so as to be more human-like. In a future prototype it would be interesting to add them to the robot with a minimum degree of functionality and evaluate the results. It was also pointed out by 5 users that the camera of the robot is at excessively high height, especially for seniors in wheelchairs (cf. Fig.
17, top left picture). There were also minor complains by 6 users regarding the screen visibility, in terms of displaying small letters and visualization at greater viewing angles, and 14 users would like the robot to have even more advanced interaction, e.g. through speech and dialogue. All this information is extremely valuable and will guide the development of the SocialRobot platform before reaching its final version in the market.
Below, we list the main user suggestions and their expectations about an upcoming robot prototype (Q29):Add arms and use the robot to help carrying things.
Play music (e.g. playlist with songs) and TV.
Conduct activities together with the elderly (e.g. memory training).
Sing songs, play games, and say additional friendly sentences.
Follow the person or drive toward him/her when called by voice.
Conclusions and Lessons LearnedAn overview of the SocialRobot framework and the deployment of the platform in a real world pilot has been presented in this article. The project places emphasis in supporting the elderly to maintain their self-esteem in managing the daily routine by addressing their security, privacy, safety and autonomy. The system provides a modular designed platform that also supports caregivers, both family members, friends and therapists, in their daily tasks. The solution proposed seeks a balance between addressing the opportunities and challenges of an aging society rather than seeing the increase in longevity as a burden and a threat. We focus on the ways in which lifestyle, attitude, and skills can be supported and changed to create a better quality of life for older people.
In this work, innovation emerges from the human–robot interaction perspective (e.g. emotion and face recognition, and advanced interaction) the robotic perspective (e.g. robot design and autonomous behavior); and the social care model perspective (e.g. an elderly practice-oriented model integrating new types of social interaction and robotic monitoring).
Still, as the robot development is an ongoing effort, in the future we intend to explore the social care model perspective (e.g. additional wellness services) and the software perspective (e.g. adaptation to daily routine occurrences as elderly age) at a greater depth, by moving the robot from a common area of the care center to the elderly residences, and conducting user studies over larger periods than the one reported.
Furthermore, we have described the integration of the SocialRobot components, and turned our attention to the validation of the system and deployment process. Results confirm the effectiveness of the integration architecture defined and the potential of the system to deliver care and wellness services to the elderly. Moreover, the service robot deployment yielded propitious reactions from the care center residents, which have provided their valuable feedback on the usability, appearance, interaction and satisfaction of the robot, while performing a week-long pilot in the care center facilities.
The presence of the robot in the premises of Zuyderland aroused people’s curiosity and made them apparently happier. This cue was not only extracted from the questionnaire results, but also by inspecting the pictures taken from the robot’s point of view, e.g. Fig.
17. In a total of 169 pictures, and excluding those without people in the photo (8) and those where people were not looking at the robot during the shot (17), the participants were openly smiling in 118 of them (81.9%), and looking seriously or neutral in 26 of them (18.1%).
The robot was deemed as useful, friendly, kind, accessible, fun, non-invasive and safe. A key aspect regarding safety is that at any instance if the user feels uncomfortable with the robot, it may be stopped by simply pressing the red button located at the platform’s back. We plan to further evaluate to what extent the users feel that they are always in control of the operations.
Seniors generally appreciated the robot’s looks and appearance, movement and interaction. Nevertheless, there are a few issues to be improved in the future to meet the expectations of the users. Feedback from the users (Q16, Q28, Q29) suggests that the robot could be more human-like, e.g. by adding arms to it. Additionally, despite the low score provided to animacy (Q17), the users did not suggest specifically that the robot should be more animate in the qualitative questions Q28 and Q29. Therefore, it remains uncertain if increasing the animacy while interacting is something that the elderly users necessarily look for in a social robot. Still, the evaluation questionnaires allowed us to learn immensely about the impact, design, and expectations of the elderly towards a service robot operating in a real-world care center scenario.
There was also an issue that we did not consider when designing the user questionnaire: all questions are positively valenced. This may have an impact on evaluations, as this type of questionnaires are more likely to receive increased evaluations, thus being a limitation of the work presented. In the future, we will interleave positive and negative statements in the questionnaire.
Additional room for improvement in our work includes: conducting a systematic analysis to further support the claims of positive evaluation and acceptance of the robot, adding more services with proved usability for elderly users, encompassing some of the additional features reported by users in the robot without compromising the cost of the platform, extending the interaction period between users and the robot, thus allowing to move the robot into the elderly residences for a more personalized experience and developing a more lasting relationship. Moreover, a possible way to quantify the influence of the novelty effect of the robots on the participants, would be to hand out questionnaires after a first interaction with the robot, and in the end of the week, the participants would answer a similar questionnaire to understand how their feelings towards the robot evolved. This will also be a matter for deeper study in a future work.
Three key general points derived from the experience of the SocialRobot project are:(i)fully achieving the user’s expectations is a huge challenge, not only in our case but for robotics in general;(ii)technical development and innovation is crucial, however appearance and first impression for users is ultimately what leads to acceptance and adoption;(iii)end user and stakeholder’s feedback is the driving force towards the development of a commercially acceptable solution.
With this work, the consortium promoted an important dissemination action of the SocialRobot project with the robot working as a fully autonomous system, interacting with elderly, caregivers and visitors. Not only do the outcomes provide interesting perspectives, but they also allowed project partners to disseminate material that illustrates a working system deployed in a real world human populated environment. This is of incalculable value, seeing as the system is not limited to a prototype working in a lab environment, but has also been validated and deployed in the real world with real people that know little about robots. In sum, this pilot is a step forward towards the exploitation and commercialization of the platform, fostering future cooperation and partnerships.
In the future, we also plan to develop additional robot services according to the research and industrial stakeholders needs, and further explore the project’s results so as to define a penetration strategy in the AAL and elderly care market.
Noteshttp://mrl.isr.uc.pt/projects/socialrobot.
http://www.giraffplus.eu.
http://www.robot-era.eu.
http://hobbit.acin.tuwien.ac.at.
http://www.enrichme.eu.
http://www.growmeup.eu.
http://www.socrates-project.eu.
http://www.radio-project.eu.
http://strands.acin.tuwien.ac.at.
http://miraculous-life.eu.
http://cogniwin.eu.
http://doremi-fp7.eu.
For more details on the SoCoNet, please visit:http://www.citard-serv.com/products-soconet.php.
In ROS, a service is the way of implementing a synchronized request–reply communication. A providing ROS node (application) offers a service, and a client calls the service by sending the request message and awaiting the reply.
https://www.youtube.com/watch?v=If2FRVdR0K0&hd=1.
ReferencesEuropean Commission (2015) The 2015 Ageing Report: underlying assumptions and projection methodologies, Joint Report prepared by the European Commission (DG ECFIN) and the Economic Policy Committee (AWG), Directorate-General for Economic and Financial Affairs, Brussels, BelgiumPortugal D, Trindade P, Christodoulou E, Samaras G, Dias J (2015) On the development of a service robot for social interaction with the elderly. In: Proceeedings of the IET international conference on technologies for active and assisted living (TechAAL 2015), Kingston, London, UKHagen C (1998) The rancho levels of cognitive functioning (revised), 3rd Edn.
http://blogs.shu.edu/wp-content/blogs.dir/369/files/2013/11/Rancho-Level1.pdf. Accessed 28 May 2018Breazeal C (2002) Designing sociable robots. MIT Press, CambridgeMATHGoogle ScholarFong T, Nourbakhsh I, Dautenhahn K (2003) A survey of socially interactive robots. Robot Auton Syst 42(3):143–166ArticleMATHGoogle ScholarRoy N, Baltus G, Fox D, Gemperle F, Goetz J, Hirsch T, Margaritis D, Montemerlo M, Pineau J, Schulte J, Thrun S (2000) Towards personal service robots for the elderly. In: Workshop on interactive robots and entertainment (WIRE 2000), Pittsburgh, PA, USAWada K, Shibata T, Saito T, Tanie K (2004) Effects of robot-assisted activity for elderly people and nurses at a day service center. Proc IEEE 92(11):1780–1788ArticleGoogle ScholarGoodrich MA, Schults AC (2007) Human–robot interaction: a survey. Found Trends Hum–Comput Interact 1(3):203–275ArticleGoogle ScholarSales FF, Portugal D, Rocha RP (2014) Real-time people detection and mapping system for a mobile robot using a RGB-D sensor. In: Proceedings of the 11th international conference on informatics in control, automation and robotics (ICINCO 2014), Vienna, AustriaMarder-Eppstein E, Berger E, Foote T, Gerkey B, Konolige K (2010) The office marathon: robust navigation in an indoor office environment. In: Proceedings of the 2010 IEEE international conference on robotics and automation (ICRA 2010), Anchorage, Alaska, pp 300–307Garzo A, Martinez L, Isken M, Lowet D, Remazeilles A (2012) User studies of a mobile assistance robot for supporting elderly: methodology and results. In: Workshop on assistance and service robotics in a human environment, international conference on intelligent robots and systems (IROS 2012), Vilamoura, Algarve, PortugalDixon C, Webster M, Saunders J, Fisher M, Dautenhahn K (2014) The fridge door is open—temporal verification of a robotic assistant’s behaviours. Advances in autonomous robotics systems, lecture notes in computer science. Springer, Vol. 8717, pp 97–108Schiffer S, Ferrein A, Lakemeyer G (2012) CAESAR: an intelligent domestic service robot. In: Intelligent service robotics 5(4), pp 259–273. SpringerChen TL, Ciocarlie M, Cousins S, Grice P, Hawkins K, Hsiao K, Kemp CC, King C, Lazewatsky DA, Leeper A, Nguyen H, Paepcke A, Pantofaru C, Smart WD, Takayama L (2013) Robots for humanity: using assistive robots to empower people with disabilities. IEEE Robot Autom Mag 20(1):30–39ArticleGoogle ScholarBadii A, Etxeberria I, Huijnen C, Maseda M, Dittenberger S, Hochgatterer A, Thiemert D, Rigaud AS (2009) CompanionAble–mobile robot companion and smart home system for people with mild cognitive impairment. J Nutr Health Aging 13(Suppl. 1):S113Google ScholarCoradeschi S et al (2014) GiraffPlus: a system for monitoring activities and physiological parameters and promoting social interaction for elderly. Human–computer systems interaction: backgrounds and applications 3, advances in intelligent systems and computing. Springer, vol. 300, pp 261–271Saunders J, Burke N, Koay KL, Dautenhahn K (2014) A user friendly robot architecture for re-ablement and co-learning in a sensorised home. Assistive technology: from research to practice, assistive technology research series. IOS Press, vol. 33, pp 49–58Esposito R, Cavallo F, Dario P, Marcellini F, Bevilacqua R, Felici E (2014) Robot-era project: preliminary results of robotic service in smart environments with elderly people. AAL Forum, Bucharest, RomaniaNani M, Caleb-Solly P, Dogramadzi S, Fear T, van den Heuvel H (2010) MOBISERV: an integrated intelligent home environment for the provision of health, nutrition and mobility services to the elderly. In: Proceedings of 4th companion robotics workshop, BrusselsFischinger D, Einramhof P, Papoutsakis K, Wohlkinger W, Mayer P, Panek P, Hofmann S, Koertner T, Weiss A, Argyros A, Vincze M (2016) Hobbit, a care robot supporting independent living at home: first prototype and lessons learned. Robot Auton Syst 75:60–78ArticleGoogle ScholarBreazeal C, Scassellati B (2000) Infant-like social interactions between a robot and a human caregiver. Adapt Behav 8(1):49–74ArticleGoogle ScholarHirsch T, Forlizzi J, Hyder E, Goetz J, Kurtz C, Strobac J (2000) The ELDer project: social, emotional, and environmental factors in the design of eldercare technologies. In: Proceedings of the conference on universal usability (CUU ’00), pp 72–79Sixsmith A, Gutman G (2013) Technologies for active aging. Springer, BerlinBookGoogle ScholarYoung JE, Hawkins R, Sharlin E, Igarashi T (2009) Toward acceptable domestic robots: applying insights from social psychology. Int J Soc Robot 1(1):95–108ArticleGoogle ScholarBroadbent E, Stafford R, MacDonald B (2009) Acceptance of healthcare robots for the older population: review and future directions. Int J Soc Robot 1(4):319–330ArticleGoogle ScholarFrennert S, Östlund B, Eftring H (2012) Would Granny let an assistive robot into her home? Social robotics, lecture notes in computer science. Springer, Vol. 7621, pp 128–137Krishnan RH, Pugazhenthi S (2014) Mobility assistive devices and self-transfer robotic systems for elderly, a review. Intell Serv Robot 7(1):37–49ArticleGoogle ScholarPalopoli L (2015) Navigation assistance and guidance of older adults across complex public spaces: the DALi approach. Intell Serv Robot 8(2):77–92ArticleGoogle ScholarSantos L, Portugal D, Christodoulou E, Samaras G, Alvito P, Dias J (2014) Personalizable ICT-based service provision: the SocialRobot solution. In: Proceedings of the AmI 2014 international workshop on intelligent environments supporting healthcare and well-being (WISHWell 2014), Eindhoven, The NetherlandsQuigley M, Conley K, Gerkey B, Faust J, Foote T, Leibs J, Wheeler R, Ng A (2009) ROS: an open-source robot operating system. In: Proceedings of the IEEE international conference on robotics and automation (ICRA 2009), Workshop on Open Source Software, Kobe, JapanAlvito P, Marques C, Carriço P, Freire J (2014) A robotic platform for the social robot project. In: Proceedings of the 23rd IEEE international symposium on robot and human interactive communication (ROMAN 2014), Workshop on interactive robots for aging and/or impaired people, EdinburghSocial Robot Project D1.1: specification of user needs and requirements.
http://mrl.isr.uc.pt/projects/socialrobot/index.php?Itemid=73. Accessed 28 May 2018Social Robot Project D2.1: Overall system architecture design.
http://mrl.isr.uc.pt/projects/socialrobot/index.php?Itemid=73. Accessed 28 May 2018Randelli G, Bonanni TM, Iocchi L, Nardi D (2012) Knowledge acquisition through human-robot multimodal interaction. Intell Serv Robot 6(1):19–31ArticleGoogle ScholarGrisetti G, Stachniss C, Burgard W (2007) Improved techniques for grid mapping with rao-blackwellized particle filters. IEEE Trans Robot 23(1):34–46ArticleGoogle ScholarFox D, Burgard W, Thrun S (1997) The dynamic window approach to collision avoidance. IEEE Robot Autom 4(1):23–33ArticleGoogle ScholarGerkey B, Konolige KK (2008) Planning and control in unstructured terrain. In: Proceedings of the IEEE international conference on robotics and automation (ICRA 2008), workshop on path planning on costmaps, Pasadena, CA, USAThrun S, Burgard W, Fox D (2005) Probabilistic robotics. MIT Press, CambridgeMATHGoogle ScholarPortugal D, Pippin C, Rocha RP, Christensen HH (2014) Finding optimal routes for multi-robot patrolling in generic graphs. In: Proceedings of 2014 IEEE/RSJ international conference on intelligent robots and systems (IROS 2014), ChicagoViola P, Jones M (2001) Rapid object detection using a boosted cascade of simple features. In: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition (CVPR 2001). IEEE, vol. 1Eyben F, Wöllmer M, Schuller BB (2009) openEAR—introducing the Munich open-source emotion and affect recognition toolkit. In: Proceedings of 3rd international conference on affective computing and intelligent interaction and workshops (ACII 2009), Amsterdam, Holland, pp 576–581Ben Moussa M, Kasap Z, Thalmann NM, Chandramouli K, Mirza S, Zhang Q, Izquierdo E, Biperis I, Daras P (2010) Towards an expressive virtual tutor: an implementation of a virtual tutor based on an empirical study of non-verbal behaviour. In: Proceedings of of the 2010 ACM workshop on surreal media and virtual cloning (SMVC 2010), Florence, Italy, pp 39–44Portugal D, Santos L, Alvito P, Dias J, Samaras G, Christodoulou E (2015) SocialRobot: an interactive mobile robot for elderly home care. In: Proceedings of the IEEE/SICE international symposium on system integration (SII 2015), Nagoya, JapanMachado Santos J, Portugal D, Rocha RP (2013) An evaluation of 2D SLAM techniques available in robot operating system. In: Proceedings of the 11th IEEE international symposium on safety, security, and rescue robotics (SSRR 2013), Linköping, SwedenNourbakhsh IR, Kunz C, Willeke T (2003) The mobot museum robot installations: a five year experiment. In: Proceedings of the IEEE/RSJ international conference on intelligent robots and systems (IROS 2003), Las Vegas, Nevada, USA, pp 3636–3641Download referencesAcknowledgementsThis work was supported by the SocialRobot Project, funded under the 7th Framework Programme (FP7) Industry-Academia Partnerships and Pathways (IAPP), Marie Curie Programme 2011 by the European Commission, under Grant Agreement 285870. The authors would like to sincerely thank the Zuyderland Hoogstaete care center team in Sittard (The Netherlands), especially Roy Beumers, Leon van de Weem, Rachelle Wintjens and Cindy Wings, as well as the remaining researchers involved in the SocialRobot Project.
Author informationAffiliationsCitard Services Ltd., 1 Evrytanias Str., 2064, Strovolos, Nicosia, CyprusDavid Portugal & Eleni ChristodoulouIDMind - Engenharia de Sistemas, Lda., 1600-546, Lisbon, PortugalPaulo AlvitoDepartment of Computer Science, University of Cyprus, PO Box 20537, 1678, Nicosia, CyprusGeorge SamarasInstitute of Systems and Robotics, University of Coimbra, 3030-290, Coimbra, PortugalJorge DiasKhalifa University of Science, Technology and Research (KUSTAR), Al Saada Street, Abu Dhabi, 127788, UAEJorge DiasYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarCorresponding authorCorrespondence toDavid Portugal.
Ethics declarationsConflict of interestThe authors declare that they have no conflict of interest.
Additional informationPublisher's NoteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Appendix A: User questionnaires (English version)Appendix A: User questionnaires (English version)Social robot questionnaire(to be handed out after a user interacts with the robot)Please let us know your role (senior, visitor, caregiver, other): ________Please, provide below answers from 1 (strongly disagree) to 10 (strongly agree).
UsabilityI believe that the robot is useful. _________The robot is easy to use. _________I felt very confident using the robot. _________I believe that the robot could help me be more effective in carrying out my daily activities. _________I believe that the robot could save me time when I use it. _________I believe that the robot could meet my needs. _________I learned to use the robot quickly. _________The robot is simple to use. _________The robot could make me feel more motivated to carry out my daily activities/tasks. _________The robot could help me be more active (i.e., participate in more activities, be more socially active). _________The robot could help me be more independent / autonomous. _________The robot could help to reduce the demand for care from my carergivers. _________The robot makes me feel happier than when I am alone. _________The robot makes me feel less concerned, worried or preoccupied. _________Robot appearance and interactionPlease rate the humanity of the robot. Machine-Like (1) to Human-Like (10). _________Please rate the animacy of the robot. Stagnant (1) to Lively (10). _________Please rate the likeability of the robot. Unfriendly (1) to Friendly (10). _________Please rate the perceived intelligence of the robot. Incompetent (1) to Intelligent (10). _________Please rate the perceived safety of the robot. Unsafe (1) to Safe (10). _________SatisfactionI am satisfied with the robot. _________I would recommend the robot to a friend. _________The robot is fun. _________The robot is not invasive. _________The robot is respectful of my wishes, preferences, and private data. _________The robot performed well during the demonstration. _________Qualitative questionsPlease name 1 or 2 things that you liked the most about the robot: _________Please name 1 or 2 things that you liked the least about the robot: _________Please name 1 or 2 things that you would you like to have on the robot, which was not there: _________Please name 1 or 2 things that could help you in your daily life, in the current state of the robot: _________Rights and permissionsReprints and PermissionsAbout this articleCite this articlePortugal, D., Alvito, P., Christodoulou, E.
et al.
A Study on the Deployment of a Service Robot in an Elderly Care Center.
Int J of Soc Robotics11,317–341 (2019). https://doi.org/10.1007/s12369-018-0492-5Download citationAccepted:17 September 2018Published:10 November 2018Issue Date:01 April 2019DOI:https://doi.org/10.1007/s12369-018-0492-5Share this articleAnyone you share the following link with will be able to read this content:Sorry, a shareable link is not currently available for this article.
Provided by the Springer Nature SharedIt content-sharing initiativeKeywordsAdvertisementOver 10 million scientific documents at your fingertipsNot logged in- 129.170.195.194North East Research Libraries (8200828607) - Dartmouth College Acquisitions Services (8200831269)© 2022 Springer Nature Switzerland AG. Part ofSpringer Nature.
