old id = 536
US government agencies plan to increase their use of facial recognition technology | MIT Technology Review
2021
https://www.technologyreview.com/2021/08/24/1032967/us-government-agencies-plan-to-increase-their-use-of-facial-recognition-technology

Featured Topics Newsletters Events Podcasts Featured Topics Newsletters Events Podcasts US government agencies plan to increase their use of facial recognition technology A new survey shows the controversial systems are poised to play an even bigger role in federal business.
By Tate Ryan-Mosley archive page In this April 14, 2014 photo, a surveillance camera is attached to a light pole along Boylston Street in Boston. The Boston City Council voted unanimously, Wednesday, June 24, 2020, to pass a ban on the use of facial recognition technology.
AP Photo/Steven Senne File A 90-page report published by the US Government Accountability Office (GAO) details how federal agencies currently use, and plan to expand their use of, facial recognition systems. Ten of 24 agencies surveyed plan to broaden their use of the technology by 2023. Ten agencies are also investing in research and development for the technology.
The report, published August 24, is the outcome of a study requested by Congress on federal agencies’ use of facial recognition during fiscal year 2020. It characterizes the use of the technology as “increasingly common,” with most agencies surveyed using it for cybersecurity, domestic law enforcement, or physical security. The report also asked all agencies that participated in the study about their future plans for facial recognition.
The results come after a year of public backlash from privacy and civil liberties advocates against police and government use of the technology.
Facial recognition has proved to be less accurate on people with darker skin , women, and younger and older people. A report from the GAO released earlier this summer also described a lack of oversight by federal law enforcement agencies that use the technology.
Eighteen of the 24 federal agencies surveyed currently use some form of facial recognition, with many agencies owning more than one system. Some federal agencies that use facial recognition fell outside the scope of this report, and no comprehensive survey on government use of the technology has been done. Most of the systems in use by those surveyed are federally owned, though six systems come from commercial vendors including Clearview AI, Vigilant Solutions, and Acuant FaceID.
The Departments of Agriculture, Commerce, Defense, Homeland Security, Health and Human Services, Interior, Justice, State, Treasury, and Veterans Affairs all plan to expand their use of facial recognition between 2020 and 2023. These 10 agencies are implementing 17 different facial recognition systems. Thirteen of those systems will be owned by the agencies, two will be owned by local law enforcement, and two agencies are using Clearview AI.
Many agencies are already using or plan to use facial recognition to help secure sensitive data and technology as well as physical locations. Other applications focus on justice and military matters.
The Office of the Inspector General, for example, started using Vintra in May 2021 to aid investigations by searching surveillance video for “directional movement, vehicles, or people.” The US Marshals Service is developing a touchless prisoner identification system to aid in booking and transporting prisoners. US Immigration and Customs Enforcement is working with the Lehigh County District Attorney’s Office in Pennsylvania to expand access to its existing facial recognition system through integration with a “gang intelligence application.” The Department of Agriculture plans to use facial recognition systems to monitor live surveillance video for individuals on watchlists, if funding is approved.
Both the US Air Force (part of the Defense Department) and the Fish and Wildlife Service (part of the Interior Department) are working on projects with Clearview AI that the agencies plan to expand. Clearview AI is controversial because its matching algorithm references a database of over three billion public images scrapped from the internet. Other facial recognition systems used by law enforcement are based on much smaller databases, often developed and owned by the government, such as a mugshot database where those included have been previously indicted for a crime.
Related Story Technology doesn’t rule us. We direct it, but often by inaction.
Ten agencies are also working on research and development in this area, including the Departments of Justice, Defense, Homeland Security, and State. The agencies ranged in their goals, but some reported researching the well-documented bias of many facial recognition systems. The Department of Justice, for example, studied the relationship between skin tone and false match rates in facial recognition algorithms. Others were researching how to make such systems more accurate even while scanning people who are wearing masks.
The report also showed extensive interagency coordination and sharing of facial recognition systems and information. Many federal agencies reported that they procured their facial recognition systems from state and local governments. The Department of Homeland Security revealed that its information network “contains a mechanism to request third party facial recognition searches through the listed state and local entities, such as fusion centers.” A spokesperson for the nonprofit digital rights group the Electronic Frontier Foundation said: “This important GAO report exposes the federal government’s growing reliance on face surveillance technology. Most disturbing is its use by law enforcement agencies. Yet face surveillance is so invasive of privacy, so discriminatory against people of color, and so likely to trigger false arrests, that the government should not be using face surveillance at all.” In June, the GAO released a report on the facial recognition capabilities of 42 federal agencies that employ law enforcement officers. It showed that several law enforcement agencies used facial recognition in the aftermath of the racial justice protests last summer and the January attack on the US Capitol. The report also showed that 13 of the 42 agencies do not fully understand their own use of the technology. Reporting from BuzzFeed News shows that the GAO report was likely incomplete, with five federal agencies saying that they had not used Clearview AI’s system when they had.
Adoption of the technology is growing at all levels of government. This past March, Clearview AI said that 3,100 of the 18,000 US federal, state, county, and municipal law enforcement agencies—around 17%—have used its software.
There is no federal regulation in the US on law enforcement’s use of facial recognition technology, though legislation is anticipated.
 Many states and cities do ban law enforcement and government use of the software, though local bans don’t prevent federal use.
hide by Tate Ryan-Mosley Share linkedinlink opens in a new window twitterlink opens in a new window facebooklink opens in a new window emaillink opens in a new window Popular This new data poisoning tool lets artists fight back against generative AI Melissa Heikkilä How to fix the internet Katie Notopoulos Think that your plastic is being recycled? Think again.
Douglas Main 15 Climate Tech Companies to Watch Amy Nordrum Deep Dive Artificial intelligence This new data poisoning tool lets artists fight back against generative AI The tool, called Nightshade, messes up training data in ways that could cause serious damage to image-generating AI models.
By Melissa Heikkilä archive page Driving companywide efficiencies with AI Advanced AI and ML capabilities revolutionize how administrative and operations tasks are done.
By MIT Technology Review Insights archive page Minds of machines: The great AI consciousness conundrum Philosophers, cognitive scientists, and engineers are grappling with what it would take for AI to become conscious.
By Grace Huckins archive page Generative AI deployment: Strategies for smooth scaling Our global poll examines key decision points for putting AI to use in the enterprise.
By MIT Technology Review Insights archive page Stay connected Illustration by Rose Wong Get the latest updates from MIT Technology Review Discover special offers, top stories, upcoming events, and more.
Enter your email Thank you for submitting your email! It looks like something went wrong.
We’re having trouble saving your preferences. Try refreshing this page and updating them one more time. If you continue to get this message, reach out to us at customer-service@technologyreview.com with a list of newsletters you’d like to receive.
The latest iteration of a legacy Advertise with MIT Technology Review © 2023 MIT Technology Review About About us Careers Custom content Advertise with us International Editions Republishing MIT News Help Help & FAQ My subscription Editorial guidelines Privacy policy Terms of Service Write for us Contact us twitterlink opens in a new window facebooklink opens in a new window instagramlink opens in a new window rsslink opens in a new window linkedinlink opens in a new window
