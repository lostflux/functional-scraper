old id = 46
Elon Musk’s Plan to Open Source the Twitter Algorithm Won’t Solve Anything | WIRED
2021
https://www.wired.com/story/twitter-open-algorithm-problem

To revist this article, visit My Profile, thenView saved stories.
To revist this article, visit My Profile, thenView saved stories.
Will KnightElon Musk’s Plan to Open Source the Twitter Algorithm Won’t Solve AnythingTo revist this article, visit My Profile, thenView saved stories.
To revist this article, visit My Profile, thenView saved stories.
ApplicationContent moderationRecommendation algorithmEnd UserBig companySectorSocial mediaSource DataClickstreamTechnologyMachine learningWhen Elon Muskvictory-tweeted his$44 billion acquisition of Twitteron Monday evening, he committed to improving the social network by, among other things, “making the algorithms open source to increase trust.”In aTED talk earlier this month, the entrepreneur suggested that the algorithm that determines how tweets are promoted and demoted could be uploaded to the software hosting platform GitHub, making it available to people outside of the company. “People can look through it and say, ‘Oh, I see a problem here, I don’t agree with this,’” Musk said. “They can highlight issues and suggest changes, in the same way that you update Linux or Signal.”In reality, cracking Twitter open to see how it truly works would involve a lot more than just uploading some code to GitHub. And proving the existence—or absence—of biases that may be subtle in nature and depend on a multitude of ever-changing factors may prove to be far more difficult than Musk suggests.
On the face of it, greater transparency makes a lot of sense. Social platforms likeTwitter,Facebook, andTikTokwield enormous influence and power but are largely opaque to their users and regulators. And just as the source code for a computer program provides a way to inspect it for bugs or backdoors, revealing the code that makes Twitter tick might, in theory, show that the platform promotes certain types of content over others.
“I'm very excited about seeing what happens,” saysDerek Ruths, an associate professor at McGill University in Canada who studies large social platforms. Ruths says he has refrained from teaching his students about social recommendation systems thus far because they are so opaque.
While Ruths admits to misgivings about what less moderation—another of Musks’ promised “improvements”—might mean for the platform, he believes more transparency will be useful and hopes that other social networks will feel pressured to reveal more about how they operate. “It has the potential to be a really interesting experiment that is long overdue,” Ruths says.
The idea has stirred up some debate around political bias baked into the platform. Some on the right of the political divide arerubbing their hands at the prospectof finally proving that conservative perspectives are routinely “shadow banned”—or prevented from receiving the kind of prominence that they actually deserve. But they may be disappointed by the complexity of untangling how the platform really operates.
The first problem is that there is no single algorithm that guides the way Twitter decides to elevate or bury content, unlike whatMusk has impliedin the past. Rather, according to sources within Twitter’s technical team who spoke on condition of anonymity, decisions are the result of many different algorithms that perform a complex dance atop mountains of data and a multitude of human actions. Results are also tailored to each user based on their personal information and behavior. “There is no ‘master algorithm’ for Twitter,” one company source says.
Another issue is that Twitter uses machine learning to guide many decisions. For instance, Twitter trains numerous machine learning models to help decide which posts to prioritize on users’ feeds based on a dizzying number of factors. These models cannot be inspected like regular code; they need to be tested in an environment that replicates the real world as closely as possible. The models also change rapidly in the real system, in response to a constant flow of new data, user behavior, and input from moderators. This would quickly make them an unreliable source of information.
“In this age of machine learning, it isn’t the algorithms, it’s the data,” saysDavid Karger, a professor and computer scientist at MIT. Karger says Musk could improve Twitter by making the platform more open, so that others can build on top of it in new ways. “What makes Twitter important is not the algorithms,” he says. “It’s the people who are tweeting.”A deeper picture of how Twitter works would also mean opening up more than just the handwritten algorithms. “The code is fine; the data is better; the code and data combined into a model could be best," saysAlex Engler, a fellow in governance studies at the Brookings Institution who studies AI’s impact on society. Engler adds that understanding the decisionmaking processes that Twitter’s algorithms are trained to make would also be crucial.
The machine learning models that Twitter uses are still only part of the picture, because the entire system also reacts to real-time user behavior in complex ways. If users are particularly interested in a certain news story, then related tweets will naturally get amplified. “Twitter is a socio-technical system,” says a second Twitter source. “It is responsive to human behavior.”ContentThis content can also be viewed on the site itoriginatesfrom.
This fact was illustrated byresearch that Twitter publishedin December 2021 showing that right-leaning posts received more amplifications than left-leaning ones, although the dynamics behind this phenomenon were unclear.
“That’s why we audit,” saysEthan Zuckerman, a professor at the University of Massachusetts Amherst who teaches public policy, communication, and information. “Even the people who build these tools end up discovering surprising shortcomings and flaws.”One irony of Musk’s professed motives for acquiring Twitter, Zuckerman says, is that the company has been remarkably transparent about the way its algorithm works of late. In August 2021,Twitter launched a contestthat gave outside researchers access to an image-cropping algorithm that had exhibited biased behavior. The company has also been working on ways to give users greater control over the algorithms that surface content, according to those with knowledge of the work.
Releasing some Twitter code would provide greater transparency, saysDamon McCoy, an associate professor at New York University who studies security and privacy of large, complex systems including social networks, but even those who built Twitter may not fully understand how it works.
A concern for Twitter’s engineering team is that, amid all this complexity, some code may be taken out of context and highlighted as a sign of bias. Revealing too much about how Twitter’s recommendation system operates might also result in security problems. Access to a recommendation system would make it easier to game the system and gain prominence. It may also be possible to exploit machine learning algorithms in ways that might be subtle and hard to detect. “Bad actors right now are probing the system and testing,” McCoy says. Access to Twitter’s models “may well help outsiders understand some of the principles used to elevate some content over others.”On April 18, as Musk was escalating his efforts to acquire Twitter, someone with access to Twitter’s Github, where the company already releases some of its code, created a new repository called “the algorithm”—perhaps a developer’s dig at the idea that the company could easily release details of how it works. Shortly after Musk’s acquisition was announced, it disappeared.
Additional reporting by Tom Simonite.
More From WIREDContact© 2022 Condé Nast. All rights reserved. Use of this site constitutes acceptance of ourUser AgreementandPrivacy Policy and Cookie StatementandYour California Privacy Rights.
Wiredmay earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.
Ad Choices
