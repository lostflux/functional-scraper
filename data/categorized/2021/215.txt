old id = 2555
Intel's Neuromorphic Chip Gets A Major Upgrade - IEEE Spectrum
2021
https://spectrum.ieee.org/neuromorphic-computing-with-lohi2

TopicsSectionsMoreFor IEEE MembersFor IEEE MembersIEEE SpectrumFollow IEEE SpectrumSupport IEEE SpectrumIEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Enjoy more free content and benefits by creating an accountSaving articles to read later requires an IEEE Spectrum accountThe Institute content is only available for membersDownloading full PDF issues is exclusive for IEEE MembersAccess toSpectrum's Digital Edition is exclusive for IEEE MembersFollowing topics is a feature exclusive for IEEE MembersAdding your response to an article requires an IEEE Spectrum accountCreate an account to access more content and features onIEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, considerJoining IEEE.
Join the world’s largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum’s articles, archives, PDF downloads, and other benefits.
Learn more →Access Thousands of Articles — Completely FreeCreate an account and get exclusive content and features:Save articles, download collections,andtalk to tech insiders— all free! For full access and benefits,join IEEEas a paying member.
Intel's Neuromorphic Chip Gets A Major UpgradeLoihi 2 packs 1 million neurons in a chip half the size of its predecessorMany AIs may depend on thingscalledneural networks, but there's very little about them that works inthe way human and animal brains do. Intel has been experimenting withcomputers that think more like a braindoes for several years now, racking up some impressive ifquirkyresults with their Loihi neuromorphic chip. Now Loihi is getting its first upgrade, and it's a pretty big one. Using a manufacturing process calledIntel 4that's not yet available for commercial chips, the company packed in up to eight-times as many artificial neurons into a chip that's half the area of Loihi. That, and a host of changes motivated by the past few years of experiments, make the Loihi 2 faster and more flexible, saysMike Davies director of Intel's neuromorphic computing lab.
Unlike the artificial neurons in conventional AI, which store information as weights that measure the strength of connection between neurons, Loihi's neurons carry information in the timing of digitally-represented spikes, which is more analogous to what goes on in your brain. Neural computation is triggered by these spikes, so there's no need for a central clock to keep things synchronous. And much of the chip will be idle when there is no event to observe, saving power.
Some 250 research partners have been using Loihi systems for things like controlling drones or robot arms, optimizing train schedules, searching databases, andlearning to identify different odors. "The results have been quite encouraging," says Davies. Some energy efficiency gains were "orders of magnitude" and there were also gains in energy efficiency and the amount of data needed for the system to learn. (The results are tabulated in theMay 2021 issue ofProceedings of the IEEE.
)But these experiments also pointed to a set of limitations that Davies' team wanted to address in the next generation. For one, Davies says, the neural network model Loihi used wasn't flexible enough to do all the things Intel and its partners wanted. They also found that the model of neural activity as a binary spike where only the timing information was conveyed from one neuron to another limited the precision of Loihi's calculations. Other hinderances included congestion between multiple Loihi chips and challenges to integrating the system with conventional computers.
IntelLoihi 2 tackles these issues using the same basic architecture, but with a set of circuits that were "redesigned from the ground up," according to Davies. Here's a summary of what's new:New spike messages to improve precision:The spike signals in original-flavor Loihi contained only timing information. This there-or-not information, is called a binary-value spike message. Loihi 2 allows spikes that have both timing and magnitude parameters, without much of an energy or performance penalty. "We can solve the same problems with fewer resources if we have this magnitude that can be sent alongside" the timing information, says Davies.
Enhanced programmability:The previous Loihi was designed for a specific spiking-neural-network (SNN) model. Loihi 2 neuromorphic cores can now also do arithmetic, comparison, program control flow and other operations that allow the chip to perform and expanded set of SNN models.
Faster learning:Loihi basically supported one set of brain-inspired learning rules. Loihi 2 changes this in a way that lets it perform some of the latest learning algorithms, as well as an approximation of the backpropagation algorithm used in deep learning. The change means algorithms that could only be done as proof-of-concept on Loihi can be scaled up on Loihi 2 allowing it to learn more quickly.
More of everything:As mentioned above, Loihi 2 is built using a manufacturing process so advanced the company doesn't yet even use its own commercial chips. That means a million neurons per chip versus Loihi's 125,000. What's more, the circuits and memory that implement those neurons and their memory were optimized leading to between 2x and 160x more resources for neuromorphic computing, depending on what kind of network is running.
Speedier circuits:Loihi 2's redesigned circuits mean a doubling of processing speeds when updating the state of neurons, five-fold faster synaptic operations, and as much as a 10-fold bump in the speed of spike generation. All told, the chip can now process neuromorphic networks up to 5000-times faster than biological neuronsNew chip interfaces:Loihi 2 chips support 4x faster asynchronous chip-to-chip signaling, as well as a feature that reduces interchip bandwidth needs 10-fold. It's also all set to do communications in a 3D chip-stacking arrangement and has an Ethernet interface and one for emerging event-based sensors, such asProphesee's camera chips.
As is a common theme with chips having new architectures, software is the key to getting any use out of it. "Software continues to hold back the field," says Davies. "There hasn't been the emergence of a single software framework as you see in the deep learning world.""Because the emergence of a single framework hasn't happened, we're now offering something ourselves," he says. The new software framework, Lava, takes the lessons of the previous three-and-a-half years of research projects and attempts to offer a common platform that support them all. Lava is an open-source framework that supports systems that do event-based, asynchronous message passing, not just Loihi or Loihi 2.
There are no specific plans to commercialize Loihi 2, says Davies. "This is still a research chip that we are going to be offering to research partners." Davies says that the technology behind Loihi is likely to first appear as an acceleration core on a system-on-chip that is performing a specific algorithm rather than as a general purpose chip.
Intel may not be ready to make a business out of neuromorphic chips, but that doesn't mean others aren't. Sydney-basedBrainchipreceived itsfirst shipmentof finished event-based neural processor chips in August and is hoping to help customers develop low-power systems where things like incremental and one-shot learning would be helpful.
Lol that's a good oneWouldn't be really better to call it "ANN chip/computing", instead of "neuromorphic chip/computing"?Video Friday: Drone in a CageRemembering 1982 IEEE President Robert LarsonAcer Goes Big on Glasses-Free, 3D Monitors—Look Out, VRRelated StoriesAI Fuses With Quantum Computing in Promising New MemristorPrinting Circuits on Nanomagnets Yields a New Breed of AISome AI Systems May Be Impossible to ComputeA Circuit to Boost Battery LifeDigital low-dropout voltage regulators will save time, money, and powerYOU'VE PROBABLY PLAYEDhundreds, maybe thousands, of videos on your smartphone. But have you ever thought about what happens when you press “play”?The instant you touch that little triangle, many things happen at once. In microseconds, idle compute cores on your phone'sprocessorspring to life. As they do so, their voltages and clock frequencies shoot up to ensure that the video decompresses and displays without delay. Meanwhile, other cores, running tasks in the background, throttle down. Charge surges into the active cores' millions of transistors and slows to a trickle in the newly idled ones.
This dance, calleddynamic voltage and frequency scaling(DVFS), happens continually in the processor, called a system-on-chip (SoC), that runs your phone and your laptop as well as in the servers that back them. It's all done in an effort to balance computational performance with power consumption, something that's particularly challenging for smartphones. The circuits that orchestrate DVFS strive to ensure a steady clock and a rock-solid voltage level despite the surges in current, but they are also among the most backbreaking to design.
That's mainly because the clock-generation and voltage-regulation circuits are analog, unlike almost everything else on your smartphone SoC. We've grown accustomed to a near-yearly introduction of new processors with substantially more computational power, thanks to advances in semiconductor manufacturing. “Porting” a digital design from an old semiconductor process to a new one is no picnic, but it's nothing compared to trying to move analog circuits to a new process. The analog components that enable DVFS, especially a circuit called a low-dropout voltage regulator (LDO), don't scale down like digital circuits do and must basically be redesigned from scratch with every new generation.
If we could instead build LDOs—and perhaps other analog circuits—from digital components, they would be much less difficult to port than any other part of the processor, saving significant design cost and freeing up engineers for other problems that cutting-edge chip design has in store. What's more, the resulting digital LDOs could be much smaller than their analog counterparts and perform better in certain ways. Research groups in industry and academia have tested at least a dozen designs over the past few years, and despite some shortcomings, a commercially useful digital LDO may soon be in reach.
Low-dropout voltage regulators (LDOs) allow multiple processor cores on the same input voltage rail (VIN) to operate at different voltages according to their workloads. In this case, Core 1 has the highest performance requirement. Its head switch, really a group of transistors connected in parallel, is closed, bypassing the LDO and directly connecting Core 1 to VIN, which is supplied by an external power management IC. Cores 2 through 4, however, have less demanding workloads. Their LDOs are engaged to supply the cores with voltages that will save power.
The basic analog low-dropout voltage regulator [left] controls voltage through a feedback loop. It tries to make the output voltage (VDD) equal to the reference voltage by controlling the current through the power PFET. In the basic digital design [right], an independent clock triggers a comparator [triangle] that compares the reference voltage to VDD. The result tells control logic how many power PFETs to activate.
A TYPICAL SYSTEM-ON-CHIPfor a smartphone is a marvel ofintegration. On a single sliver of silicon it integrates multiple CPU cores, a graphics processing unit, a digital signal processor, a neural processing unit, an image signal processor, as well as a modem and other specialized blocks of logic. Naturally, boosting the clock frequency that drives these logic blocks increases the rate at which they get their work done. But to operate at a higher frequency, they also need a higher voltage. Without that, transistors can't switch on or off before the next tick of the processor clock. Of course, a higher frequency and voltage comes at the cost of power consumption. So these cores and logic units dynamically change their clock frequencies and supply voltages—often ranging from 0.95 to 0.45 volts— based on the balance of energy efficiency and performance they need to achieve for whatever workload they are assigned—shooting video, playing back a music file, conveying speech during a call, and so on.
Typically, an external power-management IC generates multiple input voltage (VIN) values for the phone's SoC. These voltages are delivered to areas of the SoC chip along wide interconnects called rails. But the number of connections between the power-management chip and the SoC is limited. So, multiple cores on the SoC must share the same VINrail.
But they don't have to all get the same voltage, thanks to the low-dropout voltage regulators. LDOs along with dedicated clock generators allow each core on a shared rail to operate at a unique supply voltage and clock frequency. The core requiring the highest supply voltage determines the shared VINvalue. The power-management chip sets VINto this value and this core bypasses the LDO altogether through transistors called head switches.
To keep power consumption to a minimum, other cores can operate at a lower supply voltage. Software determines what this voltage should be, and analog LDOs do a pretty good job of supplying it. They are compact, low cost to build, and relatively simple to integrate on a chip, as they do not require large inductors or capacitors.
But these LDOs can operate only in a particular window of voltage. On the high end, the target voltage must be lower than the difference between VINand the voltage drop across the LDO itself (the eponymous “dropout” voltage). For example, if the supply voltage that would be most efficient for the core is 0.85 V, but VINis 0.95 V and the LDO's dropout voltage is 0.15 V, that core can't use the LDO to reach 0.85 V and must work at the 0.95 V instead, wasting some power. Similarly, if VINhas already been set below a certain voltage limit, the LDO's analog components won't work properly and the circuit can't be engaged to reduce the core supply voltage further.
The main obstacle that has limited use of digital LDOs so far is the slow transient response.
However, if the desired voltage falls inside the LDO's window, software enables the circuit and activates a reference voltage equal to the target supply voltage.
HOW DOES THE LDOsupply the right voltage? In the basic analog LDO design, it's by means of an operational amplifier, feedback, and a specialized powerp-channel field effect transistor (PFET). The latter is a transistor that reduces its current with increasing voltage to its gate. The gate voltage to this power PFET is an analog signal coming from the op amp, ranging from 0 volts to VIN. The op amp continuously compares the circuit's output voltage—the core's supply voltage, or VDD—to the target reference voltage. If the LDO's output voltage falls below the reference voltage—as it would when newly active logic suddenly demands more current—the op amp reduces the power PFET's gate voltage, increasing current and lifting VDDtoward the reference voltage value. Conversely, if the output voltage rises above the reference voltage—as it would when a core's logic is less active—then the op amp increases the transistor's gate voltage to reduce current and lower VDD.
A basicdigitalLDO, on the other hand, is made up of a voltage comparator, control logic, and a number of parallel power PFETs. (The LDO also has its own clock circuit, separate from those used by the processor core.) In the digital LDO, the gate voltages to the power PFETs are binary values instead of analog, either 0 V or VIN.
With each tick of the clock, the comparator measures whether the output voltage is below or above the target voltage provided by the reference source. The comparator output guides the control logic in determining how many of the power PFETs to activate. If the LDO's output is below target, the control logic will activate more power PFETs.Their combined current props up the core's supply voltage, and that value feeds back to the comparator to keep it on target. If it overshoots, the comparator signals to the control logic to switch some of the PFETs off.
NEITHER THE ANALOGnor the digital LDO is ideal, of course. The key advantage of an analog design is that it can respond rapidly to transient droops and overshoots in the supply voltage, which is especially important when those events involve steep changes. These transients occur because a core's demand for current can go up or down greatly in a matter of nanoseconds. In addition to the fast response, analog LDOs are very good at suppressing variations in VINthat might come in from the other cores on the rails. And, finally, when current demands are not changing much, it controls the output tightly without constantly overshooting and undershooting the target in a way that introduces ripples in VDD.
When a core's current requirement changes suddenly it can cause the LDO's output voltage to overshoot or droop [top]. Basic digital LDO designs do not handle this well [bottom left]. However, a scheme called adaptive sampling with reduced dynamic stability [bottom right] can reduce the extent of the voltage excursion. It does this by ramping up the LDO's sample frequency when the droop gets too large, allowing the circuit to respond faster.
Source:S.B. Nasir et al., IEEE International Solid-State Circuits Conference (ISSCC), February 2015, pp. 98–99.
These attributes have made analog LDOs attractive not just for supplying processor cores, but for almost any circuit demanding a quiet, steady supply voltage. However, there are some critical challenges that limit the effectiveness of these designs. First analog components are much more complex than digital logic, requiring lengthy design times to implement them in advanced technology nodes. Second, they don't operate properly when VINis low, limiting how low a VDDthey can deliver to a core. And finally, the dropout voltage of analog LDOs isn't as small as designers would like.
Taking those last points together, analog LDOs offer a limited voltage window at which they can operate. That means there are missed opportunities to enable LDOs for power saving—ones big enough to make a noticeable difference in a smartphone's battery life.
Digital LDOs undo many of these weaknesses: With no complex analog components, they allow designers to tap into a wealth of tools and other resources for digital design. So scaling down the circuit for a new process technology will need much less effort. Digital LDOs will also operate over a wider voltage range. At the low-voltage end, the digital components can operate at VINvalues that are off-limits to analog components. And in the higher range, the digital LDO's dropout voltage will be smaller, resulting in meaningful core-power savings.
But nothing's free, and the digital LDO has some serious drawbacks. Most of these arise because the circuit measures and alters its output only at discrete times, instead of continuously. That means the circuit has a comparatively slow response to supply voltage droops and overshoots. It's also more sensitive to variations in VIN, and it tends to produce small ripples in the output voltage, both of which could degrade a core's performance.
How Much Power Do LDOs Save?It might seem straightforward that low-dropout voltage regulators (LDOs) could minimize processor power consumption by allowing cores to run at a variety of power levels, but exactly how do they do that? The total power consumed by a core is simply the product of the supply voltage and the current through that core. But voltage and current each have both a static component and a dynamic one—dependent on how frequently transistors are switching. The core current's static component is made up of the current that leaks across devices even when the transistors are not switching and is dependent on supply voltage. Its dynamic component, on the other hand, is a product of capacitance, clock frequency, and supply voltage.
For a core connected directly to a voltage rail supplied by the external power supply IC, lowering VINresults in a quadratic reduction in dynamic power with respect to frequency plus a static power reduction that depends on the sensitivity of leakage current to VIN. So lowering the rail voltage saves quite a lot.
For cores using the LDO to deliver a supply voltage that is lower than VIN, you have to take into account the power consumed by the LDO itself. At a minimum, that's the product of the voltage across the LDO (the eponymous dropout voltage in the circuit's name) and the core current. When you factor that in, the dynamic power saving from lowering the voltage is a linear relation to supply voltage rather than the quadratic one you get without the LDO.
Even so, using an LDO to scale supply voltage is worthwhile. LDOs significantly lower the SoC processor power by allowing multiple cores on a shared VINto operate at lower voltage values.
Of these, the main obstacle that has limited the use of digital LDOs so far is their slow transient response. Cores experience droops and overshoots when the current they draw abruptly changes in response to a change in its workload. The LDO response time to droop events is critical to limiting how far voltage falls and how long that condition lasts. Conventional cores add a safety margin to the supply voltage to ensure correct operation during droops. A greater expected droop means the margin must be larger, degrading the LDO's energy-efficiency benefits. So, speeding up the digital LDO's response to droops and overshoots is the primary focus of the cutting-edge research in this field.
SOME RECENT ADVANCEShave helped speed the circuit's response to droops and overshoots. One approach uses the digital LDO's clock frequency as a control knob to trade stability and power efficiency for response time.
A lower frequency improves LDO stability, simply because the output will not be changing as often. It also lowers the LDO's power consumption, because the transistors that make up the LDO are switching less frequently. But this comes at the cost of a slower response to transient current demands from the processor core. You can see why that would be, if you consider that much of a transient event might occur within a single clock cycle if the frequency is too low.
Conversely, a high LDO clock frequency reduces the transient response time, because the comparator is sampling the output often enough to change the LDO's output current earlier in the transient event. However, this constant sampling degrades the stability of the output and consumes more power.
The gist of this approach is to introduce a clock whose frequency adapts to the situation, a scheme called adaptive sampling frequency with reduced dynamic stability. When voltage droops or overshoots exceed a certain level, the clock frequency increases to more rapidly reduce the transient effect. It then slows down to consume less power and keep the output voltage stable. This trick is achieved by adding a pair of additional comparators to sense the overshoot and droop conditions and trigger the clock. In measurements from a test chip using this technique, the VDDdroop reduced from 210 to 90 millivolts—a 57 percent reduction versus a standard digital LDO design. And the time it took for voltage to settle to a steady state shrank to 1.1 microseconds from 5.8 µs, an 81 percent improvement.
An alternative approach for improving the transient response time is to make the digital LDO a little bit analog. The design integrates a separate analog-assisted loop that responds instantly to load current transients. The analog-assisted loop couples the LDO's output voltage to the LDO's parallel PFETs through a capacitor, creating a feedback loop that engages only when there is a steep change in output voltage. So, when the output voltage droops, it reduces the voltage at the activated PFET gates and instantaneously increases current to the core to reduce the magnitude of the droop. Such an analog-assisted loop has been shown to reduce the droop from 300 to 106 mV, a 65 percent improvement, and overshoot from 80 to 70 mV (13 percent).
An alternative way to make digital LDOs respond more quickly to voltage droops is to add an analog feedback loop to the power PFET part of the circuit [top]. When output voltage droops or overshoots, the analog loop engages to prop it up [bottom], reducing the extent of the excursion.
Source:M. Huang et al., IEEE Journal of Solid-State Circuits, January 2018, pp. 20–34.
Of course, both of these techniques have their drawbacks. For one, neither can really match the response time of today's analog LDOs. In addition, the adaptive sampling frequency technique requires two additional comparators and the generation and calibration of reference voltages for droop and overshoot, so the circuit knows when to engage the higher frequency. The analog-assisted loop includes some analog components, reducing the design-time benefit of an all-digital system.
Developments in commercial SoC processors may help make digital LDOs more successful, even if they can't quite match analog performance. Today, commercial SoC processors integrate all-digital adaptive circuits designed to mitigate performance problems when droops occur. These circuits, for example, temporarily stretch the core's clock period to prevent timing errors. Such mitigation techniques could relax the transient response-time limits, allowing the use of digital LDOs and boosting processor efficiency. If that happens, we can expect more efficient smartphones and other computers, while making the process of designing them a whole lot easier.
