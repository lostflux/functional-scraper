old id = 3402
Sarcos Demonstrates Powered Exosuit That Gives Workers Super Strength - IEEE Spectrum
2021
https://spectrum.ieee.org/automaton/robotics/industrial-robots/sarcos-guardian-xo-powered-exoskeleton

TopicsSectionsMoreFor IEEE MembersFor IEEE MembersIEEE SpectrumFollow IEEE SpectrumSupport IEEE SpectrumIEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Enjoy more free content and benefits by creating an accountSaving articles to read later requires an IEEE Spectrum accountThe Institute content is only available for membersDownloading full PDF issues is exclusive for IEEE MembersAccess toSpectrum's Digital Edition is exclusive for IEEE MembersFollowing topics is a feature exclusive for IEEE MembersAdding your response to an article requires an IEEE Spectrum accountCreate an account to access more content and features onIEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, considerJoining IEEE.
Join the world’s largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum’s articles, archives, PDF downloads, and other benefits.
Learn more →Access Thousands of Articles — Completely FreeCreate an account and get exclusive content and features:Save articles, download collections,andtalk to tech insiders— all free! For full access and benefits,join IEEEas a paying member.
Sarcos Demonstrates Powered Exosuit That Gives Workers Super StrengthIt won't make you look like Iron Man but the Guardian XO allows you to lift 200 pounds without breaking a sweatOne year ago, forIEEE Spectrum’sspecial report on the Top Tech for 2019,Sarcos Roboticspromised that by the end of the year they’d be ready to ship apowered exoskeleton that would be the future of industrial work. And late last month, Sarcos invited us to Salt Lake City, Utah, to see what that future looks like.
Sarcos has been developing powered exoskeletons and the robotic technologies that make them possible for decades, and the lobby of the company’s headquarters is a resting place for concepts and prototype hardware that’s been abandoned along the way. But now, Sarcos is ready to unveil the prototype of the Guardian XO, a strength-multiplying exoskeleton that’s about to begin shipping.
As our introductory briefing concludes, Sarcos CEOBen Wolffis visibly excited to be able to show off what they’ve been working on in their lab. “If you were to ask the question, What does 30 years and $300 million look like,” Wolff tells us, “you're going to see it downstairs.”This is what we see downstairs:Guardian XO operator Fletcher Garrison demonstrates the company’s exosuit by lifting a 125-pound payload. Sarcos says this task usually requires three people.
GIF: Evan Ackerman/IEEE SpectrumHow the Guardian XO WorksThe Sarcos Guardian XO is a 24-degrees-of-freedom full-body robotic exoskeleton. While wearing it, a human can lift 200 pounds (90 kilograms)while feeling like they’re lifting just 10 lbs (4.5 kg). The Guardian XO is fully electrical and untethered with a runtime of 2 hours, and hot-swappable battery packs can keep it going for a full work day. It takes seconds to put on and take off, and Sarcos says new users can be trained to use the system in minutes. One Guardian XO costs $100,000 per year to rent, and the company will be shipping its first batch of alpha units to customers (including both heavy industry and the U.S. military) in January.
The prototype that Sarcos demonstrated had all of the functionality of the version that will ship in January, but latter models will include plastic fairings over the suit as well as quick-change end-effectors.
Photo: Evan Ackerman/IEEE SpectrumIn a practical sense, the Guardian XO is a humanoid robot that uses a real human as its command and control system. As companies of all kinds look towards increasing efficiency through automation, Sarcos believes that the most effective solution is a direct combination of humans and machines,enhancing the intelligence and judgement of humans with the strength and endurance of robots. (Investors in the company include Caterpillar, GE Ventures, Microsoft, and Schlumberger.)The first thing to understand about the Guardian XO is that like a humanoid robot, it’s self-supporting. Since it has its own legs and feet, the 150 lb weight of the suit (and whatever it’s carrying) bypasses its user and is transferred directly into the ground. You don’t strap the robot to you—you strap yourself to the robot, a process that takes less than a minute. So although it looks heavy and bulky (and it is definitely both of those things), at least the weight of the system isn’t something that the user experiences directly. You can see how that works by watching Guardian XO operator Fletcher Garrison lifting all kinds of payloads in the video below.
Hands On With the Guardian XOWhen Sarcos reached out and asked if we wanted to come to Salt Lake City to try out the XO, we immediately said yes (disclosure: Sarcos covered our costs to attend a media event last month). But we were disappointed when, in the end, we were only allowed to try out a one-armed version of the exoskeleton. I even offered to sign additional waivers but, alas, the company wouldn’t let me into the full suit. So my experience with the exo was pretty limited—a hands-on, literally, of a single XO arm.
That’s me trying out the one-arm XO system. It’s not quite like the full-body suit, but Sarcos still required me to sign a “waiver of liability, assumption of risk, and indemnity agreement.”Photo: Evan Ackerman/IEEE SpectrumStill, it was an amazing sensation. The arm I tested, which Sarcos saysuses the same control system as the full-body suit, was incredibly easy to operate. In terms of control, all the exo tries to do is get out of the way of your limbs: It uses force sensors to detect every motion that you make, and then moves its own limbs in parallel, smoothly matching your body with its own hardware. If you take a step, it takes a step with you. If you swing your arm back and forth, it swings its arm back and forth in the same way, right next to yours. There’s no discernible lag to this process, and it’s so intuitive that Sarcos says most people take just a minute or two to get comfortable using the system, and just an hour or two to be comfortable doing work in it.
The Guardian XO can augment the strength of the user all the way up to making a 200-pound load feel like it weighs zero pounds. Typically, this is not how the exoskeleton works, though, since it can be disconcerting to be lifting something heavy and not feel like you’re lifting anything at all. It’s better to think of the exo as a tool that makes you stronger rather than a tool that makes objects weightless, especially since you still have to deal with inertia. Remember, even if something has no apparent weight (either because you’re in space or because you’re holding it with a powered exoskeleton), it still has mass, which you have to be aware of when trying to move it or stop it from moving. The amount of help that the exo gives you is easy to adjust; it’s got a graphical control panel on the left wrist.
This ammo crate weighs 110 pounds, but the exoskeleton makes it feel like each arm is lifting just 6 pounds. The Guardian XO is designed for loads of up to 200 lbs.
GIF: Evan Ackerman/IEEE SpectrumHow Safe Is the Exoskeleton?With a robotic system this powerful (XO has a peak torque of about 4000 inch-pounds, or 450 newton-meters), Sarcos made safety a top priority. For example, to move the exo’s arms, your hands need to be holding down triggers. If you let go of the triggers (for whatever reason), the arms will lock in place, which has the added benefit of letting the exo hold stuff up for you while you, say, check your phone. All of the joints are speed limited, meaning that you can’t throw a punch with the exo—they told me this during my demo, so of course I tried it, and the joints locked themselves as soon as I exceeded their safety threshold. If the system loses power for any reason, current shunts back through the motors, bringing them down gradually rather than abruptly. And by design the joints are not capable of exceeding a human range of motion, which means that the exoskeleton can’t bend or twist in a way that would injure you. Interestingly, the Guardian XO’s joint speeds are easily fast enough to allow you to run, although that’s been limited for safety reasons as well.
We asked about whether falling down was much of a risk, but it turns out that having a human in the loop for control makes that problem much simpler. Sarcos hasn’t had to program the Guardian XO to balance itself, because the human inside does all of that naturally. Having someone try to push you over while you’re in the exoskeleton is no different than having someone try to push you over while you’re out of it, because you’ll keep your own balance in either case. If you do end up falling over, Sarcos claims that the exoskeleton is designed as a roll cage, so odds are you’ll be fine, although it’s not clear how easy it would be to get out of it afterwards (or get it off of you).
More of a concern is how the XO will operate around other people. While its mass and bulk may not make all that much of a different to the user, it seems like working collaboratively could be a problem, as could working in small spaces or around anything fragile. The suit does have force feedback so that you’ll feel if you contact something, but by then it might be too late to prevent an accident.
With a pair of 12 lb 500 watt-hour battery packs, the exoskeleton can operate for over 2 hours during normal use.
GIF: Evan Ackerman/IEEE SpectrumEnergy Efficiency and ReliabilityEfficiency might not seem like a big deal for an exoskeleton like this, but what Sarcos has managed is very impressive. The Guardian XO uses about 500 watts while fully operational—that is, while carrying 160 lbs and walking at 3 mph. To put that in context,SRI’s DURUS robot, which was designed specifically for efficiency (and is significantly smaller and lighter than the Guardian XO), used 350 watts while just walking. “That’s really one of our key innovations,” says Sarcos COO Chris Beaufait. “There aren’t many robots in the world that are as efficient as what we’re doing.” These innovations come in the form of energy recovery mechanisms, reductions in the number of individual computers on-board, and getting everything as tightly integrated as possible. With a pair of 12 lb 500 watt-hour battery packs, the exoskeleton can operate for over 2 hours during normal use, and Sarcos expects to improve the efficiency from 500 watts to 425 watts or better by January.
Since the Guardian XO is a commercial product, it has to be reliable enough to be a practical tool that’s cost effective to use. “The difference between being an R&D shop that can prove a concept versus making a commercially viable product that’s robust—it takes an entirely different skill set and mind set,” Wolff, the CEO, told us. “That’s been a challenge. I think it’s the biggest challenge that robotics companies have, and we’ve put a lot of blood, sweat, and tears into that.”Wolff says that future XO versions (not the alpha model that will ship in January) will be able to walk outdoors over challenging terrain, through a foot of mud, and in the rain or snow. It will be able to go up and down stairs, although they’re currently working on making sure that this will be safe. The expectation, Wolff tells us, is that there won’t be much ongoing service or maintenance required for the exo’s customers. We’re not sure we share Sarcos’ confidence yet—this is a complex system that’s going to be used by non-engineers in semi and unstructured environments. A lot of unexpected scenarios can happen, and until they do, we won’t know for sure how well the Guardian XO will stand up to real-world use.
Guardian XO ApplicationsThe Guardian XO has been designed to target some specific (but also very common) types of jobs that require humans to repetitively lift heavy things. These jobs are generally not automatable, or at least not automatable in a way that’s cost effective—the skill of a human is required. These jobs are also labor intensive, which creates both short term and long term problems for human workers. Short term, acute injuries (like back injuries) lead to lost productivity. Long term, these injuries add up to serious medical problems for workers, many of whom can only function for between five and eight years before their bodies become permanently damaged.
Wolff believes that this is where there’s an opportunity for powered exoskeletons. Using the Guardian XO to offload the kinds of tasks that put strain on a worker’s body means that humans can work at a job longer without injury. And they can keep working at that same job as they age, since the exoskeleton takes jobs that used to be about strength and instead makes them about skill and experience.
Sarcos says that one worker in an exoskeleton can handle tasks that would otherwise take between 4 and 10 people.
Photo: Evan Ackerman/IEEE SpectrumOf course, the sad fact is that none of this stuff about worker health would matter all that much if companies couldn’t be convinced that exoskeletons could also save them money. Fortunately for workers, it’s an easy argument to make. Since the Guardian XO can lift 200 pounds, Wolff says that it can improve the productivity of its user by up to an order of magnitude: “Overall, we’re seeing across the board improved productivity of somewhere between 4 and 10 times in use cases that we’ve looked at. So what that means is, one worker in an exoskeleton can do the work of between 4 and 10 employees without any stress or strain on their body.”On the 4x end of the scale, it’s just about being able to lift more, and for longer.
OSHArecommends a maximum one person load of 51 pounds, a number that gets adjusted downwards if the object has to be lifted repetitively, held for a long time, or moved. The Guardian XO allows a worker to lift four times that, for hours, while walking at up to 3 mph. Things are a little more complicated on the 10x end of the scale, but you can imagine a single 200 pound object that requires an overhead crane plus several people to manage it. It’s not just about the extra people—it’s also about the extra time and infrastructure required, when a single worker in a Guardian XO could just pick up that same object and move it by themselves.
The obvious question at this point is whether introducing powered exoskeletons is going to put people out of work. Wolff insists that is not the reality of the industry right now, since the real problem is finding qualified workers to hire in the first place. “None of our customers are talking about firing people,” Wolff says. “All of them are talking about simply not being able to produce enough of their products or services to keep their customers happy.” It should keep workers happy as well. Wolff tells us that they’ve had “enthusiastic responses” from workers who’ve tried the Guardian XO out, with their only concern being whether the exoskeleton can be adjusted to fit folks of different shapes and sizes. While initial units will be adjustable for people ranging in height from 5’4” to 6’, by next year, Sarcos promises that they’ll be adjustable enough to cover 90 percent of the American workforce.
A rendering of how the Guardian XO will look with fairings applied.
Image: SarcosCost and Availability“We could not have made this an economically viable product three years ago,” Wolff says. “The size, power, weight, and cost of all of the components that we use—all of that has now gotten to a point where this is commercially feasible.” What that means, for Sarcos and the companies that they’re partnering with, is that each exoskeleton costs about $100,000 per year. The alpha units will be going to companies that can afford at least 10 of them at once, and Sarcos will send a dedicated engineer along with each batch. The Guardian XO is being sold as a service rather than a product—at least for now, it’s more of a rental with dedicated customer support. “The goal is this has to be stupid simple to manage and use,” says Wolff, adding that Sarcos expects to learn a lot over the next few months once the exoskeletons start being deployed. Commercial versions should ship later in 2020.
I made sure to ask Wolff when I might be able to rent one of these things from my local hardware store for the next time I have to move, but disappointingly, he doesn’t see that happening anytime soon. Sarcos still has a lot to learn about how to make a business out of exoskeletons, and they’d rather keep expectations realistic than promise anyone an Iron Man suit. It’s too late for me, though—I’ve seen what the Guardian XO can do. And I want one.
[Sarcos]Video Friday: Drone in a CageRemembering 1982 IEEE President Robert LarsonAcer Goes Big on Glasses-Free, 3D Monitors—Look Out, VRRelated StoriesExosuit That Helps With the Heavy LiftingDextrous Robotics Wants To Move Boxes With ChopsticksZebra Technologies To Acquire Fetch Robotics for $305 MillionHow the U.S. Army Is Turning Robots Into Team PlayersEngineers battle the limits of deep learning for battlefield botsRoMan, the Army Research Laboratory's robotic manipulator, considers the best way to grasp and move a tree branch at the Adelphi Laboratory Center, in Maryland.
“I should probablynot be standing this close," I think to myself, as the robot slowly approaches a large tree branch on the floor in front of me. It's not the size of the branch that makes me nervous—it's that the robot is operating autonomously, and that while I know what it'ssupposedto do, I'm not entirely sure what itwilldo. If everything works the way the roboticists at theU.S. Army Research Laboratory (ARL)in Adelphi, Md., expect, the robot will identify the branch, grasp it, and drag it out of the way. These folks know what they're doing, but I've spent enough time around robots that I take a small step backwards anyway.
This article is part of our special report on AI, “The Great AI Reckoning.”The robot, namedRoMan, for Robotic Manipulator, is about the size of a large lawn mower, with a tracked base that helps it handle most kinds of terrain. At the front, it has a squat torso equipped with cameras and depth sensors, as well as a pair of arms that were harvested from aprototype disaster-response robotoriginally developed at NASA's Jet Propulsion Laboratory for a DARPA robotics competition. RoMan's job today is roadway clearing, a multistep task that ARL wants the robot to complete as autonomously as possible. Instead of instructing the robot to grasp specific objects in specific ways and move them to specific places, the operators tell RoMan to "go clear a path." It's then up to the robot to make all the decisions necessary to achieve that objective.
The ability to make decisions autonomously is not just what makes robots useful, it's what makes robotsrobots. We value robots for their ability to sense what's going on around them, make decisions based on that information, and then take useful actions without our input. In the past, robotic decision making followed highly structured rules—if you sense this, then do that. In structured environments like factories, this works well enough. But in chaotic, unfamiliar, or poorly defined settings, reliance on rules makes robots notoriously bad at dealing with anything that could not be precisely predicted and planned for in advance.
RoMan, along withmany other robots includinghome vacuums, drones, and autonomous cars, handles the challenges of semistructured environments through artificial neural networks—a computing approach that loosely mimics the structure of neurons in biological brains. About a decade ago, artificial neural networks began to be applied to a wide variety of semistructured data that had previously been very difficult for computers running rules-based programming (generally referred to as symbolic reasoning) to interpret. Rather than recognizing specific data structures, an artificial neural network is able to recognize data patterns, identifying novel data that are similar (but not identical) to data that the network has encountered before. Indeed, part of the appeal of artificial neural networks is that they are trained by example, by letting the network ingest annotated data and learn its own system of pattern recognition. For neural networks with multiple layers of abstraction, this technique is called deep learning.
Even though humans are typically involved in the training process, and even though artificial neural networks were inspired by the neural networks in human brains, the kind of pattern recognition a deep learning system does is fundamentally different from the way humans see the world. It's often nearly impossible to understand the relationship between the data input into the system and the interpretation of the data that the system outputs. And that difference—the "black box" opacity of deep learning—poses a potential problem for robots like RoMan and for the Army Research Lab.
In chaotic, unfamiliar, or poorly defined settings, reliance on rules makes robots notoriously bad at dealing with anything that could not be precisely predicted and planned for in advance.
This opacity means that robots that rely on deep learning have to be used carefully. A deep-learning system is good at recognizing patterns, but lacks the world understanding that a human typically uses to make decisions, which is why such systems do best when their applications are well defined and narrow in scope. "When you have well-structured inputs and outputs, and you can encapsulate your problem in that kind of relationship, I think deep learning does very well," saysTom Howard, who directs the University of Rochester's Robotics and Artificial Intelligence Laboratory and has developed natural-language interaction algorithms for RoMan and other ground robots. "The question when programming an intelligent robot is, at what practical size do those deep-learning building blocks exist?" Howard explains that when you apply deep learning to higher-level problems, the number of possible inputs becomes very large, and solving problems at that scale can be challenging. And the potential consequences of unexpected or unexplainable behavior are much more significant when that behavior is manifested through a 170-kilogram two-armed military robot.
After a coupleof minutes, RoMan hasn't moved—it's still sitting there, pondering the tree branch, arms poised like a praying mantis. For the last 10 years, the Army Research Lab'sRobotics Collaborative Technology Alliance(RCTA) has beenworking with roboticistsfrom Carnegie Mellon University, Florida State University, General Dynamics Land Systems, JPL, MIT, QinetiQ North America, University of Central Florida, the University of Pennsylvania, and other top research institutions to develop robot autonomy for use in future ground-combat vehicles. RoMan is one part of that process.
The "go clear a path" task that RoMan is slowly thinking through is difficult for a robot because the task is so abstract. RoMan needs to identify objects that might be blocking the path, reason about the physical properties of those objects, figure out how to grasp them and what kind of manipulation technique might be best to apply (like pushing, pulling, or lifting), and then make it happen. That's a lot of steps and a lot of unknowns for a robot with a limited understanding of the world.
This limited understanding is where the ARL robots begin to differ from other robots that rely on deep learning, says Ethan Stump, chief scientist of the AI for Maneuver and Mobility program at ARL. "The Army can be called upon to operate basically anywhere in the world. We do not have a mechanism for collecting data in all the different domains in which we might be operating. We may be deployed to some unknown forest on the other side of the world, but we'll be expected to perform just as well as we would in our own backyard," he says. Most deep-learning systems function reliably only within the domains and environments in which they've been trained. Even if the domain is something like "every drivable road in San Francisco," the robot will do fine, because that's a data set that has already been collected. But, Stump says, that's not an option for the military. If an Army deep-learning system doesn't perform well, they can't simply solve the problem by collecting more data.
ARL's robots also need to have a broad awareness of what they're doing. "In a standard operations order for a mission, you have goals, constraints, a paragraph on the commander's intent—basically a narrative of the purpose of the mission—which provides contextual info that humans can interpret and gives them the structure for when they need to make decisions and when they need to improvise," Stump explains. In other words, RoMan may need to clear a path quickly, or it may need to clear a path quietly, depending on the mission's broader objectives. That's a big ask for even the most advanced robot. "I can't think of a deep-learning approach that can deal with this kind of information," Stump says.
Robots at the Army Research Lab test autonomous navigation techniques in rough terrain [top, middle] with the goal of being able to keep up with their human teammates. ARL is also developing robots with manipulation capabilities [bottom] that can interact with objects so that humans don't have to.
Evan AckermanWhile I watch, RoMan is reset for a second try at branch removal. ARL's approach to autonomy is modular, where deep learning is combined with other techniques, and the robot is helping ARL figure out which tasks are appropriate for which techniques. At the moment, RoMan is testing two different ways of identifying objects from 3D sensor data: UPenn's approach is deep-learning-based, while Carnegie Mellon is using a method called perception through search, which relies on a more traditional database of 3D models. Perception through search works only if you know exactly which objects you're looking for in advance, but training is much faster since you need only a single model per object. It can also be more accurate when perception of the object is difficult—if the object is partially hidden or upside-down, for example. ARL is testing these strategies to determine which is the most versatile and effective, letting them run simultaneously and compete against each other.
Perception is oneof the things that deep learning tends to excel at. "The computer vision community has made crazy progress using deep learning for this stuff," saysMaggie Wigness, a computer scientist at ARL. "We've had good success with some of these models that were trained in one environment generalizing to a new environment, and we intend to keep using deep learning for these sorts of tasks, because it's the state of the art."ARL's modular approach might combine several techniques in ways that leverage their particular strengths. For example, a perception system that uses deep-learning-based vision to classify terrain could work alongside an autonomous driving system based on an approach called inverse reinforcement learning, where the model can rapidly be created or refined by observations from human soldiers. Traditional reinforcement learning optimizes a solution based on established reward functions, and is often applied when you're not necessarily sure what optimal behavior looks like. This is less of a concern for the Army, which can generally assume that well-trained humans will be nearby to show a robot the right way to do things. "When we deploy these robots, things can change very quickly," Wigness says. "So we wanted a technique where we could have a soldier intervene, and with just a few examples from a user in the field, we can update the system if we need a new behavior." A deep-learning technique would require "a lot more data and time," she says.
It's not just data-sparse problems and fast adaptation that deep learning struggles with. There are also questions of robustness, explainability, and safety. "These questions aren't unique to the military," says Stump, "but it's especially important when we're talking about systems that may incorporate lethality." To be clear, ARL is not currently working on lethal autonomous weapons systems, but the lab is helping to lay the groundwork for autonomous systems in the U.S. military more broadly, which means considering ways in which such systems may be used in the future.
The requirements of a deep network are to a large extent misaligned with the requirements of an Army mission, and that's a problem.
Safety is an obvious priority, and yet there isn't a clear way of making a deep-learning system verifiably safe, according to Stump. "Doing deep learning with safety constraints is a major research effort. It's hard to add those constraints into the system, because you don't know where the constraints already in the system came from. So when the mission changes, or the context changes, it's hard to deal with that. It's not even a data question; it's an architecture question." ARL's modular architecture, whether it's a perception module that uses deep learning or an autonomous driving module that uses inverse reinforcement learning or something else, can form parts of a broader autonomous system that incorporates the kinds of safety and adaptability that the military requires. Other modules in the system can operate at a higher level, using different techniques that are more verifiable or explainable and that can step in to protect the overall system from adverse unpredictable behaviors. "If other information comes in and changes what we need to do, there's a hierarchy there," Stump says. "It all happens in a rational way."Nicholas Roy, who leads theRobust Robotics Group at MITand describes himself as "somewhat of a rabble-rouser" due to his skepticism of some of the claims made about the power of deep learning, agrees with the ARL roboticists that deep-learning approaches often can't handle the kinds of challenges that the Army has to be prepared for. "The Army is always entering new environments, and the adversary is always going to be trying to change the environment so that the training process the robots went through simply won't match what they're seeing," Roy says. "So the requirements of a deep network are to a large extent misaligned with the requirements of an Army mission, and that's a problem."Roy, who has worked on abstract reasoning for ground robots as part of the RCTA, emphasizes that deep learning is a useful technology when applied to problems with clear functional relationships, but when you start looking at abstract concepts, it's not clear whether deep learning is a viable approach. "I'm very interested in finding how neural networks and deep learning could be assembled in a way that supports higher-level reasoning," Roy says. "I think it comes down to the notion of combining multiple low-level neural networks to express higher level concepts, and I do not believe that we understand how to do that yet." Roy gives the example of using two separate neural networks, one to detect objects that are cars and the other to detect objects that are red. It's harder to combine those two networks into one larger network that detects red cars than it would be if you were using a symbolic reasoning system based on structured rules with logical relationships. "Lots of people are working on this, but I haven't seen a real success that drives abstract reasoning of this kind."For the foreseeablefuture, ARL is making sure that its autonomous systems are safe and robust by keeping humans around for both higher-level reasoning and occasional low-level advice. Humans might not be directly in the loop at all times, but the idea is that humans and robots are more effective when working together as a team. When the most recent phase of the Robotics Collaborative Technology Alliance program began in 2009, Stump says, "we'd already had many years of being in Iraq and Afghanistan, where robots were often used as tools. We've been trying to figure out what we can do to transition robots from tools to acting more as teammates within the squad."RoMan gets a little bit of help when a human supervisor points out a region of the branch where grasping might be most effective. The robot doesn't have any fundamental knowledge about what a tree branch actually is, and this lack of world knowledge (what we think of as common sense) is a fundamental problem with autonomous systems of all kinds. Having a human leverage our vast experience into a small amount of guidance can make RoMan's job much easier. And indeed, this time RoMan manages to successfully grasp the branch and noisily haul it across the room.
Turning a robot into a good teammate can be difficult, because it can be tricky to find the right amount of autonomy. Too little and it would take most or all of the focus of one human to manage one robot, which may be appropriate in special situations like explosive-ordnance disposal but is otherwise not efficient. Too much autonomy and you'd start to have issues with trust, safety, and explainability.
"I think the level that we're looking for here is for robots to operate on the level of working dogs," explains Stump. "They understand exactly what we need them to do in limited circumstances, they have a small amount of flexibility and creativity if they are faced with novel circumstances, but we don't expect them to do creative problem-solving. And if they need help, they fall back on us."RoMan is not likelyto find itself out in the field on a mission anytime soon, even as part of a team with humans. It's very much a research platform. But the software being developed for RoMan and other robots at ARL, calledAdaptive Planner Parameter Learning (APPL), will likely be used first in autonomous driving, and later in more complex robotic systems that could include mobile manipulators like RoMan. APPL combines different machine-learning techniques (including inverse reinforcement learning and deep learning) arranged hierarchically underneath classical autonomous navigation systems. That allows high-level goals and constraints to be applied on top of lower-level programming. Humans can use teleoperated demonstrations, corrective interventions, and evaluative feedback to help robots adjust to new environments, while the robots can use unsupervised reinforcement learning to adjust their behavior parameters on the fly. The result is an autonomy system that can enjoy many of the benefits of machine learning, while also providing the kind of safety and explainability that the Army needs. With APPL, a learning-based system like RoMan can operate in predictable ways even under uncertainty, falling back on human tuning or human demonstration if it ends up in an environment that's too different from what it trained on.
It's tempting to look at the rapid progress of commercial and industrial autonomous systems (autonomous cars being just one example) and wonder why the Army seems to be somewhat behind the state of the art. But as Stump finds himself having to explain to Army generals, when it comes to autonomous systems, "there are lots of hard problems, but industry's hard problems are different from the Army's hard problems." The Army doesn't have the luxury of operating its robots in structured environments with lots of data, which is why ARL has put so much effort into APPL, and into maintaining a place for humans. Going forward, humans are likely to remain a key part of the autonomous framework that ARL is developing. "That's what we're trying to build with our robotics systems," Stump says. "That's our bumper sticker: 'From tools to teammates.' "This article appears in the October 2021 print issue as "Deep Learning Goes to Boot Camp."Special Report: The Great AI ReckoningREAD NEXT:7 Revealing Ways AIs FailOr see thefull reportfor more articles on the future of AI.
