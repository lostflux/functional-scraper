old id = 616
AI and Shared Prosperity Initiative - Partnership on AI
2021
https://partnershiponai.org/workstream/shared-prosperity

OUR WORK How We Work Programs Inclusive Research & Design AI & Media Integrity AI, Labor, and the Economy FTA & ABOUT ML Safety-Critical AI Workstreams Public Policy Impact Stories RESOURCES Blog Resource Library EVENTS ABOUT US About Us Mission, Vision, & Values Pillars Tenets Team Funding Press Careers PARTNERS OUR WORK How We Work Programs Inclusive Research & Design AI & Media Integrity AI, Labor, and the Economy FTA & ABOUT ML Safety-Critical AI Workstreams Public Policy Impact Stories RESOURCES Blog Resource Library EVENTS ABOUT US About Us Mission, Vision, & Values Pillars Tenets Team Funding Press Careers PARTNERS CONTACT × SEARCH Workstreams / AI, Labor, and the Economy AI and Shared Prosperity Initiative Identifying Topics Convening Stakeholders Collecting Insights Developing Resources Engaging Audiences Stay Informed Please fill required field.
Please fill required field.
Please fill required field.
please write the name of your organization in full Please fill required field.
Subscription completed successfully.
Validation error occurred, please confirm the fields and submit again.
Oops, Sorry. Something is wrong. Please try again later.
For any questions, email communications@partnershiponai.org.
Overview Initiative Outputs Impulse Talks and Past Events Updates Steering Committee Foundational Questions for the AI and Shared Prosperity Initiative Frequently Asked Questions Media Coverage Connect With PAI About This Work Overview The AI and Shared Prosperity Initiative (AI SPI) conducts research and gathers multidisciplinary input to develop and disseminate practical frameworks that AI-developing and -deploying companies should adopt to ensure that AI progress advances broadly shared prosperity, and not the economic betterment of a few to the detriment of many. We strive to equip our Partners with practical approaches for making AI development and deployment inclusive by design.
A multi-year initiative, the AI SPI explores ways to proactively guide AI advancement in the direction of expanding the economic prospects of workers, particularly those with limited opportunities for educational advancement. The initiative draws on a range of critical perspectives in its careful examination of the relationship between AI advancement and the distribution of economic opportunity, relying on input from workers, a multi-disciplinary body of thinkers from academia, the AI industry, civil society, and the broader public.
Initiative Outputs Research & Publications AI, Labor, and the Economy Guidelines for AI and Shared Prosperity Explore PAI’s Guidelines for AI and Shared Prosperity: tools to design and deploy AI systems in service of workers’ rights and well-being.
Research & Publications AI, Labor, and the Economy AI and Job Quality – Insights from Frontline Workers This report draws from workers’ insights to point the way toward a better future for workplace AI and provides guidance for key stakeholders who want to make a positive impact.
Research & Publications AI, Labor, and the Economy Governing AI to Advance Shared Prosperity Katya Klinova’s chapter from Oxford Handbook of AI Governance reviews factors giving AI R&D a labor-saving emphasis, and respective interventions.
Research & Publications AI, Labor, and the Economy Towards a Framework for Assessing the Labor Market Impact of AI Systems This paper by Katya Klinova and Anton Korinek from the proceedings of AAAI/ACM AI, Ethics, and Society 2021 Conference lays out a step-by-step heuristics AI developers can use to anticipate both direct and indirect ways in which their technology is likely to impact the demand for labor in the broader… Research & Publications AI, Labor, and the Economy Redesigning AI for Shared Prosperity: an Agenda The Agenda contains a proposal of shared prosperity targets for the AI industry: verifiable commitments to ensure that automation technologies are “good jobs positive.” Impulse Talks and Past Events Key ideas and questions at the heart of the Initiative in the words of its Steering Committee, Research Group, and contributing experts as shared during Steering Committee deliberations and public discussions hosted by PAI and our Partners.
Please accept preferences, statistics, marketing cookies to watch this video.
Please accept preferences, statistics, marketing cookies to watch this video.
In this Impulse Talk, Lama Nachman describes how AI can be used to go “beyond automation” to assist humans on the factory floor, at home, in the classroom, as well as scalably improve the quality of life for people with disabilities.
Please accept preferences, statistics, marketing cookies to watch this video.
In this Impulse Talk, Jody Medich explains how to employ cognitive and physical ergonomics to reduce the amount of specialized knowledge required for people to use AI to amplify their capabilities and earning potential.
Please accept preferences, statistics, marketing cookies to watch this video.
In this Impulse Talk, Shakir Mohamed uses insights of decoloniality to raise critical questions about technological development and power distribution, illuminating the need to reimagine the field of AI and to actively learn from affected communities.
Please accept preferences, statistics, marketing cookies to watch this video.
In this Impulse Talk, Daron Acemoğlu gives a sobering overview of the impact of automation on labor demand and poses urgent questions about the path AI advancement is taking, as well as the role and responsibilities of the AI development community.
Please accept preferences, statistics, marketing cookies to watch this video.
In this Impulse Talk, Anton Korinek describes a pressing need and a vision for steering AI advancement away from excessive automation. He concludes by outlining some of the questions that need to be answered in order to practically execute on that vision.
Please accept preferences, statistics, marketing cookies to watch this video.
Paloma Muñoz Quick and Dunstan Allison-Hope explain why human rights are a prerequisite for shared prosperity, and point out that human rights include civil, political, economic, social and cultural rights, and more.
Please accept preferences, statistics, marketing cookies to watch this video.
PAI’s Head of Labor and Economy programs Katya Klinova hosts a conversation with members of the AI and Shared Prosperity Initiative’s Steering Committee Updates Oct 12 2022 Event/Hosted by PAI Past Event AI, Labor, and the Economy/AI and Shared Prosperity Initiative Worker Insights & Charting a Better Path for Workplace AI Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative Drawing From Worker Insights to Chart a Better Path for Workplace AI Stephanie Bell Sep 28, 2022 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative What Workers Say About Workplace AI: In Conversation With PAI’s Stephanie Bell PAI Staff May 26, 2022 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative PAI Launches New Phase of Cooperative Initiative to Share Prosperity of AI With All Communities PAI Staff May 17, 2021 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative How Many Jobs Will AI Destroy? As Many As We Tell It To.
Stephanie Bell Dec 16, 2020 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative Welcoming The AI Shared Prosperity Initiative Steering Committee Katya Klinova Sep 15, 2020 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative What’s the responsibility of the AI industry in ensuring that AI serves to create an inclusive… Katya Klinova Jun 23, 2020 Blog AI, Labor, and the Economy/AI and Shared Prosperity Initiative What are AI’s Real-World Impacts on Labor and the Economy? PAI Staff Apr 30, 2019 Steering Committee Daron Acemoglu Institute Professor Of Economics MIT Dunstan Allison-Hope Vice President Business for Social Responsibility Juana Catalina Becerra Sandoval Visiting Scholar, Responsible & Inclusive Tech IBM Dean Carignan Chief of Staff Office of the Chief Scientific Officer, Microsoft Andrea Dehlendorf Senior Advisor and Co-Founder United for Respect Arturo Franco Senior Vice President Mastercard Center for Inclusive Growth Jessica Fulton Vice President Joint Center for Political & Economic Studies Ryan Gerety Senior Advisor United for Respect Deborah Greenfield Former Deputy Director-General for Policy International Labour Organization Anton Korinek Professor of Economics University of Virginia Andrew Kortina Co-founder venmo.com & fin.com Abbie Langston Director, Equitable Economy PolicyLink Jody Medich CEO, Founder Superhuman-X Pamela Mishkin Policy Staff Member OpenAI Shakir Mohamed Senior Staff Scientist Deepmind Grace Mutung’u Project Head Open Society Foundation Lama Nachman Intel Fellow & Director Anticipatory Computing Lab Intel Reema Nanavati Executive Director Self Employed Women’s Association Aiha Nguyen Program Director Labor Futures Initiative Data & Society Research Institute Rahul Panicker Co-founder and CEO Tendril AI Damon Silvers Senior Advisor AFL-CIO Sarah Treuhaft Senior Director of Policy and Partnerships Institute on Race, Power, and Political Economy Jordan Usdan Senior Director, Strategy & Innovation Office of the CTO, Microsoft × Testimonials “Given that Black, Latinx, and Indigenous workers are particularly vulnerable to automation risk, AI companies must assess—and address—the racial equity impacts of their decisions. I hope the Initiative provides companies with actionable tools to steer their activities in a way that shrinks rather than increases America’s racial wealth gap.” Sarah Treuhaft PolicyLink “Are we investing in the ‘right’ type of AI for generating jobs and a broadly shared prosperity? I’m looking forward to the Initiative tackling this important question.” Daron Acemoglu Massachusetts Institute of Technology “We have the power to actively steer the path of technological progress in AI so as to shape the future that we want to live in. AI SPI takes the crucial step of translating this ambition into a tangible framework to guide the actions of innovators and entrepreneurs towards broadly shared prosperity.” Anton Korinek University of Virginia “If AI begins to have an outsize-impact on the economy, then AI developers will need to think in further detail about their responsibility to create a thriving, more equitable society. The AI SPI will hopefully give AI developers a sense of the different actions they can take to make a more equitable world.” Jack Clark OpenAI “AI’s current focus on competing with humans is alarming but not the only one possible: the AI and Shared Prosperity Initiative’s Agenda and the latest Boston Review issue suggest concrete steps the industry can take to modify its approach.” Lama Nachman Intel “AI and data have become new pillars impacting Future of Work and workers. Therefore the Agenda is very relevant and crucial. It puts workers as major stakeholders in governance, design of Artificial Intelligence technologies and tools in the supply chain. This will lead to equality and equitable distribution of risks and profits. The Agenda also refers to mechanisms to enable the informal sector workers to access, design and participate in the governance of AI.” Reema Nanavaty Self-Employed Women’s Association Foundational Questions for the AI and Shared Prosperity Initiative The AI SPI is founded on the belief that the path of technological advancement is not predetermined; collectively, society can actively shape its technological future with a focus on shared prosperity.
The AI and Shared Prosperity Initiative’s work will begin by investigating three primary groups of questions: Defining specific objectives an AI industry actor should pursue to contribute to shared prosperity.
What would be tangibly different about a company that ensures its AI development and deployment strategy is inclusive by design? Developing a way to measure whether progress is being made towards these objectives.
How can a given actor developing or deploying AI quantify whether it is advancing towards its objectives around contributing to shared prosperity? Developing practical frameworks, pathways, and policies that companies can adopt to advance towards their objectives, without replacing or hindering future regulation.
 The frameworks should equip the AI industry actors with practical approaches for analyzing questions such as: How can a given private sector actor anticipate the direct and indirect economic impact of their AI development and deployment on a range of stakeholders? In particular, how will their actions affect the structural features of the economy that make it more or less inclusive? How can they ensure their business activity does not shrink the economic prospects of vulnerable groups or even entire nations, but expands those? What processes should be incorporated into the planning and development cycles of AI projects to account for economic consequences? While addressing the three groups of questions above is necessary, it is not sufficient. In order to steer AI development towards an inclusive economic future, we must also address the question of how to motivate private sector actors to commit to ensuring that AI advances broadly shared prosperity. Nevertheless, decision infrastructure and concrete understanding of desirable policies are necessary if such commitment is to be acted upon. For example, no business would have been able to commit to reducing greenhouse gas emissions if emissions measurement frameworks had not been invented, and if the determination that emission reductions are desirable in the first place not been made.
Frequently Asked Questions Initiative Details How is the AI and Shared Prosperity Initiative different from existing Responsible AI research efforts? There are a number of existing efforts that aim to address some of the risks posed to economic inclusion by the advancement of AI. Notably, algorithmic fairness research tackles questions of algorithmic bias which can manifest in many domains with direct link to income and power distribution, such as hiring, access to credit, academic admissions, housing allocations, etc. While not leaving out the questions around potential exclusions produced or exacerbated by algorithmic bias, the AI SPI will specifically emphasize a relatively neglected set of questions around proactively designing AI to expand economic prospects and earning potential of workers with fewer opportunities for educational advancement. Thus, the Initiative will examine the relationship between AI advancement and the distribution of economic opportunity, which is not central to the algorithmic fairness literature.
Why focus specifically on the responsibility of the private sector? The focus of the AI SPI is on developing responsible behavior strategies for private sector actors in the AI space. We recognize that, aside from the industry’s behavior and innovators’ ideas, there are many other aspects that influence the path of AI technology progress, including regulatory regimes, public R&D, investment in human capital, tax incentives, and other factors largely determined by governments. However, the AI SPI focuses on the responsibilities of private sector actors for the following reasons: Most of the tangible applications of AI systems that affect our every-day lives are being developed by the private sector, and so have been many of the path-breaking conceptual advances in AI in recent years.
Many developers and entrepreneurs in the AI space are interested in maximizing their positive impact on the world and seek frameworks for thinking about the effects of their actions on the labor market and economic prospects of the least advantaged societal groups and nations.
AI is poised to impact the economic future worldwide, therefore the AI SPI is global in scope. Government policy is usually focused on the welfare of a single nation, while companies developing and deploying AI often operate globally and hence need to think about the global impact of their operations.
Research and public discussion of government policy for AI and the Future of Work are rapidly expanding, while the question of corporate responsibility around ensuring that AI serves shared prosperity remains relatively neglected.
That said, the importance of democratic governance for steering the progress of AI in socially beneficial directions cannot be overestimated. The AI SPI does not seek to in any way replace or impede any future regulation. Private sector actors should not be deciding the global economic future, a democratic process should. Simultaneously, we recognize that the everyday decisions around AI development and deployment do have far-reaching consequences for the distribution of economic opportunity and thus must be approached responsibly and with these consequences in mind. Guidance on how to systematically implement such an approach is currently lacking; this is the gap that the AI SPI is looking to bridge.
Is it realistic to expect profit-oriented companies to care about shared prosperity? Investing in making sure a company’s business activity supports shared prosperity and avoids putting entire groups at an economic disadvantage is not only the ethical thing to do, it also provides companies with a number of ancillary benefits: Supporting Employer Brand Reputation. Talent is a key asset in the AI business; top AI talent usually enjoys being able to choose what employer they want to work for. Ethical values of the employer are definitely not the only factor influencing that choice, but a responsible approach to the question of economic impact would be valued by altruistically-oriented prospective employees. This factor speaks to a broader economic incentive: a bad brand reputation can cost employers as much as 10% more per hire.
3 According to a UK survey by doteveryone, over 1 in 4 tech workers “have seen decisions made about a technology that they felt could have negative consequences for people or society. Nearly one in five (18%) of those went on to leave their companies as a result.” 4 Getting a Head-start Preparing for the Future Regulatory Requirements. Mandatory disclosures of human rights impacts (including economic rights impacts), as well as other measures to advance business respect for human rights are becoming more widespread and this trend is expected to continue.
5 Meeting Investor Expectations. Considering environmental, social and governance factors (ESG) is becoming common for investors who are increasingly seeking sustainable business practices and paying growing attention to long-term value.
5 Supporting Consumer Brand Reputation. Losing consumer trust is a significant risk for many businesses in the AI industry. The attention consumers pay to the environmental and social impacts and supply chain practices of major brands is spotty, but not entirely absent. We believe it is just a matter of time before consumer attention will also turn towards the economic impact of AI companies, and hope to help speed up the arrival of that moment.
Aside from that, many of the leaders in the AI Research and Development space share the commitment for supporting human flourishing, and actively look for ethical and responsible ways to grow their business.
How can I get involved in the Initiative? We invite stakeholders and visionary thinkers from a broad range of disciplines to join this effort—workers, social scientists, technologists, civil society, community and labor organizers, human rights advocates, and more. If you are interested in contributing your ideas, expertise or lived experience, or know someone whose perspective we should seek to inform how we conduct this work, please get in touch with us.
Reasons to Pursue the Initiative Why think deliberately about the direction of AI progress over letting the market forces define its path? AI advancement has the potential to vastly increase our shared prosperity. But this outcome is not guaranteed and is unlikely to happen by itself.
6 Market forces tend to favor efficiency but do not care about how the gains from progress are distributed.
 Technological progress in recent decades has reduced the labor share of income even though overall income has risen. Empirical evidence from the US points out that while tasks displaced and reinstated by technological change balanced out during the four decades following WWII, the later three decades have seen task displacement significantly outpacing reinstatement.
7 AI is poised to continue this trend, and may accelerate it.
Moreover, market prices are often significantly distorted and do not necessarily reflect society’s true scarcities; positive and negative externalities abound and might lead innovators to create businesses that are profitable, but not socially beneficial or just. A classic example is a carbon-emitting facility whose beneficiaries do not internalize the full societal costs of environmental damage. Tax regimes often further distort incentives for innovators. For example, the current tax regime favoring capital over labor, 8 combined with labor mobility restrictions, 9 creates strong incentives to develop AI applications focused disproportionately on labor-saving use cases. If these conditions remain in place, AI advancement might bring about levels of automation well above socially optimal, to the disproportionate detriment of the economically vulnerable populations around the world.
These risks are becoming increasingly recognized by the growing body of scholarship on the “future of work”. However, the current debate places a disproportionate burden of adjustment to the changing technological landscape on governments, educational institutions, and workers themselves. Questions around the role and responsibility of the AI industry remain relatively neglected.
Hasn’t technological progress always led to automation of labor? Isn’t that how we came to enjoy our standard of living and all the conveniences of modern life? There is nothing wrong or bad with automation of tasks previously done by humans; but automation is one of the key mechanisms through which technological change redistributes wealth and resources. Such redistributions can profoundly impact a large number of people, 10 and thus the question of what the private sector actors in the AI space can do to ensure the economically vulnerable populations around the world are not made worse off in the process is an important one.
Along with automating human tasks, technological change often introduces new tasks that are valued in the labor market, creating new income opportunities for people.
While it is reasonable to expect that AI will continue the trend of automating some human tasks while also creating new ones, a few aspects of the process will be important determinants of whether or not workers (and the less privileged among them in particular) will lose out as a result: Relative volume of tasks getting displaced and reinstated.
As has been stated above, in the last three decades the US have seen task displacement significantly outpacing reinstatement.
7 AI is poised to continue this trend, if not accelerate it.
Relative skills requirements of tasks displaced and reinstated.
If the new tasks that AI advancement creates require a much higher level of skills or educational attainment compared to tasks being automated, these new tasks might be of little relief for many workers whose jobs get displaced by automation.
A type of technological change that disproportionately benefits those endowed with comparatively high levels of skills and education attainment is called skill-biased. The problem with skill-biased technological change is that it is poised to exacerbate society’s structural inequalities, especially in countries where levels and quality of educational attainment are correlated with wealth.
Not all technological change is skill-biased. There is nothing inherent about AI that forces its applications to be skill-biased, or even labor-saving. One of the focus areas of the AI SPI is exploring how AI can be used to augment human’s productivity and expand the economic possibilities of people with limited access to training in a world where education remains prohibitively costly or inaccessible for many.
Can’t the potential rise in inequality be addressed by Universal Basic Income or re-training people who do not have the skills valued by the new economy? The AI and Shared Prosperity Initiative does not try to discourage efforts to expand social safety nets or improve education; these policies are extremely important. However, they may not be sufficient to ensure an inclusive economic future.
We believe that it is important to complement these efforts since both the expansion of safety nets and better education also face significant headwinds. It is unclear if a global and robust system of taxes and transfers that would pay for a UBI is feasible. Moreover, it is unclear if more and more investment in education will be able to overcome the trends of recent decades that led to income losses for lesser-educated workers. This makes the need for developing AI applications that augment humans (vs. displacing them) even more pressing. Therefore, the AI SPI is founded on a question: how can we make AI that matches the skills of humans, instead of asking humans to match the ever-changing skills requirements of economies being reshaped by AI? Why is PAI investing in the AI SPI? Translating Responsible AI principles into concrete practices is an important part of PAI’s work and mission. Dozens of organizations developing and deploying AI have published AI principles, many of them listing supporting and enabling an inclusive economy, or benefitting all. Yet an anticipation of AI advancement generating “left behind” groups remains widely shared. To deliver on its mandate, PAI must help bridge this gap. We welcome and encourage other organizations to join the effort or look at the questions the AI SPI is posing on their own.
References [1] Rodrik, D. 2020. “Technology for All”. Project Syndicate (March 6, 2020) https://www.project-syndicate.org/commentary/shaping-technological-innovation-to-serve-society-by-dani-rodrik-2020-03 [2] Acemoglu, D. and Restrepo, P., 2019. The wrong kind of AI? Artificial intelligence and the future of labor demand (No. w25682). National Bureau of Economic Research.
https://www.econstor.eu/bitstream/10419/196790/1/dp12292.pdf [3] Burgess, W., 2016. A Bad Reputation Costs a Company at Least 10% More Per Hire. Harvard Business Review.
https://hbr.org/2016/03/a-bad-reputation-costs-company-at-least-10-more-per-hire [4] Miller, C. and Coldicott, R., 2019. People, power and technology: The tech workers’ view. https://doteveryone. org. uk/report/workersview.
[5] Bağlayan, B., Landau, I., McVey, M. and Wodajo, K., 2018. Good Business: The Economic Case for Protecting Human Rights. Available at SSRN 3304959.
[6] Brynjolfsson, E. and McAfee, A., 2011. Race against the machine: How the digital revolution is accelerating innovation, driving productivity, and irreversibly transforming employment and the economy. Brynjolfsson and McAfee.
[7] Acemoglu, D. and Restrepo, P., 2019. Automation and new tasks: how technology displaces and reinstates labor. Journal of Economic Perspectives, 33(2), pp.3-30.
https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.33.2.3 [8] Acemoglu, D., Manera, A. and Restrepo, P., 2020. Does the US Tax Code Favor Automation? (No. w27052). National Bureau of Economic Research.
https://www.nber.org/papers/w27052 [9] Pritchett, L., 2020. The future of jobs is facing one, maybe two, of the biggest price distortions ever. Middle East Development Journal, pp.1-26. https://erf.org.eg/wp-content/uploads/2019/12/1370.pdf [10] Korinek, A., 2019. Integrating Ethical Values and Economic Value to Steer Progress in Artificial Intelligence (No. w26130). National Bureau of Economic Research.
https://www.nber.org/papers/w26130 Media Coverage Article Hollywood’s Screenwriters Are Right to Fear AI AI is a key issue in the current writer’s strike in Hollywood, with the Writers Guild making specific proposals on regulating the use of AI.
Will Bedingfield May 08, 2023 Article Here’s How U.S. Workers And Employers Can Co-Design Workplace Tech Automation is not coming for our jobs anytime soon, but it is coming for our tasks. Now is the time to focus on job quality.
Shalin Jyotishi Jan 09, 2023 Article How AI Can Improve Job Quality AI can either improve job quality or make it worse. A new study from PAI shares insights from workers on how employers can ensure that AI makes jobs better.
Shalin Jyotishi Nov 16, 2022 Article We can shape policies to steer AI towards inclusive growth. Here’s how How do we shape policies so AI works for shared prosperity and inclusive growth? PAI’s Head of AI, Labor, and the Economy, Katya Klinova, explains how policymakers can make this goal a reality.
Katya Klinova Oct 06, 2021 Article AI for All: Experts Weigh In on Expanding AI’s Shared Prosperity and Reducing Potential Harms AI experts say policymakers, technologists, and business leaders must work together to ensure that the benefits of artificial intelligence are spread to all, while unintended harms are mitigated.
Michael Richards May 19, 2022 Article How to solve AI’s inequality problem New digital technologies are exacerbating inequality. Here’s how scientists creating AI can make better choices.
David Rotman Apr 19, 2022 Podcast Responsible AI Economics with Katya Klinova & The Partnership on AI In recent years, the focus of AI developers has been to implement technologies that replace basic human labor. Katya Klinova shares why this is the wrong application for AI.
How AI Happens Oct 28, 2021 OUR WORK RESOURCES EVENTS ABOUT US PARTNERS © 2023 Partnership on AI | All Rights Reserved Transparency and Governance Privacy Policy
