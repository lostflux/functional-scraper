old id = 1692
This Brain-Controlled Robotic Arm Can Twist, Grasp‚Äîand Feel | WIRED
2021
https://www.wired.com/story/this-brain-controlled-robotic-arm-can-twist-grasp-and-feel

Open Navigation Menu To revist this article, visit My Profile, then View saved stories.
Close Alert Backchannel Business Culture Gear Ideas Science Security Merch To revist this article, visit My Profile, then View saved stories.
Close Alert Search Backchannel Business Culture Gear Ideas Science Security Merch Podcasts Video Artificial Intelligence Climate Games Newsletters Magazine Events Wired Insider Jobs Coupons Max G. Levy Science This Brain-Controlled Robotic Arm Can Twist, Grasp‚Äîand Feel Photograph: Getty Images Save this story Save Save this story Save Application Human-computer interaction End User Consumer Research Sector Health care Source Data Sensors Technology Robotics Nathan Copeland was 18 years old when he was paralyzed by a car accident in 2004. He lost his ability to move and feel most of his body, although he does retain a bit of sensation in his wrists and a few fingers, and he has some movement in his shoulders. While in the hospital, he joined a registry for experimental research. About six years ago, he got a call: Would you like to join our study? A team at the University of Pittsburgh needed a volunteer to test whether a person could learn to control a robotic arm simply by thinking about it. This kind of research into brain-computer interfaces has been used to explore everything from restoring motion to people with paralysis to developing a new generation of prosthetic limbs to turning thoughts into text.
Companies like Kernel and Elon Musk‚Äôs Neuralink are popularizing the idea that small electrodes implanted in the brain can read electrical activity and write data onto a computer. (No, you won‚Äôt be downloading and replaying memories anytime soon.) Copeland was excited. ‚ÄúThe inclusion criteria for studies like this is very small,‚Äù he recalls. You have to have the right injury, the right condition, and even live near the right medical hub. ‚ÄúI thought from the beginning: I can do it, I'm able to‚Äîso how can I not help push the science forward?‚Äù He soon underwent surgery in which doctors tacked lentil-sized electrode arrays onto his motor cortex and somatosensory cortex. These would read the electrical patterns of his brain activity, showing his intentions to move his wrist and fingers. Through something called a brain-computer interface (BCI), these impulses would be translated to control a robotic limb that sat atop a vertical stand beside him in the lab. Copeland began making the commute from his home in Dunbar, Pennsylvania, to Pittsburgh three times a week for lab tests. After three sessions he could make the robot move spheres and grasp cubes‚Äîall just by thinking.
But that was just the beginning. In a study published today in Science, the team reported that Copeland could feel whatever the robotic hand touched‚Äîexperiencing the sensation in his own fingers. Over the past few years, he had learned to control the hand with his thoughts while watching what it was doing in response. But once the researchers gave him touch feedback, he absolutely kicked ass, doubling his speed at performing tasks. It‚Äôs the first time a BCI for a robotic prosthetic has integrated motion commands and touch in real time. And it‚Äôs a big step toward showing just how BCIs might help circumvent the limits of paralysis.
Courtesy of UPMC/Pitt Health Sciences Media Relations Touch is important for restoring mobility, says study author Jennifer Collinger, a biomedical engineer at the University of Pittsburgh, because to take maximum advantage of future BCI prosthetics or BCI-stimulated limbs a user would need real-time tactile feedback from whatever their hand (or the robotic hand) is manipulating. The way prosthetics work now, people can shortcut around a lack of touch by seeing whether stuff is being gripped by the robotic fingers, but eyeballing is less helpful when the object is slippery, moving, or just out of sight. In everyday life, says Collinger, ‚Äúyou don't necessarily rely on vision for a lot of the things that you do. When you're interacting with objects, you rely on your sense of touch.‚Äù The brain is bidirectional: It takes information in while also sending signals out to the rest of the body, telling it to act. Even a motion that seems as straightforward as grabbing a cup calls on your brain to both command your hand muscles and listen to the nerves in your fingers.
Because Copeland‚Äôs brain hadn‚Äôt been injured in his accident, it could still‚Äîin theory‚Äîmanage this dialog of inputs and outputs. But most of the electrical messages from the nerves in his body weren‚Äôt reaching the brain. When the Pittsburgh team recruited him to their study, they wanted to engineer a workaround. They believed that a paralyzed person‚Äôs brain could both stimulate a robotic arm and be stimulated by electrical signals from it, ultimately interpreting that stimulation as the feeling of being touched on their own hand. The challenge was making it all feel natural. The robotic wrist should twist when Copeland intended it to twist; the hand should close when he intended to grab; and when the robotic pinkie touched a hard object, Copeland should feel it in his own pinkie.
Gear Everything Apple Announced at Today‚Äôs Hardware Event Brenda Stolyar Business Sam Bankman-Fried Built a Crypto Paradise in the Bahamas‚ÄîNow He's a Bad Memory Joel Khalili Science Everyone Was Wrong About Why Cats Purr Jorge Garay Security They Cracked the Code to a Locked USB Drive Worth $235 Million in Bitcoin. Then It Got Weird Andy Greenberg Of the four micro-electrode arrays implanted in Copeland‚Äôs brain, two grids read movement intentions from his motor cortex to command the robotic arm, and two grids stimulate his sensory system. From the start, the research team knew that they could use the BCI to create tactile sensation for Copeland simply by delivering electrical current to those electrodes‚Äîno actual touching or robotics required.
To build the system, researchers took advantage of the fact that Copeland retains some sensation in his right thumb, index, and middle fingers. The researchers rubbed a Q-tip there while he sat in a magnetic brain scanner, and they found which specific contours of the brain correspond to those fingers. The researchers then decoded his intentions to move by recording brain activity from individual electrodes while he imagined specific movements. And when they switched on the current to specific electrodes in his sensory system, he felt it. To him, the sensation seems like it‚Äôs coming from the base of his fingers, near the top of his right palm. It can feel like natural pressure or warmth, or weird tingling‚Äîbut he‚Äôs never experienced any pain. ‚ÄúI've actually just stared at my hand while that was going on like, ‚ÄòMan, that really feels like someone could be poking right there,‚Äô‚Äù Copeland says.
Once they had established that Copeland could experience these sensations, and that the researchers knew which brain areas to stimulate to create feeling in different parts of his hands, the next step was just to get Copeland used to controlling the robot arm. He and the research team set up a training room at the lab, hanging up posters of Pac Man and cat memes. Three days a week, a researcher would hook the electrode connector from his scalp to a suite of cables and computers, and then they would time him as he grasped blocks and spheres, moving them from left to right. Over a couple years, he got pretty damn good. He even demonstrated the system for then president Barack Obama.
But then, says Collinger, ‚ÄúHe kind of plateaued at his high level of performance.‚Äù A nonparalyzed person would need about five seconds to complete an object-moving task. Copeland could sometimes do it in six seconds, but his median time was around 20.
Gear Everything Apple Announced at Today‚Äôs Hardware Event Brenda Stolyar Business Sam Bankman-Fried Built a Crypto Paradise in the Bahamas‚ÄîNow He's a Bad Memory Joel Khalili Science Everyone Was Wrong About Why Cats Purr Jorge Garay Security They Cracked the Code to a Locked USB Drive Worth $235 Million in Bitcoin. Then It Got Weird Andy Greenberg To get him over the hump, it was time to try giving him real-time touch feedback from the robot arm.
Human fingers sense pressure, and the resulting electrical signals zip along thread-like axons from the hand to the brain. The team mirrored that sequence by putting sensors on the robotic fingertips. But objects don‚Äôt always touch the fingertips, so a more reliable signal had to come from elsewhere: torque sensors at the base of the mechanical digits.
Think of a robotic finger as a lever with a hinge on just one end where it connects to the robot‚Äôs palm. The robotic fingers want to stay put unless the BCI is telling them to move. Any nudge forward or back along the length of the finger will register a rotational force at that hinge. ‚ÄúIt is maybe not the most obvious sensor to use,‚Äù says Robert Gaunt, who co-led the study with Collinger, but it proved to be very reliable. Electrical signals from that torque sensor flash to the BCI, which then stimulates the implanted brain electrode linked to Copeland‚Äôs corresponding finger.
So when the robot‚Äôs index finger grazed a block, Copeland felt a gentle tap on his own index finger. When he gripped a hard block, the firm resistance occurring at the robotic joint gave him a stronger sensation. Routing this sense of touch directly to Copeland‚Äôs hand meant he didn‚Äôt have to rely so much on vision. For the first time, he could feel his way through the robot tasks. ‚ÄúIt just worked,‚Äù Copeland says. ‚ÄúThe first time we did it, I was like, magically better somehow.‚Äù In fact, with this new touch information, Copeland doubled his speed completing mobility tasks. ‚ÄúWe're not talking about a few hundred milliseconds of improvement,‚Äù says Gaunt. ‚ÄúWe're talking about a task that took him 20 seconds to do now takes 10 seconds to do.‚Äù Courtesy of UPMC/Pitt Health Sciences Media Relations Part of that, Gaunt says, is because it eliminated Copeland‚Äôs hesitation: "If you can't feel your hand, you go to pick something up and spend a lot more time fumbling with the object trying to make sure.
I have it in my hand? Yes.
I'm sure that I have it in? OK. So now I can pick it up and move it." Actually producing realistic sensory signals like this is ‚Äúa major win,‚Äù says Bolu Ajiboye, a neural engineer from Case Western University who was not involved with the study. ‚ÄúIt suggests that we can begin to at least approach full mimicry of natural and intact movements.‚Äù Gear Everything Apple Announced at Today‚Äôs Hardware Event Brenda Stolyar Business Sam Bankman-Fried Built a Crypto Paradise in the Bahamas‚ÄîNow He's a Bad Memory Joel Khalili Science Everyone Was Wrong About Why Cats Purr Jorge Garay Security They Cracked the Code to a Locked USB Drive Worth $235 Million in Bitcoin. Then It Got Weird Andy Greenberg And it‚Äôs important, he says, that the action happens without any noticeable lag. The brain operates with a lag of about 30 milliseconds (the time it takes for impulses to travel from hand to brain). But the robot communicates signals to the BCI every 20 milliseconds. That underpins one of the most important roles of touch in this advance, according to Ajiboye, because it means that the user can feel the robot hand‚Äôs actions in real time. And that feeling registers much faster than sight. Vision is actually the slowest form of feedback; processing sight takes around 100 to 300 milliseconds. Imagine trying to grip a slippery cup. ‚ÄúIf the only way that you knew it was slipping out of your hand was because you could see it,‚Äù Ajiboye says, ‚Äúyou‚Äôd drop the cup.‚Äù Since it‚Äôs an early proof of concept, the system has some limitations, like not being ready for home use. Copeland has to come into the lab to operate the robotic arm; he can‚Äôt wear it or take it home, although the team has given him a pared-down BCI that he can use to control his personal computer. ‚ÄúI played Sega Genesis emulators,‚Äù Copeland says, ‚ÄúAnd I actually ended up drawing a cat, which I just turned into an NFT.
‚Äù It also relies on a wired connection. ‚ÄúFor me, the threshold would have to be a wireless system,‚Äù says Rob Wudlick, a project manager at the University of Minnesota's rehabilitation medicine department who became paralyzed a decade ago. Still, he‚Äôs cautiously optimistic about the potential for BCIs, even ones that require the use of robotic arms, to help people depend less on caregivers. ‚ÄúBeing able to control a robot to give yourself water is a huge thing,‚Äù Wudlick says. ‚ÄúThe key priority is building my independence back.‚Äù Gaunt‚Äôs team is now investigating why Copeland's sensation doesn‚Äôt always feel natural, and how to best control grasping force for delicate objects or more complicated tasks. Right now, the focus is still on human-like robot arms. But they envision adapting the approach to stimulating people‚Äôs own limbs into action, an idea that‚Äôs been tried in other labs , or routing signals to and from exoskeletons. ‚ÄúIf you have a weak grasp,‚Äù says Gaunt, ‚Äúyou could imagine using an exoskeleton glove to augment that power‚Äîhelp you open your hand, help you close your hand so you can make a firm enough grasp to hold on to an object without dropping it.‚Äù The thing about the brain, then, is that it decodes intentions and reroutes commands from whatever hardware, or body, you throw at it. It‚Äôs bound to the flesh, but not constrained by it.
üì© The latest on tech, science, and more: Get our newsletters ! The 60-year-old scientific screwup that helped Covid kill The cicadas are coming.
Let‚Äôs eat them ! Decades-old flaws affect almost every Wi-Fi device How to take a slick, professional headshot with your phone What a crossword AI reveals about humans‚Äô way with words üëÅÔ∏è Explore AI like never before with our new database üéÆ WIRED Games: Get the latest tips, reviews, and more ‚ú® Optimize your home life with our Gear team‚Äôs best picks, from robot vacuums to affordable mattresses to smart speakers Contributor X Topics robotics prosthetics Neuroscience brains health perception robots Neha Mukherjee Dell Cameron Grace Browne Ben Brubaker Elizabeth Finkel Celia Ford Amit Katwala Emily Mullin Facebook X Pinterest YouTube Instagram Tiktok More From WIRED Subscribe Newsletters Mattresses Reviews FAQ Wired Staff Coupons Editorial Standards Archive Contact Advertise Contact Us Customer Care Jobs Press Center RSS Accessibility Help Cond√© Nast Store Do Not Sell My Personal Info ¬© 2023 Cond√© Nast. All rights reserved. Use of this site constitutes acceptance of our User Agreement and Privacy Policy and Cookie Statement and Your California Privacy Rights.
WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond√© Nast.
Ad Choices Select international site United States LargeChevron UK Italia Jap√≥n
