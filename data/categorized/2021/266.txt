old id = 792
Attrition in AI: What the Folks Who Left Have to Say About the Field | by Partnership on AI | AI&. | Medium
2021
https://medium.com/partnership-on-ai/attrition-in-ai-what-the-folks-who-left-have-to-say-about-the-field-55861a448dc6

Attrition in AI: What the Folks Who Left Have to Say About the Field Partnership on AI · Follow Published in AI&.
· 6 min read · Oct 19, 2021 -- Listen Share By Jeffrey Brown After three years working for a tech company that names diversity and inclusion as core values, Jessica recently quit. A machine learning engineer with a PhD. in computer science from a historically excluded group, she might seem like just the kind of person her former employer has pledged to support. Jessica, however, has a more complicated story to tell about her experience inside the company. “Jessica” is a composite based on the experiences of many different individuals in the AI industry, but by listening to her story and those of people like her, we can gain important insight about diversity in the AI field.
The tech industry’s “diversity problem” boils down to the inability to recruit and retain talent that represents the diversity of product users and other individuals and communities affected by these technologies. This is particularly troubling in the AI field, which has disproportionately harmed people of color. Organizations have often decried the “pipeline problem,” or the lack of available diverse talent.
But what happens when this diverse talent works for organizations where no one else looks like them or shares their background or experiences? This question, among others, is the subject of “Beyond the Pipeline: Addressing Attrition as a Barrier to Diversity in AI,” a forthcoming, interview-based study looking at attrition in the AI field.
 This blog post is part of a three-part series covering (respectively) the methods, findings, and recommendations of that study by the Partnership on AI’s (PAI) Diversity, Equity, and Inclusion (DEI) Workstream.
 In the first blog post , we met “Jessica,” a composite individual whose experiences represent common themes reported by the managers, people working in DEI, and folks who identified as belonging to historically excluded identities we spoke to. This time, we’ll be talking about her experiences within the AI field and broader themes derived from the in-depth interviews we conducted.
Jessica’s Story When interviewed about her time at her former company, Jessica reported a largely positive experience with her direct team, appreciating how it really fostered interdisciplinary collaboration. She said she got along particularly well with her manager, who could relate to her experience as a woman from a historically marginalized background working in tech. Despite this support system, however, she repeatedly ran into roadblocks from those higher up in the company, from microaggressions to systemic barriers like being refused promotion. According to Jessica, she brought these up to her manager who always supported her, but even her manager faced barriers to advancing in her own career at the company.
Jessica had always received glowing praise from her immediate manager, but the most recent promotion process left her career at a standstill, despite her manager advocating strongly for her to the VP and senior management. Frustrated by the process and the uphill battle to get her work recognized and respected outside of her team, she told interviewers that the best choice for herself became handing in her resignation letter a few weeks into the spring.
For our study, we interviewed over 40 folks like Jessica who worked in AI or within diversity initiatives at tech companies.
The primary researcher asked Jessica questions like “Have you ever considered leaving your current team? Organization? The field of AI?” and “What has your organization done to make the workplace more inclusive?” The researchers distilled the responses into several themes. The themes could be divided into experiences that were interpersonal and systemic, both positive and negative. We will highlight some of these below, organized under the three domains — attrition, organization culture and climate, and efforts to increase inclusion — that the researchers focused on.
Why Did They Leave? The folks that we interviewed cited a variety of reasons for leaving the teams or organizations that they worked for.
Some said that they went into the AI field to solve difficult problems using AI technology, only to be disappointed by companies that cared more about the bottom line than about making a positive impact benefitting real people.
Like Jessica, several participants described wanting to work on interdisciplinary teams and becoming frustrated when some of their proposed projects were disregarded by leaders who questioned the benefit of those projects to the company. This frustration was often compounded by difficulties these workers faced when trying to convince managers of the importance of working toward more equitable outcomes for marginalized communities affected by AI technology.
Workers also reported seeing actions within their companies that betrayed stated commitments to diversity and inclusion.
Some of these issues were systemic, like opaque promotion processes, a lack of communication of expectations during training, or a lack of clear paths for growth within organizations. Others were interpersonal, like being talked over in meetings, subtle insults based on stereotypes, or lack of recognition for contributions. Interviewed workers said that their managers were important advocates for them in both of these circumstances, but that managers only had a limited amount of power to fight company leadership that mainly consisted of people from the dominant White upper middle class that ultimately did not see systemic barriers as more important than company profits. Many participants spoke about a strong need for career growth within an interdisciplinary framework on an AI team. Their experiences on AI teams and within their organizations often did not meet this need and influenced their decisions to leave.
Participants had similar things to say about the culture of their AI teams and the broader organizations that they worked for.
Many started off by saying how positive and “nice” their teammates were, and how willing they were to collaborate and help each other. This individual collegiality, however, was often superseded by negative organizational culture.
This manifested as instances of sexism and prejudice, whether as microaggressions or more overt examples of discrimination. Interviewees described hearing subtle, negative comments that questioned their technical skills in AI. Participants in technical roles also questioned whether they belonged in the field at all and sought teams that were focused more on policy or AI ethics. Some participants who were in non-technical roles such as policy, marketing, or AI ethics, found others questioning their very presence in making decisions in areas that they were competent in because they lacked the technical credentials. Especially for female or gender-fluid participants, these micro- and macro-aggressions ran against the motivation to pursue a career specifically in the field of AI, and were enough to result in decisions to leave their teams or companies altogether.
A common thread through participant interviews was the importance of managers in fostering affirming and inclusive culture.
We spoke to workers who were on interdisciplinary teams whose managers validated and affirmed their personal and professional identities, and who made sure to support their careers despite friction from upper management. Participants praised managers who advocated for their reports despite others trying to speak over them in meetings or invalidating their expertise. The managers that we spoke to echoed these statements, and some talked about facing the same challenges that their reports experienced while progressing their careers in the AI field.
What Is Being Done? All participants, whether they were managers of AI teams, working in DEI-specific roles, or workers on AI teams, said that their organizations were actively trying to make their workplaces more inclusive. Some discussed statements released after the murder of George Floyd. Others talked about implicit bias trainings or trainings aimed at increasing awareness of cultural competency with specific groups such as Black people, Asian people, or trans people. Participants said that these trainings ranged widely in terms of effectiveness, which was already difficult to assess, measured with qualitative feelings of belonging or psychological safety. Others emphasized that, regardless of the efficacy of individual trainings, what was needed at their companies was more systemic change addressing White, middle-class norms and assumptions.
One answer to these issues may be to foster more interdisciplinary collaborations and support employee resource groups, although these strategies also have their limitations.
Our next blog post in this series will discuss recommendations that we formulated from analysis of these themes and further discussion with some of the folks in the field who worked on AI teams.
To be contacted about future DEI research and workshops at PAI, please join our mailing list here.
Together, we can change the AI industry through equitable machine learning practices.
-- -- Follow Written by Partnership on AI 196 Followers · Editor for AI&.
The Partnership on AI is a global nonprofit organization committed to the responsible development and use of artificial intelligence.
Follow More from Partnership on AI and AI&.
Partnership on AI in AI&.
Sketching the Field of AI Tools for Local Newsrooms With so many AI tools available, however, it can be tough for smaller news organizations to know which ones are appropriate for their… 10 min read · Dec 23, 2022 -- Partnership on AI in AI&.
How News Organizations Use Algorithms to Decide What to Show You Personalizing the news is a bit different from trying to guess whether a Netflix subscriber prefers horror movies or comedies.
7 min read · Dec 1, 2020 -- Partnership on AI in AI&.
A Field Guide to Making AI Art Responsibly Machine learning tools for generating synthetic media are becoming more and more accessible. We’ve written about how the availability of… 2 min read · Sep 18, 2020 -- Partnership on AI in AI&.
Local Newsrooms Should Adopt AI Ethics as They Adopt AI: 5 Recommendations At a fundamental level, what should AI ethics for local news look like? 6 min read · Jun 16, 2022 -- Recommended from Medium Unbecoming 10 Seconds That Ended My 20 Year Marriage It’s August in Northern Virginia, hot and humid. I still haven’t showered from my morning trail run. I’m wearing my stay-at-home mom… · 4 min read · Feb 16, 2022 -- 984 AL Anany The ChatGPT Hype Is Over — Now Watch How Google Will Kill ChatGPT.
It never happens instantly. The business game is longer than you know.
· 6 min read · Sep 1 -- 512 Lists The New Chatbots: ChatGPT, Bard, and Beyond · Generative AI Recommended Reading · What is ChatGPT? · Tech & Tools · Barack Obama Thoughts on Israel and Gaza It’s been 17 days since Hamas launched its horrific attack against Israel, killing over 1,400 Israeli citizens, including defenseless… 5 min read · Oct 23 -- 855 Scott-Ryan Abt in Pitfall Bye Bye, Spotify And see ya later, all you subscription services in my little empire · 4 min read · Aug 19 -- 340 Mirijam Missbichler Why Japanese Websites Look So Different & how to analyze design choices without jumping to conclusions 8 min read · May 1 -- 231 Isaac Saul A personal, non-partisan perspective on the Israel-Hamas war To understand this war, we must understand the thousand-year history that led us here 11 min read · Oct 12 -- 486 Help Status About Careers Blog Privacy Terms Text to speech Teams
