old id = 4122
自然語言處理 - 維基百科，自由嘅百科全書
2018
https://zh-yue.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86

自然語言處理自然語言處理（粵拼：zi6jin4jyu5jin4cyu2lei5；英文：natural language processing，NLP）係人工智能（AI）同語言學嘅一個綜合領域，包含咗一系列用嚟教電腦處理同運算語言同文字嘅技術，並且用呢啲技術嚟發展出有用嘅電腦系統[1]。NLP 嘅過程大致如下[1][2]：喺廿一世紀初，NLP 俾 AI 研究者視為 AI 其中一個最重要嘅領域，例如好出名嘅Google 翻譯就用咗 NLP 上嘅技術嚟做翻譯[4]，而且 NLP 方面嘅技術仲可以攞嚟做傾偈機械人等嘅休閒用途[5]。目錄定位[編輯]自然語言處理係一種人工智能（AI）技術，專門教電腦處理自然語言（natural language）。喺語言學上，自然語言係指一啲响人類當中自然噉發展出嚟嘅語言，簡單講即係好似英文同廣東話等日常講嘢會用嘅語言[註 1]。自然語言有好多重要嘅特徵[6]：... 呀噉。呢啲特徵會對「應該用咩方法應付自然語言」有具體嘅影響：廿世紀電腦要求用家俾嘅命令有極高嘅精確性（唔可以有歧義或者含糊）－喺一大串0同1裏面多咗或者少咗個0都會搞到部機做嘅運算錯嗮甚至輕機，更加唔好話會識得考慮對方講嘢嗰陣啲身體語言（理解反話嗰時必要諗嘅嘢）或者語言演變[8]。NLP 就係喺廿世紀後半橛至廿一世紀初興起嘅 AI 技術，專門諗點樣用特製嘅演算法嚟教電腦處理自然語言[1]。N-gram[編輯]N-gram嘅諗頭基於一個簡單嘅事實：N-gram 係 NLP 最簡單嘅做法之一，一串 n-gram 指一串符號當中嘅一連 n 咁多個符號：例如想像有串 100 隻字符－LLLRLRRRLL...
，一個 3-gram 嘅演算法會考慮每串連續三個符號係乜嘢樣－LLL, LLR, LRL...，再按打前嗰兩個符號嘅規律計算下一個符號最有可能係乜；例如想像家陣手上串英文字係噉嘅樣[9][10]：喺呢段字入面，如果打前兩個字符係fa，跟住嗰個符號係s嘅機率係 100% －喺串字入面，fa出現咗一次，而喺嗰次當中跟尾嗰個字符係s，所以如果淨係考慮上面段字嘅 3-gram 嘅話，「fa後面係s」嘅機率係 100%。現實應用嘅 n-gram 會用大量語料數據嚟做類似噉嘅估計，計出一隻語言啲字符（以至字）之間嘅統計關係[註 3]。精確啲講，即係話一個 n-gram 模型定義上會用[11]嘅數值預測xi{\displaystyle x_{i}}，計算N-gram 好基本（有好多進階嘅 NLP 應用都係 n-gram 搞唔掂嘅）。不過齋靠 n-gram 經已可以做到語言辨認（language identification）等比較簡單嘅 NLP 工作：想像家陣設計者攞住每隻已知嘅語言－英文、德文、法文... 呀噉，同每隻呢啲語言都搵語料數據同佢建立咗個 3-gram 模型，知道啲Pr(xi|xi−2,xi−1){\displaystyle \Pr(x_{i}|x_{i-2},x_{i-1})}嘅數值，佢跟住就可以計[12]：用日常用語講，佢做嘅嘢係要攞英文嘅 3-gram 模型，計吓「如果呢段文字係英文，會出段噉嘅字符嘅機率」，然後攞德文嘅 3-gram 模型，計吓「如果呢段文字係德文，會出段噉嘅字符嘅機率」... 如此類推，跟住就（例如）揀「出到呢段字符嘅機率」最大嗰隻語言－最後做到辨認手上段字係咩語言[12]。數據來源[編輯]要做 NLP，第一步通常係要攞啲語言性質嘅數據返嚟先。喺廿一世紀初嘅 NLP 界，語料庫（text corpus）係其中一種最常用最重要嘅數據來源。一個語料庫會係一嚿大型有結構嘅語言資源，一隻語言嘅語料庫會包含大量屬嗰隻語言嘅錄音同文字。舉個例說明，國際英文語料庫（International Corpus of English，ICE）就係一個好出名嘅英文語料庫，ICE 搵勻嗮世界各地超過 20 個以英文做官方語言一部份嘅國家或者地區（包括香港），每個國家地區對應嘅英文語料都係儲咗當地啲人講英文嘅錄音，仲有係當地啲人用英文寫嘅隨筆、書信、學術文同新聞報道等嘅多種文字材料；到咗 2018 年，ICE 對包括嘅每個國家地區都最少有 1,500,000 字咁長嘅材料（大型）[13][註 5]。之所以話語料庫「有結構」，意思係指語料庫通常都會特登設計到方便人用，例如：... 呀噉。事前處理[編輯]喺實際攞啲語言數據嚟用之前，研究者通常都會或多或少噉對啲數據做啲處理，包括：應用[編輯]自然語言處理用途好廣泛，包括咗以下呢啲：資訊提取[編輯]資訊提取（information retrieval）係指一個 NLP 程式識攞「用家嘅問題」做input，output俾出一份答到條問題嘅文件；進階啲嘅 NLP 程式仲識打分畀每份摷到嘅文件嚟表示份文件同個問題有幾咁𪐀更，然之後按呢個分嚟排先後，畀最𪐀更嘅文件畀用家睇先；好似係okapi BM25噉，呢套函數會攞用家問嘅嘢（Q{\displaystyle Q}）做input，然後同每份文件（D{\displaystyle D}）計個分數（score{\displaystyle {\text{score}}}）[27][28]：如果qi{\displaystyle q_{i}}係一隻常用字（例如英文入面嘅in或者of呀噉），噉佢嘅IDF(qi){\displaystyle {\text{IDF}}(q_{i})}分數理應會低（N−n(qi){\displaystyle N-n(q_{i})}數值細）；所以IDF(qi){\displaystyle {\text{IDF}}(q_{i})}呢嚿嘢嘅存在係為咗阻止啲常用字干擾搜尋結果。計完之後，就會每份文件得出個分數表示份文件對條問題嚟講幾有啦更，分數愈高表示愈有啦更，然後個搜尋器就可以按分數將啲摷到嘅文件列嗮出嚟，分數最高嘅行先。Okapi BM25 源於 1980 年代，到咗廿一世紀初經已廣泛噉俾搜尋器採用[27][28]。進階嘅演算法仲會考慮埋詞形還原以及同義詞等嘅好多問題，例如PageRank同HITS 演算法就會用到「個網頁有幾多高質網頁連過去」衡量摷到嘅網頁嘅「質素」，並且喺列出摷到嘅網頁嗰陣，將「質素」高啲嘅網頁排先[30][31]。機械翻譯[編輯]機械翻譯（machine translation）係指要電腦自動噉做翻譯，可以好撈絞。舉個簡單嘅例子說明，想像家陣寫個程式出嚟做英到粵翻譯[32][33][34]，而以下有兩句英文句子：喺以上呢兩句句子裏面，講緊嘢嗰個人都用咗disturbing呢隻形容詞，但係呢隻字要譯做粵文嘅話起碼有兩個可能嘅意思（歧義）[35]：對於呢隻字要點譯，要睇嗮成句句子先可以做決定：句子 1 用disturbing嚟形容一套驚慄片，而句子 2 就用disturbing嚟形容某個人所發出嘅噪音。一般會認為喺前者嘅情況當中，disturbing比較可能係指「令人不安」，而喺後者嘅情況入面，呢隻字就比較可能係指「令人覺得佢煩」。而且「啲人傾向點用disturbing呢隻字」呢點有可能隨時間演變，所以做翻譯嗰陣又要諗埋句句子係幾時寫低嘅。一個做翻譯嘅 AI 程式一定要考慮嗮咁多因素先可以俾輸出[32][36]。拉雜應用[編輯]除咗以上呢啲，NLP 仲可以攞嚟做：... 呀噉。註釋[編輯]睇埋[編輯]文獻[編輯]攷[編輯]拎[編輯]機械感知（電腦視覺·邊緣檢測·手寫辨識·物體檢測） ·機械學習（知識表示·深度學習）導覽選單查嘢
