old id = 181
Home - Partnership on AI
2020
https://www.partnershiponai.org

Partnership on AI is bringing together diverse voices from across the AI communityTo create resources for advancing positive outcomes for people and society.
Check out our newly released paper on what leads to attrition in AI and how leaders can build more inclusive AI teams.
Continuing our mission of bringing together diverse voices to ensure responsible development and deployment of AI and ML technologies, PAI is proud to welcome six new Partner organizations.
To ensure synthetic media is used for good, we need clear guidelines. That's why we're thrilled to announce a forthcoming resource with leadership from our Partners WITNESS, Adobe, and Microsoft.
A library of resources designed to help organizations and individuals begin implementing transparency at scale.
In this white paper, we explore the trade-offs of using demographic data to create fairer algorithmic decision-making systems.
As synthetic media becomes more widespread, many platforms use detection tools to assess potentially harmful content. But who gets access to these detectors?We are a non-profit community of academic, civil society, industry, and media organizations addressing the most important and difficult questions concerning the future of AI.
Stories of ImpactBy creating actionable resources for the AI community, PAI translates critical insights into positive impact on the worldInvestigating Challenges to Diversity in AIWorking in partnership with DeepMind, PAI researchers launched a study to investigate high attrition rates among women and minoritized individuals in tech.
Taking a Stand Against AI MisuseWhen a former Attorney General recommended misusing an algorithm to determine outcomes for federal prisoners, PAI released an issue brief explaining the many perils of this path.
Taking a Methodical Approach to Best PracticesPAI worked with First Draft to support information integrity, investigating what works (and what does not) when addressing deceptive content online.
Learn More About Our ImpactExploreOur WorkCurrently organized under Programs, our work contributes to the rigorous development of resources, recommendations, and best practices for AI.
Inclusive Research & DesignAt PAI, equity and inclusion are core values which we seek to promote among our Partner organizations, in our own work, and throughout the greater AI field, including in machine learning and other automated decision-making systems. This Program explores the many barriers to inclusion in the AI space — as experienced by those who work in technology and those who are consistently excluded from key decision-making processes.
The Inclusive Research and Design Program is currently creating resources to help AI practitioners and impacted communities more effectively engage one another to develop AI responsibly. Ultimately, this work seeks to achieve a more holistic reimagining of how AI is developed and deployed around the world, leading to an AI industry that recognizes end users and impacted communities as essential expert groups.
AI, Labor, and the EconomyPAI believes that AI has tremendous potential to solve major societal problems and make peoples’ lives better. At the same time, individuals and organizations must grapple with new forms of automation, wealth distribution, and economic decision-making. Whether AI promotes equality or increases injustice, whether it makes all of us richer or the poor poorer is a choice we, as a world, must consciously make.
To advance a beneficial economic future from AI, the AI, Labor, and the Economy Program gathers Partner organizations, economists, and worker representative organizations. Together, these actors work to form shared answers and recommendations for actionable steps that need to be taken to ensure AI supports an inclusive economic future.
AI and Media IntegrityWhile AI has ushered in an unprecedented era of knowledge-sharing online, it has also enabled novel forms of misinformation, manipulation, and harassment as well as amplifying harmful digital content’s potential impact and reach. PAI’s AI and Media Integrity Program directly addresses these critical challenges to the quality of public discourse by investigating AI’s impact on digital media and online information, researching timely subjects such as manipulated media detection, misinformation interventions, and content-ranking principles.
Through this Program, PAI works to ensure that AI systems bolster the quality of public discourse and online content around the world, which includes considering how we define quality in the first place. By convening a fit-for-purpose, multidisciplinary field of actors — including representatives from media, industry, academia, civil society, and users that consume content — the AI and Media Integrity Program is developing best practices for AI to have a positive impact on the global information ecosystem.
Fairness, Transparency, and Accountability & ABOUT MLFairness, Transparency, and Accountability encompasses PAI’s large body of research and programming around algorithmic fairness, explainability, criminal justice, and diversity and inclusion. In 2020 alone, this work examined the challenges organizations face when they seek to measure and mitigate algorithmic bias using demographic data, provide meaningful explanations to diverse stakeholders, address bias in recidivism risk assessment tools, and build more inclusive AI teams.
With ABOUT ML, PAI is leading a multistakeholder effort to develop guidelines for the documentation of machine learning systems, setting new industry norms for transparency in AI. This means not just identifying the necessary components of transparency, but releasing actionable resources to help organizations operationalize transparency at scale. Developed through an iterative, multistakeholder process, these resources pool the collective efforts and insights of academic researchers, industry practitioners, civil society organizations, and the impacted public.
Safety-Critical AIHow can we ensure that AI and machine learning technologies are safe? This is an urgent short-term question, with applications in computer security, medicine, transportation, and other domains. It is also a pressing longer-term question, particularly with regard to environments that are uncertain, unanticipated, and potentially adversarial.
As our lives become increasingly saturated with artificial intelligence systems, the safety of these systems becomes a vital consideration. The Safety-Critical AI Program seeks to establish social and technical foundations that will support the safe development and deployment of AI.
Learn More About Our ProgramsExploreOur PartnersWith a diverse Partner community drawn from members across the globe, PAI spans sectors, disciplines, and borders.
By gathering the leading companies, organizations, and people differently affected by artificial intelligence, PAI establishes a common ground between entities that otherwise may not have cause to work together and—in so doing—serves as a uniting force for good in the AI ecosystem.
Latest UpdatesNew Partners Bring Diversity of Expertise to Partnership on AI￼UC Berkeley – Can Documentation Improve Accountability for Artificial Intelligence?U.S. Chamber of Commerce – AI Commission on Competitiveness, Inclusion, and InnovationPartnership on AI Releases Groundbreaking Study on Attrition of Minoritized Workers in TechWorld Summit AI AmericasTTC Labs Summit 2022 – Trustworthy AI ExperiencesgRED Informatics Symposium – Fostering an Inclusive Mindset in our Informatics Design ApproachJournalismAI – How to design guidelines for the responsible use of AI in your newsroom© 2022 Partnership on AI | All Rights Reserved
