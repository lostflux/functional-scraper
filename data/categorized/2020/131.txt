old id = 1595
Predicting conversion to wet age-related macular degeneration using deep learning | Nature Medicine
2020
https://www.nature.com/articles/s41591-020-0867-7/search/advanced

Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.
AdvertisementPredicting conversion to wet age-related macular degeneration using deep learningNature Medicinevolume26,pages892–899 (2020)Cite this article9225Accesses75Citations383AltmetricMetricsdetailsSubjectsAbstractProgression to exudative ‘wet’ age-related macular degeneration (exAMD) is a major cause of visual deterioration. In patients diagnosed with exAMD in one eye, we introduce an artificial intelligence (AI) system to predict progression to exAMD in the second eye. By combining models based on three-dimensional (3D) optical coherence tomography images and corresponding automatic tissue maps, our system predicts conversion to exAMD within a clinically actionable 6-month time window, achieving a per-volumetric-scan sensitivity of 80% at 55% specificity, and 34% sensitivity at 90% specificity. This level of performance corresponds to true positives in 78% and 41% of individual eyes, and false positives in 56% and 17% of individual eyes at the high sensitivity and high specificity points, respectively. Moreover, we show that automatic tissue segmentation can identify anatomical changes before conversion and high-risk subgroups. This AI system overcomes substantial interobserver variability in expert predictions, performing better than five out of six experts, and demonstrates the potential of using AI to predict disease progression.
You have full access to this article via your institution.
MainThe application of AI to disease classification has shown great promise towards increased utility and diagnostic accuracy for medical imaging1,2,3. Recent work has demonstrated further potential in risk stratification not previously thought possible4,5. There is substantial potential for AI to improve our understanding of disease evolution, and to predict the future risk of disease onset and progression.
Prediction of disease progression is particularly important in age-related macular degeneration (AMD). AMD is the commonest cause of blindness in the developed world6; in the United States alone an estimated 148,000 adults each year progress from the early, mild form of the condition to the sight-threatening late form known as exAMD7,8,9. Once exAMD develops, sight is lost precipitously and often cannot be fully restored by current therapies, making the point of conversion from early to exAMD a critical moment in the management of this disease10. Exudative AMD typically affects one eye first, leaving sufferers reliant upon the unaffected ‘fellow’ eye to maintain their quality of life. However, 20% of these patients develop exAMD in the fellow eye within 2 years of the first11,12,13,14. This deprives individuals of essential daily activities such as reading, recognizing faces and driving.
Treatment of exAMD is most effective if administered soon after conversion10. Regular follow-up is thus the standard of care, but is not always available15. While studies are exploring preventative strategies(NCT02462889andNCT02140151), robust methods of identifying exAMD onset before conversion are needed to avoid the administration of costly, invasive treatment to the fellow eyes of all patients with unilateral exAMD, many of whom will never develop late disease in their fellow eye. To date there has been little evidence that clinicians are able to accurately predict a patient’s imminent conversion and, despite progress in deriving prognostic indicators from fundus imaging16, further work is needed to achieve clinically useful predictive accuracy.
To address this challenge we introduce an AI system to predict whether a fellow eye will convert to exAMD imminently, defined as within the ensuing 6-month period, using optical coherence tomography (OCT) scans. To demonstrate the clinical applicability of this system, we explore its use across varying operating points (sensitivity/specificity pairs) and investigate the number and potential patient impact of false-positive outputs. To better understand expert performance on the task, we compare model performance with retinal specialists and optometrists in a benchmark study using a defined silver standard of conversion date. We further investigate automatic segmentations of clinically relevant tissue types to identify early changes and study high-risk subgroups.
ResultsClinical application and deep learning architecturePredicting the future state of a progressive disease is a combination of two skills: identification of subtle signs early in the process of conversion, and modeling the future risk of exAMD. A model must be able to provide interpretable information to clinicians who may be making decisions based on its predictions. Our proposed system thus consists of two components: first predicting conversion to exAMD based on an interpretable tissue segmentation of the OCT and, second, making a prediction based on the raw OCT itself. The former adapts a two-stage architecture2, trained on a subset of manually segmented scans, that first segments 13 relevant tissue types and subsequently applies a classification network adapted to predict the risk of conversion to exAMD within the next 6 months. We ensembled the two-stage network with a model trained for the same task on the raw OCT alone. This was motivated by literature precedent on involvement of imaging features not yet captured by the segmentation model, such as reticular pseudodrusen17,18,19,20and reflectivity of tissues21in the conversion to exAMD. This approach captures the complementary performance of the two-stage network and those based on raw OCT alone (Supplementary Table1a,b).
We trained and tested our system using a retrospective, consecutive cohort of 2,795 patients across seven different sites (Supplementary Table2) and who were first diagnosed with exAMD between June 2012 and June 2017 (Fig.
1). Routine care for these patients comprises repeated bilateral OCT at varying intervals, most commonly every 4–12 weeks while undergoing therapy and every 3–12 months if therapy is ceased to monitor for disease reactivation. The dataset consisted of 62% female and 38% male patients. Ethnicities were 55% white, 10% Asian, 2% black and 33% other or unknown. Average age at first eye presentation was 78.8 years (see Extended Data Fig.
1). These figures reflect the epidemiology of AMD22.
a, After diagnosis of exAMD in one eye (the first eye), a patient commences intravitreal therapy in that first eye. Both the first eye and fellow eye are followed up regularly with further observation.
b, Selected sequential scans from the fellow eye of a patient. This eye initially showed mild, early AMD and then converted to exAMD, following which it was treated with intravitreal therapy. The timing of each follow-up visit varies depending on the treatment regimen of the first eye, as well as on factors related to the individual patient and the clinic. At each visit, an OCT scan of the first eye is performed to assess the efficacy of treatment. An OCT scan of the fellow eye is also performed, as the presence of exAMD in one eye presents a high risk of fellow eye conversion. Here, the fellow eye converts to exAMD during follow-up at 11 months (red box).
c, Illustration of the proposed AI system. The 3D OCT volume of the fellow eye (1) is used to provide a risk prediction of whether the eye will convert within a given time window. A deep learning (DL) segmentation model (2) outputs a 3D segmentation of anatomical and pathological tissue (3). A prediction model then takes this tissue segmentation as an input (4). A further prediction model takes the original 3D OCT volume as an input (5), and these two prediction models are ensembled (6) to assign a risk of conversion to exAMD within a clinically actionable time window of 6 months (7).
Fellow eyes were grouped into converting and nonconverting within the follow-up available, referring to whether they converted to exAMD during the study period. All patients had a follow-up period for their fellow eye of ≥6 months. To account for potential differences between the date a fellow eye converted and when therapeutic injections were started, all scans underwent expert review to provide a clinical ground truth of a conversion scan, in addition to the injection scan. The mean and median differences between these two events were 64.9 and 13 d, respectively (Extended Data Figs.
1and2). The dataset was randomly split at the patient level into model training and validation sets (80%) and a holdout test set on which to evaluate final model performance (20%; see Supplementary Table3andMethods).
Future prediction of conversion to exAMDWe evaluated our model on a primary outcome of identification of OCT scans at risk of developing exAMD within the ensuing 6 months. We chose this time window to enable the model to predict at least two follow-up intervals ahead of time, assuming a maximal follow-up interval of 3 months.
Our system reached a per-volumetric-scan area under the receiver operating characteristic curve (AUC) of 0.745 on the test set, predicting the clinical ground truth of ‘conversion scan’, and an AUC of 0.886 when compared to a ground truth of the actual injection date (Fig.
2). All following results use the conversion scan ground truth. This substantially outperformed baseline gradient-boosted machine models trained only on available demographic metadata (Supplementary Table4).
a, Receiver operating characteristic (ROC) curves showing per-volumetric-scan performance on prediction of imminent conversion within 6 months on the full test set (386 unique patients; 5,581 total OCT scans) against a ground truth (GT) defined as the first injection occurring within 6 months, in blue (n(positive cases) = 363,n(negative cases) = 6,578); and against a ground truth defined as the conversion date, in orange (n(positive cases) = 241,n(negative cases) = 5,340). Conservative (90% specificity) and liberal (80% sensitivity) operating points are shown. The numbers of true and false cases differ due to the exclusion of scans with unknown conversion date. Gray-shaded areas indicate 95% confidence intervals (seeMethods). The gray diagonal line indicates chance performance.
b, Precision-recall (PR) curves for the same results.
Predicting future conversion is not a routine clinical task, and there are many ways in which our proposed AI system could be used in practice. One way of exploring this is through the balance between sensitivity and specificity, where changes in management such as visit scheduling may require different operating points compared with currently unproven preventative treatments. Without risk prediction, a conservative approach would entail providing the same management to every patient with exAMD in one eye, the highest possible false-positive rate. This may not be practical, and in current practice there is no provision for changes in management for those most at risk of progression. To represent this balance, we propose a conservative (90% specificity) and a liberal (80% sensitivity) operating point. At the conservative point a sensitivity of 34% is achieved at 90% specificity; at the liberal point a specificity of 55% is achieved at 80% sensitivity. This corresponds to false positives in only 9.6% of scans at the conservative operating point and 43.4% of scans at the liberal operating point. There was minimal difference in the true- or false-positive rates at the conservative or liberal operating points when weighing the AUC to balance the average number of scans per patient (Supplementary Table5).
This approach could be extended across varying lead times and a range of different operating points as required by individual clinics, healthcare systems or therapeutic drug indications. Extended Data Fig.
3and Supplementary Table6give examples of such extensions.
To better reflect the alternative ways in which this system could be applied, we explore the performance for individual patients (n= 386) rather than scans. If applied in practice, a single correct positive prediction is sufficient to begin a potentially beneficial course of treatment if preventative treatment has commenced. In patients whose fellow eyes converted during the study period (n= 103), the system produced true positives in at least one scan during the preceding 6 months in 40.8 and 77.7% of the converting eyes for the conservative and liberal operating points, respectively. Conversely, a false-positive alert could lead to unnecessary treatment. For fellow eyes with at least 6 months of negative follow-up (n= 386), the system produced at least one false positive in 23.1% of individuals at the conservative operating point and 61.1% at the liberal operating point. Considering only those with a longer follow-up of 24 months (n= 208), this dropped to 16.8 and 55.8% for the conservative and liberal operating points, respectively (Supplementary Table7a).
Patients can still be managed effectively outside the 6-month window if conversion to exAMD is expected. We investigate false-positive predictions in fellow eyes where conversion did not occur within the 6-month window but later in the patient’s clinical history. At the conservative and liberal operating points, 23.6 and 25.8%, respectively, of all fellow eyes with false-positive predictions were ‘early’ and converted >6 months after the initial model prediction. For patients with a follow-up of at least 24 months after initial model prediction, we investigate the number of false-positive alerts that converted within a 6–24-month period. At the conservative and liberal operating points, this was 35.2 and 32.8% respectively (Supplementary Table7b).
Clinical expert benchmark for future predictionPredicting future conversion to exAMD is not a routine task performed by clinicians. In current practice, scans are assessed for signs of previous conversion. Although several prognostic imaging features have been described23, clinical expert performance at prediction of future fellow eye conversion has not previously been studied.
It is essential to establish a benchmark for human performance in practice to understand the performance of our proposed system. We used an enriched subset of the test set to meet statistical power, randomly choosing at least one scan in the 6 months before conversion for each converting fellow eye, resulting in a prevalence of 13.5% of scans that converted within 6 months (seeMethods). For each case, we obtained the predictions from our system and six clinical experts: three retinal specialists and three optometrists trained in medical retina. Each expert was asked to predict whether the eye would convert in the following 6 months, and provided two separate decisions at least 1 week apart: one (like our system) from a single OCT scan (single scan task; dataset 9 in Supplementary Table8) and one from the OCT with available historical OCTs, fundus images and patient demographic and visual acuity data (sequential scan task; dataset 10 in Supplementary Table8). We compared these against the clinical ground truth of time to exAMD conversion.
Despite the task not being routinely performed by clinicians, the experts performed better than chance alone. However, performance varied substantially: sensitivity ranged from 18 to 56%, and specificity from 61 to 93%, for the single scan task. On average, when given additional information specificity improved at the expense of reduced sensitivity (sensitivity range 8.5–41.5%, specificity range 77.4–98.6%). Interrater agreement for the single scan task was slightly better among retinal specialists (κ= 0.335) than optometrists (κ= 0.258). For the sequential task, agreement among the retinal specialists (κ= 0.143) was worse than among the optometrists (κ= 0.305). Intraobserver agreement between the single and sequential scan tasks ranged betweenκ= 0.180 and 0.523. Further details on individual expert decisions are given in Extended Data Fig.
4, and additional expert metrics and agreement comparisons are given in Extended Data Fig.
5.
Comparing these results for future prediction to our system, we outperform the majority of experts (Fig.
3). The system had a higher performance than five experts (all three retinal specialists, two optometrists) and matched one (an optometrist) for the single scan task. When experts additionally had access to each patient’s previous OCT scans, fundus images and additional clinical information, our model again outperformed five experts (two retinal specialists and all three optometrists) while one (a retinal specialist) was similar to our system. The system achieves a significantly betterF1score at the equal error point compared to five out of six experts (model, 0.38; human experts, 0.23–0.33; Supplementary Table9). We evaluate the conservative and liberal operating points with a McNemar test between each expert and the points (Supplementary Table10). At the conservative operating point the model has significantly greater sensitivity than three experts and significantly greater specificity than two experts. At the liberal operating point, where we trade specificity for sensitivity, the model has, as expected, a significantly better sensitivity than all experts but with a significantly worse specificity.
a, ROC curve showing the performance of the AI system on the clinical expert benchmark subset. Clinical experts are represented by filled circles for the single scan task and open circles for the sequential scan task. The individual points for single and sequential scan tasks for each expert are linked by dashed lines. The larger monochrome squares and circles show a human performance where a prediction of conversion requires at leastnor more (n+) retinal specialists or optometrists in agreement that the case will convert in the next 6 months. Gray-shaded regions areas indicate 95% confidence intervals (seeMethods). The gray diagonal line indicates chance performance.
b, Close-up of the region with 0–30% false-positive rate (rectangle outlined as a dotted region ina).
Visualization of anatomical subgroupsAdditional information that is interpretable to clinicians can aid effective implementation24. One such benefit of our system is that it automatically segments each scan. Extracting clinically relevant features provides a systematic method of visualizing change over time (Extended Data Fig.
6). Figure4shows a representative example, combining the risk predictions with top-down two-dimensional en face maps created from the automatic 3D segmentations. Further examples are provided in Supplementary Figs.
1–7.
a,b, In this example, progression of the right fellow eye of an 80-year-old male patient being treated in the left eye for exAMD with intravitreal injections is shown. The patient was seen at regular intervals, over which time his right eye showed a gradual progression of anatomical abnormalities before converting to the exudative form approximately 11 months after first presentation and receiving therapeutic injections beginning at 13 months.
a, For each set of images, shown are B-scan slices of OCT imaging (top left), segmentation produced by a DL segmentation model2(bottom left) anden facethickness of two clinically important retinal tissues produced by the segmentation model where blue denotes 0 mm and red denotes 0.1 mm (fibrovascular pigment epithelial detachment (fibro. PED, top right) and SHRM, bottom right)). Each set of four images is from a clinical visit (selected visits indicated with arrows) during the 12-month period shown. In the months leading to conversion, we observed an increasing presence of SHRM and fibrovascular PED. At 10.5 months, the volume of SHRM and fibrovascular PED increased further and intraretinal fluid was observed (en facemap not shown), signaling conversion to exAMD. Treatment commenced 2 months later; at this point further anatomical changes had occurred, including an additional OCT finding of subretinal fluid (en facemap not shown).
b, Prediction of the AI system for conversion to exAMD within 6 months. At the liberal operating point (yellow dotted lines) it correctly predicted conversion within 6 months for all three scans within the actual 6-month window before conversion (gray box).
By enabling the visualization of important anatomy and pathology, segmentations also provide a quantitative method to derive clinical subgroups based on segmented tissue volumes (Table1and Supplementary Table11). One clinically relevant example is provided by the Age-Related Eye Disease Study (AREDS) simplified severity scale used to assess 5-year conversion risk in clinical practice from fundus photographs, based on the size of drusenoid pigment epithelial detachment (PED)25. Taking advantage of the 3D nature of OCT, we approximate this scale using drusen volume. The findings were consistent with literature precedent—higher conversion rates were seen in subgroups with greater drusen volume. This approximation can also serve as a baseline with which to compare the model, imitating the existing scenario where AREDS has been used for recruitment into clinical trials of prophylactic treatments for exAMD. Our model outperforms measures based on drusen or hyper-reflective foci (HRF) alone (Fig.
5).
a,b, Estimation of the performance of the AREDS simplified severity scale in classifying patients as ‘high risk’. Shown are ROC curves using the volume of drusen (a) and of HRF (b). The curves were built by varying the volume threshold at which a prediction of 6-month conversion would be triggered and evaluating this against the ground truth. Operating points are shown at the 25th, 50th and 75th percentiles of volume.
This approach provides insight into model performance. The system is substantially more sensitive when features known to be predictive, such as HRF26,27and high drusen volumes28,29, are present (Table1). This is also the case for fibrovascular PED present before conversion, possibly highlighting early exudative changes. We show that the system’s performance is consistent across key demographics such as sex and ethnicity, provide further examples of clinically important subgroups—including cases selected by the appearance of the conversion scan in Supplementary Tables12and13—and present Kaplan–Meier survival plots for individual subgroups in Extended Data Fig.
7.
DiscussionWe demonstrate an AI system to predict conversion to exAMD in fellow eyes of patients with exAMD in their first eye. We propose two clinically applicable operating points and consider the system’s potential impact on clinical care through analysis of false-positive alerts, and demonstrate the value of automatic segmentation in identifying early signs of progression and studying high-risk subgroups. We establish a clinical expert benchmark for comparison because this task is not currently performed in clinical practice, showing that humans are able to perform the task albeit with high variability.
Our system has several potential implications for patient care. Future prediction of conversion is important in guiding preventative measures in AMD. These are already being explored, with examples of prophylactic intravitreal therapy (NCT02462889andNCT02140151) and gene therapies30in clinical trials, and longer-acting intravitreal therapy31,32and port-delivery systems for long-term continuous therapy33under investigation. Means of identifying those most at risk are required if these therapies are to be efficiently targeted in increasingly burdened healthcare systems and are to be acceptable to patients. Our proposed system outperforms volume-based risk predictions similar to those currently used for trial cohort selection, and may enable targeting of preventative treatments and identification of high-risk patients for inclusion in similar upcoming trials. The operating points are configurable and will vary depending on the use, healthcare system and therapy of choice.
A further implication for care is in influencing patient follow-up and improving time to treatment. Early diagnosis is paramount as delays in intervention can result in a loss of vision34. However, the mean difference between injection date and conversion date in our dataset was 64.9 d (median, 13 d). One explanation for this gap is that subtle early signs are not always treated because they are missed or do not fall within set treatment criteria, or because the patient was asymptomatic. This only partially explains the difference: there is still a substantial delay, a mean of 34 d, even in those within treatment criteria. The model may be particularly beneficial in these cases. In addition to predicting conversion, the segmentations produced provide information aimed at earlier detection of exAMD. The improvement in system performance when trained and evaluated using the scan from the date of injection as a ground truth further indicates the potential to identify conversion changes earlier. Moreover, our system does not require sequential information. While including a patient’s previous scans and demographics led to mixed results for the experts, it is plausible that AI can extract additional useful information5. However, predicting based only on single scans supports settings where patient follow-up varies depending on perceived risk. This is particularly relevant in centers that cannot offer regular follow-up, especially with increasing availability of OCT through community eye-care centers, and for future work to investigate the applicability of our system in patients that have yet to develop exAMD in either eye.
The segmentation portion of the model enables automated detection and analysis of important tissues2. One use of this is to study groups of scans based on known prognostic indicators from the OCT, as well as other important phenotypes such as pathological tissues present on the conversion scan. Not only do the en face maps provide summary information to clinicians treating a patient, but they may open up new ways to study AMD subgroups, and indeed other conditions, that may differ in their conversion risk or response to treatment in important ways.
Further imaging in patients where the model produces false-positive predictions may demonstrate particular subgroups of interest. Newer imaging modalities such as OCT angiography (OCTA) are becoming more widely used to safely acquire high-resolution images of the choroidal vasculature to identify exAMD. Recent studies employing OCTA have distinguished a form of exAMD coined as subclinical or nonexudative neovascular AMD that does not result in the appearance of macular fluid visible on conventional OCT or modalities such as fundus fluorescein angiography35,36,37. For our study, the clinical ground truth of conversion was labeled where exudation was visible. Eyes with suspected fibrovascular PED without the presence of fluid were labeled as nonexudative, but may represent examples of subclinical exAMD. It is possible that our model has identified examples that would warrant further imaging using OCTA (Supplementary Fig.
6). Such patient groups would offer an explanation for both early findings of fibrovascular material before conversion (6.6% of imminency scans), and the clustering of false-positive alerts in a small number of cases. Further work is needed to validate this hypothesis by evaluating model predictions with OCTA.
Our work builds upon a body of literature investigating the development of AMD38, and on promising early work to develop predictive models for exAMD based on fundus photographs39and OCT scans27,40,41,42. We improve on generalizability and applicability in several ways. Our datasets are representative of the patient population at a large specialist eye-care center, both in the cadence of patient visits and the inclusion of challenging cases, such as eyes with geographic atrophy (25.2% of eyes with geographic atrophy converted to exAMD in our dataset). Crucially, our clinical ground truth reflects the date of conversion rather than using injection as a proxy measure. There is often a delay between conversion and treatment; when first injection date is used as the conversion label for training model performance improves substantially. In addition, when the ground truth is based on the injection, exAMD masquerades are mislabeled as they may still receive injections.
Clinicians do not routinely make predictions about future conversion. Our results indicate that clinical experts are able to perform the task, but with large variability. Though specificity improved for all experts when given the full clinical scenario with all historical images and additional patient information, the sensitivity reduced. While an exploration of variability is beyond the scope of this work, our results open up the possibility of exploring human performance on this task as has been investigated in conditions such as diabetic retinopathy43. The low interrater agreement between individual experts may reflect that predicting conversion is not routine. Despite some literature evidence of prognostic features, no formal prognostic criteria exist. Standardized training can reduce variability between individuals, but without established criteria such training is impossible. It is possible that models may reduce this variability; future work can investigate this through human–computer interaction studies.
There are several limitations of our work. While our system was trained and evaluated on a diverse and clinically representative demographic from Moorfields Eye Hospital, the subjects are not fully representative of a global population. AMD is multifactorial, with genetics, race, sex and lifestyle factors such as smoking and diet known to contribute to disease risk44. Its incidence varies globally, being lower in Asia and Africa compared to Europe and North America6. Additional representative datasets would be required to confirm performance on a general population. In addition we tested our model on only one OCT scanner type. Different models may vary in appearance; future work should investigate generalizability across OCT manufacturers. We powered the study based on, and report performance across, individual scans. While we explore subgroups of the full dataset for per-patient and segmentation analyses, the statistical power is limited and future work should include larger datasets. We investigate a 6-month time window before a clinical ground truth of conversion date. This clinical ground truth is defined based on an OCT scan demonstrating exudative conversion. It is unlikely that the date of patient conversion corresponds exactly to when the scan was taken, but rather to a point in time between the current and previous scans. This difference may account for some of the false positives that occur in patients that still convert outside the 6-month time window. There are differences in performance by training a model on raw OCT scans compared with training on OCT segmentation. Though small, the differences suggest there are important imaging features for this task that are not captured by the segmentation model; further work could extend the segmentation model by the addition of a wider range of different tissue classes to improve performance22and investigate models using segmentation alone. Cases of undiagnosed polypoidal choroidal vasculopathy (PCV) that may masquerade as positive examples of exAMD were removed by manual OCT grading. Indocyanine green angiography can be used to confirm this diagnosis, but was unavailable routinely in the Moorfields dataset. A final limitation is that there may be important differences in treatment regimes and other patient factors that correlate with the number of scans a patient undergoes. Future work should investigate potential bias across larger datasets.
Our model was trained and evaluated on a dataset of fellow eyes of patients with exAMD in one eye. This is a population at high risk of developing exAMD in their second eye, and associated loss of vision substantially impacts quality of life in a patient who has already lost vision in their first eye. Future work can build on these results through prospective implementation and validation studies, and by investigating model performance in patients without any AMD, or with dry AMD in one or both eyes.
In summary, we introduce a clinically applicable AI system that produces a prediction of fellow eye conversion to exAMD based on OCT scans from a clinically relevant population, and that provides additional information to clinicians through automatic segmentation. The system opens up new possibilities for research and treatment for the leading cause of blindness in the developed world.
MethodsEthical and information governance approvalsThis work, and the collection of retrospective data on implied consent, received national Research Ethics Committee (REC) approval from the Cambridge East REC and Health Research Authority approval (reference no. 16/EE/0253); it complies with all relevant ethical regulations. De-identification was performed in line with guidance provided by the Information Commissioner’s Office’s Anonymisation: managing data protection risk code of practice45, and validated by the Moorfields Eye Hospital Information Technology and Information Governance departments, respectively. Only de-identified retrospective data were used for research, without the active involvement of patients.
Further details on the methods are described in a published protocol describing the DeepMind collaboration with Moorfields Eye Hospital46.
Datasets and clinical taxonomyDataset descriptionData were collected using the Moorfields Eye Hospital electronic health record (EHR) system, querying all patients receiving intravitreal injection therapy and with a diagnosis of age-related macular degeneration at seven different Moorfields sites across London, United Kingdom. The clinical data used for training and evaluation were collected by Moorfields Eye Hospital and transferred to DeepMind in a de-identified format. Retrospective data were aggregated from Moorfields Eye Hospital, including its satellite sites, where data had been archived to a central network. The data included adult patients aged >50 years, with patients aged <100 rounded to age 100 to retain anonymization. Data were collected for all patients that started treatment in one eye between June 2012 and June 2017. Data for each patient were collected until June 2018, and included OCT images (acquired using a Topcon 3D OCT-2000) at every visit for both eyes where available; clinical information containing visual acuity and whether an intravitreal injection was delivered, including drug administered; and additional patient information including age in years at each scan, sex and ethnicity. After initial exclusions this dataset consisted of 130,327 scans from 3,111 patients, and included a total of 6,149 eyes and 2,526 fellow eyes (Extended Data Fig.
8). Extended Data Fig.
7shows for all fellow eyes a survival curve of conversion to exAMD from baseline.
The data were randomly divided at the patient level into training (60%), validation (20%) and test (20%) sets. Cross-validation (CV) was performed after merging the training and validation sets (80%). Extended Data Fig.
1contains an overview of patient demographics and the data, as well as prevalence of fellow eye involvement. Further description of the dataset and labeling is provided in Extended Data Fig.
8and Supplementary Tables4and9.
Clinical taxonomyAll patients included in the dataset were diagnosed with exAMD in at least one eye—considered to be the first eye. If both eyes presented with exAMD, both eyes were considered as first eyes and excluded from the test set. Where there was only one first eye, the other eye without exAMD was known as the fellow eye. Fellow eyes that developed exAMD during our study period were labeled as converting fellow eyes (see following section for the diagnostic procedure), whereas those that did not develop the condition were labeled as nonconverting fellow eyes. Because all patients were undergoing treatment in at least one eye, OCTs of both eyes were acquired at regular intervals—generally at 4–12 weeks depending on the drug being administered and the treatment response. The drug and treatment regime followed was either ranibizumab or aflibercept, on either a pro re nata or ‘treat and extend’ scheme.
Clinical labelingOnce data were transferred, a labeling procedure was followed (1) to exclude eyes that were incorrectly coded as exAMD in the EHR and presented with other vascular conditions such as exudative choroidal neovascularization secondary to myopia, idiopathic polypoidal choroidal vasculopathy or macular oedema; and (2) to label the conversion scan of fellow eyes if exAMD has developed. The latter was required as a delay between conversion to exAMD and treatment was frequently observed (Extended Data Fig.
2b), often related to further investigations being undertaken, or if the eye was not within eligibility criteria to receive injections.
Because a consensus definition of conversion from OCT images has not previously been described in the literature., the clinical ground truth of conversion was defined as requiring both (1) the presence of subretinal or intraretinal fluid and (2) a suspicious PED, hemorrhage or subretinal hyper-reflective material (SHRM). A further definition of the presence of retinal angiomatous proliferation with surrounding intraretinal fluid was also taken. The procedure was followed to label the first scan showing signs of conversion of fellow eyes that received treatment, by two retinal specialists and one optometrist trained in OCT interpretation. Disagreements were found in 16% of scans were and arbitrated by a senior expert, independent of the original three labelers but with knowledge of their labels, whose decision superseded. Two of the three experienced graders confirmed that untreated fellow eyes did not develop exAMD, and that first eyes were correctly diagnosed. These eyes were arbitrated by the senior expert where an untreated eye was thought to have converted to exAMD, and where the diagnosis was equivocal (see Supplementary Fig.
8) or if the eye was being considered for exclusion. Because other imaging modalities often used in clinical practice—such as fundus fluorescein angiography—were unavailable (as this is not routinely performed in fellow eyes), and the lack of a consensus definition of conversion, we describe the OCT-derived conversion label as a silver standard. From this process, we found 85 fellow eyes that converted and did not yet receive treatment. A number of eyes were excluded from the dataset, including 252 diagnosed with other retinal disorders and 103 that started treatment at a visit without any signs of exAMD on the OCT scan. These eyes often presented with features commonly mistaken for exAMD, such as vitelliform lesions, non-neovascular drusenoid PEDs with overlying fluid47,48and nonexudative detachments of the neurosensory retina49. Some examples of excluded eyes are shown in Supplementary Fig.
8. Two patients had a fellow eye excluded due to disorders other than retinal conditions such as anterior eye conditions that obscured posterior segment imaging. These eyes were labeled before transfer. In addition, images were manually excluded if they were of poor quality (where the major retinal interfaces were not visible), or contained significant blink or foldover artifact that obscured the relevant features described above and would prevent a clinical decision being made.
The initial dataset for patients with confirmed neovascular AMD in one eye consisted of 3,111 patients, 6,149 eyes, 2,526 fellow eyes and 130,327 scans. The final dataset, after exclusions were applied, consisted of 2,795 patients, 4,729 eyes (including both first and fellow eyes in the the training set), 2,261 fellow eyes (777 converting and 1,484 nonconverting), 96,111 OCT scans (65,633 scans after conversion to exAMD as defined by the silver standard) and 30,478 scans before conversion or without exAMD; Extended Data Fig.
8). Extended Data Fig.
2shows a histogram of the number of scans per unique eye in test and training/validation sets. A subset of patients had only first-eye scans in the dataset. While all first eyes were excluded from the test set, first eyes with previous scans to conversion were included during training to increase prevalence.
Benchmarking the expert performanceFor this evaluation study, we recruited three consultant ophthalmologists with subspeciality training in medical retina and extensive clinical experience. These are referred to as retinal specialists 1, 2 and 3, with 14, 13 and 12 years of experience, respectively. Three hospital optometrists with specialist training in OCT interpretation and retinal diseases were also recruited, referred to as optometrists 1, 2 and 3, with 14, 15 and 10 years of experience, respectively. All participants were independent and not involved in grading scans.
A subset of the test set was used for the evaluation. A stratified sample of OCT scans from the test set was selected to achieve 90% statistical power and to balance how often each eye was represented in the benchmark. For each converting fellow eye, one scan was first sampled in the 6-month period before conversion and, where data were available, a second was sampled in the period >6 months before conversion. We then randomly sampled one further scan in the 6 months before conversion from half of the converting fellow eyes, with available scans chosen at random, and independently sampled one more scan in the nonimminent period from half of the converting fellow eyes also chosen at random. Ten scans were excluded because the quality was insufficient for diagnosis. For each nonconverting fellow eye, up to three scans were sampled conditionally on those scans having at least 6 months follow-up; nine scans were excluded due to poor quality. This led to a total of a total of 1,053 scans (336 eyes with 3 scans, 29 eyes with 2 scans and 26 eyes with 1 scan), of which 13.5% converted within 6 months. Each sampling step was performed independently of the others contingent on the constraints we described.
Experts were informed that the OCT scans in the study were of untreated fellow eyes of patients with exAMD in their first eye. The primary question asked the experts to predict whether the eye would convert within the next 6 months. The experts were also given the option to select that the eye had already developed exAMD—this selection was assumed to be interchangeable for predicting that the eye would convert within 6 months. To capture the ambiguity of clinical practice, a secondary question was presented asking the experts whether the eye would convert in 6–12 months, or whether it would not convert in the following 12 months.
To assess the performance in a realistic clinical environment, all scans were presented in random order with no time constraints. The same random order was maintained for all six experts. The task comprised two reviews, with at least 1 week between them. On the initial ‘single scan’ review, only the OCT scan was presented at each trial (dataset 9 in Supplementary Table8). On the second review, participants were presented with all the information available at the time of the OCT scan, including all historical scans of both eyes, fundus photographs, age, sex, ethnicity and, where available, information on visual acuity and treatment for both eyes (dataset 10 in Supplementary Table8). For the second review, trials were presented in a random but chronological order to avoid revealing future scans ahead of a trial that required a prediction on an earlier scan. The model received only the OCT scan.
Network architectures and training protocolSegmentation networkPrevious work developed an accurate OCT segmentation network that categorizes each voxel into one of 12 tissue classes and three different types of artifact2. The network architecture was built using a 3D U-Net50. The deep learning networks were implemented in TensorFlow51and Sonnet52. To prevent data contamination, we retrained the segmentation network from random weight initialization on the original ground truth segmentation maps while removing patients that were in the current test set. Training was performed across 300,000 training iterations with a batch size of 16 spread evenly across 16 NVIDIA Tesla V100 graphics processing units using the TF-Replicator distributed training system53. All other model details, data augmentation and training hyperparameters were kept the same as those used in ref.
2.
In addition, a further sample of scans with dry AMD was manually segmented to increase the variety in AMD phenotypes seen by the network for training (dataset 4, Supplementary Table8). Furthermore, a new tissue class, termed ‘hyper-reflective foci’, was added (described below). The segmentation network was trained to incorporate both of these additions. After training, the segmentation model generated predictions for every scan in the dataset including the validation and test set, providing tissue maps and volumes for 13 different tissues and three different types of artifact. Details of the tissue classes can be found in ref.
2. The segmentation maps were subsequently input into the classification or clinical referral model and used for clinical analysis (see below).
HRF segmentation classHRF are well-circumscribed, dot- or oval-shaped lesions that are present within the intraretinal layers. They can be visualized on OCT as small lesions with equal or greater hyper-reflectivity than the retinal pigment epithelium (RPE). The etiology of these lesions varies by disease—in macular oedema, HRF often represent lipid exudates whereas in age-related macular degeneration HRF are hypothesized to represent migrating RPE cells54. The presence of HRF has been associated with progression to the late stages of AMD—both geographic atrophy27,55and exAMD26,27. HRF have been shown to correlate with pigmentary changes visible on color fundus photography56, a feature identified in epidemiological57,58and clinical studies59as a key risk factor for AMD conversion.
Because HRF are therefore likely to be a prognostic biomarker, this feature was added as a new tissue to the segmentation model. HRF in all previously manually segmented images were identified and segmented (dataset 3, Supplementary Table8). The segmentation network was subsequently retrained to predict this new tissue (Extended Data Fig.
9).
Clinical referral and diagnosis networkThe segmentation maps were used to retrain the referral and diagnosis classification model from De Fauw et al. that outputs four referral decisions and ten additional diagnoses2. Although the clinical referral and diagnosis task is not the focus of this study, these can be used as an auxiliary task to improve performance in the main task of exAMD prediction, as discussed below. We retrained the same classification model on the current dataset where clinical diagnosis and referral labels were available—excluding any patient in our current test set. The performance of our clinical referral and diagnosis model closely matched the performance reported in ref.
2(overall accuracy, 94.5%). This motivated the generation of reliable distillation60labels by running the trained model over each scan in the dataset. These distillation labels were used as a ground truth for auxiliary tasks during training of the exAMD prediction model. We found this improved performance on the main task of future prediction.
exAMD prediction networkThe prediction model learns to map an input scan in the form of a gray-scale raw OCT scan or one-hot encoded segmentation map to predictions conversion with varying lead times. Raw OCT inputs were normalized and downsampled using linear interpolation in thex-andy-axes, with nearest-neighbor interpolation in thez-axis to prevent smoothing of subtle intensity changes across slices. The segmentation inputs were downsampled using linear interpolation in all axes, with no need for nearest-neighbor interpolation on coarsely encoded inputs. Exact input shape and voxel sizes of the inputs can be found in Supplementary Table14. We performed data augmentation using random 3D affine and elastic transformations of the input volumes using the Multidimensional Image Augmentation library (seeCode availability, below). Our deformation parameters are listed in Supplementary Table15.
The network consists of six levels of 3D convolutions organized into ‘blocks’. A block consists of convolutions with 1 × 3 × 3 and 3 × 1 × 1 kernels with skip connections to a final concat operation where the outputs of all previous convolutions plus the input are stacked in the channel dimension (see Extended Data Fig.
10). If the input has dimension [z,y,x,c] and a block hasnconvolution withkchannels each, then the final output of a block would be [z,y,x,c+n×k]. Skip connections draw inspiration from dense blocks, described in ref.
61, where each convolution receives the stacked outputs of all previous convolutions plus the input: theith convolution receives an input of size [z,y,x,c+(i− 1) ×k] leading to an explosion of parameters but denser representations. However, we found the dense skip connections at every layer in the block to be dispensable in our case. Our blocks with single skip connections per layer save memory, use fewer parameters and still achieve the benefits from dense blocks such as enhanced feature propagation and better gradients. The choice of 1 × 3 × 3 and 3 × 1 × 1 kernels is motivated by Xie et al.
62, who found that the factorized 1 × 3 × 3 and 3 × 1 × 1 saves memory and performs better than the full 3 × 3 × 3 convolution. A combination of 1 × 1 × 1 convolutions and 3D max pooling operations was performed between consecutive levels to reduce the number of feature outputs from concatenated dense blocks. The output of the network is fed to a dense layer with a global pool average that outputs exAMD conversion predictions over future time windows ranging from 3 to 24 months, as well as predictions for the auxiliary tasks of predicting additional diagnoses and referral decision (seeClinical referral and diagnosis network). For an exact description of the architecture see Supplementary Table16.
The training loss is taken as the sum of the sigmoid cross-entropy losses for the exAMD conversion and the disease components, and the softmax cross-entropy loss for the multi-class referral decision components. The following describes the loss function for the exAMD prediction model with multiple tasks. As described in the ensembling section, each model is independently trained and thus has weights that differ from those of the other models.
The loss function for each model task is given by the cross-entropy loss between the ground truth labelyand the model predictionf(x|θ) given an input scan or segmentation mapx:\(H({{y}},f(x|\theta )) = \mathop {\sum}\limits_{k = 1}^K { - y_k} \log (f_k(x|\theta ))\)whereyk= 1 for the correct class and 0 for the remainder, andfk(x|θ) is the model prediction for classkgiven that the model weighsθ.
As we describe in the paper, for the auxiliary diagnosis and clinical referral classification tasks that regularize the model, the same loss function is used with\(y_k \in [0,1]\)being the distillation labels, which are continuous due to being the prediction outputs60from the referral and diagnosis model (seeClinical referral and diagnosis network). Note that the exAMD conversion predictions and disease classifications are binary classification tasks, and the referral classification is a multi-class task (K= 4).
The total loss function per input is defined as\({\cal{L}}_{\mathrm{total}} = \overbrace {\mathop {\sum}\limits_{t = 3m}^{24m} {[H({{y}}^t,f^t)]} }^{{\mathrm{main}}\,{\mathrm{loss}}} + \overbrace {\mathop {\sum}\limits_{\mathrm{disease}} {\left[ {H({{y}}^{\mathrm{disease}},f^{{\mathrm{disease}}})} \right]} + H({{y}}^{{\mathrm{ref}}},f^{{\mathrm{ref}}})}^{{\mathrm{auxiliary}}\,{\mathrm{loss}}},\)withtbeing the time window for conversion predictions in months, and disease and ref being the auxiliary diagnosis and clinical referral classifications, respectively.
Loss weighting was found to be crucial in training the models to favor the training loss in maximizing future conversion performance. The number of post-conversion scans compared to pre-conversion constituted a 10:1 ratio, which is reflected in the label distributions. Post-conversion scans were thus loss weighted 1:10 for auxiliary task to boost performance. Masking future conversion labels in post-conversion scans improved performance, because penalization of the model for incorrect future predictions once the event has occurred is illogical.
The hyperparameters were chosen based on performance on the validation set. Batch-norm, layer-norm and dropout were ineffective in improving validation performance. Furthermore, minimal differences were found when using different model parameter settings for each input modality. Thus, the same hyperparameters were chosen for both the raw OCT input and segmentation input. The model was trained separately on each input without any parameter sharing. Training was performed with a batch size of 16 and a learning rate schedule starting with 0.0005, then set to 0.0005/8 after 60% of the total iterations, 0.0005/64 after 90% and, finally, 0.0005/256 for the final 5% of training. Optimization was performed using Adam63with 1 × 10−5weight decay, 0.9β1and 0.98β2; and learning rate warm-up over 10,000 iterations at a rate of 0.5. OCT training was run for 100,000 iterations.
CV and ensemblingWhile hyperparameter tuning was carried out using a 20% validation set, CV was used for final model ensembling due to the limited size of the dataset, to prevent overfitting. The patients in the training and validation sets were randomly partitioned into four folds at the patient level. Our final ensemble included model instances trained on each CV group (three folds used for training, one for validation). For each CV group, three instances of the exAMD prediction model with different random initializations were trained on three folds and evaluated on the validation fold. This was performed for both input types (raw OCT and segmentation map). The total number of trained models was 24, three randomly initialized instances for each of the two input modalities trained on each of the four CV groups. After training each model individually and freezing the weights, we ensembled all 24 models by taking the average over each of the models’ outputs. Ensembling all 24 models resulted in the best performance, with more instances giving insignificant improvements. At test-time evaluation, we performed ten instances of test-time augmentation (TTA) for each model using deformation parameters toned down from train-time deformation (Supplementary Table15). We observed that using TTA on the CV set improved performance but did not treat the number of TTAs or any of the deformation parameters as a hyperparameter, to avoid any subtle overfitting. In total we ensembled 240 different model outputs for each example in the test set to get the final system predictions. Extended Data Fig.
7gives a diagram of our ensembling scheme.
Clinical analysisThe segmentation network comprises five instances of the segmentation model. For clinical analyses, we used the mean segmentation map obtained by averaging the logits over the five instances. By equating each voxel to the volume it occupies, overall volumes of each tissue class can be derived. We further analyzed the mean segmentation output using calculated volumes and computer vision algorithms to perform geometric categorization of different tissue classes to derive clinically meaningful subgroups (Supplementary Table17). Four different categories of subgroup were analyzed: drusen volume, geographic atrophy (GA) presence, HRF presence and features pathognomonic of exAMD that were present on the conversion scan (that is, intraretinal fluid (IRF), subretinal fluid (SRF), SHRM and fibrovascular PED). In addition,en facemaps were produced to qualitatively analyze segmentation outputs.
Drusen stagingDrusen parameters including diameter, height, area and volume have been studied extensively and are known to correlate with exAMD conversion risk28,29. For this study, we explored conversion rates and system performance in ranges of drusen volume. To calculate the volume of drusen in the OCT scans, the drusenoid PED tissue class was isolated from each segmentation map for each scan in the test set. The distribution of drusen volume was stratified into four quartiles (0–25th, 25–50th, 50–75th and 75–100th percentiles). See Supplementary Table17for further details.
Presence of GAGeographic atrophy is identified by the attenuation of RPE tissue and is most easily visible onen facemaps. To isolate areas of GA, a connected components algorithm was subsequently run on the pixels without RPE to find areas of atrophy. Each detected atrophy region was measured along each axis of theen facemap to detect the largest diameter (major axis) of atrophy. GA was classified as present if the diameter of the major axis was ≥250 μm, as proposed by Sadda et al.
64.
Presence of HRFHRF are presented by relatively small hyper-reflective regions within the neurosensory tissue on segmentation maps. We defined HRF as definitely present if a set of connected HRF voxels was greater than or equal to four voxels, approximately equal to 5,750 μm3. This was determined using a connected components algorithm.
Conversion scan subgroupsFor each converting fellow eye, we analyzed the segmentation map on the visit determined to be when the eye converted. IRF, SRF, SHRM and fibrovascular PED were classified as present if they had a volume greater than five voxels, approximately equal to 7,200 μm3. For the subgroup analysis, all scans before conversion in these eyes were analyzed, stratified by the appearance of the conversion scan.
En facemapsGiven a 3D tissue segmentation, we calculated anen facemap per tissue by summing the number of voxels across the A-scan direction, generating a two-dimensional map of tissue thicknesses across the scanned macula area. The result is a tissue heatmap across B- and C-scans. These can be plotted across time, providing a useful summary of anatomical abnormalities across the full patient history.
Statistical analysisTo compute 95% confidence intervals for the true- and false-positive rates (that is, sensitivity and 1-specificity), we used the Clopper–Pearson interval as implemented in the Python statsmodels library (v.0.9.0). Kaplan–Meier survival curves were calculated using the Python lifelines library (v.0.14.6). Interexpert variability was calculated using Python sklearn.metrics library (v.0.20.0). ROCAUC confidence intervals were computed via Bootstrap.
Pvalues in Supplementary Table9and Extended Data Fig.
3were computed using two-sided permutation tests.
Pvalues in Supplementary Table10were computed with McNemar tests.
Reporting SummaryFurther information on research design is available in theNature Research Reporting Summarylinked to this article.
Data availabilityThe clinical data used for the training, validation and test sets were collected at Moorfields Eye Hospital NHS Foundation Trust and transferred to DeepMind in a de-identified format. Data were used with both local and national permissions. They are not publicly available and restrictions apply to their use. The data, or a test subset, may be available from Moorfields Eye Hospital NHS Foundation Trust subject to local and national ethical approvals. Moorfields Eye Hospital NHS Foundation Trust intends to make the raw data shared with DeepMind openly available to researchers as part of the Ryan Initiative for Macular Research (http://rimr.doheny.org/).
Code availabilityWe made use of several open-source libraries to conduct our experiments, namely the machine learning framework TensorFlow (https://github.com/tensorflow/tensorflow) along with the TensorFlow library Sonnet (https://github.com/deepmind/sonnet), which provides implementations of individual model components53. For image augmentation we used the multidimension image augmentation library previously open sourced by DeepMind (https://github.com/deepmind/multidim-image-augmentation). The model architecture source code is available from (https://github.com/google-health/imaging-research). Other aspects of the experimental system made use of proprietary libraries and we are unable to publicly release this code. We detail the experiments and implementation details inMethodsand in theSupplementary figuresto allow for independent replication.
ReferencesEsteva, A. et al. Dermatologist-level classification of skin cancer with deep neural networks.
Nature542, 115–118 (2017).
CASPubMedGoogle ScholarDe Fauw, J. et al. Clinically applicable deep learning for diagnosis and referral in retinal disease.
Nat. Med.
24, 1342–1350 (2018).
PubMedGoogle ScholarArdila, D. et al. End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography.
Nat. Med.
25, 954–961 (2019).
CASPubMedGoogle ScholarPoplin, R. et al. Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning.
Nat. Biomed. Eng.
2, 158–164 (2018).
PubMedGoogle ScholarTomašev, N. et al. A clinically applicable approach to continuous prediction of future acute kidney injury.
Nature572, 116–119 (2019).
PubMedPubMed CentralGoogle ScholarWong, W. L. et al. Global prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: a systematic review and meta-analysis.
Lancet Glob. Health2, e106–e116 (2014).
PubMedGoogle ScholarOwen, C. G. et al. The estimated prevalence and incidence of late stage age related macular degeneration in the UK.
Br. J. Ophthalmol.
96, 752–756 (2012).
PubMedPubMed CentralGoogle ScholarRein, D. B. et al. Forecasting age-related macular degeneration through the year 2050: the potential impact of new treatments.
Arch. Ophthalmol.
127, 533–540 (2009).
PubMedGoogle ScholarRudnicka, A. R. et al. Incidence of late-stage age-related macular degeneration in American whites: systematic review and meta-analysis.
Am. J. Ophthalmol.
160, 85–93 (2015).
PubMedGoogle ScholarLim, J. H. et al. Delay to treatment and visual outcomes in patients treated with anti-vascular endothelial growth factor for age-related macular degeneration.
Am. J. Ophthalmol.
153, 678–686 (2012).
CASPubMedPubMed CentralGoogle ScholarBek, T. & Klug, S. E. Incidence and risk factors for neovascular age-related macular degeneration in the fellow eye.
Graefes Arch. Clin. Exp. Ophthalmol.
256, 2061–2068 (2018).
PubMedGoogle ScholarZarranz-Ventura, J. et al. The neovascular age-related macular degeneration database: report 2: incidence, management, and visual outcomes of second treated eyes.
Ophthalmology121, 1966–1975 (2014).
PubMedGoogle ScholarFasler, K. et al. The Moorfields AMD Database Report 2 – Fellow Eye Involvement with Neovascular Age-related Macular Degeneration. Preprint atbioRxivhttps://doi.org/10.1101/615252(2019).
Maguire, M. G. et al. Incidence of choroidal neovascularization in the fellow eye in the comparison of age-related macular degeneration treatments trials.
Ophthalmology120, 2035–2041 (2013).
PubMedPubMed CentralGoogle ScholarAmoaku, W. et al. Action on AMD. Optimising patient management: act now to ensure current and continual delivery of best possible patient care.
Eye26, S2–S21 (2012).
PubMedPubMed CentralGoogle ScholarChew, E. Y., Lindblad, A. S. & Clemons, T. Summary results and recommendations from the Age-Related Eye Disease Study.
Arch. Ophthalmol.
127, 1678 (2009).
PubMedPubMed CentralGoogle ScholarCohen, S. Y. et al. Prevalence of reticular pseudodrusen in age-related macular degeneration with newly diagnosed choroidal neovascularisation.
Br. J. Ophthalmol.
91, 354–359 (2007).
CASPubMedGoogle ScholarZweifel, S. A., Imamura, Y., Spaide, T. C., Fujiwara, T. & Spaide, R. F. Prevalence and significance of subretinal drusenoid deposits (reticular pseudodrusen) in age-related macular degeneration.
Ophthalmology117, 1775–1781 (2010).
PubMedGoogle ScholarZhou, Q. et al. Pseudodrusen and Incidence of late age-related macular degeneration in fellow eyes in the comparison of age-related macular degeneration treatments trials.
Ophthalmology123, 1530–1540 (2016).
PubMedPubMed CentralGoogle ScholarLee, J. et al. Neovascularization in fellow eye of unilateral neovascular age-related macular degeneration according to different drusen types.
Am. J. Ophthalmol.
208, 103–110 (2019).
PubMedGoogle ScholarVeerappan, M. et al. Optical coherence tomography reflective drusen substructures predict progression to geographic atrophy in age-related macular degeneration.
Ophthalmology123, 2554–2570 (2016).
PubMedPubMed CentralGoogle ScholarVanderBeek, B. L. et al. Racial differences in age-related macular degeneration rates in the United States: a longitudinal analysis of a managed care network.
Am. J. Ophthalmol.
152, 273–282 (2011).
PubMedPubMed CentralGoogle ScholarAge-Related Eye Disease Study Research Group.A simplified severity scale for age-related macular degeneration.
Arch. Ophthal.
123, 1570–1574 (2005).
Google ScholarTonekaboni, S., Joshi, S., McCradden, M. D. & Goldenberg, A. M. What clinicians want: contextualizing explainable machine learning for clinical end use.
Proc. Mach. Learn. Res.
106, 359–380 (2019).
Google ScholarAge-Related Eye Disease Study Research Group. The Age-Related Eye Disease Study system for classifying age-related macular degeneration from stereoscopic color fundus photographs.
Am. J. Ophthalmol.
132, 668–681 (2001).
Google ScholarFragiotta, S., Rossi, T., Cutini, A., Grenga, P. L. & Vingolo, E. M. Predictive factors for development of neovascular age-related macular degeneration: a spectral-domain optical coherence tomography study.
Retina38, 245–252 (2018).
PubMedGoogle ScholarSchmidt-Erfurth, U. et al. Prediction of individual disease conversion in early AMD using artificial intelligence.
Invest. Ophthalmol. Vis. Sci.
59, 3199–3208 (2018).
CASPubMedGoogle ScholarAbdelfattah, N. S. et al. Drusen volume as a predictor of disease progression in patients with late age-related macular degeneration in the fellow eye.
Invest. Ophthalmol. Vis. Sci.
57, 1839–1846 (2016).
CASPubMedGoogle ScholarFolgar, F. A. et al. Drusen volume and retinal pigment epithelium abnormal thinning volume predict 2-year progression of age-related macular degeneration.
Ophthalmology123, 39–50 (2016).
PubMedGoogle ScholarNIHR Oxford Biomedical Research Centre.
World’s First Gene Therapy Operation for Common Cause of Sight Loss Carried Outhttps://oxfordbrc.nihr.ac.uk/worlds-first-gene-therapy-operation-for-common-cause-of-sight-loss-carried-out/(2019).
Dugel, P. U. et al. HAWK and HARRIER: phase 3, multicenter, randomized, double-masked trials of brolucizumab for neovascular age-related macular degeneration.
Ophthalmology127, 72–84 (2020).
PubMedGoogle ScholarSahni, J. et al. Simultaneous Inhibition of angiopoietin-2 and vascular endothelial growth factor-a with faricimab in diabetic macular edema: BOULEVARD phase 2 randomized trial.
Ophthalmology126, 1155–1170 (2019).
PubMedGoogle ScholarCampochiaro, P. A. et al. The port delivery system with ranibizumab for neovascular age-related macular degeneration: results from the randomized phase 2 ladder clinical trial.
Ophthalmology126, 1141–1154 (2019).
PubMedGoogle ScholarMuether, P. S., Hermann, M. M., Koch, K. & Fauser, S. Delay between medical indication to anti-VEGF treatment in age-related macular degeneration can result in a loss of visual acuity.
Graefes Arch. Clin. Exp. Ophthalmol.
249, 633–637 (2011).
CASPubMedGoogle ScholarRoisman, L. et al. Optical coherence tomography angiography of asymptomatic neovascularization in intermediate age-related macular degeneration.
Ophthalmology123, 1309–1319 (2016).
PubMedPubMed CentralGoogle Scholarde Oliveira Dias, J. R. et al. Natural history of subclinical neovascularization in nonexudative age-related macular degeneration using swept-source oct angiography.
Ophthalmology125, 255–266 (2018).
PubMedGoogle ScholarCarnevali, A. et al. Natural history of treatment-naïve quiescent choroidal neovascularization in age-related macular degeneration using OCT angiography.
Ophthalmol. Retina2, 922–930 (2018).
PubMedGoogle ScholarJager, R. D., Mieler, W. F. & Miller, J. W. Age-related macular degeneration.
N. Engl. J. Med.
358, 2606–2617 (2008).
CASPubMedGoogle ScholarBabenko, B. et al. Predicting progression of age-related macular degeneration from fundus images using deep learning. Preprint athttps://arxiv.org/abs/1904.05478(2019).
Bogunovic, H. et al. Machine learning of the progression of intermediate age-related macular degeneration based on OCT Imaging.
Invest. Ophthalmol. Vis. Sci.
58, BIO141–BIO150 (2017).
PubMedGoogle ScholarRussakoff, D. B., Lamin, A., Oakley, J. D., Dubis, A. M. & Sivaprasad, S. Deep learning for prediction of AMD progression: a pilot study.
Invest. Ophthalmol. Vis. Sci.
60, 712–722 (2019).
PubMedGoogle ScholarBanerjee, I. et al. A deep-learning approach for prognosis of age-related macular degeneration disease using SD-OCT imaging biomarkers. Preprint athttps://arxiv.org/abs/1902.10700(2019).
Krause, J. et al. Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy.
Ophthalmology125, 1264–1272 (2018).
PubMedGoogle ScholarVander, J. F. Risk factors for the incidence of advanced age-related macular degeneration in the Age-Related Eye Disease Study (AREDS).
Yearb. Ophthalmol.
2006, 119–121 (2006).
Google ScholarUK Information Commissioner’s Office.
Anonymisation: Managing Data Protection Risk Code of Practice(2015).
De Fauw, J. et al. Automated analysis of retinal imaging using machine learning techniques for computer vision.
F1000Res.
5, 1573 (2016).
PubMedGoogle ScholarBalaratnasingam, C. et al. Associations between retinal pigment epithelium and drusen volume changes during the lifecycle of large drusenoid pigment epithelial detachments.
Invest. Ophthalmol. Vis. Sci.
57, 5479–5489 (2016).
PubMedPubMed CentralGoogle ScholarBalaratnasingam, C. et al. Clinical characteristics, choroidal neovascularization, and predictors of visual outcomes in acquired vitelliform lesions.
Am. J. Ophthalmol.
172, 28–38 (2016).
PubMedGoogle ScholarLek, J. J. et al. Interpretation of subretinal fluid using OCT in intermediate age-related macular degeneration.
Ophthalmol. Retina2, 792–802 (2018).
PubMedGoogle ScholarÇiçek, Ö., Abdulkadir, A., Lienkamp, S. S., Brox, T. & Ronneberger, O. 3D U-Net: learning dense volumetric segmentation from sparse annotation. InMedical Image Computing and Computer-Assisted Intervention – MICCAI 2016Vol. 9901, 424–432 (Springer, 2016).
Abadi, M. et al. TensorFlow: large-scale machine learning on heterogeneous distributed systems. Preprint athttps://arxiv.org/abs/1603.04467(2016).
Reynolds, M. et al.
Open Sourcing Sonnet – A New Library for Constructing Neural Networks(DeepMind, accessed 26 July 2019);https://deepmind.com/blog/open-sourcing-sonnet/Buchlovsky, P. et al. TF-Replicator: distributed machine learning for researchers. Preprint athttps://arxiv.org/abs/1902.00465(2019).
Curcio, C. A., Zanzottera, E. C., Ach, T., Balaratnasingam, C. & Freund, K. B. Activated retinal pigment epithelium, an optical coherence tomography biomarker for progression in age-related macular degeneration.
Invest. Ophthalmol. Vis. Sci.
58, BIO211–BIO226 (2017).
PubMedPubMed CentralGoogle ScholarChristenbury, J. G. et al. and Age-Related Eye Disease Study 2 Ancillary Spectral Domain Optical Coherence Tomography Study Group. Progression of intermediate age-related macular degeneration with proliferation and inner retinal migration of hyperreflective foci.
Ophthalmology120, 1038–1045 (2013).
PubMedPubMed CentralGoogle ScholarFolgar, F. A. et al. Spatial correlation between hyperpigmentary changes on color fundus photography and hyperreflective foci on SDOCT in intermediate AMD.
Invest. Ophthalmol. Vis. Sci.
53, 4626–4633 (2012).
PubMedGoogle ScholarAge-Related Eye Disease Study Research Group. Risk factors associated with age-related macular degeneration. A case-control study in the age-related eye disease study: age-related eye disease study report number 3.
Ophthalmology107, 2224–2232 (2000).
PubMed CentralGoogle ScholarKlein, R., Klein, B. E., Jensen, S. C. & Meuer, S. M. The five-year incidence and progression of age-related maculopathy: the Beaver Dam Eye Study.
Ophthalmology104, 7–21 (1997).
CASPubMedGoogle ScholarBressler, S. B., Maguire, M. G., Bressler, N. M. & Fine, S. L. Relationship of drusen and abnormalities of the retinal pigment epithelium to the prognosis of neovascular macular degeneration. The Macular Photocoagulation Study Group.
Arch. Ophthalmol.
108, 1442–1447 (1990).
CASPubMedGoogle ScholarHinton, G., Vinyals, O. & Dean, J. Distilling the knowledge in a neural network. Preprint athttps://arxiv.org/abs/1503.02531(2015).
Huang, G., Liu, Z., Van Der Maaten, L. & Weinberger, K. Q. InProc. IEEE Conference on Computer Vision and Pattern Recognition4700–4708 (CVPR, 2017).
Xie, S., Sun, C., Huang, J., Tu, Z. & Murphy, K. InProc. European Conference on Computer Vision305–321 (Springer, 2018).
Kingma, D .P. & Ba, J. Adam: a method for stochastic optimization. Preprint athttps://arxiv.org/abs/1412.6980(2014).
Sadda, S. R. et al. Consensus definition for atrophy associated with age-related macular degeneration on OCT: classification of atrophy report 3.
Ophthalmology125, 537–548 (2018).
PubMedGoogle ScholarDownload referencesAcknowledgementsWe thank the patients under the care of Moorfields Eye Hospital. We would also like to thank B. Romera-Paredes, O. Ronneberger, N. Tomasev, S. Blackwell, J. Schrouff, M. Chesus, C. Cooper, V. Cornelius, A. Khawaja, R. Ahamed, T. Corkett, R. Ogbe, Y. Ibitoye, M. Bawn, J. Besley, C. Meaden, C. Chorley, S. Rowley, A. Ahmad, K. Clancy, C. Semturs, A. Varadarajan, B. Babenko, I. Traynis, Y. Liu, L. Peng, N. Hammel, K. Blumer, K. Kavukcuoglu, S. Bouton, G. Corrado, E. Manna, A. C. Bird, W. Tucker, Y. Obadeyi, Z. Jessa, D. Sim, M. Natkunarajah and A. Jindal. P.A.K. is supported by an NIHR Clinician Scientist Award (no. NIHR-CS-2014-14-023). The views expressed are those of the author(s) and not necessarily those of the NHS, the NIHR or the Department of Health. R.C. receives studentship support from the College of Optometrists, United Kingdom.
Author informationThese authors contributed equally: Jason Yim, Reena Chopra.
These authors jointly supervised this work: Joseph R. Ledsam, Pearse A. Keane, Jeffrey De Fauw.
AffiliationsDeepMind, London, UKJason Yim, Reena Chopra, Annette Obika, Clemens Meyer, Demis Hassabis, Mustafa Suleyman, Trevor Back, Joseph R. Ledsam & Jeffrey De FauwNIHR Biomedical Research Centre at Moorfields Eye Hospital and UCL Institute of Ophthalmology, London, UKReena Chopra, Marko Lukic, Josef Huemer, Katrin Fasler, Gabriella Moraes, Peng T. Khaw & Pearse A. KeaneGoogle Health, London, UKTerry Spitz, Jim Winkens, Christopher Kelly, Harry Askham, Marc Wilson, Jonathan Dixon, Cian Hughes, Alan Karthikesalingam & Dominic KingUniversity College London, London, UKGeraint ReesYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarYou can also search for this author inPubMedGoogle ScholarContributionsR.C., P.T.K., D.K., D.H., M.S., T.B., J.R.L., P.A.K. and J.D.F. initiated the project. J.Y., R.C., T.S., H.A., M.L., J.H., K.F., G.M., J.R.L., P.A.K. and J.D.F. created the dataset. J.Y., T.S., J.W., H.A., M.W., J.D. and J.D.F. contributed to software engineering. J.Y., R.C., T.S., J.W., C.K., T.B., J.R.L., P.A.K. and J.D.F. analyzed the results. J.Y., R.C., T.S., J.W., A.O., C.K., H.A., T.B., J.R.L. and J.D.F. contributed to the overall experimental design. J.Y., J.W. and J.D.F. designed the model architectures. R.C., C.K., C.H., G.R., D.K., J.R.L. and P.A.K. contributed clinical expertise. J.Y., R.C., T.S., J.R.L., P.A.K. and J.D.F. contributed to subgroup analysis experiments. J.Y., R.C., C.K., T.S. and J.D.F. contributed to statistical analysis. J.Y., R.C., T.S., A.O., C.K., J.R.L., P.A.K. and J.D.F. contributed to the human evaluation. J.Y., R.C., T.S., J.W., C.K., M.L., J.H., M.W., J.D. and J.D.F. contributed to segmentation model improvements. J.Y., R.C., T.S., J.W., M.W., J.D. and J.D.F. contributed to experiments using segmentation data. J.Y., R.C., J.R.L., P.A.K. and J.D.F. contributed to literature reviews. J.Y., R.C., T.S., J.W., J.R.L., P.A.K. and J.D.F. contributed to false-positive analysis. A.O., H.A., C.M., T.B., J.R.L., P.A.K. and J.D.F. managed the project. J.Y., R.C., G.R., J.R.L., P.A.K. and J.D.F. wrote the paper.
Corresponding authorsCorrespondence toJoseph R. Ledsam,Pearse A. KeaneorJeffrey De Fauw.
Ethics declarationsCompeting interestsP.A.K. and G.R. are paid contractors of DeepMind. P.A.K. has received speaker fees from Heidelberg Engineering, Topcon, Haag-Streit, Allergan, Novartis and Bayer. P.A.K. has served on advisory boards for Novartis and Bayer, and is an external consultant for DeepMind and Optos. M.L. received travel grants and a speaker fee from Bayer.
Additional informationPeer review informationMichael Basson was the primary editor on this article and managed its editorial process and peer review in collaboration with the rest of the editorial team.
Publisher’s noteSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Extended dataExtended Data Fig. 1 Summary statistics and patient demographic data.
A breakdown of training (60%), validation (20%) and test (20%) datasets by unique patients and unique scans.
Extended Data Fig. 2 Dataset statistics.
a, Histogram of scans per unique eye (pre-conversion) in training/validation set and test set.
b, Histogram of difference between conversion and injection date for fellow eyes in training and test set (n = 537, 214 have matching dates).
Extended Data Fig. 3 ROC curves for various time windows.
ROC curves for model predictions over time windows ofa, 3 months,b, 6 months,c, 12 months, andd, 24 months. Note that the difference in AUC between 12 and 24 month predictions is not statistically significant (p-value = 0.54, two-sided permutation test).
Extended Data Fig. 4 Confusion matrices per expert and task.
Confusion matrices for the prediction decision for all 6 experts for the single scan and sequential scan tasks, and for the system at two chosen operating points. n = 1053 trials (380 unique patients).
Extended Data Fig. 5 Clinical expert metrics on the benchmark study.
a, Metrics for each expert for the single scan and sequential scan tasks. Intra-observer agreement was assessed using Fleiss’ Kappa. (PPV: positive predictive value, NPV: negative predictive value).
b, Agreement between the clinical experts for the single and sequential tasks, measured using Fleiss’ Kappa. N = 1053 for both single and sequential task.
Extended Data Fig. 6 Aggregate volumes and volume change per 3 months before conversion for major ocular structures and abnormal tissues in patients who converted (n = 549 unique patients).
The box extends from the lower to upper quartile values of the data, with an orange line at the median. The whiskers show the 5th & 95th percentiles. For the left column, the statistics are calculated across patients, where patients with multiple scans per quarter are volumes averaged across these scans. For the right column the statistics for volume ch ange over 3 months were calculated on the difference for each patient between the mean volume for that quarter against the previous quarter. Volumes are calculated using the whole 2.3*6*6mm OCT volume.
Extended Data Fig. 7 Kaplan-Meier survival curves for full dataset and subgroups stratified by drusen stage and presence of HRF.
a, A Kaplan-Meier survival curve for fellow eye conversion to exAMD from baseline (defined as the first presentation of first eye conversion) in number of months, showing a little over 40% of patients converted during over 6 years of available follow up. The table shows number of eyes remaining at risk per month.
b, The same plot for comparison with following plots. (c–g) Plots for varying amounts of drusen, showing increasing numbers of patient convert as drusen volume increases. Drusen size categories are calculated as quartiles. The same plots are shown for patientsh, without andi, with geographic atrophy (GA), thosej, without andk, with hyper-reflective foci (HRF), and thosel, without andm, with fibrovascular pigment epithelial detachment (PED). In all plots the timeline is with reference to the first incidence of the feature in the eye.
Extended Data Fig. 8 Consort diagram.
Data labelling of the Moorfields Eye Hospital AMD dataset. Manual opt outs before data transfer are not included as none of the patients who manually opted out had digital OCT within the study dates.
Extended Data Fig. 9 Segmentation colour key and new hyperreflective foci class.
a, Colour key for 13 tissues and 3 artefacts segmented by the network.
b, Left: Raw OCT input to the segmentation network. Right: Output of the retrained segmentation network. Three hyperreflective foci apparent in the intraretinal layers were successfully segmented in this B-scan (purple).
Extended Data Fig. 10 Deep learning system diagram.
Flow chart of the deep learning system including ensembling and TTA. Model inputs are shaped as trapezoids. Deep learning networks are shaped as rectangles. Model outputs are shaped as pointed rectangles.
a, The segmentation network takes a raw OCT scan as input to generate a dense segmentation of the OCT which is then fed into a Diagnosis and referral network to obtain auxiliary task referral and diagnosis labels.
b, The auxiliary labels along with either the raw OCT scan or dense segmentation are inputted into each exAMD prediction network across each cross validation fold group. Although the arrows apply to one fold group and instance, they generalise across all fold groups and instances.
c, Ten TTA predictions are obtained from each instance. All TTA predictions are combined via averaging to obtain the final ensembled prediction.
d, Architecture of a single block in our network. Green circles are convolution layers applied sequentially to the input of the previous layer. Each convolution has stride 1 and uses ReLU activation. Four convolutions are shown for demonstrative purposes but the number of convolutions and the kernels used for each will differ between blocks. Each convolution has a skip connection to the last orange node which concatenates all the intermediate and final activations along the channel dimension as the output.
Supplementary informationSupplementary InformationSupplementary Figs. 1–8 and Tables 1–17Reporting SummaryRights and permissionsReprints and PermissionsAbout this articleCite this articleYim, J., Chopra, R., Spitz, T.
et al.
Predicting conversion to wet age-related macular degeneration using deep learning.
Nat Med26,892–899 (2020). https://doi.org/10.1038/s41591-020-0867-7Download citationReceived:23 September 2019Accepted:01 April 2020Published:18 May 2020Issue Date:June 2020DOI:https://doi.org/10.1038/s41591-020-0867-7Share this articleAnyone you share the following link with will be able to read this content:Sorry, a shareable link is not currently available for this article.
Provided by the Springer Nature SharedIt content-sharing initiativeFurther readingLeveraging clinical data across healthcare institutions for continual learning of predictive risk modelsScientific Reports(2022)Clinically applicable deep learning-based decision aids for treatment of neovascular AMDGraefe's Archive for Clinical and Experimental Ophthalmology(2022)Machine Learning Methods for Diagnosis of Eye-Related Diseases: A Systematic Review Study Based on Ophthalmic Imaging ModalitiesArchives of Computational Methods in Engineering(2022)Reporting guidelines for clinical trials of artificial intelligence interventions: the SPIRIT-AI and CONSORT-AI guidelinesTrials(2021)Deep learning-enabled medical computer visionnpj Digital Medicine(2021)You have full access to this article via your institution.
AdvertisementExplore contentAbout the journalPublish with usSearchAdvanced searchQuick linksNature Medicine (Nat Med)ISSN1546-170X(online)ISSN1078-8956(print)nature.com sitemapDiscover contentPublishing policiesAuthor & Researcher servicesLibraries & institutionsAdvertising & partnershipsCareer developmentRegional websitesLegal & Privacy© 2022 Springer Nature LimitedSign up for theNature Briefingnewsletter — what matters in science, free to your inbox daily.
