old id = 4107
Full article: The social power of algorithms
2013
https://www.tandfonline.com/doi/full/10.1080/1369118X.2016.1216147

Information, Communication & SocietyThe social power of algorithmsIntroductionThe social power of algorithmsABSTRACTABSTRACTThis article explores the questions associated with what might be thought of asthe social power of algorithms. The article, which introduces a special issue on the same topic, begins by reflecting on how we might approach algorithms from a social scientific perspective. The article is then split into two sections. The first deals with the issues that might be associated with an analysis of the power of the algorithms themselves. This section outlines a series of issues associated with the functionality of the algorithms and how these functions are powerfully deployed within social world. The second section then focuses upon thenotionof the algorithm. In this section, the article argues that we need to look beyond the algorithms themselves, as a technical and material presence, to explore how the notion or concept of the algorithm is also an important feature of their potential power. In this section, it is suggested that we look at the way that notions of the algorithm are evoked as a part of broader rationalities and ways of seeing the world. Exploring the notion of the algorithm may enable us to see how algorithms also play a part in social ordering processes, both in terms of how the algorithm is used to promote certain visions of calculative objectivity and also in relation to the wider governmentalities that this concept might be used to open up.
KEYWORDS:The recent TV dramaCasual(2016) introduced the viewer to Alex, a disenchanted internet entrepreneur who obsesses over his algorithm. Alex’s algorithm, we discover, is the key to the significant success of his online dating company Snooger. He already lives an apparently limitless if unfulfilling life of decadence and luxury. Yet, he keeps tweaking and playing with the algorithm, trying to perfect it, trying to hone and refine its powers. Alex, it would seem, wants the algorithm to perfectly match couples and to predict successful partnerships – including for himself. With a nagging need to hone, he keeps fiddling and working at the algorithm to try to perfect the outcomes. He knows how to play the algorithm to his advantage, as do other users of the site. They know what combination of profile features will produce lots of matches, but Alex wants the algorithm to match profiles in ways that cannot be played. When we return in the second season ofCasual, we find that Alex’s co-directed company is now in trouble. The problem, we discover from the venture capitalists who wish to purchase the company, is that the algorithm is just too good. Its predictions are too precise. As a result, people are finding long-term matches and no longer need the site. The answer – to make the algorithm less predictive.
InCasual’s mise-en-scène we have the algorithm as a kind of intermittent, shadowy and powerful force, drawing Alex’s pursuit of perfection but also active in shaping social connections and relations. A little like their presence in the social world, the algorithm is a part of the background or setting (see, for instance, Parisi,2013, pp. 26–36).
Casualreproduces the sense that algorithms are a powerful if largely unnoticed social presence. But we should hesitate. This is obviously an imagined sense of the power of algorithms; it is a vision in which an investment in coding can lead to uncanny and irresistible predictive powers of deduction. This example presents two things to consider. The first is that it provides an illustration of the type of embedded nature of algorithms and their potential role in social processes (amongst a range of examples, see, for instance, Kitchin & Dodge,2011or Manovich,2013). I would add, however, that it is a very particular notion of how these algorithms work and the type of role that they play. More importantly, for the purpose of the arguments I wish to develop towards the end of this article, the TV showCasualis just one illustrative example of the way in which we have come to imagine the power of the algorithm today. That is to say that when thinking about the power of the algorithm, we need to think not just about the impact and consequences of code, we also need to think about the powerful ways in which notions and ideas about the algorithm circulate through the social world. Within these notions of the algorithm, we are likely to find broader rationalities, knowledge-making and norms – with the concept of the algorithm holding powerful and convincing sway in how things are done or how they should be done.
This takes us to the doors of a very famous garage. In 1998, working out of the inauspicious surroundings of their Menlo Park garage, Larry Page and Sergey Brin developed the well-known PageRank algorithm that drives Google Search results. The power of this algorithm, MacCormick (2012, p. 25) has explained, is in its ability to ‘find needles in haystacks’. This power, as we know, is in the ability to sort and prioritise the media we encounter. Through its use of models of ‘authority’, this algorithm is able to use markers to assess importance in relation to the chosen search terms (see MacCormick,2012, p. 36). As algorithms go, the PageRank algorithm is unusual in its fame (for a discussion, see both Gillespie and Willson’s pieces in this issue). It is one of the more visible spikes in which the ‘technological unconscious’ (Thrift,2006, p. 224) is momentarily pierced by the fame of one of the component parts of a complex media assemblage. As such, the PageRank algorithm is certainly atypical. It is an algorithm we know something about, allowing us the opportunity to reflect on its ability to shape our knowledge and to produce outcomes (see Bilić,2016). It is far more common for algorithmic processes to pass us by without being noticed. Once we begin to reflect on the scale of these processes – with algorithms, sorting, filtering, searching, prioritising, recommending, deciding and so on – it is perhaps little wonder that a discussion of the social role of algorithms is picking up pace. There is a desire to try to understand how these algorithmic processes shape social and everyday life (see Willson, this issue). There is a desire to see how ‘algorithmic culture’ (Striphas,2015) is experienced and how ‘algorithmic life’ (Amoore & Piotukh,2016) is lived. This is to be expected, not least because the density of technological assemblages continues to escalate and so too, it would seem, algorithmic processes take on increasing weight and responsibility.
This suggests two preliminary problems. The first problem is understanding what an algorithm is. The second is understanding how different algorithms work. In other words, we will need descriptions to assist in the pursuit of a more detailed understanding of what we might callthe social power of algorothms. That is to say that there is a sense that we need to understand what algorithms are and what they do in order to fully grasp their influence and consequences. This is where we can hit blockages in our understandings. It is quite hard to be versed in social theory and in the technical minutiae of coding. It is not that this combination is impossible, but it is more likely to require collaborative work than being within the scope of the lone scholar. Books such as MacCormick’s (2012)9 Algorithms that changed the futureare useful for giving a sense of the scale, but it is then hard to move towards the depth of what we are looking at – the scale, variation and design principles of the many algorithmic forms still reside largely in Thrift’s (2006) ‘technological unconscious’. Social scientists end up operating in one register and coders in another, with it being difficult to permeate the divide. There is plenty of work that is now uncovering the influence of particular algorithmic processes. Bucher’s (2012) exemplary work on Facebook’s EdgeRank algorithm is one such instance (and we can also point to the piece by Neyland and Möller in this issue). Bucher’s work reveals a great deal about the nature of the news feed on that popular social media platform and how it makes certain things visible to the individual user. Indeed, we are now seeing a growing interest in treating algorithms as objects of study (see, for example, the collection edited by Ziewitz,2016a).
As this would suggest, perhaps the biggest single issue we have to consider when attempting to research the social power of algorithms is the potential difficulty of fully appreciating the object of study. Uncertainty about the algorithm could lead us to misjudge their power, to overemphasise their importance, to misconceive of the algorithm as a lone detached actor, or to miss how power might actually be deployed through such technologies. This difficulty of comprehension, amongst other things, has led Pasquale (2015) to conclude that we are living in a ‘black box society’. This is a society, he suggests, that is populated by ‘enigmatic technologies’ (Pasquale,2015, p. 1). Pasquale’s central point is that the ‘values and prerogatives that the encoded rules enact are hidden within black boxes’. This matters, Pasquale (2015, p. 8) claims, because ‘authority is increasingly expressed algorithmically’. Such a point opens up a series of questions about the role of algorithms in the deployment or expression of power. These questions would concern the nature of such an authority and whether an algorithm has the capability to express or enable authority. The association in Pasquale’s work is between big data and algorithms, with algorithms giving those big data a purpose and direction. Thus, the algorithm becomes the source of political concern, with the data being operationalised through those algorithmic decisions. As Pasquale (2015, p. 21) puts it, ‘critical decisions are made not on the basis of the data per se, but on the basis of data analyzed algorithmically’. Here, we see the role of algorithms, as decision-making parts of code (see Beer,2013, p. 65), as being analytic and decisive (for a discussion of the role of algorithms in data analytics, see Kitchin,2014, pp. 100–112). Indeed, it is often this ability to take decisions without (or with little) human intervention that is at the heart of discussions about algorithms potential power. Of course, again, this creates questions about the role of agency and the like (see, for instance, Pasquale,2015, p. 38), but there is clearly something here that should be of interest to anyone who wishes to understand the ordering of the social world, especially where software may be taking on some constitutive or performative role in ordering that world on our behalf.
As this alludes, one key problem with attempting to explore the social power of algorithms is in how we approach those algorithms in the first place. Should we treat them as lines of code, as objects, or should we see them as social processes in which the social world is embodied in the substrate of the code? The problem comes if we try to detach the algorithm from the social world in order to analyse its properties and powers – seeing it as a technical and self-contained object that exists as a distinct presence is likely to be a mistake. Detaching the algorithm in order to ask what it does requires separating the algorithm from the social world in the first place and then to treat it as a separate entity to those social processes. Algorithms are inevitably modelled on visions of the social world, and with outcomes in mind, outcomes influenced by commercial or other interests and agendas (as discussed by Williamson, this issue). As well as being produced from a social context, the algorithms are lived with, they are an integral part of that social world; they are woven into practices and outcomes. And then, we have the recursive processes as those outcomes are modelled back into algorithm design (see Parisi,2013). As algorithms afford data circulations, they can be tweaked and re-coded where the outcomes are seen to be in need of adjustment (see, for example, the discussion in Kitchin & Dodge,2011, p. 30; or Gillespie's article in this issue). So, seeing the algorithm as a separate item of study outside of its social ecology is likely to be a mistake. Algorithms should not be understood as an object that exists outside of those social processes (as discussed in a range of places in this volume, especially in the contributions from Neyland and Möllers, Kitchin and Willson). Their existence and design are a product of social forces, as are their implementations and redesigns.
To set the scene for thinking broadly about the material ways in which power may operate through the algorithm, I intend to briefly outline a series points that we might think of as representing the areas in which algorithms are in some way implicated, involved or integrated into social power dynamics (noting also that a detailed discussion of how to approach algorithms can be found in Rob Kitchin’s contribution to this issue). Emerging from the articles gathered in this volume, the below section outlines a series of issues that might be associated with the functionality of algorithms and how these functions can be seen to be a part of the deployment of power in social ordering.
Power and the algorithmOver the last 10 years, algorithms have become a fairly well-established presence in social scientific work (as outlined by Kitchin in this volume; see also Ziewitz,2016b). When we consider this work and the broader changes with which it is associated, we can begin to draw out some important analytical issues that we may wish to consider were we to be interested in understanding the social power of algorithms – or social power operating through the algorithm. A primary concern here might be the meshing of human and machine agency (see Beer,2013, pp. 63–101; Crang & Graham,2007, p. 792; Mackenzie,2006; Ziewitz,2016b, p. 7). Such observations have recently been placed into broader debates about the status of agency as processes of ‘datafication’ continue to expand and as data feeds-back into people’s lives in different ways (Kennedy, Poell, & van Dijk,2015).
We can link these broader issues to some specific questions that algorithms create for human discretion (see Amoore,2013; Berry,2014) or even link it to what Introna (2011, pp. 122–130) has called the ‘encoding of human agency’. Such a concern could well take us back beyond these interests in the algorithm, to the type of work done on cybernetics, interfaced bodies and posthumanism by Haraway (1991), Hayles (1999) and Mitchell (2003). But with the emergence of algorithmic systems in the everyday (see Willson's piece in this volume), this interest has gained new momentum, especially where algorithms are seen to be taking decisions out of the hands of human actors or where discretion is eroded by algorithmic limitations to thought (see Berry,2014, p. 11). This has led Crawford (2016) to reflect on the politics of such agency and to ask whether it is possible for algorithms to be agonistic. The questions around agency are complex, but the notion of algorithmic power is often premised on the idea that algorithms carry some form of agentic power. The role of cognition is discussed in Ben Williamson’s contribution to this collection. He takes popular visions of the ‘smart city’ and explores how these then filter into the ‘smarter classroom’ and ‘smarter education’. This focus enables Williamson to explore how the ‘learning brain’ is seen to interact with the ‘learning algorithm’. His contribution explores how we have come to understand or represent such a set of interactions. This, as he puts it, is to explore how ‘mental life is understood algorithmically’. This contribution provides us with a direct illustration of how we might explore the apparent meshing of human and machine agency, a theme that continues in relation to notions of ‘distributed agency’ in Neyland and Möllers’ article. Of course, both Neyland and Möllers and Williamson’s balanced and revealing analyses illustrate how easy it might be to get carried away with ideas that algorithms take over decision-making processes; instead, they indicate that there is a much more complex interweaving of types of agency going on that needs careful and critical understanding (see also Amoore,2013; and Yeung's piece in this issue) – if indeed agency is even the right terminology for this. As Bolin and Schwarz (2015) have discussed elsewhere, algorithmic outcomes are often ‘translated back’ into ‘traditional’ social parameters. In broad terms, however, there is a sense of a need to explore how algorithms make choices or how they provide information that informs and shapes choice. And then, of course, we have the human agents who design the algorithms, whose designs then shape how these processes play out or how desired outcomes are modelled into those systems (see Mackenzie,2006).
Given that algorithms are seen to be the decision-making parts of code, it is perhaps little surprise then that there is an interest in understanding how algorithms shape organisation, institutional, commercial and governmental decision-making. The second issue, which, related to the above, concerns the role of algorithms in such decision-making. This is to reflect on the role of algorithms in shaping how people are treated and judged. Or the way that algorithms shape outcomes and opportunities. This is to reflect on the way that algorithmic systems are built into organisational structures and to think about how they then shape decisions or become integrated into the choices that are made – and how those choices then become a part of people’s lives. Karen Yeung’s contribution explores the role of algorithms in regulation and governance. Yeung looks at the part played by algorithms and big data in ‘design-based’ regulation. Yeung explores the idea of the ‘hypernudge’ in exploring how algorithms shape choice, with big data-based nudges becoming a powerful presence in pre-empting behaviours. Elsewhere in this issue, Taina Bucher reflects on the other side of this process. As well as reflecting on the different ways that people think about algorithms, Bucher explores ‘how algorithms make people feel’ by focusing directly on the ‘situations and spaces where people and algorithms meet’ – fleshing out the details of these ‘personal stories’. As such, Bucher's piece is an examination of everyday lived experiences of algorithms and their affects. This is a perspective on the algorithm that is also endorsed by Michele Willson’s piece, which focuses on the embedded nature of algorithms as they frame everyday life. Such a perspective is also discussed as a potential analytical angle in Rob Kitchin’s contribution. Similarly, Tarleton Gillespie’s analysis illustrates how responding to algorithmic processes can facilitate the bending of the outcomes to particular agendas. Thus, those who understand the algorithms are able to render things ‘algorithmically recognizable’, as Gillespie puts it in his contribution to this issue. Here we see how algorithms are understood and potentially manipulated, particularly, as is made clear in Gillespie’s case study, when the algorithm can be recoded to render certain things less visible. Taken together, these pieces provide insights and a range of perspectives on how algorithms are deployed to shape decision-making and behaviour, and then how these algorithmic processes are experienced and reacted to at the level of everyday experience. The articles here, when used in combination, afford the analysis of algorithms at a range of scales – incorporating anything from multinational organisational structures to the individual body. We can bolster this multiscalar approach even further by looking at other resources. Cheney-Lippold (2011), for instance, has even written of the potential for an ‘algorithmic identity’ to be formed. On this point of scale, Bernhard Rieder’s piece in this collection argues that we might explore some ‘middle ground’ that resides between the more conceptual theories of algorithms and their technical details. This, for Rieder, is a potentially rich analytical space that connects broader social understandings of algorithms with an understanding of their technical capacity and integration.
This brings us to the third set of issues, which might be understood as the politics of algorithmic sorting, ordering and prediction. This would include the capacity of the algorithm to create, maintain or cement norms and notions of abnormality (see Crandall,2010, p. 83). Here, we might wonder how algorithms shape what is encountered, or how algorithms prioritise and make visible. This is to explore how the predictions of algorithmic systems feed into people’s lives, shaping what they know, who they know, what they discover, and what they experience. The power of algorithms here is in their ability to make choices, to classify, to sort, to order and to rank. That is, to decide what matters and to decide what should be most visible. Again, the search result is one example, but so too is the social media news feed or the ‘while you were away’ list of Tweets and so on. Again, Rieder’s piece makes a significant intervention in understanding such classification processes. Rieder reminds us that these algorithmic systems and, as he puts it, ‘algorithmic techniques’, do not come from nowhere, but are built upon existing classification means, ideas and categories. Mager’s (2012) work on how capitalist ideologies are embedded in search engine processes is instructive here of how broader power structures might find their ways into algorithmic processes and designs. Similarly, Rob Kitchin’s programmatic overview of the various approaches we might take to exploring algorithms picks up on this, with his emphasis upon the performative role of algorithms. Kitchin proposes that we expose how algorithms are constructed, how they work, and the performative part they then play in the world. His piece provides six methodological approaches for exploring this and for overcoming the difficulty of appreciating the performative role of algorithms in ordering processes. Grasping such performativity is placed alongside the problems of gaining access and managing the heterogeneous forms that algorithms take in Kitchin’s piece. In relation to the above point, we also, of course, have the algorithmic sealing of life, or what has been referred to in Pariser’s (2011) popular work as ‘filter bubbles’ (which is discussed by both Yeung and Rieder in this issue). This line or argument suggests that algorithmic sorting processes are likely to limit cultural experiences and social connections. This concerns the way that algorithms might narrow down or close off external influences, leaving people continually exposed to the same people, experiences, news, culture and so on. When thinking of how algorithms classify and order, we must, it is suggested, think of the way that algorithms repeat patterns and thus close down interactions to those that fit existing patterns. Extending these issues around ordering, Daniel Neyland and Norma Möllers use their piece to problematise the very notion of algorithmic power. They use a focus on the sorting and ordering dynamics of algorithms to open up questions about the difficulties of thinking of algorithms as holding some sort of power. They note that when attempting to understand power in relation to algorithms, we need to see this power as an ‘effect and not a cause of events’ (which returns us again to Yeung’s vital discussion of the concept ‘hypernudge’). That is to say that power is realised in the outcomes of algorithmic processes. Therefore, these processes such as algorithmic ‘If … Then’ processes, need careful attention. Their key point is that we need to see algorithms as being deeply relational and being a product of a set of associations. For Neyland and Möllers, the algorithms are ‘tied to’ various associations and situations in which they operate, rather than being entities in their own right. So, to understand the sorting power of algorithms, for instance, we need to understand the associations, dependencies and relations that facilitate those algorithmic processes and their outcomes – rather than seeing the algorithm as carrying social power.
All of this is by no means a fully populated list of all of the ways that algorithms might be seen to have some sort of social power (for more details, see the various papers in this collection or the overview provided by Kitchin in this issue). Rather, this is a cursory list of just a few of the most prominent issues as the functionality and performance of algorithms are considered alongside their social roles, implications and consequences. These points link directly and indirectly to a number of themes that emerge from this special issue. But the articles gathered in this volume are bursting with ideas and possibilities that stretch far beyond the cursory outline that I have provided. I have only really provided a whistle-stop tour of these far-reaching issues here.
The power of the notion of the algorithmThe previous section dealt with the issues that might be associated with an analysis of the power of the algorithms themselves. Before concluding, and to open up some further possibilities, this section focuses more directly upon the power ofthe notion of the algorithm. We need to look beyond the algorithms themselves to explore how the concept of the algorithm is also an important feature of their potential power. This is to suggest that we look at the way that notions of the algorithm are evoked as a part of broader rationalities and ways of seeing the world. The questions here would revolve around how the algorithm is envisioned to promote certain values and forms of calculative objectivity.
We can begin by linking this back to the previous section to argue that one way in which the power of algorithms might be explored is in relation to the production of truth. For Foucault, in the mid-1970s at least, the production of truth was placed centrally in understandings of the operation of power (see Foucault,2004,2014). Foucault (2004, p. 24) used a focus on truth to explore what he describes as the ‘how’ of power. In his 1976 lecture series,Society must be defended, he connects this interest in truth with his earlier interest in the connections between power and knowledge. In a lecture from the 14 January 1976, Foucault (2004, p. 24), reflecting on his approach to power in the previous years, argues that:multiple relations of power traverse, characterize, and constitute the social body; they are indissociable from a discourse of truth, and they can neither be established nor function unless a true discourse is produced, accumulated, put into circulation, and set to work. Power cannot be exercised unless a certain economy of discourses of truth functions in, on the basis of, and thanks to, that power.
We can turn to some of Foucault’s other work to try to clarify what is meant here and how power might operate through a notion or concept of the algorithm. For instance, Foucault (1991, p. 60) also claims:I do not question discourses about their silently intended meanings, but about the fact and the conditions of their manifest appearance; not about the contents which they may conceal, but about the transformations which they have effected; not about the sense preserved within them like a perpetual origin, but about the field where they co-exist, reside and disappear. It is a question of the analysis of the discourses in the dimension of their exteriority.
In a tentative mode, I would like to suggest that the term or notion of the algorithm should also be considered when attempting to understand the social power of algorithms. In some ways this power can potentially be detached from its technical and material form whilst still capturing something of the exteriority. As such, we would need to understand algorithms within their discursive practices and framings. The notion of the algorithm is evoked to influence and convince, to suggest things and to envision a certain approach, governmentality and way of ordering. Plus, the term is also part of wider rationalities and ways of thinking. Together then, this requires us to explore and illustrate the power of this term whilst also potentially using it as a focal point for opening up or revealing these wider rationalities. The notion of the algorithm is part of a wider vocabulary, a vocabulary that we might see deployed to promote a certain rationality, a rationality based upon the virtues of calculation, competition, efficiency, objectivity and the need to be strategic. As such, the notion of the algorithm can be powerful in shaping decisions, influencing behaviour and ushering in certain approaches and ideals. The algorithm’s power may then not just be in the code, but in that way that it becomes part of a discursive understanding of desirability and efficiency in which the mention of algorithms is part of ‘a code of normalization’ (Foucault,2004, p. 38). The notion of the algorithm is part of the social power we should be exploring. The term algorithm carries something of this authority. Algorithms are, largely, trusted for their precision and objectivity. A certain rationality may well then be built into this perception of the algorithm. The discourse surrounding the algorithm might well reveal something of the wider political dynamics of which they are a part.
With this in mind, we might open up this dimension of the social power of algorithms. This would require us to reveal the life of the concept and how it circulates. It would require us to reveal the powers that are attached to or associated with the algorithm; these are promises and ideals that are then projected onto the code itself. The aim would be to reveal the type of trust placed in systems that are labelled algorithmic (i.e., the idea that these are neutral and trustworthy systems working beyond human capacity). And, finally, to reveal the way that algorithmic visions are then responsible for the expansion and integration of algorithmic systems. The way that those systems are spoken about is part of how they are incorporated into social and organisational structures and a part of how their implicit logic spreads. Notions of the algorithm might, for instance, to link this to the work of Cetina (1994, p. 5), become part of the fictions upon which organisation run.
We have then a two-pronged means for approaching the social power of algorithms emerging from this. In this regard, Foucault (2004, p. 34) made the following pertinent point:It is the actual instruments that form and accumulate knowledge, the observational methods, the recording techniques, the investigative research procedures, the verification mechanisms. That is, the delicate mechanisms of power cannot function unless knowledge, or rather knowledge apparatuses, are formed, organized, and put into circulation.
There is obviously a good deal more to be said here; for the moment, I would like to simply suggest that the algorithm exists not just in code but it also exists in the social consciousness as a concept or term that is frequently used to stand for something (something that is not necessarily that code itself). To understand the social power of algorithms is to understand the power of algorithms as code whilst also attempting to understand how notions of the algorithm move out into the world, how they are framed by the discourse and what they are said to be able to achieve. Foucault’s (2004, p. 25) point is that ‘power constantly asks questions and questions us; it constantly investigates and records; it institutionalizes the search for truth, professionalizes it, and rewards it’. Part of that institutionalising of the search for truth is based upon the notions of these systems and their capacities along with the capillaries of these apparatuses and how discursive framings of their power are evoked to usher them in.
Concluding thoughtsIn terms of future work on the social power of algorithms, we would, of course, point to the need to continue to look inside the black box – or inside the algorithmic workings of the ‘black box society’ (Pasquale,2015). As has been argued before (see Graham,2004), we need to look inside these systems. This will require us to understand the technicalities of the systems as well as their social ordering potentials. We will need to understand the code, but we will also need to examine the work that is done by those modelling and coding these various types of algorithms. This would need to be accompanied by studies of how those algorithms play out in practice, watching how algorithms mesh into organisations, routines, decision-making and so on. These would require us to analyse the materiality of the algorithms and the systems of which they are a part, to understand the work of coders, to see modelling processes in action, to understand how the algorithms then become part of everyday practices, to see the decisions made and to then see how people respond to those algorithmic processes. As I have outlined in this introduction, some of this work is well under way. I would like to suggest that we also develop an interest in algorithms that explores the discourse surrounding algorithmic processes. This would be to examine the way that algorithms are a part of broader rationalities, broader programmes of social change and development. This is to think about the notion of an algorithm as also being a part of power dynamics. This, I have suggested, can be thought of in terms of the two ways in which algorithmic power works by producing truths – both as outcomes or outputs of systems and as part of the discursive reinforcement of particular norms, approaches and modes of reasoning.
The notion of the ‘algorithm’ is now taking on its own force, as a kind of evocative shorthand for the power and potential of calculative systems that can think more quickly, more comprehensively and more accurately than humans. As well as understanding the integration of algorithms, we need to understand the way that this term is incorporated into organisational, institutional and everyday understandings. The discourse surrounding algorithms may then provide a focal point for analysing broader political rationalities and modes of governance. In this stream of work, the interest might not be in understanding the social powers of the technical systems, but in understanding how the notion of the algorithm itself has a kind of social power. The algorithm is now a cultural presence, perhaps even an iconic cultural presence, not just because of what they can do but also because of what the notion of the algorithm is used to project. This means that the algorithm can be part of the deployment of power, not just in terms of its function but also in terms of how it is understood as a phenomenon. Algorithmic decisions are depicted as neutral decisions, algorithmic decisions are understood to be efficient decisions, algorithmic decisions are presented as objective and trustworthy decisions, and so on. We certainly need to gain a greater view of the inside of the algorithmic systems in which we live, but we also need to develop an analysis of the cultural prominence of the notion of the algorithm, what this stands for, what it does and what it might reveal.
Admittedly, when I chose the title for this special issue (and for this article), I created myself something of a problem. My title suggests that algorithms have or hold some form of power. As such, it leads us to try to think about the power that they hold rather than thinking about how power might operate through them or be complicit in how those algorithms are designed, function and lead to outcomes. As Foucault (2002, p. 284) once put it, ‘power is what needs to be explained, rather than being something that offers explanation’. The problem of conceptualising power in relation to algorithms is what I had hoped this issue might explore. It is easy to get caught up in a kind of sci-fi dystopia (or even utopia, depending on your perspective) of automated machines and the potent powers of intelligent environments. But the relations between power and algorithms require a broad conceptual and methodological palette from which the analysis might be developed. I have been fortunate in that the authors who have contributed to this issue have managed to skilfully sidestep any problems with the title of the issue and have used this as an opportunity to highlight exactly how we might rethink any blunt premises that the issue was built upon. I would like to thank them for engaging so carefully, thoughtfully and critically with the remit I set out. As the articles in this collection show, there are many other ways in which we might approach the questions that are suggested by thinking and questioning the social power of algorithms. It is at this point that I hand over to the articles contained in this collection in order for them to add the detail and nuance that is required. The themes I have set up in this introduction echo through the pieces, but these articles offer far more than I am able to fully summarise here.
Disclosure statementNo potential conflict of interest was reported by the author.
David Beeris Reader in Sociology at the University of York, UK. His recent work has focused predominantly on questions around the politics of data and metrics. His publications includeMetric power(2016),Punk sociology(2014),Popular culture and new media: The politics of circulation(2013) andNew media: The key concepts(2008, written with Nicholas Gane) [email:david.beer@york.ac.uk].
ReferencesRelated researchPeople also readlists articles that other readers of this article have read.
Recommended articleslists articles that we recommend and is powered by our AI driven recommendation engine.
Cited bylists all citing articles based on Crossref citations.
Articles with the Crossref icon will open in a new tab.
Browse journals by subjectArea StudiesArtsBehavioral SciencesBioscienceBuilt EnvironmentCommunication StudiesComputer ScienceEarth SciencesEconomics, Finance, Business & IndustryEducationEngineering & TechnologyEnvironment & AgricultureEnvironment and SustainabilityFood Science & TechnologyGeographyGlobal DevelopmentHealth and Social CareHumanitiesInformation ScienceLanguage & LiteratureLawMathematics & StatisticsMedicine, Dentistry, Nursing & Allied HealthMuseum and Heritage StudiesPhysical SciencesPolitics & International RelationsSocial SciencesSports and LeisureTourism, Hospitality and EventsUrban StudiesInformation forOpen accessOpportunitiesHelp and informationKeep up to dateRegistered in England & Wales No. 30990675 Howick Place | London | SW1P 1WGWe use cookies to improve your website experience. To learn about our use of cookies and how you can manage your cookie settings, please see ourCookie Policy.
By closing this message, you are consenting to our use of cookies.
Your download is now in progress and you may close this windowLogin or register to access this featureRegisternow orlearn more
