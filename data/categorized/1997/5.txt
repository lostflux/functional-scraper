old id = 3053
Why We Built a Neuromorphic Robot to Play Foosball - IEEE Spectrum
1997
https://spectrum.ieee.org/robotic-foosball-table

TopicsSectionsMoreFor IEEE MembersFor IEEE MembersIEEE SpectrumFollow IEEE SpectrumSupport IEEE SpectrumIEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.
Enjoy more free content and benefits by creating an accountSaving articles to read later requires an IEEE Spectrum accountThe Institute content is only available for membersDownloading full PDF issues is exclusive for IEEE MembersAccess toSpectrum's Digital Edition is exclusive for IEEE MembersFollowing topics is a feature exclusive for IEEE MembersAdding your response to an article requires an IEEE Spectrum accountCreate an account to access more content and features onIEEE Spectrum, including the ability to save articles to read later, download Spectrum Collections, and participate in conversations with readers and editors. For more exclusive content and features, considerJoining IEEE.
Join the world’s largest professional organization devoted to engineering and applied sciences and get access to all of Spectrum’s articles, archives, PDF downloads, and other benefits.
Learn more →Access Thousands of Articles — Completely FreeCreate an account and get exclusive content and features:Save articles, download collections,andtalk to tech insiders— all free! For full access and benefits,join IEEEas a paying member.
Why We Built a Neuromorphic Robot to Play FoosballUnlike regular AI, brain-inspired circuits need real-world testsThis robot foosball table is meant to serve as a benchmark test for neuromorphic algorithms and other technologies.
For the past25 years or so, those of us who seek to mimic the brain’s workings in silicon have held anannual workshopin the mountain town of Telluride, Colo. During those summer weeks, you can often find the participants unwinding at the bar of theNew Sheridan Hotelon the town’s main street. As far back as most can remember, there has been a foosball table in the bar’s back room. During the weeks of the workshop, you’ll usually find it surrounded by a cluster ofneuromorphicengineers engaged in a friendly rivalry that has spanned many years. It was therefore almost a foregone conclusion that someone was going to build a neuromorphic-robot foosball table.
That someone was me.
It turns out there’s more to the idea than simple fun. After all, why do we play competitive games like foosball? We are drawn to them for social reasons, but we also enjoy learning the mechanics and improving our performance. Games are how we boost our hand-eye coordination, tracking and predictive abilities, and strategic thinking. Those are all skills we want robots to have.
Top: Neuromorphic-robot foosball was born from neuromorphic engineers playing at the New Sheridan Hotel in Telluride. Bottom: In its two trips to the Telluride Neuromorphic Cognition Engineering Workshop, our robot foosball table has seen plenty of use.
Western Sydney UniversityHumans have always been fascinated by the idea of machines playing our games. As far back as the late 18th century, theMechanical Turk hoaxenthralled and amazed audiences with its (fictitious) ability to beat humans at chess. But we were all just as amazed in 1997 when IBM’sDeep Bluedid it for real. Now, such triumphs are almost a regular occurrence, with DeepMind’s AI systems first defeating a human champion atthe board game Go, and then going on to victory with the video gameStarCraft II. (An AI will probably have conquered another of your favorite games by the time you finish reading this.)These feats of computing are pretty good measures of a system’s abilities. But they fall short in some important ways. Robots need to operate in a real world full of noise, irregularities, and evolving environments. The rigid rules and constrained environment of Go will never provide such challenges. Real-world games, certainly foosball and possibly pinball, might be a better measure of whether our efforts to match the might of the human brain are really on track.
Why are weso interested in learning biology’s computational and sensing secrets? Frankly, it’s because they are so superior to today’s computing technology, which seems to be fast reaching its limits. Commodity sensors produce too much data for computers to understand, and those computers consume too much power trying to make sense of it. Biology outperforms all our technologies when it comes to sensing and perceiving the world, and biological organisms are orders of magnitude more power efficient, reliable, robust, and adaptable.
My colleague at Western Sydney University's International Center for Neuromorphic Systems (ICNS),André van Schaik, gives a great example: the humble mosquito. Its brain is composed of only about200,000 neurons, yet its flight control and obstacle avoidance are far superior to anything that we have built. Next, consider the dragonfly, which cancapture a mosquito midflight. It has about five times as many neurons as the mosquito and consumes perhaps 30 mosquitoes’ worth of energy per day, about equivalent to a few grains of sugar.
One of the most straightforward examples of how neuromorphic technology can be used in sensing is vision, which happens to be my speciality. When it comes to building devices that need to see the world, cameras with CMOS imagers are almost always used. These cameras are such a commodity that it’s easy to forget that a picture (which computer-vision researchers call a frame) is not the only way to perceive the visual world.
Cameras are built to capture a representation of a scene that’s good enough to fool our visual system. We don’t really know what features or information the visual system is using to understand the scene, so cameras simply capture as much information as possible. That approach is fine for taking static pictures, but it’s not a great fit for doing things like tracking objects through space. For example, imagine trying to track an object—a foosball ball, for instance—that’s moving so fast it completely leaves the edge of the image in the 33 milliseconds between one frame and another. Sure, you could use a camera with double the frame rate, but that means you’ve now got twice as much data to sort through just to keep track of that one object.
Biological eyes work differently. There are no frames in biology, and there are too few nerves going between the eyes and the brain to transmit whole images anyway.
Neuromorphic vision sensorsdraw inspiration from how the eye’s photoreceptors work; they still use lenses to project the world onto a grid of pixels on a silicon chip, but it’s what those pixels do with the information that’s interesting.
The pixels in neuromorphic sensors—also called event-based imagers—report only changes in illumination and only in the instant when the changes happen. They don’t produce any data when nothing is changing in front of them. This approach drastically reduces the amount of data these cameras generate, which means less data to store, to transmit, and to process. These imagers therefore use less power both in the camera itself and for all the computation that needs to happen afterward.
Tracking the ball with a neuromorphic sensor should be easy, and in the trivial case of the pinball machine, it clearly is.
StartupsPropheseeandIniVationalready have brands of event-based imagers on the market. And these sensors have even gone to space: Neuromorphic cameras from ICNS will spot satellites and space junk from orbit, and a different sensor was recently installed on the International Space Station to examine ephemeral atmospheric phenomena, such assprites.
Neuromorphic researchers have also tackled our other senses. They’ve developedsilicon cochleasto model hearing,tactomorphic sensorsto explore touch, and even asilicon noseto identify odors and gases. Beyond sensing, neuromorphic engineering seeks to understand the fundamental ways in which brains process and store information. In fact, the origins of neuromorphic engineering lie in trying to build electronic neurons to better understand how real neurons in the brain operate.
Neuromorphic sensors, and the brain-inspired algorithms that work with the data they produce, allow for specialized systems built specifically for efficient performance on certain tasks. However, it can be difficult to know when these sensors are capturing the right information or when our algorithms are working properly. That’s where the need for benchmarks comes into play.
To help understandwhy we need foosball as a neuromorphic benchmark, take the example of how an event-based imager would handle a benchmark that today’s deep-learning AIs deal with all the time, the MNIST database. MNIST (short for Modified National Institute of Standards and Technology) is like the “Hello, World!” of machine vision. Its data set of thousands of low-resolution images of handwritten numerals offers a baseline for how well an image-recognition neural network is working.
Like biological eyes, event-based cameras register only the changes in a scene. This greatly reduces the data needed for tracking the ball.
Gregory CohenAn event-based imager would momentarily see each MNIST numeral as it flashes in front of it. For such a sensor to continue to see the static numerals, either the camera must move or the digit must, and in a controlled way. Eyes do something similar: Their focus moves from point to point until the brain understands what it’s seeing.
Creating data sets like MNIST that are a suitable test for neuromorphic systems is not trivial, and the truth is they’re not very useful. The process of linking motion to imaging can be so dynamic that for anything but the most constrained tasks, the number of possibilities would be quite large. So how can we determine if neuromorphic systems are working, and how can we compare them to other approaches?There are, of course, benchmarks that are interactive simulations. For example, in autonomous driving simulations, the view fed to the algorithm from the car’s sensors changes as the car’s position changes. But these simulations have their problems. The most significant is the contrast between controlling a simulation and controlling a physical system.
The major difference between simulated systems and reality lies in the amount and nature of noise in the real world. For most AI systems, noisy data is a big problem. But there’s reason to believe that neuromorphic systems thrive with noise, and perhaps even need it. That’s not as strange as it might seem. Our own sense of movement and body position is actually enhanced by a certain amount of noise. Attempts to mitigate noise in neuromorphic systems, either through extra processing or by designing real-world systems that are closer to our idealized simulations, may have held us back.
So what we need to move neuromorphic systems forward are benchmarks that are physically embedded in the real world.
Let’s start withsomething simple: pinball. It’s actually a very good choice for a benchmarking problem because the game is so straightforward. There are only two outputs, one for each flipper, and the game largely revolves around timing. The realities of the physical system are unforgiving, and you cannot simply pause or slow the movement of the ball to allow an algorithm to catch up. Most important, there’s a score in pinball and a clear objective to maximize that score. So whichever system gets the highest score at pinball is unequivocally the better robotic pinball algorithm.
Pinball is a simple test of neuromorphic systems. It’s so simple, in fact, that we built a two-artificial-neuron system that could keep three balls in play at once.
Gregory CohenWe can also make the problem more difficult by tweaking the game a little. For example, we can add multiple balls at the same time, or even decoy balls or balls of a material that will behave differently on the pinball table. This allows us to include a wider range of tasks such as tracking, detecting, segmenting, and identifying the balls while still maintaining the score as the ultimate metric for success.
ICNS has built a demo using a robotic pinball machine that can keep three balls on the table with about the same effectiveness as a human player. Amazingly, unlike the hundreds of thousands or millions of artificial neurons found in common deep-learning-based systems, this tiny neuromorphic brain interprets and acts on the input from an event-based imager using just two artificial neurons.
Pinball is great,but my team felt there was a need for a more complicated and demanding task to further push the neuromorphic research community. Also, we like playing foosball at the New Sheridan Hotel’s bar.
Foosball looks like an easy game for robots: All the action happens in two dimensions, and it takes only eight motors to control all the little figures on the table. But it’s much more difficult than it seems.
There have been a few attempts over the years at building a robotic foosball table with varying degrees of success, but none using neuromorphic sensors and algorithms. The prior robotic systems often needed to modify the game to give the robot an advantage. For example, thefoosball table built by Brigham Young Universitymade use of a color-segmented tracking algorithm and required that the ball be the only green object on the table. Therobotic foosball table atÉcole Polytechnique Fédérale de Lausanne (EPFL), in Switzerland, is impressive, but it simplifies the task dramatically by replacing the bottom of the foosball table with a transparent plastic sheet and letting the camera look up, thereby always providing an unobstructed view of the ball.
Our approach aims to re-create the same inputs as those experienced by a human player. The camera looks down on the table, giving it an obstructed view that’s similar to what a human would have. And we use a regulation ball, not one with special markings or colors.
Our approach to building a robotic foosball table aims to re-create the same inputs as those experienced by a human player.
Our robotic foosballtable has so far made two trips from Australia to the mountains of Colorado. For three weeks at a time, teams of fresh neuromorphic engineers have descended upon the problem with gusto, taking up the challenge of programming the table to achieve the highest score. The results highlighted the difficulties of the task and the shortfalls of conventional AI methods.
For one thing, tracking the ball with a neuromorphic sensor should be easy, and in the trivial case of the pinball machine, it clearly is. However, foosball is a more dynamic game, especially when a human player is involved. Human players each have different strategies, and their movements are not always logical or even necessary.
Attempts to use non-neuromorphic solutions, such as deep learning, led to a few interesting lessons. First, it became apparent that the way deep-learning neural networks are processed—usually on a GPU—is not well suited to this type of task. GPUs operate best on batches of images rather than a single frame at a time. This is a problem, because we don’t care about where the ball was in the past, and we don’t really even care about where the ball is at the moment; what we really care about is where it’s going to be next. So the deep-learning solutions were processing a lot of unnecessary information.
Second, we found that the deep-learning methods were extremely sensitive to small variations in the problem. A slight shake of the camera, a bit of skew in the table from players pulling it in different directions, or even a shift in lighting conditions caused the elegant performance of deep-learning ball trackers to break down. It’s likely that we could increase the amount of training to handle all these small deviations—there’s a whole field of research devoted to building networks that are resilient to these sorts of things—but that would take many, many more games.
Our latest approaches look toward simpler and faster neuromorphic networks. These algorithms process every event—also called a “spike” in neuromorphic computing—from the camera and use them to update the estimation of the position of the ball.
Instead of deep learning’s vast layers of neurons, these networks use 16 small pattern-recognition networks of 18 x 18 pixels each, so only 364 pixels are being considered at any point in the game. This makes them very fast and mostly accurate. And being fast is critically important, because event-driven algorithms need to keep up with the time-sensitive data being produced by the camera. Each event necessitates no more than some small and simple calculations. While this system doesn’t pose much of a threat to an experienced player, our network’s tracking has improved to the point where it can quite reliably block the ball. Goal scoring, however, is still a work in progress.
Top: Each motor has its own controller. Bottom: The table control system supervises the motor controllers and performs other duties.
Gregory CohenDeep learning could perform a similar operation, in principle, but it needs to look at the entire image, and it performs orders of magnitude more calculations for each layer of the network. Not only is this far more data than our system uses, but it also effectively turns the event-driven output back into frames.
Currently, our algorithm is trained offline from recorded event-based data. It uses a genetic algorithm—one that evolves toward an optimal solution—to both learn what the ball looks like and to create good estimates of where it will be next. The algorithm learns how to recognize the ball from the data itself, rather than through any coding on our part. It also learns from how the ball really moves, rather than our own expectation of it. These are both important points, as our preconceptions of a good model for the ball turned out to be very far from those that work well. We also found that our simulations and expectations for the motion of the ball were wildly off.
Our next step is to move our learning from offline training to real-time online learning, allowing the network to continuously learn and adapt while the game is in progress. Among other things, that may help with a sensitivity the system has now to the specific table it’s trained on.
These event-driven algorithms are an intermediate step toward algorithms designed to work using so-called spike-based neuromorphic hardware. These brain-inspired processors, such as Intel’sLoihiand BrainChip’sAkida, encode information as the timing of spikes and are a natural fit with event-based sensors. Once we have stable spike-based algorithms, we’ll be able to make improvements more quickly.
Hopefully, we won’t be the only ones making these improvements. In designing the robot foosball table, we focused on keeping the costs down and made the entire project open source. With luck, other neuromorphic research groups will see enough value in having their own robot benchmarks. And if not, they’ll be able to find us and our foosball table inTelluride later this year.
This article appears in the March 2022 print issue as “Gooaall!!!.”Gregory Cohenis an associate professor at theInternational Center for Neuromorphic Systemsat Western Sydney University, in Australia.
The grandparent of all neuromorphic robots was certainly the CAVIAR robot from 2006 at https://youtu.be/Z2lBjn3QIMw. It is arguably the MOST NEUROMORPHIC of all such robots ever, because the entire computation and motor control was done with interconnected spiking chips interfaced with word-parallel AER buses. It was really cool! But the huge difficulty of constructing and running CAVIAR was what inspired the development of hardware-software robots like the RoboGoalie https://youtu.be/IC5x7ftJ96w now incredibly 13 years ago.
It seems like the perception part is mostly solved, maybe it is time to move on to control? There are huge opportunities (https://sites.google.com/view/tellurideneuromorphic2021/topic-areas/ltc21-learning-to-control) for neuromorphic engineers to contribute to this field that demands adaptability, speed, robustness, and high efficiency -all of which animals excel at.
Only a few of these DVS robots got written up as papers, - there were many other Telluride DVS robots that didn’t make it that far - I hope we can have a foosball paper with as distributed an author list as the Slot Car Racer paper. These robots relied on hand-crafted DVS ball trackers because they predated deep learning. Now foosball---and games like Labyrinth with similar distractors--- are more easily realized, thanks to the huge advances in practical deep learning. It's really exciting and dovetails directly with the big industrial interest in bringing neuromorphic sparse computing ideas to hardware AI: http://dx.doi.org/10.1109/MSSC.2021.3128243Readers can see how these robots are built in these papers- RoboGoalie: http://dx.doi.org/10.3389/fnins.2013.00223- Pencil Balancer: http://dx.doi.org/10.1109/ISCAS.2009.5117867- Slot Car Racer: http://dx.doi.org/10.1109/ISCAS.2015.7169170Practical Power Beaming Gets RealVideo Friday: Drone in a CageRemembering 1982 IEEE President Robert LarsonAcer Goes Big on Glasses-Free, 3D Monitors—Look Out, VRIs this what’s needed to bring augmented reality to the home office?Matthew S. Smithwrites IEEE Spectrum's Gizmo column and is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009.
Content creators are a key target for Acer’s glasses-free 3D.
Acer, the world’s fifth largest PC brand, wants to take the growing AR/VR market by the horns with its SpatialLabs glasses-free stereoscopic 3D displays.
First teased in 2021 in a variant of Acer’s ConceptD 7 laptop, the technology expands this summer in a pair of portable monitors, the SpatialLabs View and View Pro, and select Acer Predator gaming laptops. The launch is paired with artificial-intelligence-powered software for converting existing 2D content into stereoscopic 3D.
“We see a convergence of virtual and reality,” Jane Hsu,head of business Development for SpatialLabs, said in an interview. “It’s a different form for users to start interacting with a virtual world.” Glasses-free stereoscopic 3D isn’t new.
Evolutionary, not revolutionaryThe technology has powered several niche products and prototypes,such as Sony’s Spatial Reality Display, but its most famous debut was Nintendo’s 3DS portable game console.
The 3DS filtered two images through a display layer called a parallax barrier. This barrier controlled the angle an image reached the user’s eyes to create the 3D effect. Because angle was important, the 3DS used cameras that detected the user’s eyes and adjusted the image to compensate for viewing angle.
“The PC in 2022 is encountering a lot of problems.”—Jerry Kao, AcerAcer’s technology is similar. It also displays two images which are filtered through an “optical layer” and has cameras to track and compensate for the user’s viewing angle.
So, what’s different this time?“The fundamental difference is that the computing power is way different, and resolution is way different,” said Hsu. “The Nintendo, that was 800 by 240. In a sense, the technology is the same, but over time it has improved for a crystal-clear, high-resolution experience.”Resolution is important to this form of glasses-free 3D. Because it renders two images to create the 3D effect, the resolution of the display is cut in half on the horizontal axis when 3D is on. The 3DS cut resolution to 400 by 240 when 3D was on and blurry visuals werea common complaint among critics.
Acer’s SpatialLabs laptops and displays are a big improvement. Each provides native 4K (3,840 by 2,160 resolution) in 2D. That’s 43 times the pixel count of Nintendo’s 3DS. Turning 3D on shaves resolution to 1,920 by 2,160, which, while lower, is still sharper than that of a 27-inch 4K monitor.
Hsu says advancements in AI compute are also key. Partners like Nvidia and Intel can now accelerate AI in hardware, a feature that wasn’t common a half decade ago.
Acer has harnessed this for SpatialLabs GO, a software utility that can convert full-screen content from 2D to stereoscopic 3D. This should make SpatialLabs useful with a wider range of content. It can also help creators generate content for use in stereoscopic 3D by importing and converting existing assets.
A new angle on augmented realityAcer was a lead partner in Microsoft’s push for mixed-reality headsets. They were a flop, and their failure taught Acer hard lessons about how people approach AR/VR hardware in the real world.
“Acer spent a lot bringing VR headsets to market, but...it was not very successful,”Acer Co-COO Jerry Kao said in an interview. “There were limitations. It’s not comfortable, or it’s expensive, and you need space around you. So, we wanted to address this.”SpatialLabs is a complementary alternative. Creators can use Spatial Labs to achieve a 3D effect in their home office without pushing aside furniture. The Acer View Pro, meant for commercial use, may have a future in retail displays, a use that headsets can't address.
The View Pro display is built for use in kiosks and retail displays.
AcerMost of the SpatialLabs product line, including the ConceptD 7 laptop and View displays, lean toward creative professionals using programs like Maya and Blender to create 3D content. Acer says its software suite has “out-of-the-box support for all major file formats.” It recently added support for Datasmith, a plug-in used to import assets toEpic’s Unreal Engine.
But the technology is also coming to Predator gaming laptops for glasses-free stereoscopic 3D in select titles likeForza Horizon 5andThe Witcher 3: Wild Hunt. Gaming seems a natural fit given its history in Nintendo’s handheld, and Hsu thinks it will help attract mainstream attention.
“When the Turn 10 team [developer of the Forza Horizon series] saw what we had done withForza Horizon 5, they were like, ‘Wow, this is so great!’ ” said Hsu. “They said, ‘You know what? I think I can build the scene with even more depth.’ And this is just the beginning.”Does glasses-free 3D really stand a chance?SpatialLabs brings gains in resolution and performance, but it’s far from a surefire hit. Acer is the only PC maker currently pursuing the hardware. Going it alone won’t be easy.
“While the tech seems quite appealing, it will likely remain a niche product that’ll be used in rare instances by designers or developers rather than the average consumer,”Jitesh Ubrani, research manager at IDC, said in an email. He thinks Acer could find it difficult to deliver on price and availability, “both of which are tough to do for such a fringe technology.”I asked Hsu how Acer will solve these issues. “In a way he’s right, it is difficult. We’re building this ourselves,” said Hsu. “But also, the hardware is more mature.”Kao chimed in to say SpatialLabs will stand out in what might be weak year for home computers. “The PC in 2022 is encountering a lot of problems,” Kao said. He sees that as a motivation, not a barrier, for novel technology on the PC.
“Intel, Google, Microsoft, and a lot of people, they have technology,” said Kao. “But they don’t know how to leverage that technology in the product and deliver the experience to specific people. That is what Acer is good at.”DARPA Wants a Better, Badder Caspian Sea MonsterLiberty Lifter X-plane will leverage ground effectArguably, the primary job of any military organization is moving enormous amounts of stuff from one place to another as quickly and efficiently as possible. Some of that stuff is weaponry, but the vast majority are things that support that weaponry—fuel, spare parts, personnel, and so on. At the moment, the U.S. military has two options when it comes to transporting large amounts of payload. Option one is boats (a sealift), which are efficient, but also slow and require ports. Option two is planes (an airlift), which are faster by a couple of orders of magnitude, but also expensive and require runways.
To solve this, the Defense Advanced Research Projects Agency (DARPA) wants to combine traditional sealift and airlift with theLiberty Lifter program, which aims to “design, build, and flight test an affordable, innovative, and disruptive seaplane” that “enables efficient theater-range transport of large payloads at speeds far exceeding existing sea lift platforms.”DARPADARPA is asking for a design like this to take advantage of ground effect, which occurs when an aircraft’s wing deflects air downward and proximity to the ground generates a cushioning effect due to the compression of air between the bottom of the wing and the ground. This boosts lift and lowers drag to yield a substantial overall improvement in efficiency. Ground effect works on both water and land, but you can take advantage of it for only so long on land before your aircraft runs into something. Which is why oceans are the ideal place for these aircraft—or ships, depending on your perspective.
During the late 1980s, the Soviets (and later the Russians) leveraged ground effect in the design of a handful of awesomely bizarre ships and aircraft. There’s theVVA-14, which was also an airplane, along with the vehicle shown in DARPA’s video above, theLun-class ekranoplan, which operated until the late 1990s. The video clip really does not do this thing justice, so here’s a better picture, taken a couple of years ago:InstagramTheLun(only one was ever made) had a wingspan of 44 meters and was powered by eight turbojet engines. It flew about 4 meters above the water at speeds of up to 550 kilometers per hour, and could transport almost 100,000 kilograms of cargo for 2,000 km. It was based on an earlier, even larger prototype (the largest aircraft in the world at the time) that the CIA spotted in satellite images in 1967 and which seems to have seriously freaked them out. It was nicknamed the Caspian Sea Monster, and it wasn’t until the 1980s that the West understood what it was and how it worked.
In the mid 1990s, DARPA itself took a serious look at a stupendously large ground-effect vehicle of its own, theAerocon Dash 1.6 wingship. The concept image below is of a 4.5-million-kg vehicle, 175 meters long with a 100-meter wingspan, powered by 20 (!) jet engines:WikipediaWith a range of almost 20,000 km at over 700 km/h, the wingship could have carried 3,000 passengers or 1.4 million kg of cargo. By 1994, though, DARPA had decided that the potential billion-dollar project to build a wingship like this was too risky, and canceled the whole thing.
Less than 10 years later, Boeing’s Phantom Works started exploring an enormous ground-effect aircraft, thePelican Ultra Large Transport Aircraft. The Pelican would have been even larger than the Aerocon wingship, with a wingspan of 152 meters and a payload of 1.2 million kg—that’s about 178 shipping containers’ worth. Unlike the wingship, the Pelican would take advantage of ground effect to boost efficiency only in transit above water, but would otherwise use runways like a normal aircraft and be able to reach flight altitudes of 7,500 meters. Operating as a traditional aircraft and with an optimal payload, the Pelican would have a range of about 12,000 km. In ground effect, however, the range would have increased to 18,500 km, illustrating the appeal of designs like these. But Boeing dropped the project in 2005 to focus on lower cost, less risky options.
We’d be remiss if we didn’t at least briefly mention two other massive aircraft: theH-4 Hercules, the cargo seaplane built by Hughes Aircraft Co. in the 1940s, and theStratolaunch carrier aircraft, which features a twin-fuselage configuration that DARPA seems to be favoring in its concept video for some reason.
From the sound of DARPA’s announcement, they’re looking for something a bit more like the Pelican than the Aerocon Dash or theLun. DARPA wants the Liberty Lifter to be able to sustain flight out of ground effect if necessary, although it’s expected to spend most of its time over water for efficiency. It won’t use runways on land at all, though, and should be able to stay out on the water for 4 to 6 weeks at a time, operating even in rough seas—a significant challenge for ground-effect aircraft.
DARPA is looking for an operational range of 7,500 km, with a maximum payload of at least 90,000 kg, including the ability to launch and recover amphibious vehicles. The hardest thing DARPA is asking for could be that, unlike most other X-planes, the Liberty Lifter should incorporate a “low cost design and construction philosophy” inspired by the mass-produced Liberty ships of World War II.
With US $15 million to be awarded to up to two Liberty Lifter concepts, DARPA is hoping that at least one of those concepts will pass a system-level critical design review in 2025. If everything goes well after that, the first flight of a full-scale prototype vehicle could happen as early as 2027.
Modeling Microfluidic Organ-on-a-Chip DevicesRegister for this webinar to enhance your modeling and design processes for microfluidic organ-on-a-chip devices using COMSOL MultiphysicsIf you want to enhance your modeling and design processes for microfluidic organ-on-a-chip devices,tune into this webinar.
You will learn methods for simulating the performance and behavior of microfluidic organ-on-a-chip devices and microphysiological systems in COMSOL Multiphysics. Additionally, you will see how to couple multiple physical effects in your model, including chemical transport, particle tracing, and fluid–structure interaction. You will also learn how to distill simulation output to find key design parameters and obtain a high-level description of system performance and behavior.
There will also be a live demonstration of how to set up a model of a microfluidic lung-on-a-chip device with two-way coupled fluid–structure interaction. The webinar will conclude with a Q&A session.
Register now for this free webinar!Trending StoriesPractical Power Beaming Gets RealDARPA Wants a Better, Badder Caspian Sea MonsterSimple, Cheap, and Portable: A Filter-Free Desalination System for a Thirsty WorldVideo Friday: Drone in a CageAcer Goes Big on Glasses-Free, 3D Monitors—Look Out, VRAndrew Ng: Unbiggen AIHydrogen Helps Make Topological Insulators PracticalBefore Ships Used GPS, There Was the Fresnel Lens
