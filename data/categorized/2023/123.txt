old id = 1198
Yann LeCun's Deep Learning Course at CDS - NYU Center for Data Science
2023
https://cds.nyu.edu/deep-learning

NYU Center for Data Science Harnessing Dataâ€™s Potential for the World About Overview Diversity, Equity, & Inclusion About Community Partners Program Stats and Plans Contact Communications CDS Updates Community Newsletter Our People Faculty Joint Associated Visiting Affiliated Affiliated Shanghai Clinical Adjunct Leadership Fellows, Research Engineers, Research Scientists, and Postdocs Data Science Faculty Fellows Research Engineers & Research Scientists Postdoc Researchers Affiliated Postdocs Staff PhD Students PhD Alumni Past Members Research Research Home CDS Research Groups Faculty Research Areas Faculty Honors Academics PhD Program Overview Areas & Faculty Curriculum Admission Requirements FAQ Medical School Track NRT FUTURE Program Masterâ€™s Program Overview Curriculum Industry Concentration Tracks Admission Requirements FAQ Capstone Project Summer Initiative Financial Aid MS Admissions Ambassadors Undergraduate Program Overview Major in Data Science Minor in Data Science Joint Majors FAQ Contact Non-Degree Program Overview Curriculum Admission Requirements FAQ Apply Now Student Career Placement & Professional Development Overview Our Students: Career and Placement Information Alumni Spotlights Student Groups CDS Alumni Council Student Fellowships & Awards CDS Academic Integrity Statement and Policy Open House Webinars The CDS Podcast CDS Online Yann LeCunâ€™s Deep Learning Course at CDS Mathematical Tools for Data Science Brave New World Podcast Partnerships Partners Program Partnership Research Initiatives Executive Education Events CDS Events Feed The Math and Data (MaD) Seminar MaD+ Seminar Series NLP and Text-as-Data Speaker Series Computational Biology & Medicine Colloquium Data Science Lunch Seminar Series The Math and Democracy Seminar Data Science Graduate Student Seminar AI, Misinformation, and Policy Seminar Series Jobs Faculty & Staff Positions Faculty Fellows Positions Initiatives Current Initiatives AI@NYU Center for Responsible AI CURP CURP Summer 2023 Cohort CURP Summer 2022 Cohort CURP Spring 2022 Cohort CURP Spring 2021 Cohort Minds, Brains, & Machines Past Initiatives DS3 Moore-Sloan Overview Seed Grant Summer Research Initiative Showcase Community Newsletter Search for: Search for: Yann LeCunâ€™s Deep Learning Course at CDS Description This course concerns the latest techniques in deep learning and representation learning, focusing on supervised and unsupervised deep learning, embedding methods, metric learning, convolutional and recurrent nets, with applications to computer vision, natural language understanding, and speech recognition. The prerequisites include: DS-GA 1001 Intro to Data Science or a graduate-level machine learning course.
DS-GA 1008 Â· SPRING 2021 Instructorsâ€‹: Lectures â€“ Yann LeCun | Practicum â€“ Alfredo Canziani Lecturesâ€‹: â€‹Mondays, 9:30 â€“ 11:30am EST, Zoom Practica: â€‹Tuesdays, 9:30 â€“ 10:30am EST Forumâ€‹: â€‹r/NYU_DeepLearning Discord: â€‹NYU DL Material: 2021 Repo Please note weâ€™re officially supporting direct communication with students taking this course online via our Reddit and Discord platforms.
2021 edition disclaimer Check the repoâ€™s README.md and learn about: Content new organisation The semesterâ€™s second half intellectual dilemma This semester repository Previous releases Lectures Most of the lectures, labs, and notebooks are similar to the previous edition, nevertheless, some are brand new. I will try to make clear which is which.
Legend : ğŸ–¥ slides, ğŸ“ notes, ğŸ““ Jupyter notebook, ğŸ¥ YouTube video.
Translations ğŸ‡¬ğŸ‡§ English | ğŸ‡«ğŸ‡· French If youâ€™re interested in assisting the Deep Learning team with translation, please contact Alfredo Canziani at canziani@nyu.edu.
Theme 1: Introduction History and resources ğŸ¥ ğŸ–¥ Gradient descent and the backpropagation algorithm ğŸ¥ ğŸ–¥ Neural nets inference ğŸ¥ ğŸ““ Modules and architectures ğŸ¥ Neural nets training ğŸ¥ ğŸ–¥ ğŸ““ ğŸ““ Homework 1: backprop Theme 2: Parameters sharing Recurrent and convolutional nets ğŸ¥ ğŸ–¥ ğŸ“ ConvNets in practice ğŸ¥ ğŸ–¥ ğŸ“ Natural signals properties and the convolution ğŸ¥ ğŸ–¥ ğŸ““ Recurrent neural networks, vanilla and gated (LSTM) ğŸ¥ ğŸ–¥ ğŸ““ ğŸ““ Homework 2: RNN & CNN Theme 3: Energy based models, foundations Energy based models (I) ğŸ¥ ğŸ–¥ Inference for LV-EBMs ğŸ¥ ğŸ–¥ What are EBMs good for? ğŸ¥ Energy based models (II) ğŸ¥ ğŸ–¥ ğŸ“ Training LV-EBMs ğŸ¥ ğŸ–¥ Homework 3: structured prediction Theme 4: Energy based models, advanced Energy based models (III) ğŸ¥ ğŸ–¥ Unsup learning and autoencoders ğŸ¥ ğŸ–¥ Energy based models (VI) ğŸ¥ ğŸ–¥ From LV-EBM to target prop to (any) autoencoder ğŸ¥ ğŸ–¥ Energy based models (V) ğŸ¥ ğŸ–¥ AEs with PyTorch and GANs ğŸ¥ ğŸ–¥ ğŸ““ ğŸ““ Theme 5: Associative memories Energy based models (V) ğŸ¥ ğŸ–¥ Attention & transformer ğŸ¥ ğŸ–¥ ğŸ““ Theme 6: Graphs Graph transformer nets [ A ][ B ] ğŸ¥ ğŸ–¥ Graph convolutional nets (I) [from last year] ğŸ¥ ğŸ–¥ Graph convolutional nets (II) ğŸ¥ ğŸ–¥ ğŸ““ Theme 7: Control Planning and control ğŸ¥ ğŸ–¥ The Truck Backer-Upper ğŸ¥ ğŸ–¥ ğŸ““ Prediction and Planning Under Uncertainty ğŸ¥ ğŸ–¥ Theme 8: Optimisation Optimisation (I) [from last year] ğŸ¥ ğŸ–¥ Optimisation (II) ğŸ¥ ğŸ–¥ ğŸ“ Miscellaneous SSL for vision [ A ][ B ] ğŸ¥ ğŸ–¥ Low resource machine translation [ A ][ B ] ğŸ¥ ğŸ–¥ Lagrangian backprop, final project, and Q&A ğŸ¥ ğŸ–¥ ğŸ“ DS-GA 1008 Â· SPRING 2020 Â· CDS Instructorsâ€‹: Lectures â€“ Yann LeCun | Practicum â€“ Alfredo Canziani Lecturesâ€‹: â€‹Mondays, 16:55 â€“ 18:35 Practica: â€‹Tuesdays, 19:10 â€“ 20:00 Materialâ€‹: Google Drive , Notebooks NYU Deep Learning Reddit Lectures Legend: ğŸ–¥ slides, ğŸ““ Jupyter notebook, ğŸ¥ YouTube video.
Translations ğŸ‡¬ğŸ‡§ English | ğŸ‡¸ğŸ‡¦ Arabic | ğŸ‡§ğŸ‡© Bengali, Bangla | ğŸ‡¨ğŸ‡³ Chinese | ğŸ‡«ğŸ‡· French | ğŸ‡­ğŸ‡º Hungarian | ğŸ‡®ğŸ‡¹ Italian | ğŸ‡¯ğŸ‡µ Japanese | ğŸ‡°ğŸ‡· Korean | ğŸ‡®ğŸ‡· Persian | ğŸ‡µğŸ‡¹ Portuguese | ğŸ‡·ğŸ‡º Russian | ğŸ‡¹ğŸ‡· Turkish | ğŸ‡·ğŸ‡¸ Serbian | ğŸ‡ªğŸ‡¸ Spanish | ğŸ‡»ğŸ‡³ Vietnamese * Contribution Instructions Week Format Title Resources 1 Lecture 1.1. Motivation of Deep Learning, and Its History and Inspiration ğŸ–¥ï¸ ğŸ¥ 1.2. Evolution and Uses of CNNs and Why Deep Learning? Practicum 1.3. Problem Motivation, Linear Algebra, and Visualization ğŸ““ ğŸ““ ğŸ¥ 2 Lecture 2.1. Introduction to Gradient Descent and Backpropagation Algorithm ğŸ–¥ï¸ ğŸ¥ 2.2. Computing gradients for NN modules and Practical tricks for Back Propagation Practicum 2.3. Artificial neural networks (ANNs) ğŸ–¥ ğŸ““ ğŸ““ ğŸ¥ 3 Lecture 3.1. Visualization of neural networks parameter transformation and fundamental concepts of convolution ğŸ–¥ï¸ ğŸ¥ 3.2. ConvNet Evolutions, Architectures, Implementation Details and Advantages Practicum 3.3. Properties of natural signals ğŸ–¥ ğŸ““ ğŸ¥ 4 Practicum 4.1. Linear Algebra and Convolutions ğŸ““ ğŸ¥ 5 Lecture 5.1. Optimisation Techniques I ğŸ–¥ï¸ ğŸ¥ 5.2. Optimisation Techniques II Practicum 5.3. Understanding convolutions and automatic differentiation engine ğŸ““ ğŸ““ ğŸ¥ 6 Lecture 6.1. Applications of Convolutional Network ğŸ–¥ï¸ ğŸ–¥ï¸ ğŸ¥ 6.2. RNNs, GRUs, LSTMs, Attention, Seq2Seq, and Memory Networks Practicum 6.3. Architecture of RNN and LSTM Model ğŸ““ ğŸ““ ğŸ–¥ï¸ ğŸ¥ 7 Lecture 7.1. Energy-Based Models ğŸ–¥ï¸ ğŸ¥ 7.2. SSL, EBM with details and examples Practicum 7.3. Introduction to autoencoders ğŸ–¥ï¸ ğŸ““ ğŸ¥ 8 Lecture 8.1. Contrastive Methods in Energy-Based Models ğŸ–¥ï¸ ğŸ¥ 8.2. Regularized Latent Variable Energy Based Models Practicum 8.3. Generative Models â€“ Variational Autoencoders ğŸ–¥ï¸ ğŸ““ ğŸ¥ 9 Lecture 9.1. Discriminative Recurrent Sparse Auto-Encoder and Group Sparsity ğŸ–¥ï¸ ğŸ¥ 9.2. World Models and Generative Adversarial Networks Practicum 9.3. Generative Adversarial Networks ğŸ–¥ï¸ ğŸ““ ğŸ¥ 10 Lecture 10.1. Self-Supervised Learning â€“ Pretext Tasks ğŸ–¥ï¸ ğŸ¥ 10.2. Self-Supervised Learning â€“ ClusterFit and PIRL Practicum 10.3. The Truck Backer-Upper ğŸ–¥ï¸ ğŸ““ ğŸ¥ 11 Lecture 11.1. Activation and loss functions (part 1) ğŸ–¥ï¸ ğŸ–¥ï¸ ğŸ–¥ï¸ ğŸ¥ 11.2. Loss Functions (cont.) and Loss Functions for Energy Based Models Practicum 11.3. Prediction and Policy learning Under Uncertainty (PPUU) ğŸ–¥ï¸ ğŸ““ ğŸ¥ 12 Lecture 12.1. Deep Learning for NLP ğŸ–¥ï¸ ğŸ¥ 12.2. Decoding Language Models Practicum 12.3. Attention and the Transformer ğŸ–¥ï¸ ğŸ““ ğŸ¥ 13 Lecture 13.1. Graph Convolutional Networks I ğŸ–¥ï¸ ğŸ¥ 13.2. Graph Convolutional Networks II Practicum 13.3. Graph Convolutional Networks III ğŸ–¥ï¸ ğŸ““ ğŸ¥ 14 Lecture 14.1. Deep Learning for Structured Prediction ğŸ–¥ï¸ ğŸ¥ 14.2. Graphical Energy-based Methods Practicum 14.3. Overfitting and regularization ğŸ–¥ï¸ ğŸ““ ğŸ–¥ï¸ ğŸ““ ğŸ¥ 15 Practicum 15.1. Inference for Latent-Variable Energy-Based Models (EBMs) ğŸ–¥ï¸ ğŸ¥ 15.2. Training Latent-Variable Energy-Based Models (EBMs) ğŸ–¥ï¸ ğŸ¥ People Yann LeCun Role: Instructor About: Silver Professor of Computer Science and Data Science, NYU and Turing Award Winner Contact: yann@cs.nyu.edu Alfredo Canziani Role: Practicum Instructor About: Assistant Professor/Faculty Fellow (2020 â€“ 2022) of Computer Science Contact: canziani@nyu.edu Mark Goldstein Role: Assistant About: PhD student in CS at NYU Contact: goldstein@nyu.edu Zeming Lin Role: Webmaster About: PhD student in CS at NYU Contact: zl2799@nyu.edu â€” Yann Deep Learning by New York University, Yann LeCun, Alfredo Canziani is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.
Based on a work at https://cds.nyu.edu/deep-learning/ Â©2023 NYU CDS 7th floor, 60 5th Ave, New York, NY, 10011 NYU Center for Data Science About Overview Diversity, Equity, & Inclusion About Community Partners Program Stats and Plans Back Contact Communications CDS Updates Community Newsletter Back Back Our People Faculty Joint Associated Visiting Affiliated Affiliated Shanghai Clinical Adjunct Back Leadership Fellows, Research Engineers, Research Scientists, and Postdocs Data Science Faculty Fellows Research Engineers & Research Scientists Postdoc Researchers Affiliated Postdocs Back Staff PhD Students PhD Alumni Back Past Members Back Research Research Home CDS Research Groups Faculty Research Areas Faculty Honors Back Academics PhD Program Overview Areas & Faculty Curriculum Admission Requirements FAQ Medical School Track NRT FUTURE Program Back Masterâ€™s Program Overview Curriculum Industry Concentration Tracks Admission Requirements FAQ Capstone Project Summer Initiative Financial Aid MS Admissions Ambassadors Back Undergraduate Program Overview Major in Data Science Minor in Data Science Joint Majors FAQ Contact Back Non-Degree Program Overview Curriculum Admission Requirements FAQ Apply Now Back Student Career Placement & Professional Development Overview Our Students: Career and Placement Information Alumni Spotlights Back Student Groups CDS Alumni Council Student Fellowships & Awards CDS Academic Integrity Statement and Policy Open House Webinars The CDS Podcast Back CDS Online Yann LeCunâ€™s Deep Learning Course at CDS Mathematical Tools for Data Science Brave New World Podcast Back Partnerships Partners Program Partnership Research Initiatives Executive Education Back Events CDS Events Feed The Math and Data (MaD) Seminar MaD+ Seminar Series NLP and Text-as-Data Speaker Series Computational Biology & Medicine Colloquium Data Science Lunch Seminar Series The Math and Democracy Seminar Data Science Graduate Student Seminar AI, Misinformation, and Policy Seminar Series Back Jobs Faculty & Staff Positions Faculty Fellows Positions Back Initiatives Current Initiatives AI@NYU Center for Responsible AI CURP CURP Summer 2023 Cohort CURP Summer 2022 Cohort CURP Spring 2022 Cohort CURP Spring 2021 Cohort Back Minds, Brains, & Machines Back Past Initiatives DS3 Moore-Sloan Overview Seed Grant Summer Research Initiative Showcase Community Newsletter Back Back Back
