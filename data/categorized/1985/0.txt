old id = 2864
IBM and MIT kickstarted the age of quantum computing in 1981
1985
https://www.fastcompany.com/90633843/1981-quantum-computing-conference-ibm-roadmap-mit

Fast CompanyHomepageCo.DesignTechWork LifeNewsImpactPodcastsVideoRecommenderInnovation Festival 360SubscribeAWSEYBoston ScientificDeloitteDeptElevate PrizeIBMGenpactKlarnaVisaFastCo WorksAn award-winning team of journalists, designers, and videographers who tell brand stories through Fast Company's distinctive lensFast GovernmentThe future of innovation and technology in government for the greater goodMost Innovative CompaniesFast Company's annual ranking of businesses that are making an outsize impactMost Creative PeopleLeaders who are shaping the future of business in creative waysWorld Changing IdeasNew workplaces, new food sources, new medicine--even an entirely new economic systemInnovation By DesignCelebrating the best ideas in businessInnovation FestivalMost Innovative Companies SummitHow a 1981 conference kickstarted today’s quantum computing eraForty years ago, IBM researcher Charlie Bennett helped usher in the study of quantum mechanics’ impact on computing. IBM is still at it—and so is Bennett.
In May 1981, at a conference center housed in a chateau-style mansion outside Boston, a few dozen physicists and computer scientists gathered for a three-day meeting. The assembled brainpower was formidable: One attendee, Caltech’s Richard Feynman, was already a Nobel laureate and would earn a widespread reputation for genius when his 1985 memoir“Surely You’re Joking, Mr. Feynman!”: Adventures of a Curious Characterbecame a bestseller. Numerous others, such as Paul Benioff, Arthur Burks, Freeman Dyson, Edward Fredkin, Rolf Landauer, John Wheeler, and Konrad Zuse, were among the most accomplished figures in their respective research areas.
The conference they were attending,The Physics of Computation, was held from May 6 to 8 and cohosted by IBM and MIT’s Laboratory for Computer Science. It would come to be regarded as a seminal moment in the history of quantum computing—not that anyone present grasped that as it was happening.
“It’s hard to put yourself back in time,” says Charlie Bennett, a distinguished physicist and information theorist who was part of the IBM Research contingent at the event. “If you’d said ‘quantum computing,’ nobody would have understood what you were talking about.”Why was the conference so significant? According to numerous latter-day accounts, Feynman electrified the gathering by calling for the creation of a quantum computer. But “I don’t think he quite put it that way,” contends Bennett, who took Feynman’s comments less as a call to action than a provocative observation. “He just said the world is quantum,” Bennett remembers. “So if you really wanted to build a computer to simulate physics, that should probably be a quantum computer.”For a guide to who’s who in this 1981 Physics of Computation photo,click here. [Photo: courtesy of Charlie Bennett, who isn’t in it—because he took it]Even if Feynman wasn’t trying to kick off a moonshot-style effort to build a quantum computer, his talk—and The Physics of Computation conference in general—proved influential in focusing research resources. Quantum computing “was nobody’s day job before this conference,” says Bennett. “And then some people began considering it important enough to work on.”It turned out to be such a rewarding area for study that Bennett is still working on it in 2021—and he’s still at IBM Research, where he’s been, aside from the occasional academic sabbatical, since 1972. His contributions have been so significant that he’s not onlywon numerous awardsbut also had onenamed after him. (On Thursday, he was among the participants in anonline conference on quantum computing’s past, present, and futurethat IBM held to mark the 40th anniversary of the original meeting.)Charlie Bennett[Photo: courtesy of IBM]These days, Bennett has plenty of company. In recent years, quantum computing has become one of IBM’s biggest bets, as it strives to get the technology to the point where it’s capable of performing useful work at scale, particularly for the large organizations that have long been IBM’s core customer base. Quantum computing is also a major area of research focus at other tech giants such asGoogle,Microsoft,Intel, andHoneywell, as well as abevy of startups.
According to IBM senior VP and director of research Dario Gil, the 1981 Physics of Computation conference played an epoch-shifting role in getting the computing community excited about quantum physics’s possible benefits. Before then, “in the context of computing, it was seen as a source of noise—like a bothersome problem that when dealing with tiny devices, they became less reliable than larger devices,” he says. “People understood that this was driven by quantum effects, but it was a bug, not a feature.”Making progress in quantum computing has continued to require setting aside much of what we know about computers in their classical form. From early room-sized mainframe monsters to the smartphone in your pocket, computing has always boiled down to performing math with bits set either to one or zero. But instead of depending on bits, quantum computers leverage quantum mechanics through a basic building block called a quantum bit, orqubit. It can represent a one, a zero, or—in a radical departure from classical computing—both at once.
Dario Gil[Photo: courtesy of IBM]Qubits give quantum computers the potential to rapidly perform calculations that might be impossibly slow on even the fastest classical computers. That could have transformative benefits for applications ranging from drug discovery to cryptography to financial modeling. But it requires mastering an array of new challenges, includingcooling superconducting qubits to a temperature only slightly above abolute zero, or -459.67 Farenheit.
Four decades after the 1981 conference, quantum computing remains a research project in progress, albeit one that’s lately come tantalizingly close to fruition. Bennett says that timetable isn’t surprising or disappointing. For a truly transformative idea, 40 years just isn’t that much time: Charles Babbage began working on hisAnalytical Enginein the 1830s, more than a century before technological progress reached the point where early computers such as IBM’s ownAutomated Sequence Controlled Calculatorcould implement his concepts in a workable fashion. And even those machines came nowhere near fulfilling the vision scientists had already developed for computing, “including some things that [computers] failed at miserably for decades, like language translation,” says Bennett.
I think was the first time ever somebody said the phrase ‘quantum information theory.’”In 1970, as a Harvard PhD candidate, Bennett was brainstorming with fellow physics researcher Stephen Wiesner, a friend from his undergraduate days at Brandeis. Wiesner speculated that quantum physics would make it possible to “send, through a channel with a nominal capacity of one bit, two bits of information; subject however to the constraint that whichever bit the receiver choose to read, the other bit is destroyed,” as Bennett jotted in notes which—fortunately for computing history—he preserved.
Charlie Bennett’s 1970 notes on Stephen Wiesner’s musings about quantum physics and computing (click toexpand). [Photo: courtesy of Charlie Bennett]“I think was the first time ever somebody said the phrase ‘quantum information theory,'” says Bennett. “The idea that you could do things of not just a physics nature, but an information processing nature with quantum effects that you couldn’t do with ordinary data processing.”Long and winding roadLike many technological advances of historic proportions—AI is another example—quantum computing didn’t progress from idea to reality in an altogether predictable and efficient way. It took 11 years from Wiesner’s observation until enough people took the topic seriously enough to inspire the Physics of Computation conference. Bennett and the University of Montreal’s Gilles Brassard publishedimportant research on quantum cryptographyin 1984; in the 1990s, scientists realized that quantum computers had the potential to be exponentially faster than their classical forebears.
All along, IBM had small teams investigating the technology. According to Gil, however, it wasn’t until around 2010 that the company had made enough progress that it began to see quantum computing not just as an intriguing research area but as a powerful business opportunity. “What we’ve seen since then is this dramatic progress over the last decade, in terms of scale, effort, and investment,” he says.
IBM’s superconducting qubits need to be kept chilled in a ‘super fridge.’ [Photo: courtesy of IBM]As IBM made that progress, it shared it publicly so that interested parties could begin to get their heads around quantum computing at the earliest opportunity. Starting in May 2016, for instance, the companymade quantum computing available as a cloud service, allowing outsiders to tinker with the technology in a very early form.
It is really important that when you put something out, you have a path to deliver.”“One of the things that road maps provide is clarity,” he says, allowing that “road maps without execution are hallucinations, so it is really important that when you put something out, you have a path to deliver.”Scaling up quantum computing into a form that can trounce classical computers at ambitious jobs requires increasing the number of reliable qubits that a quantum computer has to work with. When IBM publishedits quantum hardware road maplast September, it had recently deployed the 65-qubit IBM Quantum Hummingbird processor, a considerable advance on its previous 5- and 27-qubit predecessors. This year, the company plans to complete the 127-qubit IBM Quantum Eagle. And by 2023, it expects to have a 1,000-qubit machine, the IBM Quantum Condor. It’s this machine, IBM believes, that may have the muscle to achieve “quantum advantage” by solving certain real-world problems faster the world’s best supercomputers.
Essential though it is to crank up the supply of qubits, the software side of quantum computing’s future is also under construction, and IBM publisheda separate road map devoted to the topicin February. Gil says that the company is striving to create a “frictionless” environment in which coders don’t have to understand how quantum computing works any more than they currently think about a classical computer’s transistors. An IBM software layer will handle the intricacies (and meld quantum resources with classical ones, which will remain indispensable for many tasks).
“You don’t need to know quantum mechanics, you don’t need to know a special programming language, and you’re not going to need to know how to do these gate operations and all that stuff,” he explains. “You’re just going to program with your favorite language, say, Python. And behind the scenes, there will be the equivalent of libraries that call on these quantum circuits, and then they get delivered to you on demand.”IBM is still working on making quantum computing ready for everyday reality, but it’s alreadyworked with designers to make it look good. [Photo: courtesy of IBM]“In this vision, we think that at the end of this decade, there may be as many as a trillion quantum circuits that are running behind the scene, making software run better,” Gil says.
Even if IBM clearly understands the road ahead, there’s plenty left to do. Charlie Bennett says that quantum researchers will overcome remaining challenges in much the same way that he and others confronted past ones. “It’s hard to look very far ahead, but the right approach is to maintain a high level of expertise and keep chipping away at the little problems that are causing a thing not to work as well as it could,” he says. “And then when you solve that one, there will be another one, which you won’t be able to understand until you solve the first one.”As for Bennett’s own current work, he says he’s particularly interested in the intersection between information theory and cosmology—”not so much because I think I can learn enough about it to make an original research contribution, but just because it’s so much fun to do.” He’s also been making explainer videos about quantum computing, a topic whose reputation for beingweird and mysterioushe blames on inadequate explanation by others.
“Unfortunately, the majority of science journalists don’t understand it,” he laments. “And they say confusing things about it—painfully, for me, confusing things.”For IBM Research, Bennett is both a living link to its past and an inspiration for its future. “He’s had such a massive impact on the people we have here, so many of our top talent,” says Gil. “In my view, we’ve accrued the most talented group of people in the world, in terms of doing quantum computing. So many of them trace it back to the influence of Charlie.”Impressive though Bennett’s 49-year tenure at the company is, the fact that he’s seen and made so much quantum computing history—including attending the 1981 conference—and is here to talk about it is a reminder of how young the field still is.
About the authorHarry McCracken is the global technology editor forFast Company, based in San Francisco. In past lives, he was editor at large forTimemagazine, founder and editor ofTechnologizer, and editor ofPC World.
MoreVideoImpactHow London plans to ‘rewild’ the cityA rocket scientist designed a solution for your moldy strawberriesThis company crushes old roads—and rebuilds them to store carbonNewsGopuff has a new investor and advisor: Former Disney CEO Bob IgerDomino’s and ‘Stranger Things’ want you to order pizza with telekinetic powersProlonged grief disorder: Helpful diagnosis or harmful stigma?Co.DesignAfter smart homes and smart rings, meet Can Go, the world’s smartest caneCluttercore: What’s really behind Gen Z’s revolt against minimalism?Adidas’s jaw-dropping new office sets an audacious standard for the future of workWork LifeA neuroscientist on the shifts in our media use and the effect on our brains3 ‘creator’ soft skills that can get you hiredHow to write a script for a job interview that feels authentic
