old id = 1164
Distributed training with TensorFlow  |  TensorFlow Core
unknown
https://www.tensorflow.org/alpha/guide/distribute_strategy

Distributed training with TensorFlowOverviewtf.distribute.Strategyis a TensorFlow API to distribute training across multiple GPUs, multiple machines, or TPUs. Using this API, you can distribute your existing models and training code with minimal code changes.
tf.distribute.Strategyhas been designed with these key goals in mind:You can distribute training usingtf.distribute.Strategywith a high-level API like KerasModel.fit, as well ascustom training loops(and, in general, any computation using TensorFlow).
In TensorFlow 2.x, you can execute your programs eagerly, or in a graph usingtf.function.
tf.distribute.Strategyintends to support both these modes of execution, but works best withtf.function. Eager mode is only recommended for debugging purposes and not supported fortf.distribute.TPUStrategy. Although training is the focus of this guide, this API can also be used for distributing evaluation and prediction on different platforms.
You can usetf.distribute.Strategywith very few changes to your code, because the underlying components of TensorFlow have been changed to become strategy-aware. This includes variables, layers, models, optimizers, metrics, summaries, and checkpoints.
In this guide, you will learn about various types of strategies and how you can use them in different situations. To learn how to debug performance issues, check out theOptimize TensorFlow GPU performanceguide.
Set up TensorFlowTypes of strategiestf.distribute.Strategyintends to cover a number of use cases along different axes. Some of these combinations are currently supported and others will be added in the future. Some of these axes are:In order to support these use cases, TensorFlow hasMirroredStrategy,TPUStrategy,MultiWorkerMirroredStrategy,ParameterServerStrategy,CentralStorageStrategy, as well as other strategies available. The next section explains which of these are supported in which scenarios in TensorFlow. Here is a quick overview:MirroredStrategytf.distribute.MirroredStrategysupports synchronous distributed training on multiple GPUs on one machine. It creates one replica per GPU device. Each variable in the model is mirrored across all the replicas. Together, these variables form a single conceptual variable calledMirroredVariable. These variables are kept in sync with each other by applying identical updates.
Efficient all-reduce algorithms are used to communicate the variable updates across the devices. All-reduce aggregates tensors across all the devices by adding them up, and makes them available on each device. It’s a fused algorithm that is very efficient and can reduce the overhead of synchronization significantly. There are many all-reduce algorithms and implementations available, depending on the type of communication available between devices. By default, it uses the NVIDIA Collective Communication Library (NCCL) as the all-reduce implementation. You can choose from a few other options or write your own.
Here is the simplest way of creatingMirroredStrategy:This will create aMirroredStrategyinstance, which will use all the GPUs that are visible to TensorFlow, and NCCL—as the cross-device communication.
If you wish to use only some of the GPUs on your machine, you can do so like this:If you wish to override the cross device communication, you can do so using thecross_device_opsargument by supplying an instance oftf.distribute.CrossDeviceOps. Currently,tf.distribute.HierarchicalCopyAllReduceandtf.distribute.ReductionToOneDeviceare two options other thantf.distribute.NcclAllReduce, which is the default.
TPUStrategytf.distribute.TPUStrategylets you run your TensorFlow training onTensor Processing Units (TPUs). TPUs are Google's specialized ASICs designed to dramatically accelerate machine learning workloads. They are available onGoogle Colab, theTPU Research Cloud, andCloud TPU.
In terms of distributed training architecture,TPUStrategyis the sameMirroredStrategy—it implements synchronous distributed training. TPUs provide their own implementation of efficient all-reduce and other collective operations across multiple TPU cores, which are used inTPUStrategy.
Here is how you would instantiateTPUStrategy:TheTPUClusterResolverinstance helps locate the TPUs. In Colab, you don't need to specify any arguments to it.
If you want to use this for Cloud TPUs:MultiWorkerMirroredStrategytf.distribute.MultiWorkerMirroredStrategyis very similar toMirroredStrategy. It implements synchronous distributed training across multiple workers, each with potentially multiple GPUs. Similar totf.distribute.MirroredStrategy, it creates copies of all variables in the model on each device across all workers.
Here is the simplest way of creatingMultiWorkerMirroredStrategy:MultiWorkerMirroredStrategyhas two implementations for cross-device communications.
CommunicationImplementation.RINGisRPC-based and supports both CPUs and GPUs.
CommunicationImplementation.NCCLuses NCCL and provides state-of-art performance on GPUs but it doesn't support CPUs.
CollectiveCommunication.AUTOdefers the choice to Tensorflow. You can specify them in the following way:One of the key differences to get multi worker training going, as compared to multi-GPU training, is the multi-worker setup. The'TF_CONFIG'environment variable is the standard way in TensorFlow to specify the cluster configuration to each worker that is part of the cluster. Learn more in thesetting up TF_CONFIG sectionof this document.
For more details aboutMultiWorkerMirroredStrategy, consider the following tutorials:ParameterServerStrategyParameter server training is a common data-parallel method to scale up model training on multiple machines. A parameter server training cluster consists of workers and parameter servers. Variables are created on parameter servers and they are read and updated by workers in each step. Check out theParameter server trainingtutorial for details.
In TensorFlow 2, parameter server training uses a central coordinator-based architecture via thetf.distribute.experimental.coordinator.ClusterCoordinatorclass.
In this implementation, theworkerandparameter servertasks runtf.distribute.Servers that listen for tasks from the coordinator. The coordinator creates resources, dispatches training tasks, writes checkpoints, and deals with task failures.
In the programming running on the coordinator, you will use aParameterServerStrategyobject to define a training step and use aClusterCoordinatorto dispatch training steps to remote workers. Here is the simplest way to create them:To learn more aboutParameterServerStrategy, check out theParameter server training with Keras Model.fit and a custom training looptutorial.
In TensorFlow 1,ParameterServerStrategyis available only with an Estimator viatf.compat.v1.distribute.experimental.ParameterServerStrategysymbol.
CentralStorageStrategytf.distribute.experimental.CentralStorageStrategydoes synchronous training as well. Variables are not mirrored, instead they are placed on the CPU and operations are replicated across all local GPUs. If there is only one GPU, all variables and operations will be placed on that GPU.
Create an instance ofCentralStorageStrategyby:This will create aCentralStorageStrategyinstance which will use all visible GPUs and CPU. Update to variables on replicas will be aggregated before being applied to variables.
Other strategiesIn addition to the above strategies, there are two other strategies which might be useful for prototyping and debugging when usingtf.distributeAPIs.
Default StrategyThe Default Strategy is a distribution strategy which is present when no explicit distribution strategy is in scope. It implements thetf.distribute.Strategyinterface but is a pass-through and provides no actual distribution. For instance,Strategy.run(fn)will simply callfn. Code written using this strategy should behave exactly as code written without any strategy. You can think of it as a "no-op" strategy.
The Default Strategy is a singleton—and one cannot create more instances of it. It can be obtained usingtf.distribute.get_strategyoutside any explicit strategy's scope (the same API that can be used to get the current strategy inside an explicit strategy's scope).
This strategy serves two main purposes:OneDeviceStrategytf.distribute.OneDeviceStrategyis a strategy to place all variables and computation on a single specified device.
This strategy is distinct from the Default Strategy in a number of ways. In the Default Strategy, the variable placement logic remains unchanged when compared to running TensorFlow without any distribution strategy. But when usingOneDeviceStrategy, all variables created in its scope are explicitly placed on the specified device. Moreover, any functions called viaOneDeviceStrategy.runwill also be placed on the specified device.
Input distributed through this strategy will be prefetched to the specified device. In the Default Strategy, there is no input distribution.
Similar to the Default Strategy, this strategy could also be used to test your code before switching to other strategies which actually distribute to multiple devices/machines. This will exercise the distribution strategy machinery somewhat more than the Default Strategy, but not to the full extent of using, for example,MirroredStrategyorTPUStrategy. If you want code that behaves as if there is no strategy, then use the Default Strategy.
So far you've learned about different strategies and how you can instantiate them. The next few sections show the different ways in which you can use them to distribute your training.
Use tf.distribute.Strategy with Keras Model.fittf.distribute.Strategyis integrated intotf.keras, which is TensorFlow's implementation of theKeras API specification.
tf.kerasis a high-level API to build and train models. By integrating into thetf.kerasbackend, it's seamless for you to distribute your training written in the Keras training frameworkusing Model.fit.
Here's what you need to change in your code:TensorFlow distribution strategies support all types of Keras models—Sequential,Functional, andsubclassed.
Here is a snippet of code to do this for a very simple Keras model with oneDenselayer:This example usesMirroredStrategy, so you can run this on a machine with multiple GPUs.
strategy.scope()indicates to Keras which strategy to use to distribute the training. Creating models/optimizers/metrics inside this scope allows you to create distributed variables instead of regular variables. Once this is set up, you can fit your model like you would normally.
MirroredStrategytakes care of replicating the model's training on the available GPUs, aggregating gradients, and more.
Here atf.data.Datasetprovides the training and eval input. You can also use NumPy arrays:In both cases—withDatasetor NumPy—each batch of the given input is divided equally among the multiple replicas. For instance, if you are using theMirroredStrategywith 2 GPUs, each batch of size 10 will be divided among the 2 GPUs, with each receiving 5 input examples in each step. Each epoch will then train faster as you add more GPUs. Typically, you would want to increase your batch size as you add more accelerators, so as to make effective use of the extra computing power. You will also need to re-tune your learning rate, depending on the model. You can usestrategy.num_replicas_in_syncto get the number of replicas.
What's supported now?Examples and tutorialsHere is a list of tutorials and examples that illustrate the above integration end-to-end with KerasModel.fit:Use tf.distribute.Strategy with custom training loopsAs demonstrated above, usingtf.distribute.Strategywith KerasModel.fitrequires changing only a couple lines of your code. With a little more effort, you can also usetf.distribute.Strategywith custom training loops.
If you need more flexibility and control over your training loops than is possible with Estimator or Keras, you can write custom training loops. For instance, when using a GAN, you may want to take a different number of generator or discriminator steps each round. Similarly, the high level frameworks are not very suitable for Reinforcement Learning training.
Thetf.distribute.Strategyclasses provide a core set of methods to support custom training loops. Using these may require minor restructuring of the code initially, but once that is done, you should be able to switch between GPUs, TPUs, and multiple machines simply by changing the strategy instance.
Below is a brief snippet illustrating this use case for a simple training example using the same Keras model as before.
First, create the model and optimizer inside the strategy's scope. This ensures that any variables created with the model and optimizer are mirrored variables.
Next, create the input dataset and calltf.distribute.Strategy.experimental_distribute_datasetto distribute the dataset based on the strategy.
Then, define one step of the training. Usetf.GradientTapeto compute gradients and optimizer to apply those gradients to update your model's variables. To distribute this training step, put it in a functiontrain_stepand pass it totf.distribute.Strategy.runalong with the dataset inputs you got from thedist_datasetcreated before:A few other things to note in the code above:Finally, once you have defined the training step, you can iterate overdist_datasetand run the training in a loop:In the example above, you iterated over thedist_datasetto provide input to your training. You are also provided with thetf.distribute.Strategy.make_experimental_numpy_datasetto support NumPy inputs. You can use this API to create a dataset before callingtf.distribute.Strategy.experimental_distribute_dataset.
Another way of iterating over your data is to explicitly use iterators. You may want to do this when you want to run for a given number of steps as opposed to iterating over the entire dataset. The above iteration would now be modified to first create an iterator and then explicitly callnexton it to get the input data.
This covers the simplest case of usingtf.distribute.StrategyAPI to distribute custom training loops.
What's supported now?Examples and tutorialsHere are some examples for using distribution strategies with custom training loops:Other topicsThis section covers some topics that are relevant to multiple use cases.
Setting up the TF_CONFIG environment variableFor multi-worker training, as mentioned before, you need to set up the'TF_CONFIG'environment variable for each binary running in your cluster. The'TF_CONFIG'environment variable is a JSON string which specifies what tasks constitute a cluster, their addresses and each task's role in the cluster. Thetensorflow/ecosystemrepo provides a Kubernetes template, which sets up'TF_CONFIG'for your training tasks.
There are two components of'TF_CONFIG': a cluster and a task.
One example of'TF_CONFIG'is:This'TF_CONFIG'specifies that there are three workers and two"ps"tasks in the"cluster"along with their hosts and ports. The"task"part specifies the role of the current task in the"cluster"—worker1(the second worker). Valid roles in a cluster are"chief","worker","ps", and"evaluator". There should be no"ps"job except when usingtf.distribute.experimental.ParameterServerStrategy.
What's next?tf.distribute.Strategyis actively under development. Try it out and provide your feedback usingGitHub issues.
Except as otherwise noted, the content of this page is licensed under theCreative Commons Attribution 4.0 License, and code samples are licensed under theApache 2.0 License. For details, see theGoogle Developers Site Policies. Java is a registered trademark of Oracle and/or its affiliates.
Last updated 2022-05-06 UTC.
Stay connectedSupport
