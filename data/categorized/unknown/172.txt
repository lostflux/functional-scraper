old id = 1379
自然語言處理 - 维基百科，自由的百科全书
unknown
https://zh.wikipedia.org/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86

自然語言處理自然語言處理（英語：Natural Language Processing，缩写作NLP）是人工智慧和語言學領域的分支學科。此領域探討如何處理及運用自然語言；自然語言處理包括多方面和步骤，基本有认知、理解、生成等部分。自然語言認知和理解是讓電腦把输入的語言变成有意思的符号和关系，然后根据目的再處理。自然語言生成系統则是把計算機數據轉化為自然語言。目录歷史[编辑]自然語言處理大體是從1950年代開始，雖然更早期也有作為。1950年，图灵發表論文「計算機器與智能（英语：Computing Machinery and Intelligence）」，提出現在所謂的「圖靈測試」作為判斷智能的條件。1954年的乔治城-IBM实验涉及全部自動翻譯（英语：automatic translation）超過60句俄文成為英文。研究人員聲稱三到五年之內即可解決機器翻譯的問題。[1]不過實際進展遠低於預期，1966年的ALPAC報告（英语：ALPAC report）發現十年研究未達預期目標，機器翻譯的研究經費遭到大幅削減。一直到1980年代末期，統計機器翻譯系統發展出來，機器翻譯的研究才得以更上一層樓。1960年代發展特別成功的NLP系統包括SHRDLU——一個詞彙設限、運作於受限如「積木世界」的一種自然語言系統，以及1964-1966年约瑟夫·维森鲍姆模擬「個人中心治療」而設計的ELIZA（英语：ELIZA）——幾乎未運用人類思想和感情的訊息，有時候卻能呈現令人訝異地類似人之間的互動。「病人」提出的問題超出ELIZA 極小的知識範圍之時，可能會得到空泛的回答。例如問題是「我的頭痛」，回答是「為什麼說你頭痛？」1970年代，程式設計師開始設計「概念本體論」（conceptual ontologies）的程式，將現實世界的資訊，架構成電腦能夠理解的資料。實例有MARGIE、SAM、PAM、TaleSpin、QUALM、Politics以及Plot Unit。許多聊天機器人在這一時期寫成，包括PARRY（英语：PARRY）、Racter（英语：Racter）以及Jabberwacky（英语：Jabberwacky）。一直到1980年代，多數自然語言處理系統是以一套複雜、人工訂定的規則為基礎。不過從1980年代末期開始，語言處理引進了機器學習的演算法，NLP產生革新。成因有兩個：運算能力穩定增加（參見摩爾定律）；以及喬姆斯基語言學理論漸漸喪失主導（例如轉換-生成文法）。該理論的架構不傾向於語料庫——機器學習處理語言所用方法的基礎。有些最早期使用的機器學習演算法，例如決策樹，是硬性的、「如果-則」規則組成的系統，類似當時既有的人工訂定的規則。不過詞性標記（英语：part-of-speech tagging）將隱馬爾可夫模型引入NLP，並且研究日益聚焦於軟性的、以機率做決定的統計模型，基礎是將輸入資料裡每一個特性賦予代表其份量的數值。許多語音識別現今依賴的快取語言模型（英语：cache language model）即是一種統計模型的例子。這種模型通常足以處理非預期的輸入數據，尤其是輸入有錯誤（真實世界的數據總免不了），並且在整合到包含多個子任務的較大系統時，結果比較可靠。許多早期的成功屬於機器翻譯領域，尤其歸功IBM的研究，漸次發展出更複雜的統計模型。這些系統得以利用加拿大和歐盟現有的語料庫，因為其法律規定政府的會議必須翻譯成所有的官方語言。不過，其他大部分系統必須特別打造自己的語料庫，一直到現在這都是限制其成功的一個主要因素，於是大量的研究致力於從有限的數據更有效地學習。近來的研究更加聚焦於非監督式學習和半監督學習（英语：semi-supervised learning）的演算法。這種演算法，能夠從沒有人工註解理想答案的資料裡學習。大體而言，這種學習比監督學習困難，並且在同量的數據下，通常產生的結果較不準確。不過沒有註解的數據量極巨（包含了全球資訊網），彌補了較不準確的缺點。近年來，深度學習技巧紛紛出爐[2][3]在自然語言處理方面獲得最尖端的成果，例如語言模型[4]、語法分析[5][6]等等。用途[编辑]在許多情況下，學者們需要通過許多不同的數據庫來確定新的研究方向，以識別研究差距並確定迄今為止尚未研究的領域。檢查所有電子數據庫很麻煩，而且經常會遺漏重要的部分。通過使用網絡抓取和自然語言處理來縮短識別研究差距所需的時間。在Google學術搜索上索引的出版物的標題, 自然语言处理標記化(Tokenization)從最高頻率到最低頻率對搭配進行排序。因此，自然语言处理標記化(Tokenization)確定了標題中未提及的關鍵字集，並將最初的想法確定為研究空白[7]。任務和限制[编辑]理論上，NLP是一種很吸引人的人機交互方式。早期的语言处理系统如SHRDLU，当它们处于一个有限的“积木世界”，运用有限的词汇表会话时，工作得相当好。这使得研究员们对此系统相当乐观，然而，当把这个系统拓展到充满了现实世界的含糊与不确定性的环境中时，他们很快丧失了信心。由於理解（understanding）自然語言，需要關於外在世界的廣泛知識以及運用操作這些知識的能力，自然語言認知，同時也被視為一個人工智慧完備（AI-complete）的問題。同時，在自然語言處理中，"理解"的定義也變成一個主要的問題。實際問題[编辑]一些NLP面臨的問題實例：不少的中文相關笑話即是利用類似結構的中文造句而成，此類笑話通常帶有“中文博大精深”之類的詞彙，敘述多以老外參加考試為背景。例子如下：老外淚流滿面，交白卷回國了。自然語言處理研究的難點[编辑]單詞的邊界界定[编辑]詞義的消歧[编辑]句法的模糊性[编辑]有瑕疵的或不規範的輸入[编辑]语言行为与计划[编辑]当前自然语言处理研究的发展趋势[编辑]第一，传统的基于句法-语义规则的理性主义方法过于复杂，随着语料库建设和语料库语言学的崛起，大规模真实文本的机器学习处理成为自然语言处理的主要选择。第二，统计数学方法越来越受到重视，自然语言处理中越来越多地使用机器自动学习的方法来获取语言知识。第三，浅层处理与深层处理并重，统计与规则方法并重，形成混合式的系统。第四，自然语言处理中越来越重视词汇的作用，出现了强烈的“词汇主义”的倾向。词汇知识库的建造成为了普遍关注的问题。[8]統計自然語言處理[编辑]統計自然語言處理運用了推測學、機率、統計的方法來解決上述，尤其是針對容易高度模糊的長串句子，當套用實際文法進行分析產生出成千上萬筆可能性時所引發之難題。處理這些高度模糊句子所採用消歧的方法通常運用到語料庫(Corpus)以及馬可夫模型（Markov models）。統計自然語言處理的技術主要由同樣自人工智慧下與學習行為相關的子領域：機器學習及資料採掘所演進而成。主要範疇[编辑]参见[编辑]参考文献[编辑]延伸閱讀[编辑]外部連結[编辑]导航菜单搜索
