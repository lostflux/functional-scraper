old id = 4388
How the National Science Foundation is taking on fairness in AI
unknown
https://www.brookings.edu/blog/techtank/2021/07/22/how-the-national-science-foundation-is-taking-on-fairness-in-ai

Guidance for the Brookings community and the public on our response to the coronavirus (COVID-19) »Learn more from Brookings scholars about the global response to coronavirus (COVID-19) »How the National Science Foundation is taking on fairness in AIHow the National Science Foundation is taking on fairness in AIMost of the public discourse around artificial intelligence (AI) policy focuses on one of two perspectives: how the government can support AI innovation, and how the government can deter its harmful or negligent use. Yet there can also be a role for government in making it easier to use AI beneficially—in this niche, the National Science Foundation (NSF) has found a way to contribute. Through a grant-making program called Fairness in Artificial Intelligence (FAI), the NSF is providing $20 million in funding to researchers working on difficult ethical problems in AI. The program, a collaboration with Amazon, has now funded 21 projects in its first two years, with an opencall for applicationsin its third and final year. This is an important endeavor, furthering a trend of federal support for the responsible advancement of technology, and the NSF should continue this important line of funding for ethical AI.
What is the NSF’s Fairness in AI Program?Alex EnglerFellow -Governance StudiesThe FAI program is an investment in what the NSF calls “use-inspired research,” where scientists attempt to address fundamental questions inspired by real world challenges and pressing scientific limitations. Use-inspired research is an alternative to the traditional “basic research,” which attempts to make fundamental advances in scientific understanding without necessarily a specific practical goal. NSF is better known for basic research in computer science, where theNSF provides 87%of all federal basic research funding. Consequently, the FAI program is a relatively small portion of the NSF’s total investment in AI—around $3.3 million per year, considering that Amazon covers half of the cost. In total, the NSFrequested $868 millionin AI spending, about 10% of its entire budget for 2021, and Congress approvedevery penny. Notably, this is a broad definition of AI spending that includes many applications of AI to other fields, rather than fundamental advances in AI itself, which is likely closer to $100 or $150 million, by rough estimation.
The FAI program is specifically oriented towards the ethical principle of “fairness”—more on this choice in a moment. While this may seem unusual, the program is a continuation of prior government funded research into the moral implications and consequences of technology. Starting in the 1970’s, the federal government startedactively shaping bioethics researchinresponseto public outcry following the AP’s reporting on the Tuskegee Syphilis Study. While the original efforts may have been reactionary, they precipitated decades of work towards improving the biomedical sciences. Launched alongside the Human Genome Project in 1990, there was anextensive line of researchoriented towards the ethical, legal, and social implications of genomics. Starting in 2018, the NSF funded21 exploratory grantson the impact ofAI on Society, a precursor to the current FAI program. Today, it’s possible to draw a rough trend line through these endeavors, in which the government is becoming more concerned with first pure science, then the ethics of the scientific process, and now the ethical outcomes of the science itself. This is a positive development, and one worth encouraging.
A focus on fairnessNSF made a conscious decision to focus on fairness rather than other prevalent themes like “trustworthiness” or “human-centered design.” Dr. Erwin Gianchandani, an NSF deputy assistant director, hasdescribedfour categories of problems in FAI’s domain, and these can each easily be tied to present and ongoing challenges facing AI. The first category is focused on themany conflicting mathematical definitions of fairnessand the lack of clarity around which are appropriate in what contexts.
One funded projectstudied the human perceptions of what fairness metrics are most appropriate for an algorithm in the context of bail decisions—the same application of theinfamous COMPAS algorithm. The study found that survey respondents slightly preferred an algorithm that had a consistent rate of false positives (how many people were unnecessarily kept in jail pending trial) between two racial groups, rather than an algorithm which was equally accurate for both racial groups. Notably, this is the opposite quality of the COMPAS algorithm, which was fair in its total accuracy, but resulted in more false positives for Black defendants.
The second category, Gianchandani writes, is “to understand how an AI system produces a given result.” The NSF sees this as directly related to fairness because giving an end-user more information about an AI’s decision empowers them to challenge that decision. This is an important point—by default, AI systems disguise the nature of a decision-making process and make it harder for an individual to interrogate the process. Maybe the most novel project funded by NSF FAI attempts to test the viability ofcrowdsourcing audits of AI systems. In a crowdsourced audit, many individuals might sign up for a tool—e.g., a website or web browser extension—that pools data about how those individuals were treated by an online AI system. By aggregating this data, the crowd can determine if the algorithm is being discriminatory, which would be functionally impossible for any individual user.
The third category seeks to use AI to make existing systems fairer, an especially important task as governments around the world are continuing to consider if and how to incorporate AI systems into public services. Oneproject from researchers at New York Universityseeks, in part, to tackle the challenge of fairness when an algorithm is used in support of a human decision-maker. This is perhaps inspired by a recentevaluation of judges using algorithmic risk assessmentsin Virginia, which concluded that the algorithm failed to improve public safety and had the unintended effect of increasing incarceration of young defendants. The NYU researchers have a similar challenge in mind—developing a tool to identify and reduce systemic biases in prosecutorial decisions made by district attorneys.
Related ContentNew White House guidance downplays important AI harmsIf not AI ethicists like Timnit Gebru, who will hold Big Tech accountable?Auditing employment algorithms for discriminationThe fourth category is perhaps the most intuitive, as it aims to remove bias from AI systems, or alternatively, make sure AI systems work equivalently well for everyone. One project looks to create common evaluation metrics for natural language processing AI, so that their effectiveness can be compared acrossmany different languages, helping to overcome a myopic focus on English. Other projects looks at fairness in less studied methods, likenetwork algorithms, and still more look to improve in specific applications, such as formedical softwareandalgorithmic hiring. These last two are especially noteworthy, since the prevailing public evidence suggests that algorithmic bias inhealth-core provisioningandhiringis widespread.
The trade-offs of corporate partnershipCritics may lament that Big Tech, which plays aprominent role in AI research, is present even in this federal program—Amazon is matching the support of the NSF, so each organization is paying around $10 million. Yet there is no reason to believe the NSF’s independence has been compromised. Amazon is not playing any role in the selection of the grant applications, and none of the grantees contacted had any concerns about the grant-selection process. NSF officials also noted that any working collaboration with Amazon (such as receiving engineering support) is entirely optional. Of course, it is worth considering what Amazon has to gain from this partnership. Reading theFAI announcement, it sticks out that the program seeks to contribute to “trustworthy AI systems that are readily accepted” and that “projects will enabled broadened acceptance of AI systems.” It is not a secret that the current generation of large technology companies would benefit enormously from increased public trust in AI. Still, corporate funding towards genuinely independent research is good and unobjectionable— especially relative to other options like companiesdirectly fundingacademic research.
Beyond the funding contribution, there may be other societal benefits from the partnership. For one, Amazon and other technology companies may pay more attention to the results of the research. For a company like Amazon, this might mean incorporating the results into its own algorithms, or into the AI systems that it sells through Amazon Web Services (AWS). Adoption into AWS cloud services may be especially impactful, since many thousands of data scientists and companies use those services for AI. As just an example, Professor Sandra Wachter of the Oxford Internet Institute waselatedto learn that ametric of fairnessshe and co-authors had advocated for had been incorporated into anAWS cloud service, making it far more accessible for data science practitioners. Generally speaking, having an expanded set of easy-to-use features for AI fairness makes it more likely that data scientists will explore and use these tools.
The value of FAIIn its totality, FAI is a small but mighty research endeavor. The myriad challenges posed by AI are all improved with more knowledge and more responsible methods driven by this independent research. While there is an enormous amount of corporate funding going into AI research, it is neither independent nor primarily aimed at fairness, and may entirely exclude some FAI topics (e.g., fairness in the government use of AI). While this is the final year of the FAI program, one of NSF FAI’s program directors, Dr. Todd Leen, stressed when contacted for this piece that the “NSF is not walking away from these important research issues,” and that FAI’s mission will be absorbed into the general computer science directorate. This absorption may come with minor downsides—for instance, a lack of clearly specified budget line and no consolidated reporting on the funded research projects. The NSF should consider tracking these investments and clearly communicating to the research community that AI fairness is an ongoing priority of the NSF.
The Biden administration could also specifically request additional NSF funding for fairness and AI. For once, this funding would not be a difficult sell to policymakers. Congress funded the totality of the NSF’s $868 million budget request for AI in 2021, and President Biden has signaled clear interest in expanding science funding; his proposed budget calls fora 20% increase in NSFfunding for fiscal year 2022, and the administration has launched aNational AI Research Taskforceco-chaired by none other than Dr. Erwin Gianchandani. With all this interest, bookmarking $5 to $10 million per year explicitly for the advancement of fairness in AI is clearly possible, and certainly worthwhile.
The National Science Foundation and Amazon are donors to The Brookings Institution. Any findings, interpretations, conclusions, or recommendations expressed in this piece are those of the author and are not influenced by any donation.
Related TopicsThe Brookings Institution
